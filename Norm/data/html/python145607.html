<h3>Question (ID-145607):</h3><h2>Text difference algorithm</h2><p>I need an algorithm that can compare two text files and highlight their difference and  ( even better!) can compute their difference in a meaningful way ( meaning, two similar files should have a similarity score higher than two dissimilar files, with the word "similar" defined in the normal terms). It sounds easy to implement, but it's not.</p>

<p>The implementation can be in c# or python, thanks.</p>
<br /><h3>Answers (Total-10):</h3><b>#0</b><br /><p>Look at <a href="http://docs.python.org/lib/module-difflib.html" rel="nofollow">difflib</a>. (Python)</p>

<p>That will calculate the diffs in various formats. You could then use the size of the context diff as a measure of how different two documents are?</p>
<br /><b>#1</b><br /><p>I can recommend to take a look at Neil Fraser's code and articles:</p>

<p><a href="http://code.google.com/p/google-diff-match-patch/" rel="nofollow">google-diff-match-patch</a></p>

<blockquote>
  <p>Currently available in Java,
  JavaScript, C++ and Python. Regardless
  of language, each library features the
  same API and the same functionality.
  All versions also have comprehensive
  test harnesses.</p>
</blockquote>

<p><a href="http://neil.fraser.name/writing/diff/" rel="nofollow">Neil Fraser: Diff Strategies</a> - for theory and implementation notes</p>
<br /><b>#2</b><br /><p>In Python, there is <a href="http://docs.python.org/lib/module-difflib.html" rel="nofollow">difflib</a>, as also others have suggested.</p>

<p><code>difflib</code> offers the <a href="http://docs.python.org/lib/sequence-matcher.html" rel="nofollow">SequenceMatcher</a> class, which can be used to give you a similarity ratio. Example function:</p>

<pre><code>def text_compare(text1, text2, isjunk=None):
    return difflib.SequenceMatcher(isjunk, text1, text2).ratio()
</code></pre>
<br /><b>#3</b><br /><p><a href="http://bazaar-vcs.org/" rel="nofollow">Bazaar</a> contains an alternative difference algorithm, called <a href="http://bramcohen.livejournal.com/37690.html" rel="nofollow">patience diff</a> (there's more info in the comments on that page) which is claimed to be better than the traditional diff algorithm. The file 'patiencediff.py' in the bazaar distribution is a simple command line front end.</p>
<br /><b>#4</b><br /><p>If you need a finer granularity than lines, you can use Levenshtein distance. Levenshtein distance is a straight-forward measure on how to similar two texts are.<br />
You can also use it to extract the edit logs and can a very fine-grained diff, similar to that on the edit history pages of SO.
Be warned though that Levenshtein distance can be quite CPU- and memory-intensive to calculate, so using difflib,as Douglas Leder suggested, is most likely going to be faster.</p>

<p>Cf. also <a href="http://stackoverflow.com/questions/132478/how-to-perform-string-diffs-in-java#132547">this answer</a>.</p>
<br /><b>#5</b><br /><p>My current understanding is that the best solution to the Shortest Edit Script (SES) problem is Myers "middle-snake" method with the Hirschberg linear space refinement.</p>

<p>The Myers algorithm is described in:</p>

<blockquote>
  <p>E. Myers, ``An O(ND) Difference
  Algorithm and Its Variations,''<br />
  Algorithmica 1, 2 (1986), 251-266.</p>
</blockquote>

<p>The GNU diff utility uses the Myers algorighm.</p>

<p>The "similarity score" you speak of is called the "edit distance" in the literature which is the number of inserts or deletes necessary to transform one sequence into the other.</p>

<p>Note that a number of people have cited the Levenshtein distance algorithm but that is, albeit easy to implement, not the optimal solution as it is inefficient (requires the use of a possibly huge n*m matrix) and does not provide the "edit script" which is the sequence of edits that could be used to transform one sequence into the other and visa versa.</p>

<p>For a good Myers / Hirschberg implementation look at:</p>

<p><a href="http://www.ioplex.com/~miallen/libmba/dl/src/diff.c" rel="nofollow">http://www.ioplex.com/~miallen/libmba/dl/src/diff.c</a></p>

<p>The particular library that it is contained within is not longer maintained but to my knowledge the diff.c module itself is still correct.</p>

<p>Mike</p>
<br /><b>#6</b><br /><p>As stated, use difflib. Once you have the diffed output, you may find the <a href="http://en.wikipedia.org/wiki/Levenshtein_distance" rel="nofollow">Levenshtein distance</a> of the different strings as to give a "value" of how different they are.</p>
<br /><b>#7</b><br /><p>There are a number of distance metrics, as paradoja mentioned there is the Levenshtein distance, but there is also <a href="http://en.wikipedia.org/wiki/New_York_State_Identification_and_Intelligence_System" rel="nofollow">NYSIIS</a> and <a href="http://en.wikipedia.org/wiki/Soundex" rel="nofollow">Soundex</a>.  In terms of Python implementations, I have used <a href="http://www.mindrot.org/projects/py-editdist/" rel="nofollow">py-editdist</a> and <a href="http://advas.sourceforge.net/" rel="nofollow">ADVAS</a> before.  Both are nice in the sense that you get a single number back as a score.  Check out ADVAS first, it implements a bunch of algorithms.</p>
<br /><b>#8</b><br /><p>You could use the <a href="http://en.wikipedia.org/wiki/Longest_common_subsequence_problem#Code_for_the_dynamic_programming_solution" rel="nofollow">solution to the Longest Common Subsequence (LCS) problem</a>. See also the discussion about possible ways to optimize this solution.</p>
<br /><b>#9</b><br /><p>One method I've employed for a different functionality, to calculate how much data was new in a modified file, could perhaps work for you as well.</p>

<p>I have a diff/patch implementation C# that allows me to take two files, presumably old and new version of the same file, and calculate the "difference", but not in the usual sense of the word. Basically I calculate a set of operations that I can perform on the old version to update it to have the same contents as the new version.</p>

<p>To use this for the functionality initially described, to see how much data was new, I simple ran through the operations, and for every operation that copied from the old file verbatim, that had a 0-factor, and every operation that inserted new text (distributed as part of the patch, since it didn't occur in the old file) had a 1-factor. All characters was given this factory, which gave me basically a long list of 0's and 1's.</p>

<p>All I then had to do was to tally up the 0's and 1's. In your case, with my implementation, a low number of 1's compared to 0's would mean the files are very similar.</p>

<p>This implementation would also handle cases where the modified file had inserted copies from the old file out of order, or even duplicates (ie. you copy a part from the start of the file and paste it near the bottom), since they would both be copies of the same original part from the old file.</p>

<p>I experimented with weighing copies, so that the first copy counted as 0, and subsequent copies of the same characters had progressively higher factors, in order to give a copy/paste operation some "new-factor", but I never finished it as the project was scrapped.</p>

<p>If you're interested, my diff/patch code is available from my Subversion repository.</p>
<br />