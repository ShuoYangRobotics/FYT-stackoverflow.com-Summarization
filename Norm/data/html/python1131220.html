<h3>Question (ID-1131220):</h3><h2>Get MD5 hash of a files without open it in Python</h2><p>I have used hashlib (which replaces md5 in Python 2.6/3.0) and it worked fine if I opened a file and put its content in hashlib.md5 function.</p>

<p>The problem is with very big files that their sizes could exceed RAM size.</p>

<p>How to get a MD5 hash of a file without open it?</p>
<br /><h3>Answers (Total-4):</h3><b>#0</b><br /><p>Break the file into 128-byte chunks and feed them to MD5 consecutively using <code>update()</code>.</p>

<p>This takes advantage of the fact that MD5 has 128-byte digest blocks. Basically, when MD5 <code>digest()</code>s the file, this is exactly what it is doing.</p>

<p>If you make sure you free the memory on each iteration (i.e. not read the entire file to memory), this shall take no more than 128 bytes of memory.</p>

<p>One example is to read the chunks like so:</p>

<pre><code>f = open(fileName)
while not endOfFile:
    f.read(128)
</code></pre>
<br /><b>#1</b><br /><p>You need to read the file in chunks of suitable size:</p>

<pre><code>def md5_for_file(f, block_size=2**20):
    md5 = hashlib.md5()
    while True:
        data = f.read(block_size)
        if not data:
            break
        md5.update(data)
    return md5.digest()
</code></pre>
<br /><b>#2</b><br /><p>if you care about more pythonic (no 'while True') way of reading the file check this code:</p>

<pre><code>import hashlib
md5 = hashlib.md5()
with open('myfile.txt','rb') as f: 
    for chunk in iter(lambda: f.read(8192), ''): 
         md5.update(chunk)
return md5.digest()
</code></pre>
<br /><b>#3</b><br /><p>u can't get it's md5 without read full content. but u can use <a href="http://docs.python.org/library/hashlib.html#hashlib.hash.update" rel="nofollow">update</a> function to read the files content block by block.<br />
m.update(a); m.update(b) is equivalent to m.update(a+b)</p>
<br />