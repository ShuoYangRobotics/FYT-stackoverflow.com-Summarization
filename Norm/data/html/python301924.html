<h3>Question (ID-301924):</h3><h2>Python: urllib/urllib2/httplib confusion</h2><p>I'm trying to test the functionality of a web app by scripting a login sequence in Python, but I'm having some troubles.</p>

<p>Here's what I need to do:</p>

<ol>
<li>Do a POST with a few parameters and headers.</li>
<li>Follow a redirect</li>
<li>Retrieve the HTML body.</li>
</ol>

<p>Now, I'm relatively new to python, but the two things I've tested so far haven't worked. First I used httplib, with putrequest() (passing the parameters within the URL), and putheader(). This didn't seem to follow the redirects.</p>

<p>Then I tried urllib and urllib2, passing both headers and parameters as dicts. This seems to return the login page, instead of the page I'm trying to login to, I guess it's because of lack of cookies or something.</p>

<p>Am I missing something simple?</p>

<p>Thanks.</p>
<br /><h3>Answers (Total-8):</h3><b>#0</b><br /><p>Focus on <code>urllib2</code> for this, it works quite well.  Don't mess with <code>httplib</code>, it's not the top-level API.</p>

<p>What you're noting is that <code>urllib2</code> doesn't follow the redirect.</p>

<p>You need to fold in an instance of <code>HTTPRedirectHandler</code> that will catch and follow the redirects.</p>

<p>Further, you may want to subclass the default <code>HTTPRedirectHandler</code> to capture information that you'll then check as part of your unit testing.</p>

<pre><code>cookie_handler= urllib2.HTTPCookieProcessor( self.cookies )
redirect_handler= HTTPRedirectHandler()
opener = urllib2.build_opener(redirect_handler,cookie_handler)
</code></pre>

<p>You can then use this <code>opener</code> object to POST and GET, handling redirects and cookies properly.</p>

<p>You may want to add your own subclass of <code>HTTPHandler</code> to capture and log various error codes, also.</p>
<br /><b>#1</b><br /><p>I had to do this exact thing myself recently.  I only needed classes from the standard library.  Here's an excerpt from my code:</p>

<pre><code>from urllib import urlencode
from urllib2 import urlopen, Request

# encode my POST parameters for the login page
login_qs = urlencode( [("username",USERNAME), ("password",PASSWORD)] )

# extract my session id by loading a page from the site
set_cookie = urlopen(URL_BASE).headers.getheader("Set-Cookie")
sess_id = set_cookie[set_cookie.index("=")+1:set_cookie.index(";")]

# construct headers dictionary using the session id
headers = {"Cookie": "session_id="+sess_id}

# perform login and make sure it worked
if "Announcements:" not in urlopen(Request(URL_BASE+"login",headers=headers), login_qs).read():
    print "Didn't log in properly"
    exit(1)

# here's the function I used after this for loading pages
def download(page=""):
    return urlopen(Request(URL_BASE+page, headers=headers)).read()

# for example:
print download(URL_BASE + "config")
</code></pre>
<br /><b>#2</b><br /><p>@S.Lott, thank you. Your suggestion worked for me, with some modification. Here's how I did it.</p>

<pre><code>data = urllib.urlencode(params)
url = host+page
request = urllib2.Request(url, data, headers)
response = urllib2.urlopen(request)

cookies = CookieJar()
cookies.extract_cookies(response,request)

cookie_handler= urllib2.HTTPCookieProcessor( cookies )
redirect_handler= HTTPRedirectHandler()
opener = urllib2.build_opener(redirect_handler,cookie_handler)

response = opener.open(request)
</code></pre>
<br /><b>#3</b><br /><p>I'd give Mechanize (<a href="http://wwwsearch.sourceforge.net/mechanize/" rel="nofollow">http://wwwsearch.sourceforge.net/mechanize/</a>) a shot. It may well handle your cookie/headers transparently.</p>
<br /><b>#4</b><br /><p>Try <a href="http://twill.idyll.org/" rel="nofollow">twill</a> - a simple language that allows users to browse the Web from a command-line interface. With twill, you can navigate through Web sites that use forms, cookies, and most standard Web features. More to the point, <em>twill</em> is written in <code>Python</code> and has a <a href="http://twill.idyll.org/python-api.html" rel="nofollow">python API</a>, e.g:</p>

<pre><code>from twill import get_browser
b = get_browser()

b.go("http://www.python.org/")
b.showforms()
</code></pre>
<br /><b>#5</b><br /><p>Here's my take on this issue.</p>

<pre><code>#!/usr/bin/env python

import urllib
import urllib2


class HttpBot:
    """an HttpBot represents one browser session, with cookies."""
    def __init__(self):
        cookie_handler= urllib2.HTTPCookieProcessor()
        redirect_handler= urllib2.HTTPRedirectHandler()
        self._opener = urllib2.build_opener(redirect_handler, cookie_handler)

    def GET(self, url):
        return self._opener.open(url).read()

    def POST(self, url, parameters):
        return self._opener.open(url, urllib.urlencode(parameters)).read()


if __name__ == "__main__":
    bot = HttpBot()
    ignored_html = bot.POST('https://example.com/authenticator', {'passwd':'foo'})
    print bot.GET('https://example.com/interesting/content')
    ignored_html = bot.POST('https://example.com/deauthenticator',{})
</code></pre>
<br /><b>#6</b><br /><p>Besides the fact that you may be missing a cookie, there might be some field(s) in the form that you are not POSTing to the webserver. The best way would be to capture the actual POST from a web browser. You can use <a href="https://addons.mozilla.org/en-US/firefox/addon/3829" rel="nofollow">LiveHTTPHeaders</a>  or <a href="http://www.wireshark.org/" rel="nofollow">WireShark</a> to snoop the traffic and mimic the same behaviour in your script.</p>
<br /><b>#7</b><br /><p><a href="http://funkload.nuxeo.org/" rel="nofollow">Funkload</a> is a great web app testing tool also.  It wraps webunit to handle the browser emulation, then gives you both functional and load testing features on top.</p>
<br />