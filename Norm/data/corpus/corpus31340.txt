Question (ID-31340): How do threads work in Python, and what are common Python-threading specific pitfalls? I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up. 

 From what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so? 

 Where is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python. 
 Answers (Total-5): #0 Python's a fairly easy language to thread in, but there are caveats. The biggest thing you need to know about is the Global Interpreter Lock. This allows only one thread to access the interpreter. This means two things: 1) you rarely ever find yourself using a lock statement in python and 2) if you want to take advantage of multi-processor systems, you have to use separate processes. EDIT: I should also point out that you can put some of the code in C/C++ if you want to get around the GIL as well. 

 Thus, you need to re-consider why you want to use threads. If you want to parallelize your app to take advantage of dual-core architecture, you need to consider breaking your app up into multiple processes. 

 If you want to improve responsiveness, you should CONSIDER using threads. There are other alternatives though, namely microthreading . There are also some frameworks that you should look into: 

 stackless python 

 Kamaelia 

 greenlets 
 #1 Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this: 

 
 http://blog.snaplogic.org/?p=94 
 http://www.artima.com/weblogs/viewpost.jsp?thread=214235 
 http://effbot.org/pyfaq/can-t-we-get-rid-of-the-global-interpreter-lock.htm 
 http://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/ 
 

 From the last link an interesting quote: 

 
 Let me explain what all that means. 
 Threads run inside the same virtual
 machine, and hence run on the same
 physical machine. Processes can run
 on the same physical machine or in
 another physical machine. If you
 architect your application around
 threads, you’ve done nothing to access
 multiple machines. So, you can scale
 to as many cores are on the single
 machine (which will be quite a few
 over time), but to really reach web
 scales, you’ll need to solve the
 multiple machine problem anyway. 
 

 If you want to use multi core, pyprocessing defines an process based API to do real parallelization. The PEP also includes some interesting benchmarks. 
 #2 Below is a basic threading sample. It will spawn 20 threads; each thread will output its thread number. Run it and observe the order in which they print. 

 import threading
class Foo (threading.Thread):
 def __init__(self,x):
  self.__x = x
  threading.Thread.__init__(self)
 def run (self):
   print str(self.__x)

for x in xrange(20):
 Foo(x).start()
 

 As you have hinted at Python threads are implemented through time-slicing. This is how they get the "parallel" effect. 

 In my example my Foo class extends thread, I then implement the run method, which is where the code that you would like to run in a thread goes. To start the thread you call start() on the thread object, which will automatically invoke the run method... 

 Of course, this is just the very basics. You will eventually want to learn about semaphores, mutexes, and locks for thread synchronization and message passing. 
 #3 Use threads in python if the individual workers are doing I/O bound operations. If you are trying to scale across multiple cores on a machine either find a good IPC framework for python or pick a different language. 
 #4 Try to remember that the GIL is set to poll around every so often in order to do show the appearance of multiple tasks. This setting can be fine tuned, but I offer the suggestion that there should be work that the threads are doing or lots of context switches are going to cause problems. 

 I would go so far as to suggest multiple parents on processors and try to keep like jobs on the same core(s).