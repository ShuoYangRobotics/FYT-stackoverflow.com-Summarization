[[{"text": ["node_after_b == node_a will try to call node_after_b.__eq__(node_a):"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "node_after_b == node_a", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "node_after_b.__eq__(node_a)", "childNum": 0, "tag": "code", "childList": []}]}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; class B(object):\n...     def __eq__(self, other):\n...         print \"B.__eq__()\"\n...         return False\n... \n&gt;&gt;&gt; class A(object):\n...     def __eq__(self, other):\n...         print \"A.__eq__()\"\n...         return False\n... \n&gt;&gt;&gt; a = A()\n&gt;&gt;&gt; b = B()\n&gt;&gt;&gt; a == b\nA.__eq__()\nFalse\n&gt;&gt;&gt; b == a\nB.__eq__()\nFalse\n&gt;&gt;&gt;\n</code>\n</pre>\n", "senID": 1}, {"text": ["Try to override Node.__eq__() with an optimized version before resorting to C."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "Node.__eq__()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["UPDATE"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["I made this little experiment (python 2.6.6):"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n #!/usr/bin/env python\n# test.py\nclass A(object):\n    def __init__(self, id):\n        self.id = id\n\nclass B(A):\n    def __eq__(self, other):\n        return self.id == other.id\n\n@profile\ndef main():\n    list_a = []\n    list_b = []\n    for x in range(100000):\n        list_a.append(A(x))\n        list_b.append(B(x))\n\n    ob_a = A(1)\n    ob_b = B(1)\n    for ob in list_a:\n        if ob == ob_a:\n            x = True\n        if ob is ob_a:\n            x = True\n        if ob.id == ob_a.id:\n            x = True\n        if ob.id == 1:\n            x = True\n    for ob in list_b:\n        if ob == ob_b:\n            x = True\n        if ob is ob_b:\n            x = True\n        if ob.id == ob_b.id:\n            x = True\n        if ob.id == 1:\n            x = True\n\nif __name__ == '__main__':\n    main()\n</code>\n</pre>\n", "senID": 5}, {"text": ["Results:"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n Timer unit: 1e-06 s\n\nFile: test.py Function: main at line 10 Total time: 5.52964 s\n\nLine #      Hits         Time  Per Hit % Time  Line Contents\n==============================================================\n    10                                           @profile\n    11                                           def main():\n    12         1            5      5.0      0.0      list_a = []\n    13         1            3      3.0      0.0      list_b = []\n    14    100001       360677      3.6      6.5      for x in range(100000):\n    15    100000       763593      7.6     13.8          list_a.append(A(x))\n    16    100000       924822      9.2     16.7          list_b.append(B(x))\n    17\n    18         1           14     14.0      0.0      ob_a = A(1)\n    19         1            5      5.0      0.0      ob_b = B(1)\n    20    100001       500454      5.0      9.1      for ob in list_a:\n    21    100000       267252      2.7      4.8          if ob == ob_a:\n    22                                                       x = True\n    23    100000       259075      2.6      4.7          if ob is ob_a:\n    24                                                       x = True\n    25    100000       539683      5.4      9.8          if ob.id == ob_a.id:\n    26         1            3      3.0      0.0              x = True\n    27    100000       271519      2.7      4.9          if ob.id == 1:\n    28         1            3      3.0      0.0              x = True\n    29    100001       296736      3.0      5.4      for ob in list_b:\n    30    100000       472204      4.7      8.5          if ob == ob_b:\n    31         1            4      4.0      0.0              x = True\n    32    100000       283165      2.8      5.1          if ob is ob_b:\n    33                                                       x = True\n    34    100000       298839      3.0      5.4          if ob.id == ob_b.id:\n    35         1            3      3.0      0.0              x = True\n    36    100000       291576      2.9      5.3          if ob.id == 1:\n    37         1            3      3.0      0.0              x = True\n</code>\n</pre>\n", "senID": 7}, {"text": ["I was very surprised:"], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": "\"dot\" access (ob.property) seems to be very expensive (line 25 versus line 27).", "tag": "none", "senID": 9}, {"text": "there was not much difference between is and '==', at least for simple objects", "tag": "none", "senID": 10}]}, {"text": ["Then I tried with more complex objects and results are consistent with the first experiment. "], "childNum": 0, "tag": "p", "senID": 11, "childList": []}, {"text": ["Are you swapping a lot?", "If your dataset is so large that it does not fit available RAM, I guess you may experience some kind of I/O contention related to virtual memory fetches. "], "childNum": 0, "tag": "p", "senID": 12, "childList": []}, {"text": ["Are you running Linux?", "If so, could you post a vmstat of your machine while running your program?", "Send us the output of something like:"], "childNum": 0, "tag": "p", "senID": 13, "childList": []}, {"code": "<pre>\n<code>\n vmstat 10 100\n</code>\n</pre>\n", "senID": 14}, {"text": ["Good luck!"], "childNum": 0, "tag": "p", "senID": 15, "childList": []}, {"text": ["UPDATE (from comments by OP)"], "childNum": 0, "tag": "p", "senID": 16, "childList": []}, {"text": ["I sugested playing with sys.setcheckinterval and enable/disable the GC.", "The rationale is that for this particular case (huge number of instances) the default GC reference count check is somewhat expensive and its default interval is away too often."], "childNum": 0, "tag": "p", "senID": 17, "childList": []}, {"text": ["My guess:"], "childNum": 0, "tag": "p", "senID": 18, "childList": []}], [{"text": ["Have you considered Pyrex / Cython? "], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Pyrex", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.cosc.canterbury.ac.nz/greg.ewing/python/Pyrex/"}, {"href": "http://cython.org/", "text": "Cython", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["It compiles python to C and then to .pyd automatically, so it might speed things up a fair bit without much work. "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["This would require a fair amount of work, but...you might consider using Floyd-Warshall running on a GPU.", "There has been a lot of work done on making Floyd-Warshall run very efficiently on a GPU.", "A quick google search yields:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["http://cvit.iiit.ac.in/papers/Pawan07accelerating.pdf"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://cvit.iiit.ac.in/papers/Pawan07accelerating.pdf", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://cvit.iiit.ac.in/papers/Pawan07accelerating.pdf"}]}, {"text": ["http://my.safaribooksonline.com/book/programming/graphics/9780321545411/gpu-computing-for-protein-structure-prediction/ch43lev1sec2#X2ludGVybmFsX0ZsYXNoUmVhZGVyP3htbGlkPTk3ODAzMjE1NDU0MTEvNDg3"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://my.safaribooksonline.com/book/programming/graphics/9780321545411/gpu-computing-for-protein-structure-prediction/ch43lev1sec2#X2ludGVybmFsX0ZsYXNoUmVhZGVyP3htbGlkPTk3ODAzMjE1NDU0MTEvNDg3", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://my.safaribooksonline.com/book/programming/graphics/9780321545411/gpu-computing-for-protein-structure-prediction/ch43lev1sec2#X2ludGVybmFsX0ZsYXNoUmVhZGVyP3htbGlkPTk3ODAzMjE1NDU0MTEvNDg3"}]}, {"text": ["http://www.gpucomputing.net/?q=node/1203"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://www.gpucomputing.net/?q=node/1203", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.gpucomputing.net/?q=node/1203"}]}, {"text": ["http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter43.html"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter43.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter43.html"}]}, {"text": ["Even though, as implemented in Python, Floyd-Warshall was slower by an order of magnitude, a good GPU version on a powerful GPU might still significantly outperform your new Python code."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["Here's an anecdote.", "I had a short, simple, compute-intensive piece of code that did something similar to a hough accumulation.", "In Python, optimized as I could get it, it took ~7s on a speedy i7.", "I then wrote a completely non-optimized GPU version; it took ~0.002s on an Nvidia GTX 480.", "YMMV, but for anything significantly parallel, the GPU is likely to be a long term winner, and since it's a well-studied algorithm, you should be able to utilize existing highly-tuned code."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["For the Python / GPU bridge, I'd recommend PyCUDA or PyOpenCL."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}], [{"text": ["I don't see anything wrong with your code regarding performance (without trying to grok the algorithm), you are just getting hit by the big number of iterations.", "Parts of your code get executed 40 million times! "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "million", "childNum": 0, "tag": "strong", "pos": 1, "childList": []}]}, {"text": ["Notice how 80% of the time is spent in 20% of your code - and those are the 13 lines that get executed 24+ million times.", "By the way with this code you provide great illustration to the Pareto principle (or \"20% of beer drinkers drink 80% of the beer\")."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "Pareto principle", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Pareto_principle"}]}, {"text": ["First things first: have you tried Psycho?", "It's a JIT compiler that can greatly speed up your code - considering the big number of iterations - say by a factor of 4x-5x - and all you have to do (after downloading and installing, of course) is to insert this snippet in the beginning:"], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "First things first", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "Psycho", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://psyco.sourceforge.net/introduction.html"}]}, {"code": "<pre>\n<code>\n import psyco\npsyco.full()\n</code>\n</pre>\n", "senID": 3}, {"text": ["This is why i liked Psycho and used it in GCJ too, where time is of essence - nothing to code, nothing to get wrong and sudden boost from 2 lines added."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["Back to nit-picking (which changes like replacing == with is etc is, because of the small % time improvement).", "Here they are the 13 lines \"at fault\":"], "childNum": 2, "tag": "p", "senID": 5, "childList": [{"text": "==", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "is", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n Line    #   Hits    Time    Per Hit % Time  Line Contents\n412 42350234    197075504439    4653.5  8.1 for node_c, (distance_b_c, node_after_b) in node_b_distances.items(): # Can't use iteritems() here, as deleting from the dictionary\n386 42076729    184216680432    4378.1  7.6 for node_c, (distance_a_c, node_after_a) in self.node_distances[node_a].iteritems():\n362 41756882    183992040153    4406.3  7.6 for node_c, (distance_b_c, node_after_b) in node_b_distances.iteritems(): # Think it's ok to modify items while iterating over them (just not insert/delete) (seems to work ok)\n413 41838114    180297579789    4309.4  7.4 if(distance_b_c &gt; cutoff_distance):\n363 41244762    172425596985    4180.5  7.1 if(node_after_b == node_a):\n389 41564609    172040284089    4139.1  7.1 if(node_c == node_b): # a-b path\n388 41564609    171150289218    4117.7  7.1 node_b_update = False\n391 41052489    169406668962    4126.6  7   elif(node_after_a == node_b): # a-b-a-b path\n405 41564609    164585250189    3959.7  6.8 if node_b_update:\n394 24004846    103404357180    4307.6  4.3 (distance_b_c, node_after_b) = node_b_distances[node_c]\n395 24004846    102717271836    4279    4.2 if(node_after_b != node_a): # b doesn't already go to a first\n393 24801082    101577038778    4095.7  4.2 elif(node_c in node_b_distances): # b can already get to c\n</code>\n</pre>\n", "senID": 6}, {"text": ["A) Besides the lines you mention, i notice that #388 has relatively high time when it is trivial, all it does it node_b_update = False.", "Oh but wait - each time it gets executed, False gets looked up in the global scope!", "To avoid that, assign F, T = False, True in th e beginning of the method and replace later uses of False and True with locals F and T. This should decrease overall time, although by little (3%?", ")."], "childNum": 7, "tag": "p", "senID": 7, "childList": [{"text": "node_b_update = False", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "False", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "F, T = False, True", "childNum": 0, "tag": "code", "pos": 2, "childList": []}, {"text": "False", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "True", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "F", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "T", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"text": ["B) I notice that the condition in #389 occurred \"only\" 512,120 times (based on number of executions of #390) vs the condition in #391 with 16,251,407.", "Since there is no dependency, it makes sense to reverse the order of those checks - because of the early \"cut\" that should give little boost (2%?).", "I am not sure if avoiding pass statements altogether will help but if it does not hurt readability:"], "childNum": 1, "tag": "p", "senID": 8, "childList": [{"text": "pass", "childNum": 0, "tag": "code", "pos": 2, "childList": []}]}, {"code": "<pre>\n<code>\n if (node_after_a is not node_b) and (node_c is not node_b):\n   # neither a-b-a-b nor a-b path\n   if (node_c in node_b_distances): # b can already get to c\n       (distance_b_c, node_after_b) = node_b_distances[node_c]\n       if (node_after_b is not node_a): # b doesn't already go to a first\n           distance_b_a_c = neighbour_distance_b_a + distance_a_c\n           if (distance_b_a_c &lt; distance_b_c): # quicker to go via a\n               node_b_update = T\n   else: # b can't already get to c\n       distance_b_a_c = neighbour_distance_b_a + distance_a_c\n       if (distance_b_a_c &lt; cutoff_distance): # not too for to go\n           node_b_update = T\n</code>\n</pre>\n", "senID": 9}, {"text": ["C) I just noticed you are using try-except in a case (#365-367) you just need default value from a dictionary - try using instead .get(key, defaultVal) or create your dictionaries with collections.defaultdict(itertools.repeat(float('+inf'))).", "Using try-except has it's price - see #365 reports 3.5% of the time, that's setting up stack frames and whatnot."], "childNum": 3, "tag": "p", "senID": 10, "childList": [{"text": "try-except", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": ".get(key, defaultVal)", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "collections.defaultdict(itertools.repeat(float('+inf')))", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"text": ["D) Avoid indexed access (be it with obj.field or obj[idx]) when possible.", "For example i see you use self.node_distances[node_a] in multiple places (#336, 339, 346, 366, 386), which means for every use indexing is used twice (once for .", "and once for []) - and that gets expensive when executed tens of millions of times.", "Seems to me you can just do at the method beginning node_a_distances = self.node_distances[node_a] and then use that further."], "childNum": 7, "tag": "p", "senID": 11, "childList": [{"text": ".", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "[", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "]", "childNum": 0, "tag": "code", "pos": 2, "childList": []}, {"text": "self.node_distances[node_a]", "childNum": 0, "tag": "code", "pos": 3, "childList": []}, {"text": ".", "childNum": 0, "tag": "code", "childList": []}, {"text": "[]", "childNum": 0, "tag": "code", "childList": []}, {"text": "node_a_distances = self.node_distances[node_a]", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["I would have posted this as an update to my question, but Stack Overflow only allows 30000 characters in questions, so I'm posting this as an answer."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Update: My best optimisations so far"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "Update:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["I've taken on board people's suggestions, and now my code runs about 21% faster than before, which is good - thanks everyone!"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["This is the best I've managed to do so far.", "I've replaced all the == tests with is for nodes, disabled garbage collection and re-written the big if statement part at Line 388, in line with @Nas Banov's suggestions.", "I added in the well-known try/except trick for avoiding tests (line 390 - to remove the test node_c in node_b_distances), which helped loads, since it hardly ever throws the exception.", "I tried switching lines 391 and 392 around, and assigning node_b_distances[node_c] to a variable, but this way was the quickest."], "childNum": 6, "tag": "p", "senID": 3, "childList": [{"text": "==", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "is", "childNum": 0, "tag": "code", "pos": 2, "childList": []}, {"text": "if", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "try/except", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "node_c in node_b_distances", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "node_b_distances[node_c]", "childNum": 0, "tag": "code", "pos": 3, "childList": []}]}, {"text": ["However, I still haven't tracked down the memory leak yet (see graph in my question).", "But I think this might be in a different part of my code (that I haven't posted here).", "If I can fix the memory leak, then this program will run quickly enough for me to use :)"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n Timer unit: 3.33366e-10 s\nFile: routing_distances.py\nFunction: propagate_distances_node at line 328\nTotal time: 760.74 s\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n328                                               @profile\n329                                               def propagate_distances_node(self, node_a, cutoff_distance=200):\n330                                                       \n331                                                   # a makes sure its immediate neighbours are correctly in its distance table\n332                                                   # because its immediate neighbours may change as binds/folding change\n333    791349   4158169713   5254.5      0.2          for (node_b, neighbour_distance_b_a) in self.neighbours[node_a].iteritems():\n334    550522   2331886050   4235.8      0.1              use_neighbour_link = False\n335                                                       \n336    550522   2935995237   5333.1      0.1              if(node_b not in self.node_distances[node_a]): # a doesn't know distance to b\n337     15931     68829156   4320.5      0.0                  use_neighbour_link = True\n338                                                       else: # a does know distance to b\n339    534591   2728134153   5103.2      0.1                  (node_distance_b_a, next_node) = self.node_distances[node_a][node_b]\n340    534591   2376374859   4445.2      0.1                  if(node_distance_b_a &gt; neighbour_distance_b_a): # neighbour distance is shorter\n341        78       347355   4453.3      0.0                      use_neighbour_link = True\n342    534513   3145889079   5885.5      0.1                  elif((None is next_node) and (float('+inf') == neighbour_distance_b_a)): # direct route that has just broken\n343        74       327600   4427.0      0.0                      use_neighbour_link = True\n344                                                               \n345    550522   2414669022   4386.1      0.1              if(use_neighbour_link):\n346     16083     81850626   5089.3      0.0                  self.node_distances[node_a][node_b] = (neighbour_distance_b_a, None)\n347     16083     87064200   5413.4      0.0                  self.nodes_changed.add(node_a)\n348                                                           \n349                                                           ## Affinity distances update\n350     16083     86580603   5383.4      0.0                  if((node_a.type == Atom.BINDING_SITE) and (node_b.type == Atom.BINDING_SITE)):\n351       234      6656868  28448.2      0.0                      self.add_affinityDistance(node_a, node_b, self.chemistry.affinity(node_a.data, node_b.data))     \n352                                                   \n353                                                   # a sends its table to all its immediate neighbours\n354    791349   4034651958   5098.4      0.2          for (node_b, neighbour_distance_b_a) in self.neighbours[node_a].iteritems():\n355    550522   2392248546   4345.4      0.1              node_b_changed = False\n356                                               \n357                                                       # b integrates a's distance table with its own\n358    550522   2520330696   4578.1      0.1              node_b_chemical = node_b.chemical\n359    550522   2734341975   4966.8      0.1              node_b_distances = node_b_chemical.node_distances[node_b]\n360                                                       \n361                                                       # For all b's routes (to c) that go to a first, update their distances\n362  46679347 222161837193   4759.3      9.7              for node_c, (distance_b_c, node_after_b) in node_b_distances.iteritems(): # Think it's ok to modify items while iterating over them (just not insert/delete) (seems to work ok)\n363  46128825 211963639122   4595.0      9.3                  if(node_after_b is node_a):\n364                                                               \n365  18677439  79225517916   4241.8      3.5                      try:\n366  18677439 101527287264   5435.8      4.4                          distance_b_a_c = neighbour_distance_b_a + self.node_distances[node_a][node_c][0]\n367    181510    985441680   5429.1      0.0                      except KeyError:\n368    181510   1166118921   6424.5      0.1                          distance_b_a_c = float('+inf')\n369                                                                   \n370  18677439  89626381965   4798.6      3.9                      if(distance_b_c != distance_b_a_c): # a's distance to c has changed\n371    692131   3352970709   4844.4      0.1                          node_b_distances[node_c] = (distance_b_a_c, node_a)\n372    692131   3066946866   4431.2      0.1                          node_b_changed = True\n373                                                                   \n374                                                                   ## Affinity distances update\n375    692131   3808548270   5502.6      0.2                          if((node_b.type == Atom.BINDING_SITE) and (node_c.type == Atom.BINDING_SITE)):\n376     96794   1655818011  17106.6      0.1                              node_b_chemical.add_affinityDistance(node_b, node_c, self.chemistry.affinity(node_b.data, node_c.data))\n377                                                                   \n378                                                               # If distance got longer, then ask b's neighbours to update\n379                                                               ## TODO: document this!\n380  18677439  88838493705   4756.5      3.9                      if(distance_b_a_c &gt; distance_b_c):\n381                                                                   #for (node, neighbour_distance) in node_b_chemical.neighbours[node_b].iteritems():\n382   1656796   7949850642   4798.3      0.3                          for node in node_b_chemical.neighbours[node_b]:\n383   1172486   6307264854   5379.4      0.3                              node.chemical.nodes_changed.add(node)\n384                                                       \n385                                                       # Look for routes from a to c that are quicker than ones b knows already\n386  46999631 227198060532   4834.0     10.0              for node_c, (distance_a_c, node_after_a) in self.node_distances[node_a].iteritems():\n387                                                           \n388  46449109 218024862372   4693.8      9.6                  if((node_after_a is not node_b) and # not a-b-a-b path\n389  28049321 126269403795   4501.7      5.5                     (node_c is not node_b)):         # not a-b path\n390  27768341 121588366824   4378.7      5.3                      try: # Assume node_c in node_b_distances ('try' block will raise KeyError if not)\n391  27768341 159413637753   5740.8      7.0                          if((node_b_distances[node_c][1] is not node_a) and # b doesn't already go to a first\n392   8462467  51890478453   6131.8      2.3                             ((neighbour_distance_b_a + distance_a_c) &lt; node_b_distances[node_c][0])):\n393                                                               \n394                                                                       # Found a route\n395    224593   1168129548   5201.1      0.1                              node_b_distances[node_c] = (neighbour_distance_b_a + distance_a_c, node_a)\n396                                                                       ## Affinity distances update\n397    224593   1274631354   5675.3      0.1                              if((node_b.type == Atom.BINDING_SITE) and (node_c.type == Atom.BINDING_SITE)):\n398     32108    551523249  17177.1      0.0                                  node_b_chemical.add_affinityDistance(node_b, node_c, self.chemistry.affinity(node_b.data, node_c.data))\n399    224593   1165878108   5191.1      0.1                              node_b_changed = True\n400                                                                       \n401    809945   4449080808   5493.1      0.2                      except KeyError:\n402                                                                   # b can't already get to c (node_c not in node_b_distances)\n403    809945   4208032422   5195.5      0.2                          if((neighbour_distance_b_a + distance_a_c) &lt; cutoff_distance): # not too for to go\n404                                                                       \n405                                                                       # These lines of code copied, for efficiency \n406                                                                       #  (most of the time, the 'try' block succeeds, so don't bother testing for (node_c in node_b_distances))\n407                                                                       # Found a route\n408    587726   3162939543   5381.7      0.1                              node_b_distances[node_c] = (neighbour_distance_b_a + distance_a_c, node_a)\n409                                                                       ## Affinity distances update\n410    587726   3363869061   5723.5      0.1                              if((node_b.type == Atom.BINDING_SITE) and (node_c.type == Atom.BINDING_SITE)):\n411     71659   1258910784  17568.1      0.1                                  node_b_chemical.add_affinityDistance(node_b, node_c, self.chemistry.affinity(node_b.data, node_c.data))\n412    587726   2706161481   4604.5      0.1                              node_b_changed = True\n413                                                                   \n414                                                               \n415                                                       \n416                                                       # If any of node b's rows have exceeded the cutoff distance, then remove them\n417  47267073 239847142446   5074.3     10.5              for node_c, (distance_b_c, node_after_b) in node_b_distances.items(): # Can't use iteritems() here, as deleting from the dictionary\n418  46716551 242694352980   5195.0     10.6                  if(distance_b_c &gt; cutoff_distance):\n419    200755    967443975   4819.0      0.0                      del node_b_distances[node_c]\n420    200755    930470616   4634.9      0.0                      node_b_changed = True\n421                                                               \n422                                                               ## Affinity distances update\n423    200755   4717125063  23496.9      0.2                      node_b_chemical.del_affinityDistance(node_b, node_c)\n424                                                       \n425                                                       # If we've modified node_b's distance table, tell its chemical to update accordingly\n426    550522   2684634615   4876.5      0.1              if(node_b_changed):\n427    235034   1383213780   5885.2      0.1                  node_b_chemical.nodes_changed.add(node_b)\n428                                                   \n429                                                   # Remove any neighbours that have infinite distance (have just unbound)\n430                                                   ## TODO: not sure what difference it makes to do this here rather than above (after updating self.node_distances for neighbours)\n431                                                   ##       but doing it above seems to break the walker's movement\n432    791349   4367879451   5519.5      0.2          for (node_b, neighbour_distance_b_a) in self.neighbours[node_a].items(): # Can't use iteritems() here, as deleting from the dictionary\n433    550522   2968919613   5392.9      0.1              if(neighbour_distance_b_a &gt; cutoff_distance):\n434       148       775638   5240.8      0.0                  del self.neighbours[node_a][node_b]\n435                                                           \n436                                                           ## Affinity distances update\n437       148      2096343  14164.5      0.0                  self.del_affinityDistance(node_a, node_b)\n</code>\n</pre>\n", "senID": 5}]]