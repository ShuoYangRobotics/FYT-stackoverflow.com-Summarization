[[{"text": ["Using scipy.weave and SSE2 intrinsics gives a marginal improvement.", "The first invocation is a bit slower since the code needs to be loaded from the disk and cached, subsequent invocations are faster:"], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "scipy.weave", "tag": "a", "pos": 0, "childList": [{"text": "scipy.weave", "tag": "code"}], "childNum": 1, "href": "http://www.scipy.org/Weave"}, {"text": "scipy.weave", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "SSE2", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/SSE2"}]}, {"code": "<pre>\n<code>\n import numpy\nimport time\nfrom os import urandom\nfrom scipy import weave\n\nSIZE = 2**20\n\ndef faster_slow_xor(aa,bb):\n    b = numpy.fromstring(bb, dtype=numpy.uint64)\n    numpy.bitwise_xor(numpy.frombuffer(aa,dtype=numpy.uint64), b, b)\n    return b.tostring()\n\ncode = \"\"\"\nconst __m128i* pa = (__m128i*)a;\nconst __m128i* pend = (__m128i*)(a + arr_size);\n__m128i* pb = (__m128i*)b;\n__m128i xmm1, xmm2;\nwhile (pa &lt; pend) {\n  xmm1 = _mm_loadu_si128(pa); // must use unaligned access \n  xmm2 = _mm_load_si128(pb); // numpy will align at 16 byte boundaries\n  _mm_store_si128(pb, _mm_xor_si128(xmm1, xmm2));\n  ++pa;\n  ++pb;\n}\n\"\"\"\n\ndef inline_xor(aa, bb):\n    a = numpy.frombuffer(aa, dtype=numpy.uint64)\n    b = numpy.fromstring(bb, dtype=numpy.uint64)\n    arr_size = a.shape[0]\n    weave.inline(code, [\"a\", \"b\", \"arr_size\"], headers = ['\"emmintrin.h\"'])\n    return b.tostring()\n</code>\n</pre>\n", "senID": 1}, {"text": ["Taking into account the comments, I revisited the code to find out if the copying could be avoided.", "Turns out I read the documentation of the string object wrong, so here goes my second try:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n support = \"\"\"\n#define ALIGNMENT 16\nstatic void memxor(const char* in1, const char* in2, char* out, ssize_t n) {\n    const char* end = in1 + n;\n    while (in1 &lt; end) {\n       *out = *in1 ^ *in2;\n       ++in1; \n       ++in2;\n       ++out;\n    }\n}\n\"\"\"\n\ncode2 = \"\"\"\nPyObject* res = PyString_FromStringAndSize(NULL, real_size);\n\nconst ssize_t tail = (ssize_t)PyString_AS_STRING(res) % ALIGNMENT;\nconst ssize_t head = (ALIGNMENT - tail) % ALIGNMENT;\n\nmemxor((const char*)a, (const char*)b, PyString_AS_STRING(res), head);\n\nconst __m128i* pa = (__m128i*)((char*)a + head);\nconst __m128i* pend = (__m128i*)((char*)a + real_size - tail);\nconst __m128i* pb = (__m128i*)((char*)b + head);\n__m128i xmm1, xmm2;\n__m128i* pc = (__m128i*)(PyString_AS_STRING(res) + head);\nwhile (pa &lt; pend) {\n    xmm1 = _mm_loadu_si128(pa);\n    xmm2 = _mm_loadu_si128(pb);\n    _mm_stream_si128(pc, _mm_xor_si128(xmm1, xmm2));\n    ++pa;\n    ++pb;\n    ++pc;\n}\nmemxor((const char*)pa, (const char*)pb, (char*)pc, tail);\nreturn_val = res;\nPy_DECREF(res);\n\"\"\"\n\ndef inline_xor_nocopy(aa, bb):\n    real_size = len(aa)\n    a = numpy.frombuffer(aa, dtype=numpy.uint64)\n    b = numpy.frombuffer(bb, dtype=numpy.uint64)\n    return weave.inline(code2, [\"a\", \"b\", \"real_size\"], \n                        headers = ['\"emmintrin.h\"'], \n                        support_code = support)\n</code>\n</pre>\n", "senID": 3}, {"text": ["The difference is that the string is allocated inside the C code.", "It's impossible to have it aligned at a 16-byte-boundary as required by the SSE2 instructions, therefore the unaligned memory regions at the beginning and the end are copied using byte-wise access. "], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["The input data is handed in using numpy arrays anyway, because weave insists on copying Python str objects to std::strings.", "frombuffer doesn't copy, so this is fine, but the memory is not aligned at 16 byte, so we need to use _mm_loadu_si128 instead of the faster _mm_load_si128."], "childNum": 6, "tag": "p", "senID": 5, "childList": [{"text": "weave", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "str", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "std::string", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "frombuffer", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "_mm_loadu_si128", "childNum": 0, "tag": "code", "childList": []}, {"text": "_mm_load_si128", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Instead of using _mm_store_si128, we use _mm_stream_si128, which will make sure that any writes are streamed to main memory as soon as possible---this way, the output array does not use up valuable cache lines. "], "childNum": 2, "tag": "p", "senID": 6, "childList": [{"text": "_mm_store_si128", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "_mm_stream_si128", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["As for the timings, the slow_xor entry in the first edit referred to my improved version (inline bitwise xor, uint64), I removed that confusion.", "slow_xor refers to the code from the original questions.", "All timings are done for 1000 runs."], "childNum": 3, "tag": "p", "senID": 7, "childList": [{"text": "slow_xor", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "uint64", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "slow_xor", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"tag": "ul", "num": 4, "lis": [{"text": ["slow_xor"], "childNum": 0, "tag": "code", "senID": 8, "childList": []}, {"text": ["faster_slow_xor"], "childNum": 0, "tag": "code", "senID": 9, "childList": []}, {"text": ["inline_xor"], "childNum": 0, "tag": "code", "senID": 10, "childList": []}, {"text": ["inline_xor_nocopy"], "childNum": 0, "tag": "code", "senID": 11, "childList": []}]}, {"text": ["The code was compiled using gcc 4.4.3 and I've verified that the compiler actually uses the SSE instructions."], "childNum": 0, "tag": "p", "senID": 12, "childList": []}], [{"text": ["Performance comparison: numpy vs. Cython vs. C vs. Fortran vs. Boost.Python (pyublas)"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n | function               | time, usec | ratio | type         |\n|------------------------+------------+-------+--------------|\n| slow_xor               |       2020 |   1.0 | numpy        |\n| xorf_int16             |       1570 |   1.3 | fortran      |\n| xorf_int32             |       1530 |   1.3 | fortran      |\n| xorf_int64             |       1420 |   1.4 | fortran      |\n| faster_slow_xor        |       1360 |   1.5 | numpy        |\n| inline_xor             |       1280 |   1.6 | C            |\n| cython_xor             |       1290 |   1.6 | cython       |\n| xorcpp_inplace (int32) |        440 |   4.6 | pyublas      |\n| cython_xor_vectorised  |        325 |   6.2 | cython       |\n| inline_xor_nocopy      |        172 |  11.7 | C            |\n| xorcpp                 |        144 |  14.0 | boost.python |\n| xorcpp_inplace         |        122 |  16.6 | boost.python |\n#+TBLFM: $3=@2$2/$2;%.1f\n</code>\n</pre>\n", "senID": 1}, {"text": ["To reproduce results, download http://gist.github.com/353005 and type make (to install dependencies, type: sudo apt-get install build-essential python-numpy python-scipy cython gfortran, dependencies for Boost.Python, pyublas are not included due to they require manual intervention to work)"], "childNum": 5, "tag": "p", "senID": 2, "childList": [{"text": "http://gist.github.com/353005", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://gist.github.com/353005"}, {"text": "make", "childNum": 0, "tag": "code", "childList": []}, {"text": "sudo apt-get install build-essential python-numpy python-scipy cython gfortran", "childNum": 0, "tag": "code", "childList": []}, {"text": "Boost.Python", "childNum": 0, "tag": "code", "childList": []}, {"text": "pyublas", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Where:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"tag": "ul", "num": 3, "lis": [{"text": ["slow_xor()"], "childNum": 0, "tag": "code", "senID": 4, "childList": []}, {"text": ["faster_slow_xor()"], "childNum": 0, "tag": "code", "senID": 5, "childList": []}, {"text": ["cython_xor()"], "childNum": 0, "tag": "code", "senID": 6, "childList": []}]}, {"text": ["And xor_$type_sig() are:"], "childNum": 1, "tag": "p", "senID": 7, "childList": [{"text": "xor_$type_sig()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n ! xorf.f90.template\nsubroutine xor_$type_sig(a, b, n, out)\n  implicit none\n  integer, intent(in)             :: n\n  $type, intent(in), dimension(n) :: a\n  $type, intent(in), dimension(n) :: b\n  $type, intent(out), dimension(n) :: out\n\n  integer i\n  forall(i=1:n) out(i) = ieor(a(i), b(i))\n\nend subroutine xor_$type_sig\n</code>\n</pre>\n", "senID": 8}, {"text": ["It is used from Python as follows:"], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"code": "<pre>\n<code>\n import xorf # extension module generated from xorf.f90.template\nimport numpy as np\n\ndef xor_strings(a, b, type_sig='int64'):\n    assert len(a) == len(b)\n    a = np.frombuffer(a, dtype=np.dtype(type_sig))\n    b = np.frombuffer(b, dtype=np.dtype(type_sig))\n    return getattr(xorf, 'xor_'+type_sig)(a, b).tostring()\n</code>\n</pre>\n", "senID": 10}, {"text": ["xor.cpp:"], "childNum": 1, "tag": "p", "senID": 11, "childList": [{"text": "xor.cpp", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://gist.github.com/353005#file_xor.cpp"}]}, {"code": "<pre>\n<code>\n #include &lt;inttypes.h&gt;\n#include &lt;algorithm&gt;\n#include &lt;boost/lambda/lambda.hpp&gt;\n#include &lt;boost/python.hpp&gt;\n#include &lt;pyublas/numpy.hpp&gt;\n\nnamespace { \n  namespace py = boost::python;\n\n  template&lt;class InputIterator, class InputIterator2, class OutputIterator&gt;\n  void\n  xor_(InputIterator first, InputIterator last, \n       InputIterator2 first2, OutputIterator result) {\n    // `result` migth `first` but not any of the input iterators\n    namespace ll = boost::lambda;\n    (void)std::transform(first, last, first2, result, ll::_1 ^ ll::_2);\n  }\n\n  template&lt;class T&gt;\n  py::str \n  xorcpp_str_inplace(const py::str&amp; a, py::str&amp; b) {\n    const size_t alignment = std::max(sizeof(T), 16ul);\n    const size_t n         = py::len(b);\n    const char* ai         = py::extract&lt;const char*&gt;(a);\n    char* bi         = py::extract&lt;char*&gt;(b);\n    char* end        = bi + n;\n\n    if (n &lt; 2*alignment) \n      xor_(bi, end, ai, bi);\n    else {\n      assert(n &gt;= 2*alignment);\n\n      // applying Marek's algorithm to align\n      const ptrdiff_t head = (alignment - ((size_t)bi % alignment))% alignment;\n      const ptrdiff_t tail = (size_t) end % alignment;\n      xor_(bi, bi + head, ai, bi);\n      xor_((const T*)(bi + head), (const T*)(end - tail), \n           (const T*)(ai + head),\n           (T*)(bi + head));\n      if (tail &gt; 0) xor_(end - tail, end, ai + (n - tail), end - tail);\n    }\n    return b;\n  }\n\n  template&lt;class Int&gt;\n  pyublas::numpy_vector&lt;Int&gt; \n  xorcpp_pyublas_inplace(pyublas::numpy_vector&lt;Int&gt; a, \n                         pyublas::numpy_vector&lt;Int&gt; b) {\n    xor_(b.begin(), b.end(), a.begin(), b.begin());\n    return b;\n  }\n}\n\nBOOST_PYTHON_MODULE(xorcpp)\n{\n  py::def(\"xorcpp_inplace\", xorcpp_str_inplace&lt;int64_t&gt;);     // for strings\n  py::def(\"xorcpp_inplace\", xorcpp_pyublas_inplace&lt;int32_t&gt;); // for numpy\n}\n</code>\n</pre>\n", "senID": 12}, {"text": ["It is used from Python as follows:"], "childNum": 0, "tag": "p", "senID": 13, "childList": []}, {"code": "<pre>\n<code>\n import os\nimport xorcpp\n\na = os.urandom(2**20)\nb = os.urandom(2**20)\nc = xorcpp.xorcpp_inplace(a, b) # it calls xorcpp_str_inplace()\n</code>\n</pre>\n", "senID": 14}], [{"text": ["Here are my results for cython"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n slow_xor   0.456888198853\nfaster_xor 0.400228977203\ncython_xor 0.232881069183\ncython_xor_vectorised 0.171468019485\n</code>\n</pre>\n", "senID": 1}, {"text": ["Vectorising in cython shaves about 25% off the for loop on my computer, However more than half the time is spent building the python string (the return statement) - I don't think the extra copy can be avoided (legally) as the array may contain null bytes."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "return", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["The illegal way would be to pass in a Python string and mutate it in place and would double the speed of the function."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["xor.py"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "xor.py", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n from time import time\nfrom os import urandom\nfrom numpy import frombuffer,bitwise_xor,byte,uint64\nimport pyximport; pyximport.install()\nimport xor_\n\ndef slow_xor(aa,bb):\n    a=frombuffer(aa,dtype=byte)\n    b=frombuffer(bb,dtype=byte)\n    c=bitwise_xor(a,b)\n    r=c.tostring()\n    return r\n\ndef faster_xor(aa,bb):\n    a=frombuffer(aa,dtype=uint64)\n    b=frombuffer(bb,dtype=uint64)\n    c=bitwise_xor(a,b)\n    r=c.tostring()\n    return r\n\naa=urandom(2**20)\nbb=urandom(2**20)\n\ndef test_it():\n    t=time()\n    for x in xrange(100):\n        slow_xor(aa,bb)\n    print \"slow_xor  \",time()-t\n    t=time()\n    for x in xrange(100):\n        faster_xor(aa,bb)\n    print \"faster_xor\",time()-t\n    t=time()\n    for x in xrange(100):\n        xor_.cython_xor(aa,bb)\n    print \"cython_xor\",time()-t\n    t=time()\n    for x in xrange(100):\n        xor_.cython_xor_vectorised(aa,bb)\n    print \"cython_xor_vectorised\",time()-t\n\nif __name__==\"__main__\":\n    test_it()\n</code>\n</pre>\n", "senID": 5}, {"text": ["xor_.pyx"], "childNum": 1, "tag": "p", "senID": 6, "childList": [{"text": "xor_.pyx", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n cdef char c[1048576]\ndef cython_xor(char *a,char *b):\n    cdef int i\n    for i in range(1048576):\n        c[i]=a[i]^b[i]\n    return c[:1048576]\n\ndef cython_xor_vectorised(char *a,char *b):\n    cdef int i\n    for i in range(131094):\n        (&lt;unsigned long long *&gt;c)[i]=(&lt;unsigned long long *&gt;a)[i]^(&lt;unsigned long long *&gt;b)[i]\n    return c[:1048576]\n</code>\n</pre>\n", "senID": 7}], [{"text": ["An easy speedup is to use a larger 'chunk':"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n def faster_xor(aa,bb):\n    a=frombuffer(aa,dtype=uint64)\n    b=frombuffer(bb,dtype=uint64)\n    c=bitwise_xor(a,b)\n    r=c.tostring()\n    return r\n</code>\n</pre>\n", "senID": 1}, {"text": ["with uint64 also imported from numpy of course.", "I timeit this at 4 milliseconds, vs 6 milliseconds for the byte version."], "childNum": 4, "tag": "p", "senID": 2, "childList": [{"text": "uint64", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "numpy", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "timeit", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "byte", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["Your problem isn't the speed of NumPy's xOr method, but rather with all of the buffering/data type conversions.", "Personally I suspect that the point of this post may have really been to brag about Python, because what you are doing here is processing THREE GIGABYTES of data in timeframes on par with non-interpreted languages, which are inherently faster."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["The below code shows that even on my humble computer Python can xOr \"aa\" (1MB) and \"bb\" (1MB) into \"c\" (1MB) one thousand times (total 3GB) in under two seconds.", "Seriously, how much more improvement do you want?", "Especially from an interpreted language!", "80% of the time was spent calling \"frombuffer\" and \"tostring\".", "The actual xOr-ing is completed in the other 20% of the time.", "At 3GB in 2 seconds, you would be hard-pressed to improve upon that substantially even just using memcpy in c."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "two seconds", "childNum": 0, "tag": "em", "pos": 0, "childList": []}, {"text": "substantially", "childNum": 0, "tag": "em", "pos": 5, "childList": []}]}, {"text": ["In case this was a real question, and not just covert bragging about Python, the answer is to code so as to minimize the number, amount and frequency of your type conversions such as \"frombuffer\" and \"tostring\".", "The actual xOr'ing is lightning fast already."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n from os import urandom\nfrom numpy import frombuffer,bitwise_xor,byte,uint64\n\ndef slow_xor(aa,bb):\n    a=frombuffer(aa,dtype=byte)\n    b=frombuffer(bb,dtype=byte)\n    c=bitwise_xor(a,b)\n    r=c.tostring()\n    return r\n\nbb=urandom(2**20)\naa=urandom(2**20)\n\ndef test_it():\n    for x in xrange(1000):\n    slow_xor(aa,bb)\n\ndef test_it2():\n    a=frombuffer(aa,dtype=uint64)\n    b=frombuffer(bb,dtype=uint64)\n    for x in xrange(1000):\n        c=bitwise_xor(a,b);\n    r=c.tostring()    \n\ntest_it()\nprint 'Slow Complete.'\n#6 seconds\ntest_it2()\nprint 'Fast Complete.'\n#under 2 seconds\n</code>\n</pre>\n", "senID": 3}, {"text": ["Anyway, the \"test_it2\" above accomplishes exactly the same amount of xOr-ing as \"test_it\" does, but in 1/5 the time.", "5x speed improvement should qualify as \"substantial\", no?"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["The fastest bitwise XOR is \"^\".", "I can type that much quicker than \"bitwise_xor\" ;-)"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "much", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}], [{"text": ["If you want to do fast operations on array data types, then you should try Cython (cython.org).", "If you give it the right declarations it should be able to compile down to pure c code."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["How badly do you need the answer as a string?", "Note that the c.tostring() method has to copy the data in c to a new string, as Python strings are immutable (and c is mutable).", "Python 2.6 and 3.1 have a bytearray type, which acts like str (bytes in Python 3.x) except for being mutable."], "childNum": 7, "tag": "p", "senID": 0, "childList": [{"text": "c.tostring()", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "copy", "childNum": 0, "tag": "em", "pos": -1, "childList": []}, {"text": "c", "childNum": 0, "tag": "code", "pos": 2, "childList": []}, {"text": "c", "childNum": 0, "tag": "code", "childList": []}, {"text": "bytearray", "childNum": 0, "tag": "code", "childList": []}, {"text": "str", "childNum": 0, "tag": "code", "childList": []}, {"text": "bytes", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Another optimization is using the out parameter to bitwise_xor to specify where to store the result."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "out", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "bitwise_xor", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["On my machine I get"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n slow_xor (int8): 5.293521 (100.0%)\noutparam_xor (int8): 4.378633 (82.7%)\nslow_xor (uint64): 2.192234 (41.4%)\noutparam_xor (uint64): 1.087392 (20.5%)\n</code>\n</pre>\n", "senID": 3}, {"text": ["with the code at the end of this post.", "Notice in particular that the method using a preallocated buffer is twice as fast as creating a new object (when operating on 4-byte (uint64) chunks).", "This is consistent with the slower method doing two operations per chunk (xor + copy) to the faster's 1 (just xor)."], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "uint64", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"text": ["Also, FWIW, a ^ b is equivalent to bitwise_xor(a,b), and a ^= b is equivalent to bitwise_xor(a, b, a)."], "childNum": 4, "tag": "p", "senID": 5, "childList": [{"text": "a ^ b", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "bitwise_xor(a,b)", "childNum": 0, "tag": "code", "childList": []}, {"text": "a ^= b", "childNum": 0, "tag": "code", "childList": []}, {"text": "bitwise_xor(a, b, a)", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["So, 5x speedup without writing any external modules :)"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n from time import time\nfrom os import urandom\nfrom numpy import frombuffer,bitwise_xor,byte,uint64\n\ndef slow_xor(aa, bb, ignore, dtype=byte):\n    a=frombuffer(aa, dtype=dtype)\n    b=frombuffer(bb, dtype=dtype)\n    c=bitwise_xor(a, b)\n    r=c.tostring()\n    return r\n\ndef outparam_xor(aa, bb, out, dtype=byte):\n    a=frombuffer(aa, dtype=dtype)\n    b=frombuffer(bb, dtype=dtype)\n    c=frombuffer(out, dtype=dtype)\n    assert c.flags.writeable\n    return bitwise_xor(a, b, c)\n\naa=urandom(2**20)\nbb=urandom(2**20)\ncc=bytearray(2**20)\n\ndef time_routine(routine, dtype, base=None, ntimes = 1000):\n    t = time()\n    for x in xrange(ntimes):\n        routine(aa, bb, cc, dtype=dtype)\n    et = time() - t\n    if base is None:\n        base = et\n    print \"%s (%s): %f (%.1f%%)\" % (routine.__name__, dtype.__name__, et,\n        (et/base)*100)\n    return et\n\ndef test_it(ntimes = 1000):\n    base = time_routine(slow_xor, byte, ntimes=ntimes)\n    time_routine(outparam_xor, byte, base, ntimes=ntimes)\n    time_routine(slow_xor, uint64, base, ntimes=ntimes)\n    time_routine(outparam_xor, uint64, base, ntimes=ntimes)\n</code>\n</pre>\n", "senID": 7}], [{"text": ["You could try the symmetric difference of the bitsets of sage."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["http://www.sagemath.org/doc/reference/sage/misc/bitset.html"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://www.sagemath.org/doc/reference/sage/misc/bitset.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.sagemath.org/doc/reference/sage/misc/bitset.html"}]}], [{"text": ["The fastest way (speedwise) will be doing what Max.", "S recommended.", "Implement it in C."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["The supporting code for this task should be rather simple to write.", "It is just one function in a module creating a new string and doing the xor.", "That's all.", "When you have implemented one module like that, it is simple to take the code as template.", "Or you even take a module implemented from somebody else that implements a simple enhancement module for Python and just throw out everything not needed for your task."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["The real complicated part is just, doing the RefCounter-Stuff right.", "But once realized how it works, it is manageable -- also since the task at hand is really simple (allocate some memory, and return it -- params are not to be touched (Ref-wise))."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Get rid of the function call, and do the xor operation inline."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}]]