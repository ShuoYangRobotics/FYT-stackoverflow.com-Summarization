<h3>Question ( ID-3481378 ) : </h3><h2><span style="background-color:yellow;">regex</span> that matches a string that contains some text </h2><p>I need a <span style="background-color:yellow;">regex</span> that matches </p>
<pre><code>re.compile('userpage')


href="www.example.com?u=userpage&as=233&p=1"
href="www.example.com?u=userpage&as=233&p=2"
</code></pre>
<p>I want to <span style="background-color:yellow;">get</span> all urls that have u = userpage and p = 1 </p>
<p>How can I modify the <span style="background-color:yellow;">regex</span> above to find both u = userpage and p = 1 ? </p>
<br /><h3>Answers ( Total-6 ) : </h3><b># 0 </b><br /><p>if you want to use , in my opinion , something more proper approach , than <span style="background-color:yellow;">regexp</span> : </p>
<pre><code>from urlparse import *
urlparsed = urlparse('www.example.com?u=userpage&as=233&p=1')
# -> ParseResult(scheme='', netloc='', path='www.example.com', params='', query='u=userpage&as=233&p=1', fragment='')
qdict = dict(parse_qsl(urlparsed.query))
# -> {'as': '233', 'p': '1', 'u': 'userpage'}
qdict.get('p') == '1' and qdict.get('u') == 'userpage'
# -> True
</code></pre>
<br /><b># 1 </b><br /><pre><code>import lxml.html, urlparse

d = lxml.html.parse(...)
for link in d.xpath('//a/@href'):
    url = urlparse.urlparse(link)
    if not url.query:
        continue
    params = urlparse.parse_qs(url.query)
    if 'userpage' in params.get('u', []) and '1' in params.get('p', []):
        print link
</code></pre>
<br /><b># 2 </b><br /><p>Regex is not a good choice for this because 1 ) the params could appear in either order , and 2 ) you need to do extra checks for query separators so that you do n't match potential oddities like " flu = userpage " , " sp = 1 " , " u = userpage % 20haha " , or " s = 123 " . ( Note : I missed two of those cases in my first pass ! So did others. ) Also : 3 ) you already have a good URL parsing library in Python which does the work for you . </p>
<p>With <span style="background-color:yellow;">regex</span> you 'd need something clumsy like : </p>
<pre><code>q = re.compile(r'([?&]u=userpage&(.*&)?p=1(&|$))|([?&]p=1&(.*&)?u=userpage(&|$))')
return q.search(href) is not None
</code></pre>
<p>With <span style="background-color:yellow;">urlparse</span> you can do this. <span style="background-color:yellow;">urlparse</span> gives you a little more than you want but you can use a helper function to keep the <span style="background-color:yellow;">result</span> simple : </p>
<pre><code>def has_qparam(qs, key, value):
    return value in qs.get(key, [])

qs = urlparse.parse_qs(urlparse.urlparse(href).query)
return has_qparam(qs, 'u', 'userpage') and has_qparam(qs, 'p', '1')
</code></pre>
<br /><b># 3 </b><br /><p>/ ( ( u = userpage ) . * ? ( p = 1 ) ) | ( ( p = 1 ) . * ? ( u = userpage ) ) / </p>
<p>This will <span style="background-color:yellow;">get</span> all strings that contain the two bits you 're looking for . </p>
<br /><b># 4 </b><br /><p>To make sure you do n't accidentally match parts like bu = userpage , u = userpagezap , p = 111 or zap = 1 , you need abundant use of the \ b " word-boundary " RE pattern element. I.e. : </p>
<pre><code>re.compile(r'\bp=1\b.*\bu=userpage\b|\bu=userpage\b.*\bp=1\b')
</code></pre>
<p>The word-boundary elements in the RE 's pattern prevent the above-mentioned , presumably-undesirable " accidental " matches. Of course , if in your application they 're not " undesirable " , i.e. , if you positively want to match p = 123 and the like , you can easily <span style="background-color:yellow;">remove</span> some or all of the word-boundary elements above ! - ) </p>
<br /><b># 5 </b><br /><p>It is possible to do this with string hacking , but you should n't. It 's already in the standard library : </p>
<pre><code>>>> import urllib.parse
>>> urllib.parse.parse_qs("u=userpage&as=233&p=1")
{'u': ['userpage'], 'as': ['233'], 'p': ['1']}
</code></pre>
<p>and hence </p>
<pre><code>import urllib.parse
def filtered_urls( urls ):
    for url in urls:
        try:
            attrs = urllib.parse.parse_qs( url.split( "?" )[ 1 ] )
        except IndexError:
            continue

        if "userpage" in attrs.get( "u", "" ) and "1" in attrs.get( "p", "" ):
            yield url

foo = [ "www.example.com?u=userpage&as=233&p=1", "www.example.com?u=userpage&as=233&p=2" ]

print( list( filtered_urls( foo ) ) )
</code></pre>
<p>Note that this is Python 3 -- in Python <span style="background-color:yellow;">parse_qs</span> is in <span style="background-color:yellow;">urlparse</span> instead . </p>
<br />