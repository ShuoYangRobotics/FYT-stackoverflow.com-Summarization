<h3>Question ( ID-1927660 ) : </h3><h2>Compare two images the python/linux way </h2><p>Trying to solve a problem of preventing duplicate images to <span style="background-color:yellow;">be</span> uploaded . </p>
<p>I have two JPGs. Looking at them I can see that they are in fact identical. But for some reason they have different file size ( one is pulled from a <span style="background-color:yellow;">backup</span> , the other is another upload ) and so they have a different md5 checksum . </p>
<p>How can I efficiently and confidently <span style="background-color:yellow;">compare</span> two images in the same sense as a human would <span style="background-color:yellow;">be</span> able to see that they are clearly identical ? </p>
<p>Example : http : //static.peterbe.com/a.jpg and http : //static.peterbe.com/b.jpg </p>
<p>Update </p>
<p>I wrote this script : </p>
<pre><code>import math, operator
from PIL import Image
def compare(file1, file2):
    image1 = Image.open(file1)
    image2 = Image.open(file2)
    h1 = image1.histogram()
    h2 = image2.histogram()
    rms = math.sqrt(reduce(operator.add,
                           map(lambda a,b: (a-b)**2, h1, h2))/len(h1))
    return rms

if __name__=='__main__':
    import sys
    file1, file2 = sys.argv[1:]
    print compare(file1, file2)
</code></pre>
<p>Then I downloaded the two visually identical images and ran the script. Output : </p>
<pre><code>58.9830484122
</code></pre>
<p>Can anybody tell me what a suitable cutoff should <span style="background-color:yellow;">be</span> ? </p>
<p>Update II </p>
<p>The difference <span style="background-color:yellow;">between</span> a.jpg and <span style="background-color:yellow;">b.jpg</span> is that the second one has <span style="background-color:yellow;">been</span> <span style="background-color:yellow;">saved</span> with <span style="background-color:yellow;">PIL</span> : </p>
<pre><code>b=Image.open('a.jpg')
b.save(open('b.jpg','wb'))
</code></pre>
<p>This apparently applies some very very light quality modifications. I 've now solved my problem <span style="background-color:yellow;">by</span> applying the same <span style="background-color:yellow;">PIL</span> <span style="background-color:yellow;">save</span> to the file <span style="background-color:yellow;">being</span> uploaded without doing anything with it and it now works ! </p>
<br /><h3>Answers ( Total-6 ) : </h3><b># 0 </b><br /><p>There is a OSS project that uses WebDriver to take screen shots and then <span style="background-color:yellow;">compares</span> the images to see if there are any issues ( http : //code.google.com/p/fighting-layout-bugs/ ) ) . It does it <span style="background-color:yellow;">by</span> openning the file into a stream and then comparing every <span style="background-color:yellow;">bit</span> . </p>
<p>You may <span style="background-color:yellow;">be</span> able to do something similar with <span style="background-color:yellow;">PIL</span> . </p>
<p>EDIT : </p>
<p>After more research I found </p>
<pre><code>h1 = Image.open("image1").histogram()
h2 = Image.open("image2").histogram()

rms = math.sqrt(reduce(operator.add,
    map(lambda a,b: (a-b)**2, h1, h2))/len(h1))
</code></pre>
<p>on http : //snipplr.com/view/757/compare-two-pil-images-in-python/ and http : //effbot.org/zone/pil-comparing-images.htm </p>
<br /><b># 1 </b><br /><p>I guess you should decode the images and do a pixel <span style="background-color:yellow;">by</span> pixel comparison to see if they 're reasonably similar . </p>
<p>With <span style="background-color:yellow;">PIL</span> and Numpy you can do it quite easily : </p>
<pre><code>import Image
import numpy
import sys

def main():
    img1 = Image.open(sys.argv[1])
    img2 = Image.open(sys.argv[2])

    if img1.size != img2.size or img1.getbands() != img2.getbands():
        return -1

    s = 0
    for band_index, band in enumerate(img1.getbands()):
        m1 = numpy.array([p[band_index] for p in img1.getdata()]).reshape(*img1.size)
        m2 = numpy.array([p[band_index] for p in img2.getdata()]).reshape(*img2.size)
        s += numpy.sum(numpy.abs(m1-m2))
    print s

if __name__ == "__main__":
    sys.exit(main())
</code></pre>
<p>This will give you a numeric value that should <span style="background-color:yellow;">be</span> very close to 0 if the images are quite the same . </p>
<br /><b># 2 </b><br /><p>First, I should note they’re <strong>not</strong> identical; b has been recompressed and lost quality. You can see this if you look carefully on a good monitor.</p>
<p>To determine that they are subjectively “the same,” you would have to do something like what fortran suggested, although you will have to arbitrarily establish a threshold for “sameness.” To make s independent of image size, and to handle channels a little more sensibly, I would consider doing the RMS (root mean square) Euclidean distance in colorspace between the pixels of the two images. I don’t have time to write out the code right now, but basically for each pixel, you compute</p>
<pre><code>(R_2 - R_1) ** 2 + (G_2 - G_1) ** 2 + (B_2 - B_1) ** 2
</code></pre>
<p>, adding in an </p>
<p>( A_2 - A_1 ) * * 2 </p>
<p>term if the image has an alpha channel , etc. The result is the square of the colorspace distance <span style="background-color:yellow;">between</span> the two images. Find the mean ( average ) across all pixels , then take the square root of the resulting scalar. Then decide a reasonable threshold for this value . </p>
<p></p>
<br /><b># 3 </b><br /><p>the problem of knowing what makes some features of the image more important than other is a whole scientific program. I would suggest some alternatives depending on the solution you want : </p>
<ul>if your problem is to see if there is a flipping of <span style="background-color:yellow;">bits</span> in your JPEGs , then try to image the difference image ( there was perhaps a minor edit locally ? ) , to see if images are globally the same , use the Kullback Leibler distance to <span style="background-color:yellow;">compare</span> your histograms , to see if you have some qualittative change , <span style="background-color:yellow;">before</span> applying other answers , filter your image using the functions <span style="background-color:yellow;">below</span> to raise the importance of high-level frequencies : </ul>
<p>code : </p>
<pre><code>def FTfilter(image,FTfilter):
    from scipy.fftpack import fft2, fftshift, ifft2, ifftshift
    from scipy import real
    FTimage = fftshift(fft2(image)) * FTfilter
    return real(ifft2(ifftshift(FTimage)))
    #return real(ifft2(fft2(image)* FTfilter))


#### whitening
def olshausen_whitening_filt(size, f_0 = .78, alpha = 4., N = 0.01):
    """
    Returns the whitening filter used by (Olshausen, 98)

    f_0 = 200 / 512

    /!\ you will have some problems at dewhitening without a low-pass

    """
    from scipy import mgrid, absolute
    fx, fy = mgrid[-1:1:1j*size[0],-1:1:1j*size[1]]
    rho = numpy.sqrt(fx**2+fy**2)
    K_ols = (N**2 + rho**2)**.5 * low_pass(size, f_0 = f_0, alpha = alpha)
    K_ols /= numpy.max(K_ols)

    return  K_ols

def low_pass(size, f_0, alpha):
    """
    Returns the low_pass filter used by (Olshausen, 98)

    parameters from Atick (p.240)
    f_0 = 22 c/deg in primates: the full image is approx 45 deg
    alpha makes the aspect change (1=diamond on the vert and hor, 2 = anisotropic)

    """

    from scipy import mgrid, absolute
    fx, fy = mgrid[-1:1:1j*size[0],-1:1:1j*size[1]]
    rho = numpy.sqrt(fx**2+fy**2)
    low_pass = numpy.exp(-(rho/f_0)**alpha)

    return  low_pass
</code></pre>
<p>( shameless copy from http : //www.incm.cnrs-mrs.fr/LaurentPerrinet/Publications/Perrinet08spie ) </p>
<br /><b># 4 </b><br /><p>You can either <span style="background-color:yellow;">compare</span> it using <span style="background-color:yellow;">PIL</span> ( iterate through pixels / segments of the picture and <span style="background-color:yellow;">compare</span> ) or if you 're looking for a complete identical copy comparison , try comparing the MD5 hash of <span style="background-color:yellow;">both</span> files . </p>
<br /><b># 5 </b><br /><p>From here </p>
<p>The quickest way to determine if two images have exactly the same contents is to get the difference <span style="background-color:yellow;">between</span> the two images , and then calculate the <span style="background-color:yellow;">bounding</span> <span style="background-color:yellow;">box</span> of the non-zero regions in this image. If the images are identical , all pixels in the difference image are zero , and the <span style="background-color:yellow;">bounding</span> <span style="background-color:yellow;">box</span> function returns None . </p>
<pre><code>import ImageChops

def equal(im1, im2):
    return ImageChops.difference(im1, im2).getbbox() is None
</code></pre>
<br />