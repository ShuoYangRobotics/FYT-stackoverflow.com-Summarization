<h3>Question ( ID-6880069 ) : </h3><h2>Compile to byte code takes up too much memory </h2><p>I need to import a very large dictionary into python and I 'm running into some unexpected memory bottlenecks. The dictionary has the form, </p>
<pre><code>d = {(1,2,3):(1,2,3,4), (2,5,6)=(4,2,3,4,5,6), ... }
</code></pre>
<p>So each <span style="background-color:yellow;">key</span> is a <span style="background-color:yellow;">3-tuple</span> and each value is a relatively small <span style="background-color:yellow;">tuple</span> of arbitrary size ( probably never more than <span style="background-color:yellow;">30</span> elements ) . What makes the dictionary large is the number of <span style="background-color:yellow;">keys.</span> A smaller example of what I 'm working with has roughly <span style="background-color:yellow;">247257</span> <span style="background-color:yellow;">keys.</span> I generate this dictionary through a simulation so I can write out a text file that defines this dictionary and for the example I just mentioned this is a 94MB file. The bottleneck I am running into is that the initial compile to python byte code eats up about <span style="background-color:yellow;">14GB</span> of ram. So the first time I import the dictionary I see the RAM usage spike up and after a good <span style="background-color:yellow;">10</span> seconds everything is loaded. If the .pyc file is already generated the import is nearly instant. Using pympler , I 've determined that this dictionary is only about <span style="background-color:yellow;">200</span> MB in memory. What is the deal here ? Do I have any other options on how get this dictionary loaded into python or at least compiled to byte code. I 'm running the generating simulations in C + + and I ca n't write files an whatever format I need. Are there any options there ( python libraries , etc. ) ? I 'm interfacing with some software that needs this data as a dictionary so please no other suggestions in that realm. Also just in case you are wondering , I have defined the dictionary in the text file like the definition above as well as like so, </p>
<pre><code>d = {}
d[1,2,3] = (1,2,3,4)
d[2,5,6] = (4,2,3,4,5,6)
...
</code></pre>
<p>Both give the same memory spike in compile to byte code. In fact , the second one seems to be slightly worse , which is surprising to me. There 's got to be some way to tame the amount of ram the initial compile needs. It seems like it should somehow be able to do the compile one <span style="background-color:yellow;">key-value</span> pair at a time. Any ideas ? </p>
<p>Other info : using python <span style="background-color:yellow;">2.6.5</span> </p>
<br /><h3>Answers ( Total-6 ) : </h3><b># 0 </b><br /><p>I guess the problem is that while parsing your file an enormous syntax tree is made with a small overhead for each element that all add up. Once the bytecode is generated the syntax tree is no longer necessary and dumped , resulting in your <span style="background-color:yellow;">200MB</span> data . </p>
<p>Have you tried storing the data in a seperate file in the following format and then dynamically load it in python ? </p>
<pre><code>1,2,3=1,2,3
2,5,6=4,2,3,4,5,6
</code></pre>
<p>The Python script should look something like this : </p>
<pre><code>file = open("filename")
d = {}

for line in file:
    key, val = line.split("=")
    key = tuple(key.split(","))
    d[key] = tuple(val.split(","))

file.close()
</code></pre>
<br /><b># <span style="background-color:yellow;">1</span> </b><br /><p>http : //docs.python.org/library/shelve.html </p>
<br /><b># <span style="background-color:yellow;">2</span> </b><br /><p>I 'm guessing that your big compile spike happens when you do " import module_containing_humungous_dict_statement " . Then it does n't matter if you 've got just one statement or <span style="background-color:yellow;">247257</span> separate assignment statements , the whole module will still get compiled at once. You could try using the separate-assignment-statement form , and then opening the file , reading one line at a time , and exec'ing it. Then you will only be compiling one line at a time. Will probably take a while . </p>
<br /><b># <span style="background-color:yellow;">3</span> </b><br /><p>I suspect creating the list to use as a <span style="background-color:yellow;">key</span> is what is expensive. Define a function that takes the three parts of the triple as input and returns a pipe delimited string. Use that as your <span style="background-color:yellow;">key</span> . </p>
<br /><b># 4 </b><br /><p>The way I read your question , you are generating Python source in your simulator , and the generated source has the contents of the giant dictionary hard-coded. If that is true , then you might as easily generate this : </p>
<pre><code>def giantdict():
  d0 = {(1, 2): (3, 4), (3, 4): (5, 6), ...}  # first 1000 key/value pairs here
  d1 = {(1, 2): (3, 4), (3, 4): (5, 6), ...}  # next 1000 key/value pairs
  d2 = {(1, 2): (3, 4), (3, 4): (5, 6), ...}  # next 1000 key/value pairs
  d3 = {(1, 2): (3, 4), (3, 4): (5, 6), ...}  # next 1000 key/value pairs
  # ... until you're done
  bigd = d0
  bigd.update(d1)
  del d1
  bigd.update(d2)
  del d2
  # ... continue updating with all the dN dictionaries
  return bigd
</code></pre>
<p>I 'm not sure that this will improve the compile time , but it would be something to try. If there is a penalty to putting everything in one data structure at compile time , splitting it up and assembling the pieces at run time may work around it . </p>
<p>While this kind of code ( mine or yours ) would draw my fury and ire if a human wrote it , I see no need for generated code to be " nice " , as long as you know that no human will ever need to read it or maintain it . </p>
<br /><b># <span style="background-color:yellow;">5</span> </b><br /><p>Here 's a class that uses a <span style="background-color:yellow;">defaultdict</span> for the automatic nesting of indexed values , with some special <span style="background-color:yellow;">__getitem__</span> and <span style="background-color:yellow;">__setitem__</span> methods to accept <span style="background-color:yellow;">tuples</span> as arguments : </p>
<pre><code>from collections import defaultdict

defdict3level = (lambda : defaultdict(lambda : 
                            defaultdict( lambda : 
                                defaultdict(tuple))))

class dict3level(object):
    def __init__(self):
        self.defdict = defdict3level()

    def __getitem__(self, key):
        if isinstance(key, tuple):
            if len(key)==3:
                return self.defdict[key[0]][key[1]][key[2]]
            elif len(key)==2:
                return self.defdict[key[0]][key[1]]
            elif len(key)==1:
                return self.defdict[key[0]]
        else:
            return self.defdict[key]

    def __setitem__(self, key, value):
        if isinstance(key, tuple) and len(key)==3:
            self.defdict[key[0]][key[1]][key[2]] = value
        else:
            self.defdict[key] = value

    def __getattr__(self, attr):
        return getattr(self.defdict, attr)
</code></pre>
<p>Now exec all your assignments like before : </p>
<pre><code>d = dict3level()
d[1,2,3] = (1,2,3,4)
d[1,2,7] = (3,4,5,6)
d[2,5,6] = (4,2,3,4,5,6)
</code></pre>
<p>You can still get a specific entry for a specific <span style="background-color:yellow;">tuple</span> : </p>
<pre><code># get a specific entry
print d[1,2,3]
</code></pre>
<p>But you can also navigate your dict by levels : </p>
<pre><code># get all different 0'th index values
print d.keys()

# get all sub values in d[1,2,*]
print d[1,2].keys()
for key in d[1,2]:
    print "d[1,2,%d] = %s" % (key, d[1,2][key])

# no such entry, return empty tuple
print d[1,2,0]
</code></pre>
<p>Gives : </p>
<pre><code>print d[1,2,3] -> (1, 2, 3, 4)
print d.keys() -> [1, 2]
print d[1,2].keys() -> [3, 7]
for key in d[1,2]:... -> 
    d[1,2,3] = (1, 2, 3, 4)
    d[1,2,7] = (3, 4, 5, 6)
print d[1,2,0] -> ()
</code></pre>
<p>( Do n't know how this will affect your memory and/or pickling issues , but the resulting structure has a lot more capability to it. ) </p>
<br />