<h3>Question ( ID-556730 ) : </h3><h2>Python list serialization - <span style="background-color:yellow;">fastest</span> method </h2><p>I need to load ( de-serialize ) a pre-computed list of integers <span style="background-color:yellow;">from</span> a <span style="background-color:yellow;">file</span> in a Python script ( into a Python list ) . The list is large ( upto millions of items ) , and I can choose the <span style="background-color:yellow;">format</span> I store it in , as long as loading is <span style="background-color:yellow;">fastest</span> . </p>
<p>Which is the <span style="background-color:yellow;">fastest</span> method , and why ? </p>
<ol>Using import on a .py <span style="background-color:yellow;">file</span> that just contains the list assigned to a variable Using cPickle 's load Some other method ( perhaps numpy ? ) </ol>
<p>Also , how can one benchmark such things reliably ? </p>
<p>Addendum : measuring this reliably is difficult , because import is cached so it ca n't be executed multiple times in a test. The loading with pickle also gets <span style="background-color:yellow;">faster</span> after the <span style="background-color:yellow;">first</span> time probably because page-precaching by the OS. Loading 1 million numbers with cPickle takes 1.1 sec the <span style="background-color:yellow;">first</span> time run , and 0.2 sec on subsequent executions of the script . </p>
<p>Intuitively I <span style="background-color:yellow;">feel</span> cPickle should be <span style="background-color:yellow;">faster</span> , but I 'd appreciate numbers ( this is quite a challenge to measure , I think ) . </p>
<p>And yes , it 's important <span style="background-color:yellow;">for</span> me that this performs quickly . </p>
<p>Thanks </p>
<br /><h3>Answers ( Total-6 ) : </h3><b># 0 </b><br /><p>I would guess cPickle will be <span style="background-color:yellow;">fastest</span> if you really need the thing in a list . </p>
<p>If you can use an <span style="background-color:yellow;">array</span> , which is a built-in sequence type , I timed this at a quarter of a second <span style="background-color:yellow;">for</span> 1 million integers : </p>
<pre><code>from array import array
from datetime import datetime

def WriteInts(theArray,filename):
    f = file(filename,"wb")
    theArray.tofile(f)
    f.close()

def ReadInts(filename):
    d = datetime.utcnow()
    theArray = array('i')
    f = file(filename,"rb")
    try:
        theArray.fromfile(f,1000000000)
    except EOFError:
        pass
    print "Read %d ints in %s" % (len(theArray),datetime.utcnow() - d)
    return theArray

if __name__ == "__main__":
    a = array('i')
    a.extend(range(0,1000000))
    filename = "a_million_ints.dat"
    WriteInts(a,filename)
    r = ReadInts(filename)
    print "The 5th element is %d" % (r[4])
</code></pre>
<br /><b># 1 </b><br /><p>For benchmarking , see the timeit module in the Python standard library. To see what is the <span style="background-color:yellow;">fastest</span> way , implement all the ways you can think of and measure them with timeit . </p>
<p>Random thought : depending on what you 're doing exactly , you may <span style="background-color:yellow;">find</span> it <span style="background-color:yellow;">fastest</span> to store " sets of integers " in the style used in .newsrc <span style="background-color:yellow;">files</span> : </p>
<pre><code>1, 3-1024, 11000-1200000
</code></pre>
<p>If you need to check whether something is in that set , then loading and matching with such a representation should be among the <span style="background-color:yellow;">fastest</span> ways. This assumes your sets of integers are reasonably dense , with long consecutive sequences of adjacent values . </p>
<br /><b># 2 </b><br /><p>" how can one benchmark such things reliably ? " </p>
<p>I do n't get the question . </p>
<p>You write a bunch of little <span style="background-color:yellow;">functions</span> to create and save your list in various <span style="background-color:yellow;">forms</span> . </p>
<p>You write a bunch of little <span style="background-color:yellow;">functions</span> to load your lists in their various <span style="background-color:yellow;">forms</span> . </p>
<p>You write a little timer <span style="background-color:yellow;">function</span> to get start time , execute the load procedure a <span style="background-color:yellow;">few</span> dozen times ( to get a solid average that 's long enough that OS scheduling noise does n't dominate your measurements ) . </p>
<p>You summarize your data in a little report . </p>
<p>What 's unreliable about this ? </p>
<p>Here are some unrelated questions that shows how to measure and compare performance . </p>
<p>http : //stackoverflow.com/questions/489999/python-convert-list-of-ints-to-one-number </p>
<p>http : //stackoverflow.com/questions/376461/string-concatenation-vs-string-substitution-in-python </p>
<br /><b># 3 </b><br /><p>Do you need to always load the whole <span style="background-color:yellow;">file</span> ? If not , upack_from ( ) might be the best solution. Suppose , that you have 1000000 integers , but you 'd like to load just the ones <span style="background-color:yellow;">from</span> 50000 to 50099 , you 'd do : </p>
<pre><code>import struct
intSize = struct.calcsize('i') #this value would be constant for a given arch
intFile = open('/your/file.of.integers')
intTuple5K100 = struct.unpack_from('i'*100,intFile,50000*intSize)
</code></pre>
<br /><b># 4 </b><br /><p>To help you with timing , the Python Library provides the timeit module : </p>
<blockquote>This module provides a simple way to time small bits of Python code. It has both command line as well as callable interfaces. It avoids a number of common traps <span style="background-color:yellow;">for</span> measuring execution times . </blockquote>
<p>An example ( <span style="background-color:yellow;">from</span> the manual ) that compares the cost of using hasattr ( ) vs. try/except to test <span style="background-color:yellow;">for</span> missing and present object attributes : </p>
<pre><code>% timeit.py 'try:' '  str.__nonzero__' 'except AttributeError:' '  pass'
100000 loops, best of 3: 15.7 usec per loop
% timeit.py 'if hasattr(str, "__nonzero__"): pass'
100000 loops, best of 3: 4.26 usec per loop
% timeit.py 'try:' '  int.__nonzero__' 'except AttributeError:' '  pass'
1000000 loops, best of 3: 1.43 usec per loop
% timeit.py 'if hasattr(int, "__nonzero__"): pass'
100000 loops, best of 3: 2.23 usec per loop
</code></pre>
<br /><b># 5 </b><br /><p>cPickle will be the <span style="background-color:yellow;">fastest</span> since it is saved in binary and no real python code has to be parsed . </p>
<p>Other advantates are that it is more secure ( since it does not execute commands ) and you have no problems with setting $ PYTHONPATH correctly . </p>
<br />