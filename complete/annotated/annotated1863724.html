<h3>Question ( ID-1863724 ) : </h3><h2>Reasons for this disparity in execution speed ? </h2><p>I wrote a quick Python script to compare two <span style="background-color:yellow;">files</span> , each containing unordered hashes , in order to verify that both <span style="background-color:yellow;">files</span> are identical aside from order. Then I rewrote it in Ruby for educational purposes . </p>
<p>The Python implementation takes seconds , while the Ruby implementation takes around 4 minutes . </p>
<p>I have a feeling this is most likely due to my lack of Ruby knowledge , any ideas on what I am doing wrong ? </p>
<p>Environment is Windows XP x64 , Python 2.6 , Ruby 1.8.6 </p>
<p>Python </p>
<pre><code>f = open('c:\\file1.txt', 'r')

hashes = dict()

for line in f.readlines():
    if not line in hashes:
        hashes[line] = 1
    else:
        hashes[line] += 1


print "Done file 1"

f.close()

f = open('c:\\file2.txt', 'r')

for line in f.readlines():
    if not line in hashes:
        print "Hash not found!"
    else:
        hashes[line] -= 1

f.close()

print "Done file 2"

num_errors = 0

for key in hashes.keys():
    if hashes[key] != 0:
        print "Uneven hash count: %s" % key
        num_errors += 1

print "Total of %d mismatches found" % num_errors
</code></pre>
<p>Ruby </p>
<pre><code>file = File.open("c:\\file1.txt", "r")
hashes = {}

file.each_line { |line|
  if hashes.has_key?(line)
    hashes[line] += 1
  else
    hashes[line] = 1
  end
}

file.close()

puts "Done file 1"

file = File.open("c:\\file2.txt", "r")

file.each_line { |line|
  if hashes.has_key?(line)
    hashes[line] -= 1
  else
    puts "Hash not found!"
  end
}

file.close()

puts "Done file 2"

num_errors = 0
hashes.each_key{ |key|
  if hashes[key] != 0
    num_errors += 1
  end
}

puts "Total of #{num_errors} mismatches found"
</code></pre>
<p>EDIT To give an idea of scale , each <span style="background-color:yellow;">file</span> is pretty big , over 900 <span style="background-color:yellow;">000</span> hashes . </p>
<p>PROGRESS </p>
<p>Using a nathanvda 's suggestions , here is the optimized ruby script : </p>
<pre><code>f1 = "c:\\file1.txt"
f2 = "c:\\file2.txt"

hashes = Hash.new(0)

File.open(f1, "r") do |f|
  while line = f.gets
    hashes[line] += 1
  end
end  

not_founds = 0

File.open(f2, "r") do |f|
  while line = f.gets
    if hashes.has_key?(line)
      hashes[line] -= 1
    else
      not_founds += 1
    end
  end
end

num_errors = hashes.values.to_a.select { |z| z != 0}.size   

puts "Total of #{not_founds} lines not found in file2"
puts "Total of #{num_errors} mismatches found"
</code></pre>
<p>On windows with Ruby 1.8.7 , the original version took 250 seconds and the optimized version took 223 . </p>
<p>On a linux VM ! running ruby 1.9.1 , the original version ran in 81 seconds , about 1/3 the time as windows 1.8.7. Interestingly , the optimized version took longer at 89 seconds. Note that while <span style="background-color:yellow;">line</span> = ... was necessary due to memory constraints . </p>
<p>On windows with Ruby 1.9.1 , the original took 457 seconds and the optimized version took 543 . </p>
<p>On windows with jRuby , the original took 45 seconds and the optimized version took 43 . </p>
<p>I am somewhat surprised by the results , I was expecting 1.9.1 to be an improvement over 1.8.7 . </p>
<br /><h3>Answers ( Total-8 ) : </h3><b># <span style="background-color:yellow;">0</span> </b><br /><p>It could be because dicts in Python are much faster than hashes in Ruby </p>
<p>I 've just run a quick test , building a hash of <span style="background-color:yellow;">12345678</span> item in Ruby1.8.7 took 3 times as long as Python. Ruby1.9 was about twice as long as Python . </p>
<p>Here is how I tested python </p>
<pre><code>$ time python -c "d={}
for i in xrange(12345678):d[i]=1"
</code></pre>
<p>ruby </p>
<pre><code>$ time ruby -e "d={};12345678.times{|i|d[i]=1}"
</code></pre>
<p>Not enough to account for your discrepancy though . </p>
<p>Perhaps <span style="background-color:yellow;">file</span> I/O is worth looking <span style="background-color:yellow;">into</span> - comment out all the hash code and see how long the empty loops take to run over the <span style="background-color:yellow;">files</span> . </p>
<p>Here 's another version in Python using <span style="background-color:yellow;">defaultdict</span> and context managers </p>
<pre><code>from collections import defaultdict
hashes = defaultdict(int)

with open('c:\\file1.txt', 'r') as f:
    for line in f:
        hashes[line] += 1

print "Done file 1"

with open('c:\\file2.txt', 'r') as f:
    for line in f:
        if line in hashes:
            hashes[line] -= 1
        else:
            print "Hash not found!"

print "Done file 2"

num_errors = 0
for key,value in hashes.items():  # hashes.iteritems() might be better here
    if value != 0:
        print "Uneven hash count: %s" % key
        num_errors += 1

print "Total of %d mismatches found" % num_errors
</code></pre>
<br /><b># 1 </b><br /><p>I 've found Ruby 's reference implementation ( well , Ruby ) to be ( unscientifically stated ) dog slow . </p>
<p>If you have the opportunity , please try running your program under JRuby ! Charles Nutter and other Sun folks claim to have sped Ruby up dramatically . </p>
<p>I for one would be most <span style="background-color:yellow;">interested</span> in your results . </p>
<br /><b># 2 </b><br /><p>On the python side , you could iterate over the dictionary items like this : </p>
<pre><code>for key, value in hashes.iteritems():
    if value != 0:
        print "Uneven hash count: %s" % key
        num_errors += 1
</code></pre>
<p>Also : </p>
<pre><code>for line in f.readlines():
    hashes[line] = hashes.setdefault(line, 0) + 1
</code></pre>
<p>... but I ca n't help you with the Ruby side , other than to suggest you hunt down a profiler . </p>
<br /><b># 3 </b><br /><p>I 'm not a Ruby expert , so someone please correct me if I 'm wrong : </p>
<p>I see a small optimization potential . </p>
<p>If you say </p>
<pre><code>hashes = hash.new(0)
</code></pre>
<p>then a reference to an undefined hash will return <span style="background-color:yellow;">0</span> and store the key ; and you can do </p>
<pre><code>hashes[line] += 1
</code></pre>
<p>every time , without the enclosing if and else . </p>
<p>Caveat : Untested ! </p>
<p>If storing the key does n't happen automatically , there 's yet another hash constructor using a block where you can do it explicitly . </p>
<br /><b># 4 </b><br /><p>Python 's dictionary is brutally fast. See http : //stackoverflow.com/questions/327311/how-are-pythons-built-in-dictionaries-implemented Perhaps Ruby 's is not so crash hot . </p>
<p>I doubt it 's the hash functions. There 's no way the Ruby devs would have a hash function that 's an order of magnitude worse than Python 's . </p>
<p>Perhaps Ruby 1.8 is slow at dynamically resizing large hash tables ? How does your problem scale with smaller <span style="background-color:yellow;">files</span> ? </p>
<br /><b># 5 </b><br /><p>I was able to speed up your ruby code a bit as follows : </p>
<pre><code>require 'benchmark'

Benchmark.bm(10) do |x|

  x.report("original version") do
    file = File.open("c:\\file1.txt", "r")
    hashes = {}

    file.each_line { |line|
      if hashes.has_key?(line)
        hashes[line] += 1
      else
        hashes[line] = 1
      end
    }

    file.close()

    #puts "Done file 1"

    not_founds = 0

    file = File.open("c:\\file2.txt", "r")

    file.each_line { |line|
      if hashes.has_key?(line)
        hashes[line] -= 1
      else
        not_founds += 1        
      end
    }

    file.close()

    #puts "Done file 2"

    num_errors = 0
    hashes.each_key{ |key|
      if hashes[key] != 0
        num_errors += 1
      end
    }

    puts "Total of #{not_founds} lines not found in file2"
    puts "Total of #{num_errors} mismatches found"

  end


  x.report("my speedup") do
    hashes = {}
    File.open("c:\\file1.txt", "r") do |f|
      lines = f.readlines
      lines.each { |line|
        if hashes.has_key?(line)
          hashes[line] += 1
        else
          hashes[line] = 1
        end
      }
    end  

    not_founds = 0

    File.open("c:\\file2.txt", "r") do |f|
      lines = f.readlines
      lines.each { |line|
        if hashes.has_key?(line)
          hashes[line] -= 1
        else
          not_founds += 1
        end
      }
    end

    num_errors = hashes.values.to_a.select { |z| z != 0}.size   

    puts "Total of #{not_founds} lines not found in file2"
    puts "Total of #{num_errors} mismatches found"

  end

end
</code></pre>
<p>so i read the <span style="background-color:yellow;">files</span> in one bug chunk , this is in my case a bit faster ( i tested on Windows XP , ruby 1.8.6 and a <span style="background-color:yellow;">file</span> of <span style="background-color:yellow;">100000</span> <span style="background-color:yellow;">lines</span> ) . I benchmarked all different ways to read <span style="background-color:yellow;">files</span> ( i could think off ) , and this was the fastest way. Also i did speed up the counting of the values in a hash a bit , but this is only visible if you did it for very large numbers : ) </p>
<p>So i get a very small speed-increase here. The output on my machine is as follows : </p>
<pre><code>                user     system      total        real
original versionTotal of 16 lines not found in file2
Total of 4 mismatches found
   1.000000   0.015000   1.015000 (  1.016000)
my speedup v1Total of 16 lines not found in file2
Total of 4 mismatches found
   0.812000   0.047000   0.859000 (  0.859000)
</code></pre>
<p>Who has any ideas to improve this further ? </p>
<p>If the f.readlines goes slower , because of the size , i found that </p>
<pre><code>File.open("c:\\file2.txt", "r") do |f|
  while (line=f.gets)
    if hashes.has_key?(line)
      hashes[line] -= 1
    else
      not_founds += 1
    end
  end
end
</code></pre>
<p>is just a tad quicker for me . </p>
<p>I was thinking about about a way to improve the </p>
<pre><code>if hashes.has_key?(line) ...
</code></pre>
<p>code a bit , but could not think of anything . </p>
<p>Have you tried using Ruby 1.9 ? </p>
<p>I have a Windows 7 Virtual Machine with Ruby 1.9.1 , and there the f.readlines was slower , and i needed to use the while ( <span style="background-color:yellow;">line</span> = f.gets ) because of the memory limitations : ) </p>
<p>Since a lot uf Ruby users test mainly on Unix related platforms , i guess that could explain why the code is sub-optimal on Windows. Has anybody compared the above mentioned performance on Unix ? Is this a ruby vs. python problem , or Ruby-windows vs. Ruby-Unix ? </p>
<br /><b># 6 </b><br /><p>I 'd bet results of Ruby 1.9.x , which is faster or on par with Python in most areas , are caused by an additional overhead required by hashes/dictionaries implementation because the are ordered in Ruby contrary to Python . </p>
<br /><b># 7 </b><br /><p>I 'll try to do a benchmark in my copious free time , but try using group_by . It 's not only more like functional programming , but I 've found it to be a lot faster than the procedural version in MRI . </p>
<pre><code>def convert_to_hash(file)
  values_hash = file.each_line.group_by {|line| line}
  # Hash.[] converts an array of pairs into a hash
  count_hash = Hash[ values_hash.map{|line, lines| [line, lines.length]}]
  count_hash
end

hash1 = convert_to_hash(file)
hash2 = convert_to_hash(file2)
# compare if the two hashes are equal
</code></pre>
<br />