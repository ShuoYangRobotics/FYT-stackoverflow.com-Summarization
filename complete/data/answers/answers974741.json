[[{"text": ["Probably a unit math error on your part. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Just noticing that 500KB/s (kilobytes) is equal to 4Mb/s (megabits)."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "500KB/s (kilobytes) is equal to 4Mb/s (megabits)", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.google.com/search?hl=en&rlz=1C1GGLS%5FenUS291US304&q=500%20KB%20in%20Mb&aq=f&oq=&aqi=g1"}]}], [{"text": ["As for the html parsing, the fastest/easiest you will probably get is using lxml\nAs for the http requests themselves: httplib2 is very easy to use, and could possibly speed up downloads because it supports http 1.1 keep-alive connections and gzip compression.", "There is also pycURL which claims to be very fast (but more difficult to use), and is build on curllib, but I've never used that."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "lxml", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://codespeak.net/lxml/"}, {"text": "httplib2", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://code.google.com/p/httplib2/"}, {"text": "pycURL", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://pycurl.sourceforge.net/"}]}, {"text": ["You could also try to download different files concurrently, but also keep in mind that trying to optimize your download times too far may be not very polite towards the website in question."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Sorry for the lack of hyperlinks, but SO tells me \"sorry, new users can only post a maximum of one hyperlink\""], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Transfer speeds can be easily misleading.. Could you try with the following script, which simply downloads the same URL with both wget and urllib.urlretrieve - run it a few times incase you're behind a proxy which caches the URL on the second attempt."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "wget", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "urllib.urlretrieve", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["For small files, wget will take slightly longer due to the external process' startup time, but for larger files that should be come irrelevant."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n from time import time\nimport urllib\nimport subprocess\n\ntarget = \"http://example.com\" # change this to a more useful URL\n\nwget_start = time()\n\nproc = subprocess.Popen([\"wget\", target])\nproc.communicate()\n\nwget_end = time()\n\n\nurl_start = time()\nurllib.urlretrieve(target)\nurl_end = time()\n\nprint \"wget -&gt; %s\" % (wget_end - wget_start)\nprint \"urllib.urlretrieve -&gt; %s\"  % (url_end - url_start)\n</code>\n</pre>\n", "senID": 2}], [{"text": ["urllib works for me as fast as wget.", "try this code.", "it shows the progress in percentage just as wget."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import sys, urllib\ndef reporthook(a,b,c): \n    # ',' at the end of the line is important!\n    print \"% 3.1f%% of %d bytes\\r\" % (min(100, float(a * b) / c * 100), c),\n    #you can also use sys.stdout.write\n    #sys.stdout.write(\"\\r% 3.1f%% of %d bytes\" \n    #                 % (min(100, float(a * b) / c * 100), c)\n    sys.stdout.flush()\nfor url in sys.argv[1:]:\n     i = url.rfind('/')\n     file = url[i+1:]\n     print url, \"-&gt;\", file\n     urllib.urlretrieve(url, file, reporthook)\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Maybe you can wget and then inspect the data in Python?"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"code": "<pre>\n<code>\n import subprocess\n\nmyurl = 'http://some_server/data/'\nsubprocess.call([\"wget\", \"-r\", \"-np\", \"-A\", \"files\", myurl])\n</code>\n</pre>\n", "senID": 0}], [{"text": ["There shouldn't be a difference really.", "All urlretrieve does is make a simple HTTP GET request.", "Have you taken out your data processing code and done a straight throughput comparison of wget vs. pure python?"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Please show us some code.", "I'm pretty sure that it has to be with the code and not on urlretrieve. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I've worked with it in the past and never had any speed related issues."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["You can use wget -k to engage relative links in all urls."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "wget -k", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["please look at below, extremely strange problem.", "urllib.urlopen is giving strange result"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "urllib.urlopen is giving strange result", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/7120983/urllib-urlopen-is-giving-strange-result"}]}], [{"text": ["Since python suggests using urllib2 instead of urllib, I take a test between urllib2.urlopen and wget."], "childNum": 4, "tag": "p", "senID": 0, "childList": [{"text": "urllib2", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "urllib", "childNum": 0, "tag": "code", "childList": []}, {"text": "urllib2.urlopen", "childNum": 0, "tag": "code", "childList": []}, {"text": "wget", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["The result is, it takes nearly the same time for both of them to download the same file.Sometimes, urllib2 performs even better. "], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "urllib2", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["The advantage of wget lies in a dynamic progress bar to show the percent finished and the current download speed when transferring."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "wget", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["The file size in my test is 5MB.I haven't used any cache module in python and I am not aware of how wget works when downloading big size file. "], "childNum": 2, "tag": "p", "senID": 3, "childList": [{"text": "5MB", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "wget", "childNum": 0, "tag": "code", "childList": []}]}]]