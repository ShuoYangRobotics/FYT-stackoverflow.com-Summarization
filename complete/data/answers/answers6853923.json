[[{"text": ["Neither Rpy or Scipy is necessary, although numpy may make it a bit easier.", "This problem seems ideally suited to a line-by-line parser.", "Simply open the file, read a row into a string, scan the row into an array (see numpy.fromstring), update your running sums and move to the next line."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Python's File I/O doesn't have bad performance, so you can just use the file module directly.", "You can see what functions are available in it by typing help (file) in the interactive interpreter.", "Creating a file is part of the core language functionality and doesn't require you to import file."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "file", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "help (file)", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "import file", "childNum": 0, "tag": "code", "pos": 2, "childList": []}]}, {"text": ["Something like:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n f = open (\"C:\\BigScaryFinancialData.txt\", \"r\");\nfor line in f.readlines():\n    #line is a string type\n    #do whatever you want to do on a per-line basis here, for example:\n    print len(line)\n</code>\n</pre>\n", "senID": 2}, {"text": ["Disclaimer: This is a Python 2 answer.", "I'm not 100% sure this works in Python 3."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["I'll leave it to you to figure out how to show the top 10 rows and find the row sums.", "This can be done with simple program logic that shouldn't be a problem without any special libraries.", "Of course, if the rows have some kind of complicated formatting that makes it difficult to parse out the values, you might want to use some kind of module for parsing, re for example (type help(re) into the interactive interpreter)."], "childNum": 2, "tag": "p", "senID": 4, "childList": [{"text": "re", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "help(re)", "childNum": 0, "tag": "code", "pos": 2, "childList": []}]}], [{"text": ["I don't know anything about Rpy.", "I do know that SciPy is used to do serious number-crunching with truly large data sets, so it should work for your problem."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["As zephyr noted, you may not need either one; if you just need to keep some running sums, you can probably do it in Python.", "If it is a CSV file or other common file format, check and see if there is a Python module that will parse it for you, and then write a loop that sums the appropriate values. "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["I'm not sure how to get the top ten rows.", "Can you gather them on the fly as you go, or do you need to compute the sums and then choose the rows?", "To gather them you might want to use a dictionary to keep track of the current 10 best rows, and use the keys to store the metric you used to rank them (to make it easy to find and toss out a row if another row supersedes it).", "If you need to find the rows after the computation is done, slurp all the data into a numpy.array, or else just take a second pass through the file to pull out the ten rows. "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["How huge is your data, is it larger than your PC's memory?", "If it can be loaded into memory, you can use numpy.loadtxt() to load text data into a numpy array.", "for example:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import numpy as np\nwith file(\"data.csv\", \"rb\") as f:\n   title = f.readline()  # if your data have a title line.\n   data = np.loadtxt(f, delimiter=\",\") # if your data splitted by \",\"\n   print np.sum(data, axis=0)  # sum along 0 axis to get the sum of every column\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Since this has the R tag I'll give some R solutions:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"tag": "ul", "num": 4, "lis": [{"text": "Overview\n", "tag": "none", "senID": 1}, {"text": ["bigmemory"], "childNum": 0, "tag": "code", "senID": 2, "childList": []}, {"text": "XDF format ", "tag": "none", "senID": 3}, {"text": "Hadoop interfaces to R (RHIPE, etc.)", "tag": "none", "senID": 4}]}], [{"text": ["As @gsk3 noted, bigmemory is a great package for this, along with the packages biganalytics and bigtabulate (there are more, but these are worth checking out).", "There's also ff, though that isn't as easy to use."], "childNum": 4, "tag": "p", "senID": 0, "childList": [{"text": "bigmemory", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "biganalytics", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "bigtabulate", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "ff", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"text": ["Common to both R and Python is support for HDF5 (see the ncdf4 or NetCDF4 packages in R), which makes it very speedy and easy to access massive data sets on disk.", "Personally, I primarily use bigmemory, though that's R specific.", "As HDF5 is available in Python and is very, very fast, it's probably going to be your best bet in Python."], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "ncdf4", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "NetCDF4", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "bigmemory", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}]]