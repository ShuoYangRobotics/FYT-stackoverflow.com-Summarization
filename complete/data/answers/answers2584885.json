[[{"text": ["With BeautifulSoup:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from BeautifulSoup import BeautifulSoup    \n''.join(BeautifulSoup(page).findAll(text=True))\n</code>\n</pre>\n", "senID": 1}, {"text": ["Found at http://www.ghastlyfop.com/blog/2008/12/strip-html-tags-from-string-python.html"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://www.ghastlyfop.com/blog/2008/12/strip-html-tags-from-string-python.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.ghastlyfop.com/blog/2008/12/strip-html-tags-from-string-python.html"}]}], [{"text": ["Solution using BeautifulSoup:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "BeautifulSoup", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n from BeautifulSoup import BeautifulSoup\ndef removeTag(soup, tagname):\n    for tag in soup.findAll(tagname):\n        contents = tag.contents\n        parent = tag.parent\n        tag.extract()\n\ns = BeautifulSoup(\"abcd &lt;b&gt; btag &lt;/b&gt; hello &lt;d&gt;dtag&lt;/d&gt;\")\n\nremoveTag(s,\"b\")\nprint s\nremoveTag(s, \"d\")\nprint s\n</code>\n</pre>\n", "senID": 1}, {"text": ["returns:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt;\nabcd  hello &lt;d&gt;dtag&lt;/d&gt;\nabcd  hello\n</code>\n</pre>\n", "senID": 3}], [{"text": ["If you don't mind Python (although regexps are fairly generic), you can take some inspiration from Django's strip_tags filter."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Django's strip_tags filter", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.djangoproject.com/browser/django/trunk/django/utils/html.py#L57"}]}, {"text": ["Reproduced here for completeness -"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n def strip_tags(value):\n    \"\"\"Returns the given HTML with all tags stripped.\"\"\"\n    return re.sub(r'&lt;[^&gt;]*?&gt;', '', force_unicode(value))\n</code>\n</pre>\n", "senID": 2}, {"text": ["EDIT: If you're using this, or any other regexp solution, please keep in mind that it lets through carefully-crafted HTML (see comment) as well as HTML comments and hence should not be used with untrusted input.", "Consider using some of the beautifulsoup, html5lib or lxml answers for untrusted input instead."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["Looks like you want HTMLParser.", "(html.parser in Python 3."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "HTMLParser", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "html.parser", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"code": "<pre>\n<code>\n from HTMLParser import HTMLParser\nfrom sys import stdout\nclass Filter(HTMLParser):\n    def __init__(self, ignored_tags):\n        super(Filter, self).__init__()\n        self.ignorelevel = 0\n        self. ignored_tags = ignored_tags\n    def handle_starttag(self, tag, attrs):\n        if self.ignorelevel &gt; 0:\n            self.ignorelevel += 1\n        elif tag in self.ignored_tags:\n            self.ignorelevel = 1\n        else:\n            # One of these two.  Test and see.\n            stdout.write(self.get_starttag_text())\n            #stdout.write('&lt;' + self.get_starttag_text() + '&gt;')\n    def handle_startendtag(self, tag, attrs):\n        if self.ignorelevel == 0 and tag not in self.ignored_tags:\n            # One of these two.  Test and see.\n            stdout.write(self.get_starttag_text())\n            #stdout.write('&lt;' + self.get_starttag_text() + '/&gt;')\n    def handle_endtag(self, tag):\n        if self.ignorelevel &gt; 0:\n            self.ignorelevel -= 1\n            if self.ignorelevel &gt; 0:\n                return\n        stdout.write('&lt;/' + tag + '&gt;')\n    def handle_data(self, data):\n        stdout.write(data)\n    def handle_charref(self, name):\n        stdout.write('&amp;#' + name + ';')\n    def handle_entityref(self, name):\n        stdout.write('&amp;' + name + ';')\n    def handle_comment(self, data):\n        stdout.write('&lt;!-- ' + data + ' --&gt;')\n    def handle_decl(self, data):\n        stdout.write('&lt;!' + data + '&gt;')\n    def handle_pi(self, data):\n        stdout.write('&lt;?' + data + '&gt;')\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Try with:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import re\ninput = 'this is test &lt;b&gt; bold text &lt;/b&gt; normal text'\noutput = re.compile(r'&lt;[^&lt;]*?/?&gt;').sub('', input)\nprint output\n</code>\n</pre>\n", "senID": 1}], [{"text": ["I would use http://code.google.com/p/html5lib/ if you want to include some safe tags."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://code.google.com/p/html5lib/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.google.com/p/html5lib/"}]}, {"text": ["See the \"Sanitizing Tokenizer\" section at http://code.google.com/p/html5lib/wiki/UserDocumentation."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://code.google.com/p/html5lib/wiki/UserDocumentation", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.google.com/p/html5lib/wiki/UserDocumentation"}]}, {"text": ["Remember to test for vulnerabilities if it's an important service: http://ha.ckers.org/xss.html."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://ha.ckers.org/xss.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://ha.ckers.org/xss.html"}]}], [{"text": ["Sam's answer should do what's wanted fairly well as far as I can tell, but it may pay to make sure that any left over &lt;&gt; characters are replaced with &amp;lt; and &amp;gt; respectively to prevent misuse/invalid HTML. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["This approach has the advantage that it can accept incredibly malformed HTML references/tags.", "BeautifulSoup also handles malformed tags fairly well but html5lib, sgmllib and htmllib can choke on invalid code, some more than others if I remember correctly."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["The following code also validates &amp; HTML references:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n import re\nfrom htmlentitydefs import name2codepoint, codepoint2name\n\nS = '1234567890ABCDEF'\nDHex = {}\nfor i in S:\n    DHex[i.lower()] = None\n    DHex[i.upper()] = None\n\ndef IsHex(S):\n    if not S: return False\n    for i in S: \n        if i not in DHex:\n            return False\n    return True\n\ndef UnEscape(S, LReEscape=None):\n    # Converts HTML character references into a unicode string to allow manipulation\n    #\n    # If LUnEscape is provided, then the positions of the escaped characters will be \n    # added to allow turning the result back into HTML with ReEscape below, validating \n    # the references and escaping all the rest\n    # \n    # This is needed to prevent browsers from stripping out e.g. &amp;#32; (spaces) etc\n    re = LReEscape != None\n\n    LRtn = []\n    L = S.split('&amp;')\n    xx = 0\n    yy = 0\n    for iS in L:\n        if xx:\n            LSplit = iS.split(';')\n            if LSplit[0].lower() in name2codepoint:\n                # A character reference, e.g. '&amp;amp;'\n                a = unichr(name2codepoint[LSplit[0].lower()])\n                LRtn.append(a+';'.join(LSplit[1:]))\n                if re: LReEscape.append((yy, a))\n\n            elif LSplit[0] and LSplit[0][0] == '#' and LSplit[0][1:].isdigit():\n                # A character number e.g. '&amp;#52;'\n                a = unichr(int(LSplit[0][1:]))\n                LRtn.append(a+';'.join(LSplit[1:]))\n                if re: LReEscape.append((yy, a))\n\n            elif LSplit[0] and LSplit[0][0] == '#' and LSplit[0][1:2].lower() == 'x' and IsHex(LSplit[0][2:]):\n                # A hexadecimal encoded character\n                a = unichr(int(LSplit[0][2:].lower(), 16)) # Hex -&gt; base 16\n                LRtn.append(a+';'.join(LSplit[1:]))\n                if re: LReEscape.append((yy, a))\n\n            else: LRtn.append('&amp;%s' % ';'.join(LSplit))\n        else: LRtn.append(iS)\n        xx += 1\n        yy += len(LRtn[-1])\n    return ''.join(LRtn)\n\ndef ReEscape(LReEscape, S, EscFn):\n    # Re-escapes the output of UnEscape to HTML, ensuring e.g. &amp;#32; \n    # is turned back again and isn't stripped at a browser level\n    L = []\n    prev = 0\n    for x, c in LReEscape:\n        if x != prev:\n            L.append(EscFn(S[prev:x]))\n\n        o = ord(c)\n        if o in codepoint2name:\n            L.append('&amp;%s;' % codepoint2name[o])\n        else: L.append('&amp;#%s;' % o)\n        prev = x+len(c)\n    L.append(EscFn(S[prev:]))\n    return ''.join(L)\n\ndef escape(value):\n    # Escape left over &lt;&gt;&amp; tags\n    value = value.replace('&amp;', '&amp;amp;')\n    value = value.replace('&gt;', '&amp;gt;')\n    value = value.replace('&lt;', '&amp;lt;')\n    return value\n\ndef strip_tags(value):\n    # Strip HTML tags\n    value = re.sub(r'&lt;[^&gt;]*?&gt;', '', value)\n    print 'No Tags:', value\n\n    # Validate &amp; references\n    LReEscape = []\n    value = UnEscape(value, LReEscape)\n    value = ReEscape(LReEscape, value, EscFn=escape)\n    print 'References Validated:', value\n    return value\n\nif __name__ == '__main__':\n    # Outputs:\n    #  No Tags: this is test  bold text  normal text &gt;&lt; &amp;blah &amp;amp; &amp;amp\n    #  References Validated: this is test  bold text  normal text &amp;gt;&amp;lt; &amp;amp;blah &amp;amp; &amp;amp;\n    strip_tags('this is test &lt;b&gt; bold text &lt;/b&gt; normal text &gt;&lt; &amp;blah &amp;amp; &amp;amp')\n</code>\n</pre>\n", "senID": 3}], [{"text": ["This is working code taken from my project Supybot, so it's fairly well tested:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Supybot", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://sf.net/projects/supybot/"}]}, {"code": "<pre>\nclass HtmlToText(sgmllib.SGMLParser):\n    \"\"\"Taken from some eff-bot code on c.l.p.\"\"\"\n    entitydefs = htmlentitydefs.entitydefs.copy()\n    entitydefs['nbsp'] = ' '\n    def __init__(self, tagReplace=' '):\n        self.data = []\n        self.tagReplace = tagReplace\n        sgmllib.SGMLParser.__init__(self)\n\n    def unknown_starttag(self, tag, attr):\n        self.data.append(self.tagReplace)\n\n    def unknown_endtag(self, tag):\n        self.data.append(self.tagReplace)\n\n    def handle_data(self, data):\n        self.data.append(data)\n\n    def getText(self):\n        text = ''.join(self.data).strip()\n        return normalizeWhitespace(text)\n\ndef htmlToText(s, tagReplace=' '):\n    \"\"\"Turns HTML into text.  tagReplace is a string to replace HTML tags with.\n    \"\"\"\n    x = HtmlToText(tagReplace)\n    x.feed(s)\n    return x.getText()\n</pre>\n", "senID": 1}, {"text": ["As the docstring notes, it originated with Fredrik Lundh, not me.", "As they say, great authors steal :)"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]]