[[{"text": ["Here is pretty much everything you need to get started.", "Read the section \"Listing 7.", "Simple Python Web site crawler\".", "The examples are even written in python."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["http://www.ibm.com/developerworks/linux/library/l-spider/"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://www.ibm.com/developerworks/linux/library/l-spider/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.ibm.com/developerworks/linux/library/l-spider/"}]}, {"text": ["Good luck!"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["A popular web scraping module for Python is Scrapy.", "Go ahead and take a look at the tutorial link at the bottom for instance."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Scrapy", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://scrapy.org/"}]}], [{"text": ["you're looking for \"web scraping\". "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["you can Google around to find quite a bit of different techniques and utilities such as this one"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["http://www.webscrape.com/"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://www.webscrape.com/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.webscrape.com/"}]}, {"text": ["more info "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["http://blogs.computerworld.com/node/324"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "http://blogs.computerworld.com/node/324", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://blogs.computerworld.com/node/324"}]}], [{"text": ["Is it necessary to do it in Python?", "If not, HTTrack could be the perfect solution for you.", "This can copy entire sites into a hierarchy of HTML files.", "If you are looking for a Python solution, try Scrapy."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "HTTrack", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.httrack.com/"}, {"text": "Scrapy", "tag": "a", "pos": 3, "childList": [], "childNum": 0, "href": "http://scrapy.org/"}]}], [{"text": ["You could use wget with the --spider option."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "wget", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.gnu.org/software/wget/"}, {"text": "--spider", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["Last time I had to do something like this, I started something like this:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from BeautifulSoup import BeautifulSoup\nimport urllib\nhtml = urllib.urlopen(\"http://www.someurl.com\")\nhtml = html.read()\nsoup = BeautifulSoup(html)\n</code>\n</pre>\n", "senID": 1}, {"text": ["Here is the documentation for Beautiful Soup (http://www.crummy.com/software/BeautifulSoup/documentation.html) and while it may be overkill for your purposes, it is handy to know in my opinion."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]]