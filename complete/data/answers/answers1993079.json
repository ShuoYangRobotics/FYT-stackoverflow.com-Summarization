[[{"text": ["You want to do non-blocking I/O with the select module."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "select module", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/select.html"}]}, {"text": ["There are a couple of different specific techniques.", "select.select should work for every major platform.", "There are other variations that are more efficient (and could matter if you are checking tens of thousands of connections simultaneously) but you will then need to write the code for you specific platform."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["I've run into this situation before.", "Just make a pool of Tasks, and spawn a fixed number of threads that run an endless loop which grabs a Task from the pool, run it, and repeat.", "Essentially you're implementing your own thread abstraction and using the OS threads to implement it."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["This does have drawbacks, the major one being that if your Tasks block for long periods of time they can prevent the execution of other Tasks.", "But it does let you create an unbounded number of Tasks, limited only by memory."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Does Python have any sort of asynchronous IO functionality?", "That would be the preferred answer IMO - spawning an extra thread for each outbound connection isn't as neat as having a single thread which is effectively event-driven."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Using different processes, and pipes to transfer data.", "Using threads in python is pretty lame.", "From what I heard, they don't actually run in parallel, even if you have a multi-core processor...", "But maybe it was fixed in python3."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["The standard way is to have each thread get next tasks in a loop instead of dying after processing just one.", "This way you don't have to keep track of the number of threads, since you just fire a fixed number of them.", "As a bonus, you save on thread creation/destruction."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Make sure your threads get destroyed properly after they've been used or use a threadpool, although per what I see they're not that effective in Python"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["see here:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["http://code.activestate.com/recipes/203871/"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://code.activestate.com/recipes/203871/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.activestate.com/recipes/203871/"}]}], [{"text": ["Using the select module or a similar library would most probably be a more efficient solution, but that would require bigger architectural changes."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "select", "tag": "a", "pos": 0, "childList": [{"text": "select", "tag": "code"}], "childNum": 1, "href": "http://docs.python.org/library/select.html"}, {"text": "select", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["If you just want to limit the number of threads, a global counter should be fine, as long as you access it in a thread safe way."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Be careful to minimize the default thread stack size.", "At least on Linux, the default limit puts severe restrictions on the number of created threads.", "Linux allocates a chunk of the process virtual address space to the stack (usually 10MB).", "300 threads x 10MB stack allocation = 3GB of virtual address space dedicated to stack, and on a 32 bit system you have a 3GB limit.", "You can probably get away with much less."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["A counting semaphore should do the trick."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from socket import *\nfrom threading import *\n\nmaxthreads = 1000\nthreads_sem = Semaphore(maxthreads)\n\nclass MyThread(Thread):\n    def __init__(self, conn, addr):\n        Thread.__init__(self)\n        self.conn = conn\n        self.addr = addr\n    def run(self):\n        try:\n            read = conn.recv(4096)\n            if read == 'go away\\n':\n                global running\n                running = False\n            conn.close()\n        finally:\n            threads_sem.release()\n\nsock = socket()\nsock.bind(('0.0.0.0', 2323))\nsock.listen(1)\nrunning = True\nwhile running:\n    conn, addr = sock.accept()\n    threads_sem.acquire()\n    MyThread(conn, addr).start()\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Twisted is a perfect fit for this problem.", "See http://twistedmatrix.com/documents/current/core/howto/clients.html for a tutorial on writing a client."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Twisted", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://twistedmatrix.com/trac/"}, {"text": "http://twistedmatrix.com/documents/current/core/howto/clients.html", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://twistedmatrix.com/documents/current/core/howto/clients.html"}]}, {"text": ["If you don't mind using alternate Python implmentations, Stackless has light-weight (non-native) threads.", "The only company I know doing much with it though is CCP--they use it for tasklets in their game on both the client and server.", "You still need to do async I/O with Stackless because if a thread blocks, the process blocks."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "Stackless", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.stackless.com/"}]}], [{"text": ["As mentioned in another thread, why do you spawn off a new thread for each single operation?", "This is a classical producer - consumer problem, isn't it?", "Depending a bit on how you look at it, the proxy checkers might be comsumers or producers."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Anyway, the solution is to make a \"queue\" of \"tasks\" to process, and make the threads in a loop check if there are any more tasks to perform in the queue, and if there isn't, wait a predefined interval, and check again."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You should protect your queue with some locking mechanisms, i.e.", "semaphores, to prevent race conditions."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["It's really not that difficult.", "But it requires a bit of thinking getting it right.", "Good luck!"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}]]