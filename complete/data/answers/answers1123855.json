[[{"text": ["It doesn't look like there's an official way to handle this yet.", "Or at least, not based on this:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"tag": "ul", "num": 1, "lis": [{"text": ["http://bugs.python.org/issue3831"], "childNum": 0, "tag": "a", "senID": 1, "childList": []}]}, {"text": ["You could try something like what this post is doing -- accessing the underlying pipe filehandles:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"tag": "ul", "num": 1, "lis": [{"text": ["http://haltcondition.net/?p=2319"], "childNum": 0, "tag": "a", "senID": 3, "childList": []}]}, {"text": ["and then use select."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["Actually you can use multiprocessing.Queue objects in select.select.", "i.e. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n que = multiprocessing.Queue()\n(input,[],[]) = select.select([que._reader],[],[])\n</code>\n</pre>\n", "senID": 1}, {"text": ["would select que only if it is ready to be read from. "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["No documentation about it though.", "I was reading the source code of the multiprocessing.queue library (at linux it's usually sth like /usr/lib/python2.6/multiprocessing/queue.py) to find it out."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["With Queue.Queue I didn't have found any smart way to do this (and I would really love to)."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["You could use something like the Observer pattern, wherein Queue subscribers are notified of state changes."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Observer", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Observer%5Fpattern"}]}, {"text": ["In this case, you could have your worker thread designated as a listener on each queue, and whenever it receives a ready signal, it can work on the new item, otherwise sleep."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Seems like using threads which forward incoming items to a single Queue which you then wait on is a practical choice when using multiprocessing in a platform independent manner."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Avoiding the threads requires either handling low-level pipes/FDs which is both platform specific and not easy to handle consistently with the higher-level API.  "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Or you would need Queues with the ability to set callbacks which i think are the proper higher level interface to go for.", "I.e.", "you would write something like:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\nsinglequeue = Queue()\n  incoming_queue1.setcallback(singlequeue.put)\n  incoming_queue2.setcallback(singlequeue.put)\n  ...\n  singlequeue.get()\n</pre>\n", "senID": 3}, {"text": ["Maybe the multiprocessing package could grow this API but it's not there yet.", "The concept works well with py.execnet which uses the term \"channel\" instead of \"queues\", see here http://tinyurl.com/nmtr4w "], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "http://tinyurl.com/nmtr4w", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://tinyurl.com/nmtr4w"}]}], [{"text": ["Not sure how well the select on a multiprocessing queue works on windows.", "As select on windows listens for sockets and not file handles, I suspect there could be problems."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["My answer is to make a thread to listen to each queue in a blocking fashion, and to put the results all into a single queue listened to by the main thread, essentially multiplexing the individual queues into a single one."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["My code for doing this is:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n \"\"\"\nAllow multiple queues to be waited upon.\n\nqueue,value = multiq.select(list_of_queues)\n\"\"\"\nimport queue\nimport threading\n\nclass queue_reader(threading.Thread):\n    def __init__(self,inq,sharedq):\n        threading.Thread.__init__(self)\n        self.inq = inq\n        self.sharedq = sharedq\n    def run(self):\n        while True:\n            data = self.inq.get()\n            print (\"thread reads data=\",data)\n            result = (self.inq,data)\n            self.sharedq.put(result)\n\nclass multi_queue(queue.Queue):\n    def __init__(self,list_of_queues):\n        queue.Queue.__init__(self)\n        for q in list_of_queues:\n            qr = queue_reader(q,self)\n            qr.start()\n\ndef select(list_of_queues):\n    outq = queue.Queue()\n    for q in list_of_queues:\n        qr = queue_reader(q,outq)\n        qr.start()\n    return outq.get()\n</code>\n</pre>\n", "senID": 3}, {"text": ["The following test routine shows how to use it:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n import multiq\nimport queue\n\nq1 = queue.Queue()\nq2 = queue.Queue()\n\nq3 = multiq.multi_queue([q1,q2])\n\nq1.put(1)\nq2.put(2)\nq1.put(3)\nq1.put(4)\n\nres=0\nwhile not res==4:\n    while not q3.empty():\n        res = q3.get()[1]\n        print (\"returning result =\",res)\n</code>\n</pre>\n", "senID": 5}, {"text": ["Hope this helps."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["Tony Wallace"], "childNum": 0, "tag": "p", "senID": 7, "childList": []}], [{"text": ["New version of above code..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Not sure how well the select on a multiprocessing queue works on windows.", "As select on windows listens for sockets and not file handles, I suspect there could be problems."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["My answer is to make a thread to listen to each queue in a blocking fashion, and to put the results all into a single queue listened to by the main thread, essentially multiplexing the individual queues into a single one."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["My code for doing this is:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n \"\"\"\nAllow multiple queues to be waited upon.\n\nAn EndOfQueueMarker marks a queue as\n    \"all data sent on this queue\".\nWhen this marker has been accessed on\nall input threads, this marker is returned\nby the multi_queue.\n\n\"\"\"\nimport queue\nimport threading\n\nclass EndOfQueueMarker:\n    def __str___(self):\n        return \"End of data marker\"\n    pass\n\nclass queue_reader(threading.Thread):\n    def __init__(self,inq,sharedq):\n        threading.Thread.__init__(self)\n        self.inq = inq\n        self.sharedq = sharedq\n    def run(self):\n        q_run = True\n        while q_run:\n            data = self.inq.get()\n            result = (self.inq,data)\n            self.sharedq.put(result)\n            if data is EndOfQueueMarker:\n                q_run = False\n\nclass multi_queue(queue.Queue):\n    def __init__(self,list_of_queues):\n        queue.Queue.__init__(self)\n        self.qList = list_of_queues\n        self.qrList = []\n        for q in list_of_queues:\n            qr = queue_reader(q,self)\n            qr.start()\n            self.qrList.append(qr)\n    def get(self,blocking=True,timeout=None):\n        res = []\n        while len(res)==0:\n            if len(self.qList)==0:\n                res = (self,EndOfQueueMarker)\n            else:\n                res = queue.Queue.get(self,blocking,timeout)\n                if res[1] is EndOfQueueMarker:\n                    self.qList.remove(res[0])\n                    res = []\n        return res\n\n    def join(self):\n        for qr in self.qrList:\n            qr.join()\n\ndef select(list_of_queues):\n    outq = queue.Queue()\n    for q in list_of_queues:\n        qr = queue_reader(q,outq)\n        qr.start()\n    return outq.get()\n</code>\n</pre>\n", "senID": 4}, {"text": ["The follow code is my test routine to show how it works:"], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"code": "<pre>\n<code>\n import multiq\nimport queue\n\nq1 = queue.Queue()\nq2 = queue.Queue()\n\nq3 = multiq.multi_queue([q1,q2])\n\nq1.put(1)\nq2.put(2)\nq1.put(3)\nq1.put(4)\nq1.put(multiq.EndOfQueueMarker)\nq2.put(multiq.EndOfQueueMarker)\nres=0\nhave_data = True\nwhile have_data:\n    res = q3.get()[1]\n    print (\"returning result =\",res)\n    have_data = not(res==multiq.EndOfQueueMarker)\n</code>\n</pre>\n", "senID": 6}]]