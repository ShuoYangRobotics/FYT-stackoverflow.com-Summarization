[[{"text": ["Python's compiler is deliberately dirt-simple -- this makes it fast and highly predictable.", "Apart from some constant folding, it basically generates bytecode that faithfully mimics your sources.", "Somebody else already suggested dis, and it's indeed a good way to look at the bytecode you're getting -- for example, how for i in [1, 2, 3]: isn't actually doing constant folding but generating the literal list on the fly, while for i in (1, 2, 3): (looping on a literal tuple instead of a literal list) is able to constant-fold (reason: a list is a mutable object, and to keep to the \"dirt-simple\" mission statement the compiler doesn't bother to check that this specific list is never modified so it could be optimized into a tuple)."], "childNum": 5, "tag": "p", "senID": 0, "childList": [{"text": "dis", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/dis.html?highlight=dis#module-dis"}, {"text": "for i in [1, 2, 3]:", "childNum": 0, "tag": "code", "childList": []}, {"text": "for i in (1, 2, 3):", "childNum": 0, "tag": "code", "childList": []}, {"text": "is", "childNum": 0, "tag": "strong", "childList": []}, {"text": "could", "childNum": 0, "tag": "em", "childList": []}]}, {"text": ["So there's space for ample manual micro-optimization -- hoisting, in particular.", "I.e., rewrite"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n for x in whatever():\n    anobj.amethod(x)\n</code>\n</pre>\n", "senID": 2}, {"text": ["as"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n f = anobj.amethod\nfor x in whatever():\n    f(x)\n</code>\n</pre>\n", "senID": 4}, {"text": ["to save the repeated lookups (the compiler doesn't check whether a run of anobj.amethod can actually change anobj's bindings &amp;c so that a fresh lookup is needed next time -- it just does the dirt-simple thing, i.e., no hoisting, which guarantees correctness but definitely doesn't guarantee blazing speed;-)."], "childNum": 2, "tag": "p", "senID": 5, "childList": [{"text": "anobj.amethod", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "anobj", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["The timeit module (best used at a shell prompt IMHO) makes it very simple to measure the overall effects of compilation + bytecode interpretation (just ensure the snippet you're measuring has no side effects that would affect the timing, since timeit does run it over and over in a loop;-).", "For example:"], "childNum": 3, "tag": "p", "senID": 6, "childList": [{"text": "timeit", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/timeit.html?highlight=timeit#module-timeit"}, {"text": "timeit", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "does", "childNum": 0, "tag": "strong", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n $ python -mtimeit 'for x in (1, 2, 3): pass'\n1000000 loops, best of 3: 0.219 usec per loop\n$ python -mtimeit 'for x in [1, 2, 3]: pass'\n1000000 loops, best of 3: 0.512 usec per loop\n</code>\n</pre>\n", "senID": 7}, {"text": ["you can see the costs of the repeated list construction -- and confirm that is indeed what we're observing by trying a minor tweak:"], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"code": "<pre>\n<code>\n $ python -mtimeit -s'Xs=[1,2,3]' 'for x in Xs: pass'\n1000000 loops, best of 3: 0.236 usec per loop\n$ python -mtimeit -s'Xs=(1,2,3)' 'for x in Xs: pass'\n1000000 loops, best of 3: 0.213 usec per loop\n</code>\n</pre>\n", "senID": 9}, {"text": ["moving the iterable's construction to the -s setup (which is run only once and not timed) shows that the looping proper is slightly faster on tuples (maybe 10%), but the big issue with the first pair (list slower than tuple by over 100%) is mostly with the construction."], "childNum": 1, "tag": "p", "senID": 10, "childList": [{"text": "-s", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Armed with timeit and the knowledge that the compiler's deliberately very simple minded in its optimizations, we can easily answer other questions of yours:"], "childNum": 1, "tag": "p", "senID": 11, "childList": [{"text": "timeit", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n $ python -mtimeit -s'def f(): pass' 'f()'\n10000000 loops, best of 3: 0.192 usec per loop\n$ python -mtimeit -s'class o: pass' 'o()'\n1000000 loops, best of 3: 0.315 usec per loop\n$ python -mtimeit -s'class n(object): pass' 'n()'\n10000000 loops, best of 3: 0.18 usec per loop\n</code>\n</pre>\n", "senID": 12}, {"text": ["so we see: instantiating a new-style class and calling a function (both empty) are about the same speed, with instantiations possibly having a tiny speed margin, maybe 5%; instantiating an old-style class is slowest (by about 50%).", "Tiny differences such as 5% or less of course could be noise, so repeating each try a few times is advisable; but differences like 50% are definitely well beyond noise."], "childNum": 0, "tag": "p", "senID": 13, "childList": []}, {"code": "<pre>\n<code>\n $ python -mtimeit -s'from math import sqrt' 'sqrt(1.2)'\n1000000 loops, best of 3: 0.22 usec per loop\n$ python -mtimeit '1.2**0.5'\n10000000 loops, best of 3: 0.0363 usec per loop\n$ python -mtimeit '1.2*0.5'\n10000000 loops, best of 3: 0.0407 usec per loop\n</code>\n</pre>\n", "senID": 14}, {"text": ["and here we see: calling sqrt is slower than doing the same computation by operator (using the ** raise-to-power operator) by roughly the cost of calling an empty function; all arithmetic operators are roughly the same speed to within noise (the tiny difference of 3 or 4 nanoseconds is definitely noise;-).", "Checking whether constant folding might interfere:"], "childNum": 2, "tag": "p", "senID": 15, "childList": [{"text": "sqrt", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "**", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n $ python -mtimeit '1.2*0.5'\n10000000 loops, best of 3: 0.0407 usec per loop\n$ python -mtimeit -s'a=1.2; b=0.5' 'a*b'\n10000000 loops, best of 3: 0.0965 usec per loop\n$ python -mtimeit -s'a=1.2; b=0.5' 'a*0.5'\n10000000 loops, best of 3: 0.0957 usec per loop\n$ python -mtimeit -s'a=1.2; b=0.5' '1.2*b'\n10000000 loops, best of 3: 0.0932 usec per loop\n</code>\n</pre>\n", "senID": 16}, {"text": ["...we see that this is indeed the case: if either or both numbers are being looked up as variables (which blocks constant folding), we're paying the \"realistic\" cost.", "Variable lookup has its own cost:"], "childNum": 0, "tag": "p", "senID": 17, "childList": []}, {"code": "<pre>\n<code>\n $ python -mtimeit -s'a=1.2; b=0.5' 'a'\n10000000 loops, best of 3: 0.039 usec per loop\n</code>\n</pre>\n", "senID": 18}, {"text": ["and that's far from negligible when we're trying to measure such tiny times anyway.", "Indeed constant lookup isn't free either:"], "childNum": 1, "tag": "p", "senID": 19, "childList": [{"text": "constant", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"code": "<pre>\n<code>\n $ python -mtimeit -s'a=1.2; b=0.5' '1.2'\n10000000 loops, best of 3: 0.0225 usec per loop\n</code>\n</pre>\n", "senID": 20}, {"text": ["as you see, while smaller than variable lookup it's quite comparable -- about half."], "childNum": 0, "tag": "p", "senID": 21, "childList": []}, {"text": ["If and when (armed with careful profiling and measurement) you decide some nucleus of your computations desperately need optimization, I recommend trying cython -- it's a C / Python merge which tries to be as neat as Python and as fast as C, and while it can't get there 100% it surely makes a good fist of it (in particular, it makes binary code that's quite a bit faster than you can get with its predecessor language, pyrex, as well as being a bit richer than it).", "For the last few %'s of performance you probably still want to go down to C (or assembly / machine code in some exceptional cases), but that would be really, really rare."], "childNum": 2, "tag": "p", "senID": 22, "childList": [{"text": "cython", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.cython.org/"}, {"text": "pyrex", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://www.cosc.canterbury.ac.nz/greg.ewing/python/Pyrex/"}]}], [{"text": ["S.Lott is right: the big effects are data structures and algorithms.", "Also, if you are doing a lot of I/O, how you manage it will make a big difference."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["But if you are curious about the compiler internals: it will fold constants, but it will not inline functions or unroll loops.", "Inlining functions is a hard problem in a dynamic language."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You can see what the compiler does by disassembling some compiled code.", "Put some sample code in my_file.py, then use:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n python -m dis my_file.py\n</code>\n</pre>\n", "senID": 3}, {"text": ["This source:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n def foo():\n    return \"BAR!\"\n\nfor i in [1,2,3]:\n    print i, foo()\n</code>\n</pre>\n", "senID": 5}, {"text": ["produces:"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n 1           0 LOAD_CONST               0 (&lt;code object foo at 01A0B380, file \"\\foo\\bar.py\", line 1&gt;)\n              3 MAKE_FUNCTION            0\n              6 STORE_NAME               0 (foo)\n\n  4           9 SETUP_LOOP              35 (to 47)\n             12 LOAD_CONST               1 (1)\n             15 LOAD_CONST               2 (2)\n             18 LOAD_CONST               3 (3)\n             21 BUILD_LIST               3\n             24 GET_ITER\n        &gt;&gt;   25 FOR_ITER                18 (to 46)\n             28 STORE_NAME               1 (i)\n\n  5          31 LOAD_NAME                1 (i)\n             34 PRINT_ITEM\n             35 LOAD_NAME                0 (foo)\n             38 CALL_FUNCTION            0\n             41 PRINT_ITEM\n             42 PRINT_NEWLINE\n             43 JUMP_ABSOLUTE           25\n        &gt;&gt;   46 POP_BLOCK\n        &gt;&gt;   47 LOAD_CONST               4 (None)\n             50 RETURN_VALUE\n</code>\n</pre>\n", "senID": 7}, {"text": ["Notice that only the top-level code in the module is disassembled, you need to write a little more code yourself to recurse through the nested code objects if you want to see the function definitions disassembled as well."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}], [{"text": ["The speed of your code might be automatically improved by using the Psyco module."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Psyco", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://psyco.sourceforge.net/psycoguide/node8.html"}]}, {"text": ["As for Numpy, it generally speeds things up by a significant factor.", "I consider it a must when manipulating numerical arrays."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You might also want to speed up the critical parts of your code with Cython or Pyrex, which allow you to create faster extension modules without having to write a full-fledged extension module in C (which would be more cumbersome)."], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "Cython", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://cython.org/"}, {"href": "http://www.cosc.canterbury.ac.nz/greg.ewing/python/Pyrex/version/Doc/About.html", "text": "Pyrex", "childNum": 0, "tag": "a", "childList": []}]}], [{"text": ["Here's what's interesting."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": ["Data Structure"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Algorithm"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]}, {"text": ["Those will yield dramatic improvements.  "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Your list is good for -- at best -- a few single-digit performance improvements."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["You need to fundamentally rethink your data structures if you want to see real speed improvements."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}], [{"text": ["I'm the author of Arauna.", "I know nothing about Python, but I do know that Arauna is extremely optimized, both high level (data structures &amp; algorithms) and low-level (cache friendly code, SIMD, multithreading).", "It's a hard target to go for..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["If you already know that your algorithm is as fast as possible, and you know that C would be much faster, then you may want to implement the core of your code in C as a C extension to Python.", "You can pragmatically decide which part of the code goes in C and which is in Python, using each language to its full potential."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "C extension to Python", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://nedbatchelder.com/text/whirlext.html"}]}, {"text": ["Unlike some other languages, calling between C and Python is very fast, so there's no penalty for crossing the border often."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}]]