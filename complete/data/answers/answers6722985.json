[[{"text": ["Generator expressions are evaluated lazily, so if you only need to determine whether or not your word is valid,  I would expect the following to be more efficient since it doesn't necessarily force it to build the full list once it finds a match:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n def word_exists(wordlist, word_fragment):\n    return any(w.startswith(word_fragment) for w in wordlist)\n</code>\n</pre>\n", "senID": 1}, {"text": ["Note that the lack of square brackets is important for this to work. "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["However this is obviously still linear in the worst case.", "You're correct that binary search would be more efficient; you can use the built-in bisect module for that.", "It might look something like this:"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "bisect", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"code": "<pre>\n<code>\n from bisect import bisect_left\ndef word_exists(wordlist, word_fragment):\n    try:\n        return wordlist[bisect_left(wordlist, word_fragment)].startswith(word_fragment)\n    except IndexError:\n        return False # word_fragment is greater than all entries in wordlist\n</code>\n</pre>\n", "senID": 4}, {"text": ["bisect_left runs in O(log(n)) so is going to be considerably faster for a large wordlist."], "childNum": 1, "tag": "p", "senID": 5, "childList": [{"text": "bisect_left", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Edit: I would guess that the example you gave loses out if your word_fragment is something really common (like 't'), in which case it probably spends most of its time assembling a large list of valid words, and the gain from only having to do a partial scan of the list is negligible.", "Hard to say for sure, but it's a little academic since binary search is better anyway."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["You're right that you can do this more efficiently given that the list is sorted."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I'm building off of @Peter's answer, which returns a single element.", "I see that you want all the words that start with a given prefix.", "Here's how you do that:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n from bisect import bisect_left\nwordlist[bisect_left(wordlist, word_fragment):\n         bisect_left(wordlist, word_fragment[:-1] + chr(ord(word_fragment[-1])+1))]\n</code>\n</pre>\n", "senID": 2}, {"text": ["This returns the slice from your original sorted list."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["As Peter suggested I would use the Bisect module.", "Especially if you're reading from a large file of words."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If you really need speed you could make a daemon ( How do you create a daemon in Python?", ") that has a pre-processed data structure suited for the task"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "How do you create a daemon in Python?", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/473620/how-do-you-create-a-daemon-in-python"}]}, {"text": ["I suggest you could use \"tries\""], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["http://www.topcoder.com/tc?module=Static&amp;d1=tutorials&amp;d2=usingTries"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://www.topcoder.com/tc?module=Static&amp;d1=tutorials&amp;d2=usingTries", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.topcoder.com/tc?module=Static&d1=tutorials&d2=usingTries"}]}, {"text": ["an example would be:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n start={'a':nodea,'b':nodeb,'c':nodec...}\nnodea={'a':nodeaa,'b':nodeab,'c':nodeac...}\nnodeb={'a':nodeba,'b':nodebb,'c':nodebc...}\netc..\n</code>\n</pre>\n", "senID": 5}, {"text": ["then if you want all the words starting with ab you would just traverse\nstart['a']['b'] and that would be all the words you want."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["to build it you could iterate through your wordlist and for each word, iterate through the characters adding a new default dict where required."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}], [{"code": "<pre>\n<code>\n def win(wordlist, word_fragment):\n    for w in wordlist:\n        if w.startswith(word_fragment):\n            return True\n    return False\n</code>\n</pre>\n", "senID": 0}, {"text": ["and a (much) faster alternative in my computer:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n wordlist = '|' + '|'.join(wordlist)\n\ndef win(wordlist, word_fragment):\n    return wordlist.find('|' + word_fragment) &gt;= 0\n</code>\n</pre>\n", "senID": 2}, {"text": ["using timeit and a list of 119 words (hit at pos 117):"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n first code =      23.7743686215\nsecond code =     0.730970647231 *\nfrom other answers:\nPeter is_valid = 28.8863064379\nPeter bisect =    0.653793858957 **\n</code>\n</pre>\n", "senID": 4}, {"text": ["result however could vary with long lists.", "bisect gets the best times with lists longer than aprox 100 word and the hit at the end of the list."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["In the case the hit is at the beginning of the list (pos 4, this would be the case of common frecuently-found word_fragments) things change:"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n first code =      0.812527867094\nsecond code =     0.348066418047  **\nfrom other answers:\nPeter is_valid = 1.45509848559\nPeter bisect =    0.650626750662  *\n</code>\n</pre>\n", "senID": 7}], [{"text": ["In case of binary search (assuming wordlist is sorted), I'm thinking of something like this:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n wordlist = \"ab\", \"abc\", \"bc\", \"bcf\", \"bct\", \"cft\", \"k\", \"l\", \"m\"\nfragment = \"bc\"\na, m, b = 0, 0, len(wordlist)-1\niterations = 0\n\nwhile True:\n    if (a + b) / 2 == m: break # endless loop = nothing found\n    m = (a + b) / 2\n    iterations += 1\n    if wordlist[m].startswith(fragment): break # found word\n    if wordlist[m] &gt; fragment &gt;= wordlist[a]: a, b = a, m\n    elif wordlist[b] &gt;= fragment &gt;= wordlist[m]: a, b = m, b\n\nif wordlist[m].startswith(fragment):\n    print wordlist[m], iterations\nelse:\n    print \"Not found\", iterations\n</code>\n</pre>\n", "senID": 1}, {"text": ["It will find one matched word, or none.", "You will then have to look to the left and right of it to find other matched words.", "My algorithm might be incorrect, its just a rough version of my thoughts."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Here's my fastest way to narrow the list wordlist down to a list of valid words starting with a given fragment :"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "wordlist", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["sect() is a generator function that uses the excellent Peter's idea to employ bisect, and the islice() function :"], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "sect()", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "bisect", "childNum": 0, "tag": "strong", "childList": []}, {"text": "islice()", "childNum": 0, "tag": "strong", "childList": []}]}, {"code": "<pre>\n<code>\n from bisect import bisect_left\nfrom itertools import islice\n\nfrom time import clock\n\nA,B = [],[]\n\n\niterations = 5\nrepetition = 10\n\nwith open('words.txt') as f:\n    wordlist = f.read().split()\n\nwordlist.sort()\nprint 'wordlist[0:10]==',wordlist[0:10]\n\n\ndef sect(wordlist,word_fragment):\n    lgth = len(word_fragment)\n    for w in islice(wordlist,bisect_left(wordlist, word_fragment),None):\n        if w[0:lgth]==word_fragment:\n            yield w\n        else:\n            break\n\n\ndef hooloo(wordlist,word_fragment):\n    usque = len(word_fragment)\n    for w in wordlist:\n        if w[:usque] &gt; word_fragment:\n            break\n        if w.startswith(word_fragment):\n            yield w\n\n\nfor rep in xrange(repetition):\n    te = clock()\n    for i in xrange(iterations):\n        newlistA = list(sect(wordlist,'VEST'))\n    A.append(clock()-te)\n\n    te = clock()\n    for i in xrange(iterations):\n        newlistB = list(hooloo(wordlist,'VEST'))\n    B.append(clock() - te)\n\n\nprint '\\niterations =',iterations,'   number of tries:',repetition,'\\n'\nprint newlistA,'\\n',min(A),'\\n'\nprint newlistB,'\\n',min(B),'\\n'\n</code>\n</pre>\n", "senID": 2}, {"text": ["result"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n wordlist[0:10]== ['AA', 'AAH', 'AAHED', 'AAHING', 'AAHS', 'AAL', 'AALII', 'AALIIS', 'AALS', 'AARDVARK']\n\niterations = 5    number of tries: 30 \n\n['VEST', 'VESTA', 'VESTAL', 'VESTALLY', 'VESTALS', 'VESTAS', 'VESTED', 'VESTEE', 'VESTEES', 'VESTIARY', 'VESTIGE', 'VESTIGES', 'VESTIGIA', 'VESTING', 'VESTINGS', 'VESTLESS', 'VESTLIKE', 'VESTMENT', 'VESTRAL', 'VESTRIES', 'VESTRY', 'VESTS', 'VESTURAL', 'VESTURE', 'VESTURED', 'VESTURES'] \n0.0286089433154 \n\n['VEST', 'VESTA', 'VESTAL', 'VESTALLY', 'VESTALS', 'VESTAS', 'VESTED', 'VESTEE', 'VESTEES', 'VESTIARY', 'VESTIGE', 'VESTIGES', 'VESTIGIA', 'VESTING', 'VESTINGS', 'VESTLESS', 'VESTLIKE', 'VESTMENT', 'VESTRAL', 'VESTRIES', 'VESTRY', 'VESTS', 'VESTURAL', 'VESTURE', 'VESTURED', 'VESTURES'] \n0.415578236899\n</code>\n</pre>\n", "senID": 4}, {"text": ["sect() is 14.5 times faster than holloo()"], "childNum": 2, "tag": "p", "senID": 5, "childList": [{"text": "sect()", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "holloo()", "childNum": 0, "tag": "strong", "childList": []}]}, {"text": ["PS:"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["I know the existence of timeit, but here, for such a result, clock() is fully sufficient"], "childNum": 2, "tag": "p", "senID": 7, "childList": [{"text": "timeit", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "clock()", "childNum": 0, "tag": "strong", "childList": []}]}], [{"text": ["Doing binary search in the list is not going to guarantee you anything.", "I am not sure how that would work either.  "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["You have a list which is ordered, it is a good news.", "The algorithmic performance complexity of both your cases is O(n) which is not bad, that you just have to iterate through the whole wordlist once."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["But in the second case, the performance (engineering performance) should be better because you are breaking as soon as you find that rest cases will not apply.", "Try to have a list where 1st element is match and rest 38000 - 1 elements do not match, you will the second will beat the first."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]]