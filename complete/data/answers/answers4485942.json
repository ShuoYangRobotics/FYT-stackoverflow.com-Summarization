[[{"text": ["I think what you are looking for arebuffers."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "I think what you are looking for arebuffers.", "childNum": 1, "tag": "strong", "pos": 0, "childList": [{"text": "buffers", "tag": "a"}]}, {"href": "http://docs.python.org/library/functions.html#buffer", "text": "buffers", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["The characteristic of buffers is that they \"slice\" an object supporting the buffer interface without copying its content, but essentially opening a \"window\" on the sliced object content.", "Some more technical explanation is available here.", "An excerpt:"], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "without copying its content", "childNum": 0, "tag": "em", "pos": 0, "childList": []}, {"text": "here", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://docs.python.org/c-api/buffer.html"}]}, {"text": ["In your case the code should look more or less like this:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; s = 'Hugely_long_string_not_to_be_copied'\n&gt;&gt;&gt; ij = [(0, 3), (6, 9), (12, 18)]\n&gt;&gt;&gt; for i, j in ij:\n...     print buffer(s, i, j-i)  # Should become process(...)\nHug\n_lo\nstring\n</code>\n</pre>\n", "senID": 3}, {"text": ["HTH!"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["A wrapper that uses index offsets to a mmap object could work, yes. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["But before you do that, are you sure that generating these substrings are a problem?", "Don't optimize before you have found out where the time and memory actually goes.", "I wouldn't expect this to be a significant problem."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["If you are using Python3 you can use protocol buffer and memory views.", "Assuming that the text is stored somewhere in the filesystem:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n f = open(FILENAME, 'rb')\ndata = bytearray(os.path.getsize(FILENAME))\nf.readinto(data)\n\nmv = memoryview(data)\n\nfor (i, j) in huge_list_of_indices:\n    process(mv[i:j])\n</code>\n</pre>\n", "senID": 1}, {"text": ["Check also this article.", "It might be useful."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "this", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://eli.thegreenplace.net/2011/11/28/less-copies-in-python-with-the-buffer-protocol-and-memoryviews/"}]}], [{"text": ["Maybe a wrapper that uses index offsets is indeed what you are looking for.", "Here is an example that does the job.", "You may have to add more checks on slices (for overflow and negative indexes) depending on your needs."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n #!/usr/bin/env python\n\nfrom collections import Sequence\nfrom timeit import Timer\n\ndef process(s):\n    return s[0], len(s)\n\nclass FakeString(Sequence):\n    def __init__(self, string):\n        self._string = string\n        self.fake_start = 0\n        self.fake_stop = len(string)\n\n    def setFakeIndices(self, i, j):\n        self.fake_start = i\n        self.fake_stop = j\n\n    def __len__(self):\n        return self.fake_stop - self.fake_start\n\n    def __getitem__(self, ii):\n        if isinstance(ii, slice):\n            if ii.start is None:\n                start = self.fake_start\n            else:\n                start = ii.start + self.fake_start\n            if ii.stop is None:\n                stop = self.fake_stop\n            else:\n                stop = ii.stop + self.fake_start\n            ii = slice(start,\n                       stop,\n                       ii.step)\n        else:\n            ii = ii + self.fake_start\n        return self._string[ii]\n\ndef initial_method():\n    r = []\n    for n in xrange(1000):\n        r.append(process(huge_string[1:9999999]))\n    return r\n\ndef alternative_method():\n    r = []\n    for n in xrange(1000):\n        fake_string.setFakeIndices(1, 9999999)\n        r.append(process(fake_string))\n    return r\n\n\nif __name__ == '__main__':\n    huge_string = 'ABCDEFGHIJ' * 100000\n    fake_string = FakeString(huge_string)\n\n    fake_string.setFakeIndices(5,15)\n    assert fake_string[:] == huge_string[5:15]\n\n    t = Timer(initial_method)\n    print \"initial_method(): %fs\" % t.timeit(number=1)\n</code>\n</pre>\n", "senID": 1}, {"text": ["which gives:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n initial_method(): 1.248001s  \nalternative_method(): 0.003416s\n</code>\n</pre>\n", "senID": 3}], [{"text": ["The example the OP gives, will give nearly biggest performance difference between slicing and not slicing possible."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If processing actually does something that takes significant time, the problem may hardly exist."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "may", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Fact is OP needs to let us know what process does.", "The most likely scenario is it does something significant, and therefore he should profile his code."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "profile his code.", "childNum": 0, "tag": "strong", "pos": 1, "childList": []}]}, {"text": ["Adapted from op's example:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n #slice_time.py\n\nimport time\nimport string\ntext = string.letters * 1000\nimport random\nindices = range(len(text))\nrandom.shuffle(indices)\nimport re\n\n\ndef greater_processing(a_string):\n    results = re.findall('m', a_string)\n\ndef medium_processing(a_string):\n    return re.search('m.*?m', a_string)                                                                              \n\ndef lesser_processing(a_string):\n    return re.match('m', a_string)\n\ndef least_processing(a_string):\n    return a_string\n\ndef timeit(fn, processor):\n    t1 = time.time()\n    for i in indices:\n        fn(i, i + 1000, processor)\n    t2 = time.time()\n    print '%s took %0.3f ms %s' % (fn.func_name, (t2-t1) * 1000, processor.__name__)\n\ndef test_part_slice(i, j, processor):\n    return processor(text[i:j])\n\ndef test_copy(i, j, processor):\n    return processor(text[:])\n\ndef test_text(i, j, processor):\n    return processor(text)\n\ndef test_buffer(i, j, processor):\n    return processor(buffer(text, i, j - i))\n\nif __name__ == '__main__':\n    processors = [least_processing, lesser_processing, medium_processing, greater_processing]\n    tests = [test_part_slice, test_copy, test_text, test_buffer]\n    for processor in processors:\n        for test in tests:\n            timeit(test, processor)\n</code>\n</pre>\n", "senID": 4}, {"text": ["And then the run..."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"code": "<pre>\n<code>\n In [494]: run slice_time.py\ntest_part_slice took 68.264 ms least_processing\ntest_copy took 42.988 ms least_processing\ntest_text took 33.075 ms least_processing\ntest_buffer took 76.770 ms least_processing\ntest_part_slice took 270.038 ms lesser_processing\ntest_copy took 197.681 ms lesser_processing\ntest_text took 196.716 ms lesser_processing\ntest_buffer took 262.288 ms lesser_processing\ntest_part_slice took 416.072 ms medium_processing\ntest_copy took 352.254 ms medium_processing\ntest_text took 337.971 ms medium_processing\ntest_buffer took 438.683 ms medium_processing\ntest_part_slice took 502.069 ms greater_processing\ntest_copy took 8149.231 ms greater_processing\ntest_text took 8292.333 ms greater_processing\ntest_buffer took 563.009 ms greater_processing\n</code>\n</pre>\n", "senID": 6}, {"text": ["Notes:"], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Yes I tried OP's original test_1 with [i:] slice and it's much slower, making his test even more bunk."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["Interesting that buffer almost always performs slightly slower then slicing.", "This time there is one where it does better though!", "The real test though is below and buffer seems to do better for larger substrings while slicing does better for smaller substrings."], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"text": ["And, yes, I do have some randomness in this test so test away and see the different results :).", "It also may be interesting to changes the size of the 1000's."], "childNum": 0, "tag": "p", "senID": 10, "childList": []}, {"text": ["So, maybe some others believe you, but I don't, so I'd like to know something about what processing does and how you came to the conclusion: \"slicing is the problem."], "childNum": 3, "tag": "p", "senID": 11, "childList": [{"text": "I don't", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "processing does", "childNum": 0, "tag": "strong", "childList": []}, {"text": "slicing is the problem.", "childNum": 0, "tag": "strong", "childList": []}]}, {"text": ["I profiled medium processing in my example and upped the string.letters multiplier to 100000 and raised the length of the slices to 10000.", "Also below is one with slices of length 100.", "I used cProfile for these (much less overhead then profile!", ")."], "childNum": 0, "tag": "p", "senID": 12, "childList": []}, {"code": "<pre>\n<code>\n test_part_slice took 77338.285 ms medium_processing\n         31200019 function calls in 77.338 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.000    0.000   77.338   77.338 &lt;string&gt;:1(&lt;module&gt;)\n        2    0.000    0.000    0.000    0.000 iostream.py:63(write)\n  5200000    8.208    0.000   43.823    0.000 re.py:139(search)\n  5200000    9.205    0.000   12.897    0.000 re.py:228(_compile)\n  5200000    5.651    0.000   49.475    0.000 slice_time.py:15(medium_processing)\n        1    7.901    7.901   77.338   77.338 slice_time.py:24(timeit)\n  5200000   19.963    0.000   69.438    0.000 slice_time.py:31(test_part_slice)\n        2    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n        2    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n        2    0.000    0.000    0.000    0.000 {isinstance}\n        2    0.000    0.000    0.000    0.000 {method 'decode' of 'str' objects}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n  5200000    3.692    0.000    3.692    0.000 {method 'get' of 'dict' objects}\n  5200000   22.718    0.000   22.718    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n        4    0.000    0.000    0.000    0.000 {time.time}\n\n\ntest_buffer took 58067.440 ms medium_processing\n         31200103 function calls in 58.068 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.000    0.000   58.068   58.068 &lt;string&gt;:1(&lt;module&gt;)\n        3    0.000    0.000    0.000    0.000 __init__.py:185(dumps)\n        3    0.000    0.000    0.000    0.000 encoder.py:102(__init__)\n        3    0.000    0.000    0.000    0.000 encoder.py:180(encode)\n        3    0.000    0.000    0.000    0.000 encoder.py:206(iterencode)\n        1    0.000    0.000    0.001    0.001 iostream.py:37(flush)\n        2    0.000    0.000    0.001    0.000 iostream.py:63(write)\n        1    0.000    0.000    0.000    0.000 iostream.py:86(_new_buffer)\n        3    0.000    0.000    0.000    0.000 jsonapi.py:57(_squash_unicode)\n        3    0.000    0.000    0.000    0.000 jsonapi.py:69(dumps)\n        2    0.000    0.000    0.000    0.000 jsonutil.py:78(date_default)\n        1    0.000    0.000    0.000    0.000 os.py:743(urandom)\n  5200000    6.814    0.000   39.110    0.000 re.py:139(search)\n  5200000    7.853    0.000   10.878    0.000 re.py:228(_compile)\n        1    0.000    0.000    0.000    0.000 session.py:149(msg_header)\n        1    0.000    0.000    0.000    0.000 session.py:153(extract_header)\n        1    0.000    0.000    0.000    0.000 session.py:315(msg_id)\n        1    0.000    0.000    0.000    0.000 session.py:350(msg_header)\n        1    0.000    0.000    0.000    0.000 session.py:353(msg)\n        1    0.000    0.000    0.000    0.000 session.py:370(sign)\n        1    0.000    0.000    0.000    0.000 session.py:385(serialize)\n        1    0.000    0.000    0.001    0.001 session.py:437(send)\n        3    0.000    0.000    0.000    0.000 session.py:75(&lt;lambda&gt;)\n  5200000    4.732    0.000   43.842    0.000 slice_time.py:15(medium_processing)\n        1    5.423    5.423   58.068   58.068 slice_time.py:24(timeit)\n  5200000    8.802    0.000   52.645    0.000 slice_time.py:40(test_buffer)\n        7    0.000    0.000    0.000    0.000 traitlets.py:268(__get__)\n        2    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n        1    0.000    0.000    0.000    0.000 uuid.py:101(__init__)\n        1    0.000    0.000    0.000    0.000 uuid.py:197(__str__)\n        1    0.000    0.000    0.000    0.000 uuid.py:531(uuid4)\n        2    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n        1    0.000    0.000    0.000    0.000 {built-in method now}\n       18    0.000    0.000    0.000    0.000 {isinstance}\n        4    0.000    0.000    0.000    0.000 {len}\n        1    0.000    0.000    0.000    0.000 {locals}\n        1    0.000    0.000    0.000    0.000 {map}\n        2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.StringIO' objects}\n        1    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n        2    0.000    0.000    0.000    0.000 {method 'decode' of 'str' objects}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n        1    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n  5200001    3.025    0.000    3.025    0.000 {method 'get' of 'dict' objects}\n        1    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n        3    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n  5200000   21.418    0.000   21.418    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n        1    0.000    0.000    0.000    0.000 {method 'send_multipart' of 'zmq.core.socket.Socket' objects}\n        2    0.000    0.000    0.000    0.000 {method 'strftime' of 'datetime.date' objects}\n        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n        1    0.000    0.000    0.000    0.000 {posix.close}\n        1    0.000    0.000    0.000    0.000 {posix.open}\n        1    0.000    0.000    0.000    0.000 {posix.read}\n        4    0.000    0.000    0.000    0.000 {time.time}\n</code>\n</pre>\n", "senID": 13}, {"text": ["Smaller slices (100 length)."], "childNum": 0, "tag": "p", "senID": 14, "childList": []}, {"code": "<pre>\n<code>\n test_part_slice took 54916.153 ms medium_processing\n         31200019 function calls in 54.916 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.000    0.000   54.916   54.916 &lt;string&gt;:1(&lt;module&gt;)\n        2    0.000    0.000    0.000    0.000 iostream.py:63(write)\n  5200000    6.788    0.000   38.312    0.000 re.py:139(search)\n  5200000    8.014    0.000   11.257    0.000 re.py:228(_compile)\n  5200000    4.722    0.000   43.034    0.000 slice_time.py:15(medium_processing)\n        1    5.594    5.594   54.916   54.916 slice_time.py:24(timeit)\n  5200000    6.288    0.000   49.322    0.000 slice_time.py:31(test_part_slice)\n        2    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n        2    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n        2    0.000    0.000    0.000    0.000 {isinstance}\n        2    0.000    0.000    0.000    0.000 {method 'decode' of 'str' objects}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n  5200000    3.242    0.000    3.242    0.000 {method 'get' of 'dict' objects}\n  5200000   20.268    0.000   20.268    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n        4    0.000    0.000    0.000    0.000 {time.time}\n\n\ntest_buffer took 62019.684 ms medium_processing\n         31200103 function calls in 62.020 seconds\n\n   Ordered by: standard name\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.000    0.000   62.020   62.020 &lt;string&gt;:1(&lt;module&gt;)\n        3    0.000    0.000    0.000    0.000 __init__.py:185(dumps)\n        3    0.000    0.000    0.000    0.000 encoder.py:102(__init__)\n        3    0.000    0.000    0.000    0.000 encoder.py:180(encode)\n        3    0.000    0.000    0.000    0.000 encoder.py:206(iterencode)\n        1    0.000    0.000    0.001    0.001 iostream.py:37(flush)\n        2    0.000    0.000    0.001    0.000 iostream.py:63(write)\n        1    0.000    0.000    0.000    0.000 iostream.py:86(_new_buffer)\n        3    0.000    0.000    0.000    0.000 jsonapi.py:57(_squash_unicode)\n        3    0.000    0.000    0.000    0.000 jsonapi.py:69(dumps)\n        2    0.000    0.000    0.000    0.000 jsonutil.py:78(date_default)\n        1    0.000    0.000    0.000    0.000 os.py:743(urandom)\n  5200000    7.426    0.000   41.152    0.000 re.py:139(search)\n  5200000    8.470    0.000   11.628    0.000 re.py:228(_compile)\n        1    0.000    0.000    0.000    0.000 session.py:149(msg_header)\n        1    0.000    0.000    0.000    0.000 session.py:153(extract_header)\n        1    0.000    0.000    0.000    0.000 session.py:315(msg_id)\n        1    0.000    0.000    0.000    0.000 session.py:350(msg_header)\n        1    0.000    0.000    0.000    0.000 session.py:353(msg)\n        1    0.000    0.000    0.000    0.000 session.py:370(sign)\n        1    0.000    0.000    0.000    0.000 session.py:385(serialize)\n        1    0.000    0.000    0.001    0.001 session.py:437(send)\n        3    0.000    0.000    0.000    0.000 session.py:75(&lt;lambda&gt;)\n  5200000    5.399    0.000   46.551    0.000 slice_time.py:15(medium_processing)\n        1    5.958    5.958   62.020   62.020 slice_time.py:24(timeit)\n  5200000    9.510    0.000   56.061    0.000 slice_time.py:40(test_buffer)\n        7    0.000    0.000    0.000    0.000 traitlets.py:268(__get__)\n        2    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n        1    0.000    0.000    0.000    0.000 uuid.py:101(__init__)\n        1    0.000    0.000    0.000    0.000 uuid.py:197(__str__)\n        1    0.000    0.000    0.000    0.000 uuid.py:531(uuid4)\n        2    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n        1    0.000    0.000    0.000    0.000 {built-in method now}\n       18    0.000    0.000    0.000    0.000 {isinstance}\n        4    0.000    0.000    0.000    0.000 {len}\n        1    0.000    0.000    0.000    0.000 {locals}\n        1    0.000    0.000    0.000    0.000 {map}\n        2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.StringIO' objects}\n        1    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n        2    0.000    0.000    0.000    0.000 {method 'decode' of 'str' objects}\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n        1    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n  5200001    3.158    0.000    3.158    0.000 {method 'get' of 'dict' objects}\n        1    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n        3    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n  5200000   22.097    0.000   22.097    0.000 {method 'search' of '_sre.SRE_Pattern' objects}\n        1    0.000    0.000    0.000    0.000 {method 'send_multipart' of 'zmq.core.socket.Socket' objects}\n        2    0.000    0.000    0.000    0.000 {method 'strftime' of 'datetime.date' objects}\n        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n        1    0.000    0.000    0.000    0.000 {posix.close}\n        1    0.000    0.000    0.000    0.000 {posix.open}\n        1    0.000    0.000    0.000    0.000 {posix.read}\n        4    0.000    0.000    0.000    0.000 {time.time}\n</code>\n</pre>\n", "senID": 15}], [{"text": ["Completely contradictory.", "How can you imagine to find a way for not creating what the function requires ?"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "", "childNum": 0, "tag": "br", "pos": 0, "childList": []}]}]]