[[{"text": ["If you need fast serialization use marshal module.", "It's around 400x faster than your methods."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "marshal", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.python.org/doc/2.5.2/lib/module-marshal.html"}]}], [{"text": ["You want the struct module."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n packed = struct.pack('l', 123456)\nassert struct.unpack('l', packed)[0] == 123456\n</code>\n</pre>\n", "senID": 1}], [{"text": ["How about"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from binascii import hexlify, unhexlify\n\ndef xstr(x):\n    hex = '%x' % x\n    return unhexlify('0'*(len(hex)%2) + hex)[::-1]\n\ndef xlong(s):\n    return int(hexlify(s[::-1]), 16)\n</code>\n</pre>\n", "senID": 1}, {"text": ["I didn't time it but it should be faster and also work on larger numbers, since it doesn't use recursion."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["In fact, I have a lack of long(s,256) .", "I lurk more and see that there are 2 function in Python CAPI file \"longobject.h\":"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n PyObject * _PyLong_FromByteArray( const unsigned char* bytes, size_t n, int little_endian, int is_signed);\nint _PyLong_AsByteArray(PyLongObject* v, unsigned char* bytes, size_t n, int little_endian, int is_signed);\n</code>\n</pre>\n", "senID": 1}, {"text": ["They do the job.", "I don't know why there are not included in some python module, or correct me if I'am wrong."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["I'm guessing you don't care about the string format, you just want a serialization?", "If so, why not use Python's built-in serializer, the cPickle module?", "The dumps function will convert any python object including a long integer to a string, and the loads function is its inverse.", "If you're doing this for saving out to a file, check out the dump and load functions, too."], "childNum": 5, "tag": "p", "senID": 0, "childList": [{"text": "cPickle", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.python.org/doc/2.5.2/lib/module-cPickle.html"}, {"text": "dumps", "childNum": 0, "tag": "code", "pos": 2, "childList": []}, {"text": "loads", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "dump", "childNum": 0, "tag": "code", "pos": 3, "childList": []}, {"text": "load", "childNum": 0, "tag": "code", "childList": []}]}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; import cPickle\n&gt;&gt;&gt; print cPickle.loads(cPickle.dumps(13**666)) % 666\n73\n&gt;&gt;&gt; print (13**666) % 666\n73\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Performance of cPickle vs. marshal (Python 2.5.2, Windows):"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "cPickle", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "marshal", "childNum": 0, "tag": "code", "childList": []}]}, {"code": "<pre>\n<code>\n python -mtimeit -s\"from cPickle import loads,dumps;d=13**666\" \"loads(dumps(d))\"\n1000 loops, best of 3: 600 usec per loop\n\npython -mtimeit -s\"from marshal import loads,dumps;d=13**666\" \"loads(dumps(d))\"\n100000 loops, best of 3: 7.79 usec per loop\n\npython -mtimeit -s\"from pickle import loads,dumps;d= 13**666\" \"loads(dumps(d))\"\n1000 loops, best of 3: 644 usec per loop\n</code>\n</pre>\n", "senID": 1}, {"text": ["marshal is much faster."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "marshal", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}]]