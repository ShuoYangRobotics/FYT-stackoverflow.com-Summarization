[[{"text": ["PyTables and numpy are the way to go."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["PyTables will store the data on disk in HDF format, with optional compression.", "My datasets often get 10x compression, which is handy when dealing with tens or hundreds of millions of rows.", "It's also very fast; my 5 year old laptop can crunch through data doing SQL-like GROUP BY aggregation at 1,000,000 rows/second.", "Not bad for a Python-based solution!"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Accessing the data as a numpy recarray again is as simple as:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n data = table[row_from:row_to]\n</code>\n</pre>\n", "senID": 3}, {"text": ["The HDF library takes care of reading in the relevant chunks of data and converting to numpy."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["numpy.arrays are meant to live in memory.", "If you want to work with matrices larger than your RAM, you have to work around that.", "There are at least two approaches you can follow:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "numpy.array", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["You should be able to use numpy.memmap to memory map a file on disk.", "With newer python and 64-bit machine, you should have the necessary address space, without loading everything into memory.", "The OS should handle only keep part of the file in memory."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["To handle sparse matrices, you need the scipy package that sits on top of numpy -- see here for more details about the sparse-matrix options that scipy gives you."], "childNum": 4, "tag": "p", "senID": 0, "childList": [{"text": "scipy", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "numpy", "childNum": 0, "tag": "code", "childList": []}, {"href": "http://www.scipy.org/SciPy%5FTutorial#head-c60163f2fd2bab79edd94be43682414f18b90df7", "text": "here", "childNum": 0, "tag": "a", "childList": []}, {"text": "scipy", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["Stefano Borini's post got me to look into how far along this sort of thing already is.  "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "post", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/1053928/python-numpy-very-large-matrices/1053953#1053953"}]}, {"text": ["This is it.", "It appears to do basically what you want.", "HDF5 will let you store very large datasets, and then access and use them in the same ways NumPy does.  "], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "This is it.", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://h5py.alfven.org/"}]}], [{"text": ["Usually when we deal with large matrices we implement them as Sparse Matrices."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Sparse Matrices", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Sparse%5Fmatrix"}]}, {"text": ["I don't know if numpy supports sparse matrices but I found this instead."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "this", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.scipy.org/SciPy%5FTutorial"}]}], [{"text": ["As far as I know about numpy, no, but I could be wrong. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I can propose you this alternative solution: write the matrix on the disk and access it in chunks.", "I suggest you the HDF5 file format.", "If you need it transparently, you can reimplement the ndarray interface to paginate your disk-stored matrix into memory.", "Be careful if you modify the data to sync them back on the disk. "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Are you asking how to handle a 2,500,000,000 element matrix without terabytes of RAM?  "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["The way to handle 2 billion items without 8 billion bytes of RAM is by not keeping the matrix in memory."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["That means much more sophisticated algorithms to fetch it from the file system in pieces."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Make sure you're using a 64-bit operating system and a 64-bit version of Python/NumPy.", "Note that on 32-bit architectures you can address typically 3GB of memory (with about 1GB lost to memory mapped I/O and such). "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["With 64-bit and things arrays larger than the available RAM you can get away with virtual memory, though things will get slower if you have to swap.", "Also, memory maps (see numpy.memmap) are a way to work with huge files on disk without loading them into memory, but again, you need to have a 64-bit address space to work with for this to be of much use.", "PyTables will do most of this for you as well."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}]]