[[{"text": ["It is possible to do this in Python using the multiprocessing module -- this spawns multiple processes instead of threads, which bypasses the GIL and hence allows true concurrency."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "multiprocessing", "tag": "a", "pos": 0, "childList": [{"text": "multiprocessing", "tag": "code"}], "childNum": 1, "href": "http://docs.python.org/library/multiprocessing.html"}, {"text": "multiprocessing", "childNum": 0, "tag": "code", "childList": []}, {"text": "processes", "childNum": 0, "tag": "em", "childList": []}]}, {"text": ["That is not to say that Python is the 'best' language for this job; that's a subjective point which can be argued over.", "But it is certainly capable of it."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["EDIT: Yes, there are several ways to share data between processes.", "Pipes are the simplest; they are sort-of file-like handles which one process can write to and then another can read from.", "Straight from the docs:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n from multiprocessing import Process, Pipe\n\ndef f(conn):\n    conn.send([42, None, 'hello'])\n    conn.close()\n\nif __name__ == '__main__':\n    parent_conn, child_conn = Pipe()\n    p = Process(target=f, args=(child_conn,))\n    p.start()\n    print parent_conn.recv()   # prints \"[42, None, 'hello']\"\n    p.join()\n</code>\n</pre>\n", "senID": 3}, {"text": ["You could for instance have one process performing the first step and sending the results down a pipe to another process for the second step."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["It is pretty easy to do multiprocessing with R (or definitely not harder than in Python); check out multicore package and other listed here."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "multicore", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://cran.at.r-project.org/web/packages/multicore/index.html"}, {"href": "http://cran.at.r-project.org/web/views/HighPerformanceComputing.html", "text": "here", "childNum": 0, "tag": "a", "childList": []}]}], [{"text": ["I find that using R with the foreach package is really an easy way to use multithreading in your code.", "Use the doMC or the doMPI package as the parallel back-end if you have a UNIX-alike or windows respectively.", "The vignette should get you going fairly quickly.", "This method is mostly best for parallelizing for loops, and i find that using 7 of the 8 cores on my machine usually give nearly a sixfold speed increase.", "I'm not sure that you can start a second process based on results of the first, but it is worth a quick look."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "foreach", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://cran.r-project.org/web/packages/foreach/index.html"}]}, {"text": ["Good luck.", "Sorry that I am a new user and can only post one link, or I would have linked all of the other pages as well."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["On the Python side, your best bet is probably to separate the two steps in two different processes.", "There are a couple of modules that help you to achieve that.", "You would couple the two processes through pipes.", "In order to pass arbitrary data through the pipe, you need to serialize and deserialize it.", "The pickle module would be a good candidate for this."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "pipes", "childNum": 0, "tag": "em", "pos": 2, "childList": []}, {"text": "pickle", "childNum": 0, "tag": "em", "pos": 4, "childList": []}]}, {"text": ["If you want to jump ship, languages like Erlang, Haskell, Scala or Clojure have probably the concurrency features you are looking for, but I don't know how well they would integrate with R or some other statistical package that suits you."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["If I remember correctly (but I might be wrong here) one of the main purposes of Ada95 was parallel processing.", "Funny language, that was."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Jokes aside I'm not quite sure how good performance wise it would be (but seeing you are using Python now then it shouldn't be that bad) but I'd suggest Java since the basics of multithreading are quite simple there (but making a well written, complex multithreaded application is rather hard).", "Heard the Concurrency library is also quite nice, I haven't tried it out myself yet, though."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["My experiences with Java multi-threading have been very positive, although it does take a lot of getting used to.", "At the end of the day, the biggest problem wasn't the syntax or the java features but the different mindset you need to develop multi-threaded code."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If you're using eclipse there's also a profiling suite that's very helpful in debugging and optimisation.", "Causes a rather big performance hit though :)"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "a profiling suite", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.eclipse.org/articles/Article-TPTP-Profiling-Tool/tptpProfilingArticle.html"}]}]]