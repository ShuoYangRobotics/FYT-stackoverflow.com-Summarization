[[{"text": ["Two of my favorite tools for Python web scraping are Scrapy and Mechanize.", "Each of these projects has its own tutorial and best practices."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Scrapy", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://scrapy.org/"}, {"text": "Mechanize", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://wwwsearch.sourceforge.net/mechanize/"}]}], [{"text": ["Not a tool, really, but a good discussion is Michael Shrenk's book, Webbots, Spiders, and Screen Scrapers."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Webbots, Spiders, and Screen Scrapers", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://rads.stackoverflow.com/amzn/click/1593271204"}]}, {"text": ["The book succeeds very well in its stated mission: explaining how to build simple web bots and operate them in accordance with community standards.", "It\u2019s not everything you need to know, but it\u2019s the best introduction I\u2019ve seen.", "The focus is on simple, single-threaded, bots.", "There\u2019s some small mention of using multiple bots that store data in a central repository, but there\u2019s no discussion of the issues involved in writing multi-threaded or distributed bots that can process hundreds of pages per second."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["I recommend that you read this book if you\u2019re at all interested in writing Web bots, even if you\u2019re not familiar with or intending to use PHP.", "But be sure not to expect more than the book offers."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Look into using lxml instead of BeautifulSoup.", "Despite its name, it is also for parsing and scraping HTML.", "It's much, much faster than BeautifulSoup, and it even handles \"broken\" HTML better than BeautifulSoup (their claim to fame - lxml just isn't as vocal about it).", "It has a compatibility API for BeautifulSoup too if you don't want to learn the lxml API."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "lxml", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://codespeak.net/lxml/"}]}, {"text": ["Ian Blicking agrees."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "Ian Blicking agrees", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://blog.ianbicking.org/2008/12/10/lxml-an-underappreciated-web-scraping-library/"}]}, {"text": ["There's no reason to use BeautifulSoup anymore, unless you're on Google App Engine or something where anything not purely Python isn't allowed."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Take a look at the following screencasts:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": ["http://railscasts.com/episodes/190-screen-scraping-with-nokogiri"], "childNum": 0, "tag": "a", "senID": 1, "childList": []}, {"text": ["http://railscasts.com/episodes/191-mechanize"], "childNum": 0, "tag": "a", "senID": 2, "childList": []}]}, {"text": ["Or if you like it plain, the corresponding asciicasts:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": ["http://asciicasts.com/episodes/190-screen-scraping-with-nokogiri"], "childNum": 0, "tag": "a", "senID": 4, "childList": []}, {"text": ["http://asciicasts.com/episodes/191-mechanize"], "childNum": 0, "tag": "a", "senID": 5, "childList": []}]}], [{"text": ["There's an excellent Railscasts episode on ScrAPI."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Railscasts episode", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://railscasts.com/episodes/173-screen-scraping-with-scrapi"}]}], [{"text": ["For Ruby, the Scrubyt web-scraping toolkit is excellent.", "Here's an extensive introduction to it, which is worth reading even if you'll be using some other tool."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Scrubyt", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://scrubyt.org/"}, {"text": "an extensive introduction", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.rubyrailways.com/data-extraction-for-web-20-screen-scraping-in-rubyrails-episode1/"}]}]]