[[{"text": ["You could also use Stackless Python, as it allows for cooperative scheduling of microthreads.", "Here you can specify a maximum number of instructions to execute before returning.", "Setting up the routines and getting the return value out is a little more tricky though."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "cooperative scheduling", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.stackless.com/wiki/Scheduling"}]}], [{"text": ["The only \"really good\" solutions -- imposing essentially no overhead -- are going to be based on SIGALRM, either directly or through a nice abstraction layer; but as already remarked Windows does not support this.", "Threads are no use, not because it's hard to get results out (that would be trivial, with a Queue!", "), but because forcibly terminating a runaway thread in a nice cross-platform way is unfeasible."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["This leaves high-overhead multiprocessing as the only viable cross-platform solution.", "You'll want a process pool to reduce process-spawning overhead (since presumably the need to kill a runaway function is only occasional, most of the time you'll be able to reuse an existing process by sending it new functions to execute).", "Again, Queue (the multiprocessing kind) makes getting results back easy (albeit with a modicum more caution than for the threading case, since in the multiprocessing case deadlocks are possible)."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "multiprocessing", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "cross-platform", "childNum": 0, "tag": "strong", "pos": -1, "childList": []}]}, {"text": ["If you don't need to strictly serialize the executions of your functions, but rather can arrange your architecture to try two or more of them in parallel, AND are running on a multi-core machine (or multiple machines on a fast LAN), then suddenly multiprocessing becomes a high-performance solution, easily paying back for the spawning and IPC overhead and more, exactly because you can exploit as many processors (or nodes in a cluster) as you can use."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["You could use the multiprocessing library to run the code in a separate process, and call .join() on the process to wait for it to finish, with the timeout parameter set to whatever you want.", "The library provides several ways of getting data back from another process - using a Value object (seen in the Shared Memory example on that page) is probably sufficient.", "You can use the terminate() call on the process if you really need to, though it's not recommended."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "multiprocessing", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/multiprocessing.html"}]}], [{"text": ["Executing untrusted code is dangerous, and should usually be avoided unless it's impossible to do so.", "I think you're right to be worried about the time of the run() method, but the run() method could do other things as well: delete all your files, open sockets and make network connections, begin cracking your password and email the result back to an attacker, etc."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Perhaps if you can give some more detail on what the dynamically loaded code does, the SO community can help suggest alternatives."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["a quick google for \"python timeout\" reveals a TimeoutFunction class"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "TimeoutFunction", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://nick.vargish.org/clues/python-tricks.html"}]}], [{"text": ["If the timeout expires, that means the method didn't finish, so there's no result to get.", "If you have incremental results, you can store them somewhere and read them out however you like (keeping threadsafety in mind)."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Using SIGALRM-based systems is dicey, because it can deliver async signals at any time, even during an except or finally handler where you're not expecting one.", "(Other languages deal with this better, unfortunately.", ")  For example:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n try:\n    # code\nfinally:\n    cleanup1()\n    cleanup2()\n    cleanup3()\n</code>\n</pre>\n", "senID": 2}, {"text": ["A signal passed up via SIGALRM might happen during cleanup2(), which would cause cleanup3() to never be executed.", "Python simply does not have a way to terminate a running thread in a way that's both uncooperative and safe."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["You should just have the code check the timeout on its own."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n import threading\nfrom datetime import datetime, timedelta\n\nlocal = threading.local()\nclass ExecutionTimeout(Exception): pass\n\ndef start(max_duration = timedelta(seconds=1)):\n    local.start_time = datetime.now()\n    local.max_duration = max_duration\n\ndef check():\n    if datetime.now() - local.start_time &gt; local.max_duration:\n        raise ExecutionTimeout()\n\ndef do_work():\n    start()\n    while True:\n        check()\n        # do stuff here\n    return 10\n\ntry:\n    print do_work()\nexcept ExecutionTimeout:\n    print \"Timed out\"\n</code>\n</pre>\n", "senID": 5}, {"text": ["(Of course, this belongs in a module, so the code would actually look like \"timeout.start()\"; \"timeout.check()\"."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["If you're generating code dynamically, then generate a timeout.check() call at the start of each loop."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}]]