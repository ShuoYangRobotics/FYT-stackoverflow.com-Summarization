[[{"text": ["As others have mentioned, you can simply pickle the compiled regex.", "They will pickle and unpickle just fine, and be usable.", "However, it doesn't look like the pickle actually contains the result of compilation.", "I suspect you will incur the compilation overhead again when you use the result of the unpickling."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; p.dumps(re.compile(\"a*b+c*\"))\n\"cre\\n_compile\\np1\\n(S'a*b+c*'\\np2\\nI0\\ntRp3\\n.\"\n&gt;&gt;&gt; p.dumps(re.compile(\"a*b+c*x+y*\"))\n\"cre\\n_compile\\np1\\n(S'a*b+c*x+y*'\\np2\\nI0\\ntRp3\\n.\"\n</code>\n</pre>\n", "senID": 1}, {"text": ["In these two tests, you can see the only difference between the two pickles is in the string.", "Apparently compiled regexes don't pickle the compiled bits, just the string needed to compile it again."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["But I'm wondering about your application overall: compiling a regex is a fast operation, how short are your jobs that compiling the regex is significant?", "One possibility is that you are compiling all 300 regexes, and then only using one for a short job.", "In that case, don't compile them all up front.", "The re module is very good at using cached copies of compiled regexes, so you generally don't have to compile them yourself, just use the string form.", "The re module will lookup the string in a dictionary of compiled regexes, so grabbing the compiled form yourself only saves you a dictionary look up.", "I may be totally off-base, sorry if so."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["OK, this isn't pretty, but it might be what you want.", "I looked at the sre_compile.py module from Python 2.6, and ripped out a bit of it, chopped it in half, and used the two pieces to pickle and unpickle compiled regexes:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import re, sre_compile, sre_parse, _sre\nimport cPickle as pickle\n\n# the first half of sre_compile.compile    \ndef raw_compile(p, flags=0):\n    # internal: convert pattern list to internal format\n\n    if sre_compile.isstring(p):\n        pattern = p\n        p = sre_parse.parse(p, flags)\n    else:\n        pattern = None\n\n    code = sre_compile._code(p, flags)\n\n    return p, code\n\n# the second half of sre_compile.compile\ndef build_compiled(pattern, p, flags, code):\n    # print code\n\n    # XXX: &lt;fl&gt; get rid of this limitation!\n    if p.pattern.groups &gt; 100:\n        raise AssertionError(\n            \"sorry, but this version only supports 100 named groups\"\n            )\n\n    # map in either direction\n    groupindex = p.pattern.groupdict\n    indexgroup = [None] * p.pattern.groups\n    for k, i in groupindex.items():\n        indexgroup[i] = k\n\n    return _sre.compile(\n        pattern, flags | p.pattern.flags, code,\n        p.pattern.groups-1,\n        groupindex, indexgroup\n        )\n\ndef pickle_regexes(regexes):\n    picklable = []\n    for r in regexes:\n        p, code = raw_compile(r, re.DOTALL)\n        picklable.append((r, p, code))\n    return pickle.dumps(picklable)\n\ndef unpickle_regexes(pkl):\n    regexes = []\n    for r, p, code in pickle.loads(pkl):\n        regexes.append(build_compiled(r, p, re.DOTALL, code))\n    return regexes\n\nregexes = [\n    r\"^$\",\n    r\"a*b+c*d+e*f+\",\n    ]\n\npkl = pickle_regexes(regexes)\nprint pkl\nprint unpickle_regexes(pkl)\n</code>\n</pre>\n", "senID": 1}, {"text": ["I don't really know if this works, or if it speeds things up.", "I know it prints a list of regexes when I try it.", "It might be very specific to version 2.6, I also don't know that."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Some observations and musings:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["You don't need to compile to get the effect of the re.DOTALL flag (or any other flag)-- all you need to do is insert (?s)  at the start of the pattern string ... re.DOTALL -> re.S -> the s in (?s).", "Do a Ctrl-F search for sux (sic) in the re syntax docs."], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "(?s)", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "sux", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"href": "http://docs.python.org/library/re.html#regular-expression-syntax", "text": "re syntax docs", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["80ms seems a very short time, even when multiplied by \"many\" (how many??", ") short jobs."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Does each job require a new Python process to be started?", "If so, isn't 80ms small compared with process startup and shutdown overhead?", "Otherwise, please explain why it is not possible, when a user wants to run \"many\" small jobs, to do the re.compiles once per batch of jobs."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["Just compile as you go - re module will cache the compiled re's even if you dont.", "Bump the re._MAXCACHE up to 400 or 500, the short jobs will only compile the re's they need, and the long jobs benefit from a big fat cache of compiled expressions - everybody's happy!"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["As long as you create them on program start, the pyc file will cache them.", "You don't need to result to pickling."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["In a similar case (where every time some input needs to be run through ALL of the regexes), I had to split the Python script in a master-slave setup using *nix sockets; the first time the script is called, the master \u2014doing all time-expensive regex compilations\u2014 starts up and the slave for that and all subsequent invokations exchanges data with the master.", "The master stays idle maximum N seconds."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["In my case, this master/slave setup was found to be faster in all occasions than the straightforward way (many invokations against relatively little data every time; also, it had to be a script because it is called from an external application without any Python bindings).", "I don't know whether this would apply to your situation."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}]]