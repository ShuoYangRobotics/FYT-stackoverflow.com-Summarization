[[{"text": ["Variant 1 is great if you need to launch many sequential searches.", "Since set is internally a hash table, it's rather good at search.", "It takes time to build, though, and only works well if your data fit into RAM."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "set", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"text": ["Variant 3 is good for very big files, because you have plenty of address space to map them and OS caches enough data.", "You do a full scan; it can become rather slow once your data stop to fit into RAM."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["SQLite is definitely a nice idea if you need several searches in row and you can't fit the data into RAM.", "Load your strings into a table, build an index, and SQLite builds a nice b-tree for you.", "The tree can fit into RAM even if data don't (it's a bit like what @alienhard proposed), and even if it doesn't, the amount if I/O needed is dramatically lower.", "Of course, you need to create a disk-based SQLite database.", "I doubt that memory-based SQLite will beat Variant 1 significantly."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Custom hash table search with externalized strings"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Custom hash table search with externalized strings", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["To get fast access time and a lower memory consumption you could do the following:"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "and", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}, {"tag": "ul", "num": 2, "lis": [{"text": "for each line compute a string hash and add it to a hash table, e.g., ", "tag": "none", "senID": 2}, {"text": "to look up a string, compute its hash and look it up in the table. If the key is found, read the string at ", "tag": "none", "senID": 3}]}, {"text": ["Edit 1: replaced line_number by position (as pointed out by a commenter, one obviously needs the actual position and not line numbers)"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["Edit 2: provide code for an implementation with a custom hash table, which shows that this approach is more memory efficient than the other approaches mentioned:"], "childNum": 1, "tag": "p", "senID": 5, "childList": [{"text": "Edit 2: provide code for an implementation with a custom hash table, which shows that this approach is more memory efficient than the other approaches mentioned:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n from collections import namedtuple \nNode = namedtuple('Node', ['pos', 'next'])\n\ndef build_table(f, size):\n    table = [ None ] * size\n    while True:\n        pos = f.tell()\n        line = f.readline()\n        if not line: break\n        i = hash(line) % size\n        if table[i] is None:\n            table[i] = pos\n        else:\n            table[i] = Node(pos, table[i])\n    return table\n\ndef search(string, table, f):\n    i = hash(string) % len(table)\n    entry = table[i]\n    while entry is not None:\n        pos = entry.pos if isinstance(entry, Node) else entry\n        f.seek(pos)\n        if f.readline() == string:\n            return True\n        entry = entry.next if isinstance(entry, Node) else None\n    return False\n\nSIZE = 2**24\nwith open('data.txt', 'r') as f:\n    table = build_table(f, SIZE)\n    print search('Some test string\\n', table, f)\n</code>\n</pre>\n", "senID": 6}, {"text": ["The hash of a line is only used to index into the table (if we used a normal dict, the hashes would also be stored as keys).", "The file position of the line is stored at the given index.", "Collisions are resolved with chaining, i.e., we create a linked list.", "However, the first entry is never wrapped in a node (this optimization makes the code a bit more complicated but it saves quite some space). "], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["For a file with 6 million lines I chose a hash table size of 2^24.", "With my test data I got 933132 collisions.", "(A hash table of half the size was comparable in memory consumption, but resulted in more collisions.", "Since more collisions means more file access for searches, I would rather use a large table."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"code": "<pre>\n<code>\n Hash table: 128MB (sys.getsizeof([None]*(2**24)))\nNodes:       64MB (sys.getsizeof(Node(None, None)) * 933132)\nPos ints:   138MB (6000000 * 24)\n-----------------\nTOTAL:      330MB (real memory usage of python process was ~350MB)\n</code>\n</pre>\n", "senID": 9}], [{"text": ["You could also try"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n with open('input.txt') as f:\n    print search_str in f\n</code>\n</pre>\n", "senID": 1}, {"text": ["with search_str ending with the proper newline sequence('\\n' or '\\r\\n').", "This should use little memory, as the file is read progressively.", "It should also be quite fast, since only part of the file is read."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "search_str", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["I would guess many of the paths start out the same on DMOZ.", "You should use a trie data structure and store the individual characters on nodes."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "trie data structure", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Trie"}]}, {"text": ["Tries have O(m) lookup time (where m is the key length) also save a lot of space, when saving large dictionaries or tree like data."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You could also store path parts on nodes to reduce node count \u2014 this is called Patricia Trie.", "But that makes the lookup slower by the average string length comparison time.", "See SO question Trie (Prefix Tree) in Python for more info about implementations."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "Trie (Prefix Tree) in Python", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/960963/trie-prefix-tree-in-python"}]}, {"text": ["There are a couple of trie implementations on Python Package Index, but they are not very good.", "I have written one in Ruby and in Common Lisp, which is especially well suited for this task \u2013 if you ask nicely, I could maybe publish it as open source... :-)"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["what about a text indexing solution ?"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I would use Lucene in the Java world but there is a python engine called Whoosh"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["https://bitbucket.org/mchaput/whoosh/wiki/Home"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "https://bitbucket.org/mchaput/whoosh/wiki/Home", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "https://bitbucket.org/mchaput/whoosh/wiki/Home"}]}], [{"text": ["Without building an index file your searching will be to slow, and this is not so simple task.", "So better to use already developed software.", "The best way will be use Sphinx Search Engine."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Sphinx Search Engine", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://sphinxsearch.com/"}]}]]