[[{"text": ["You want to avoid doing the permutation.", "You could count how many times a character appears in both strings ( the original string and the one from the dictionary).", "Dismiss all the words from the dictionary where the frequency of characters isn't the same. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["So to check one word from the dictionary you will need to count the characters at most MAX (26, n) time. "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Implementation of Jeroen Coup\u00e9 idea from his answer with letters count:"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Jeroen Coup\u00e9", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/users/840372/jeroen-coupe"}, {"href": "http://stackoverflow.com/a/8924228/1052325", "text": "his answer", "childNum": 0, "tag": "a", "childList": []}]}, {"code": "<pre>\n<code>\n from collections import defaultdict, Counter\n\n\ndef find_longest(origin, known_words):\n    return iter_longest(origin, known_words).next()\n\ndef iter_longest(origin, known_words, min_length=1):\n    origin_map = Counter(origin)\n    for i in xrange(len(origin) + 1, min_length - 1, -1):\n        for word in known_words[i]:\n            if check_same_letters(origin_map, word):\n               yield word\n\ndef check_same_letters(origin_map, word):\n    new_map = Counter(word)\n    return all(new_map[let] &lt;= origin_map[let] for let in word)\n\ndef load_words_from(file_path):\n    known_words =  defaultdict(list)\n    with open(file_path) as f:\n        for line in f:\n            word = line.strip()\n            known_words[len(word)].append(word)\n    return known_words\n\nif __name__ == '__main__':\n    known_words = load_words_from('words_list.txt')\n    origin = 'raepkwaen'\n    big_origin = 'raepkwaenaqwertyuiopasdfghjklzxcvbnmqwertyuiopasdfghjklzxcvbnmqwertyuiopasdfghjklzxcvbnmqwertyuiopasdfghjklzxcvbnm'\n    print find_longest(big_origin, known_words)\n    print list(iter_longest(origin, known_words, 5))\n</code>\n</pre>\n", "senID": 1}, {"text": ["Output (for my small 58000 words dict):"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n counterrevolutionaries\n['reawaken', 'awaken', 'enwrap', 'weaken', 'weaker', 'apnea', 'arena', 'awake',\n 'aware', 'newer', 'paean', 'parka', 'pekan', 'prank', 'prawn', 'preen', 'renew',\n 'waken', 'wreak']\n</code>\n</pre>\n", "senID": 3}, {"text": ["Notes:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": ["It's simple implementation without optimizations."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["words_list.txt - can be /usr/share/dict/words on Linux."], "childNum": 2, "tag": "p", "senID": 6, "childList": [{"text": "words_list.txt", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "/usr/share/dict/words", "childNum": 0, "tag": "code", "childList": []}]}]}, {"text": ["UPDATE"], "childNum": 1, "tag": "p", "senID": 7, "childList": [{"text": "UPDATE", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["In case we need to find word only once, and we have dictionary with words sorted by length, e.g.", "by this script:"], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"code": "<pre>\n<code>\n with open('words_list.txt') as f:\n    words = f.readlines()\nwith open('words_by_len.txt', 'w') as f:\n    for word in sorted(words, key=lambda w: len(w), reverse=True):\n        f.write(word)\n</code>\n</pre>\n", "senID": 9}, {"text": ["We can find longest word without loading full dict to memory:"], "childNum": 0, "tag": "p", "senID": 10, "childList": []}, {"code": "<pre>\n<code>\n from collections import Counter\nimport sys\n\n\ndef check_same_letters(origin_map, word):\n    new_map = Counter(word)\n    return all(new_map[let] &lt;= origin_map[let] for let in word)\n\ndef iter_longest_from_file(origin, file_path, min_length=1):\n    origin_map = Counter(origin)\n    origin_len = len(origin)\n    with open(file_path) as f:\n        for line in f:\n            word = line.strip()\n            if len(word) &gt; origin_len:\n                continue\n            if len(word) &lt; min_length:\n                return\n            if check_same_letters(origin_map, word):\n                yield word\n\ndef find_longest_from_file(origin, file_path):\n    return iter_longest_from_file(origin, file_path).next()\n\nif __name__ == '__main__':\n    origin = sys.argv[1] if len(sys.argv) &gt; 1 else 'abcdefghijklmnopqrstuvwxyz'\n    print find_longest_from_file(origin, 'words_by_len.txt')\n</code>\n</pre>\n", "senID": 11}], [{"text": ["Then, when you are searching for a given set of letters:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["You'd need to do this separately for each word length."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["EDIT: should say that you're searching for all unique combinations of the sorted letters of the target word length (range(len(letters), 0, -1))"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "range(len(letters), 0, -1)", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["This is similar to an anagram problem I've worked on before.", "I solved that by using prime numbers to represent each letter.", "The product of the letters for each word produces a number.", "To determine if a given set of input characters are sufficient to make a work, just divide the product of the input character by the product for the number you want to check.", "If there is no remainder then the input characters are sufficient.", "I've implemented it below.", "The output is:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n $ python longest.py rasdaddea aosddna raepkwaen\nrasdaddea --&gt;  sadder\naosddna --&gt;  soda\nraepkwaen --&gt;  reawaken\n</code>\n</pre>\n", "senID": 1}, {"text": ["You can find more details and a thorough explanation of the anagrams case at:\nhttp://mostlyhighperformance.blogspot.com/2012/01/generating-anagrams-efficient-and-easy.html"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://mostlyhighperformance.blogspot.com/2012/01/generating-anagrams-efficient-and-easy.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://mostlyhighperformance.blogspot.com/2012/01/generating-anagrams-efficient-and-easy.html"}]}, {"text": ["This algorithm takes a small amount of time to set up a dictionary, and then individual checks are as easy as a single division for every word in the dictionary.", "There may be faster methods that rely on closing off parts of the dictionary if it lacks a letter, but these may end up performing worse if you have large number of input letters so it is actually not able to close off any part of the dictionary."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n import sys\n\n\ndef nextprime(x):\n    while True:\n        x += 1\n        for pot_fac in range(2,x):\n            if x % pot_fac == 0:\n                break\n        else:\n            return x\n\ndef prime_generator():\n    '''Returns a generator that produces the next largest prime as\n    compared to the one returned from this function the last time\n    it was called. The first time it is called it will return 2.'''\n    lastprime = 1\n    while True:\n        lastprime = nextprime(lastprime)\n        yield lastprime\n\n\n# Assign prime numbers to each lower case letter\ngen = prime_generator()\nprimes = dict( [ (chr(x),gen.next()) for x in range(ord('a'),ord('z')+1) ] )\n\n\nproduct = lambda x: reduce( lambda m,n: m*n, x, 1 )\nmake_key = lambda x: product( [ primes[y] for y in x ] )\n\n\ntry:\n    words = open('words').readlines()\n    words = [ ''.join( [ c for c in x.lower() \\\n                if ord('a') &lt;= ord(c) &lt;= ord('z') ] ) \\\n            for x in words ]\n    for x in words:\n        try:\n            make_key(x)\n        except:\n            print x\n            raise\n\nexcept IOError:\n    words = [ 'reawaken','awaken','enwrap','weaken','weaker', ]\n\nwords = dict( ( (make_key(x),x,) for x in words ) )\n\n\ninputs = sys.argv[1:] if sys.argv[1:] else [ 'raepkwaen', ]\nfor input in inputs:\n    input_key = make_key(input)\n    results = [ words[x] for x in words if input_key % x == 0 ]\n\n    result = reversed(sorted(results, key=len)).next()\n    print input,'--&gt; ',result\n</code>\n</pre>\n", "senID": 4}], [{"text": ["I started this last night shortly after you asked the question, but didn't get around to polishing it up until just now.", "This was my solution, which is basically a modified trie, which I didn't know until today!"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n class Node(object):\n    __slots__ = ('words', 'letter', 'child', 'sib')\n\n    def __init__(self, letter, sib=None):\n        self.words = []\n        self.letter = letter\n        self.child = None\n        self.sib = sib\n\n    def get_child(self, letter, create=False):\n        child = self.child\n        if not child or child.letter &gt; letter:\n            if create:\n                self.child = Node(letter, child)\n                return self.child\n            return None\n        return child.get_sibling(letter, create)\n\n    def get_sibling(self, letter, create=False):\n        node = self\n        while node:\n            if node.letter == letter:\n                return node\n            sib = node.sib\n            if not sib or sib.letter &gt; letter:\n                if create:\n                    node.sib = Node(letter, sib)\n                    node = node.sib\n                    return node\n                return None\n            node = sib\n        return None\n\n    def __repr__(self):\n        return '&lt;Node({}){}{}: {}&gt;'.format(chr(self.letter), 'C' if self.child else '', 'S' if self.sib else '', self.words)\n\ndef add_word(root, word):\n    word = word.lower().strip()\n    letters = [ord(c) for c in sorted(word)]\n    node = root\n    for letter in letters:\n        node = node.get_child(letter, True)\n    node.words.append(word)\n\ndef find_max_word(root, word):\n    word = word.lower().strip()\n    letters = [ord(c) for c in sorted(word)]\n    words = []\n    def grab_words(root, letters):\n        last = None\n        for idx, letter in enumerate(letters):\n            if letter == last: # prevents duplication\n                continue\n            node = root.get_child(letter)\n            if node:\n                words.extend(node.words)\n                grab_words(node, letters[idx+1:])\n            last = letter\n    grab_words(root, letters)\n    return words\n\nroot = Node(0)\nwith open('/path/to/dict/file', 'rt') as f:\n    for word in f:\n        add_word(root, word)\n</code>\n</pre>\n", "senID": 1}, {"text": ["Testing:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; def nonrepeating_words():\n...     return find_max_word(root, 'abcdefghijklmnopqrstuvwxyz')\n... \n&gt;&gt;&gt; sorted(nonrepeating_words(), key=len)[-10:]\n['ambidextrously', 'troublemakings', 'dermatoglyphic', 'hydromagnetics', 'hydropneumatic', 'pyruvaldoxines', 'hyperabductions', 'uncopyrightable', 'dermatoglyphics', 'endolymphaticus']\n&gt;&gt;&gt; len(nonrepeating_words())\n67590\n</code>\n</pre>\n", "senID": 3}, {"text": ["I think I prefer dermatoglyphics to uncopyrightable for longest word, myself.", "Performance-wise, utilizing a ~500k word dictionary (from here),"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "here", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://codehappy.net/wordlist.htm"}]}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; import timeit\n&gt;&gt;&gt; timeit.timeit(nonrepeating_words, number=100)\n62.8912091255188\n&gt;&gt;&gt;\n</code>\n</pre>\n", "senID": 5}, {"text": ["So, on average, 6/10ths of a second (on my i5-2500) to find all sixty-seven thousand words that contain no repeating letters."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["The big differences between this implementation and a trie (which makes it even further from a DAWG in general) is that: words are stored in the trie in relation to their sorted letters.", "So the word 'dog' is stored under the same path as 'god': d-g-o.", "The second bit is the the find_max_word algorithm, which makes sure every possible letter combination is visited by continually lopping off its head and re-running the search."], "childNum": 1, "tag": "p", "senID": 7, "childList": [{"text": "find_max_word", "childNum": 0, "tag": "code", "pos": 2, "childList": []}]}, {"text": ["Oh, and just for giggles:"], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; sorted(tree.find_max_word('RAEPKWAEN'), key=len)[-5:]\n['wakener', 'rewaken', 'reawake', 'reawaken', 'awakener']\n</code>\n</pre>\n", "senID": 9}], [{"text": ["At this point, your trie is the representation of all words in your dictionary that can be constructed from your bag of letters."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Edit: you may also use a DAGW (Directed Acyclic Word Graph) which will have fewer vertices.", "Although I haven't read it, this wikipedia article have a link about The World's Fastest Scrabble Program."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "DAGW (Directed Acyclic Word Graph)", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Directed_acyclic_word_graph"}, {"text": "The World's Fastest Scrabble Program", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.cs.cmu.edu/afs/cs/academic/class/15451-s06/www/lectures/scrabble.pdf"}]}], [{"text": ["When looking for words longer than 10 letters you may try to iterate over words (I think there are not so many words with 10 letters) that are longer than 10 letters and check it you have required letters in your set."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Problem is that you have to find all those len(word) >= 10 words first."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["So, what I would do:\nWhen reading the dictionary split the words into 2 categories: shorts and longs.", "You can process shorts by iterating over every possible permutation.", "Than you can process longs by iterating over then and checking it they are possible."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Of course there are many optimisations possible to both paths."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["DAWG (Directed Acyclic Word Graph)\nMark Wutka was kind enough to provide some pascal code here."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": ["http://www.wutka.com/dawg.html"], "childNum": 0, "tag": "a", "senID": 1, "childList": []}, {"text": ["http://www.wutka.com/DictConvert.ZIP"], "childNum": 0, "tag": "a", "senID": 2, "childList": []}]}], [{"text": ["Another approach, similar to @market's answer, is to precompute a 'bitmask' for each word in the dictionary.", "Bit 0 is set if the word contains at least one A, bit 1 is set if it contains at least one B, and so on up to bit 25 for Z."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If you want to search for all words in the dictionary that could be made up from a combination of letters, you start by forming the bitmask for the collection of letters.", "You can then filter out all of the words that use other letters by checking whether wordBitmask &amp; ~lettersBitMask is zero.", "If this is zero, the word only uses letters available in the collection, and so could be valid.", "If this is non-zero, it uses a letter not available in the collection and so is not allowed."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "wordBitmask &amp; ~lettersBitMask", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"text": ["The advantage of this approach is that the bitwise operations are fast.", "The vast majority of words in the dictionary will use at least one of the 17 or more letters that aren't in the collection given, and you can speedily discount them all.", "However, for the minority of words that make it through the filter, there is one more check that you still have to make.", "You still need to check that words aren't using letters more often than they appear in the collection.", "For example, the word 'weakener' must be disallowed because it has three 'e's, whereas there are only two in the collection of letters RAEPKWAEN.", "The bitwise approach alone will not filter out this word since each letter in the word appears in the collection."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]]