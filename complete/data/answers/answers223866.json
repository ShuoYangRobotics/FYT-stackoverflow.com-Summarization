[[{"text": ["No and in fact, for the specific type of task you describe, I doubt there's a \"cleaner\" way to do it than regular expressions.", "It looks like your files have embedded line breaks so typically what we'll do here is make the line your unit of decomposition, applying per-line regexes.", "Meanwhile, you create a small state machine and use regex matches to trigger transitions in that state machine.", "This way you know where you are in the file, and what types of character data you can expect.", "Also, consider using named capture groups and loading the regexes from an external file.", "That way if the format of your transcript changes, it's a simple matter of tweaking the regex, rather than writing new parse-specific code."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["With Perl, you can use Parse::RecDescent"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Parse::RecDescent", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://search.cpan.org/perldoc?Parse::RecDescent"}]}, {"text": ["It is simple, and your grammar will be maintainable later on."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Here's two parsers based on lepl parser generator library.", "They both produce the same result."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "lepl", "tag": "a", "pos": 0, "childList": [{"text": "lepl", "tag": "code"}], "childNum": 1, "href": "http://www.acooke.org/lepl/"}, {"text": "lepl", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n from pprint import pprint\nfrom lepl import AnyBut, Drop, Eos, Newline, Separator, SkipTo, Space\n\n# field = name , \":\" , value\nname, value = AnyBut(':\\n')[1:,...], AnyBut('\\n')[::'n',...]    \nwith Separator(~Space()[:]):\n    field = name &amp; Drop(':') &amp; value &amp; ~(Newline() | Eos()) &gt; tuple\n\nheader_start   = SkipTo('Chat Transcript' &amp; Newline()[2])\nheader         = ~header_start &amp; field[1:] &gt; dict\nserver_message = Drop('* ') &amp; AnyBut('\\n')[:,...] &amp; ~Newline() &gt; 'Server'\nconversation   = (server_message | field)[1:] &gt; list\nfooter_start   = 'Visitor Details' &amp; Newline() &amp; '-'*15 &amp; Newline()\nfooter         = ~footer_start &amp; field[1:] &gt; dict\nchat_log       = header &amp; ~Newline() &amp; conversation &amp; ~Newline() &amp; footer\n\npprint(chat_log.parse_file(open('chat.log')))\n</code>\n</pre>\n", "senID": 1}, {"code": "<pre>\n<code>\n from pprint import pprint\nfrom lepl import And, Drop, Newline, Or, Regexp, SkipTo\n\ndef Field(name, value=Regexp(r'\\s*(.*?)\\s*?\\n')):\n    \"\"\"'name , \":\" , value' matcher\"\"\"\n    return name &amp; Drop(':') &amp; value &gt; tuple\n\nFields = lambda names: reduce(And, map(Field, names))\n\nheader_start   = SkipTo(Regexp(r'^Chat Transcript$') &amp; Newline()[2])\nheader_fields  = Fields(\"Visitor Operator Company Started Finished\".split())\nserver_message = Regexp(r'^\\* (.*?)\\n') &gt; 'Server'\nfooter_fields  = Fields((\"Your Name, Your Question, IP Address, \"\n                         \"Host Name, Referrer, Browser/OS\").split(', '))\n\nwith open('chat.log') as f:\n    # parse header to find Visitor and Operator's names\n    headers, = (~header_start &amp; header_fields &gt; dict).parse_file(f)\n    # only Visitor, Operator and Server may take part in the conversation\n    message = reduce(Or, [Field(headers[name])\n                          for name in \"Visitor Operator\".split()])\n    conversation = (message | server_message)[1:]\n    messages, footers = ((conversation &gt; list)\n                         &amp; Drop('\\nVisitor Details\\n---------------\\n')\n                         &amp; (footer_fields &gt; dict)).parse_file(f)\n\npprint((headers, messages, footers))\n</code>\n</pre>\n", "senID": 2}, {"text": ["Output:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n ({'Company': 'Initech',\n  'Finished': '16 Oct 2008 9:45:44',\n  'Operator': 'Milton',\n  'Started': '16 Oct 2008 9:13:58',\n  'Visitor': 'Random Website Visitor'},\n [('Random Website Visitor',\n   'Where do i get the cover sheet for the TPS report?'),\n  ('Server',\n   'There are no operators available at the moment. If you would like to leave a message, please type it in the input field below and click \"Send\" button'),\n  ('Server',\n   'Call accepted by operator Milton. Currently in room: Milton, Random Website Visitor.'),\n  ('Milton', 'Y-- Excuse me. You-- I believe you have my stapler?'),\n  ('Random Website Visitor', 'I really just need the cover sheet, okay?'),\n  ('Milton',\n   \"it's not okay because if they take my stapler then I'll, I'll, I'll set the building on fire...\"),\n  ('Random Website Visitor', 'oh i found it, thanks anyway.'),\n  ('Server',\n   'Random Website Visitor is now off-line and may not reply. Currently in room: Milton.'),\n  ('Milton', \"Well, Ok. But\u2026 that's the last straw.\"),\n  ('Server',\n   'Milton has left the conversation. Currently in room:  room is empty.')],\n {'Browser/OS': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.2; .NET CLR 1.1.4322; InfoPath.1; .NET CLR 2.0.50727)',\n  'Host Name': '255.255.255.255',\n  'IP Address': '255.255.255.255',\n  'Referrer': 'Unknown',\n  'Your Name': 'Random Website Visitor',\n  'Your Question': 'Where do i get the cover sheet for the TPS report?'})\n</code>\n</pre>\n", "senID": 4}], [{"text": ["Using multiline, commented regexs can mitigate the maintainance problem somewhat.", "Try and avoid the one line super regex!"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Also, consider breaking the regex down into individual tasks, one for each 'thing' you want to get.", "eg."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n visitor = text.find(/Visitor:(.*)/)\noperator = text.find(/Operator:(.*)/)\nbody = text.find(/whatever....)\n</code>\n</pre>\n", "senID": 2}, {"text": ["instead of "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n text.match(/Visitor:(.*)\\nOperator:(.*)...whatever to giant regex/m) do\n  visitor = $1\n  operator = $2\n  etc.\nend\n</code>\n</pre>\n", "senID": 4}, {"text": ["Then it makes it easy to change how any particular item is parsed.", "As far as parsing through a file with many \"chat blocks\", just have a single simple regex that matches a single chat block, iterate over the text and pass the match data from this to your group of other matchers."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["This will obviously affect performance, but unless you processing enormous files i wouldnt worry."], "childNum": 1, "tag": "p", "senID": 6, "childList": [{"text": "enormous", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}], [{"text": ["Build a parser?", "I can't decide if your data is regular enough for that, but it might be worth looking into."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Build a parser", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://pyparsing.wikispaces.com/"}]}], [{"text": ["You might want to consider a full parser generator. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Regular expressions are good for searching text for small substrings but they're woefully under-powered if you're really interested in parsing the entire file into meaningful data. "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["They are especially insufficient if the context of the substring is important."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Most people throw regexes at everything because that's what they know.", "They've never learned any parser generating tools and they end up coding a lot of the production rule composition and semantic action handling that you can get for free with a parser generator. "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Regexes are great and all, but if you need a parser they're no substitute."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["Consider using Ragel http://www.complang.org/ragel/"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://www.complang.org/ragel/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.complang.org/ragel/"}]}, {"text": ["That's what powers mongrel under the hood.", "Parsing a string multiple times is going to slow things down dramatically. "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["I have used Paul McGuire's pyParsing class library and I continue to be impressed by it, in that it's well-documented, easy to get started, and the rules are easy to tweak and maintain.", "BTW, the rules are expressed in your python code.", "It certainly appears that the log file has enough regularity to parse each line as a stand-alone unit."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Just a quick post, I've only glanced at your transcript example but I've recently also had to look into text parsing and hoped to avoid going the route of hand rolled parsing.", "I did happen across Ragel which I've only started to get my head around but it's looking to be pretty useful."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Ragel", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.complang.org/ragel/"}]}]]