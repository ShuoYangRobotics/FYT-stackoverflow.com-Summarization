[[{"text": ["Short answer: no."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Properly dividing a json file would take intimate knowledge of the json object graph to get right."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["However, if you have this knowledge, then you could implement a file-like object that wraps the json file and spits out proper chunks."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["For instance, if you know that your json file is a single array of objects, you could create a generator that wraps the json file and returns chunks of the array."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["You would have to do some string content parsing to get the chunking of the json file right."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["I don't know what generates your json content.", "If possible, I would consider generating a number of managable files, instead of one huge file."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}], [{"text": ["So the problem is not that each file is too big, but that there are too many of them, and they seem to be adding up in memory.", "Python's garbage collector should be fine, unless you are keeping around references you don't need.", "It's hard to tell exactly what's happening without any further information, but some things you can try:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Hope this helps."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["On your mention of running out of memory I must question if you're actually managing memory.", "Are you using the \"del\" keyword to remove your old object before trying to read a new one?", "Python should never silently retain something in memory if you remove it. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["in addition to @codeape"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I would try writing a custom json parser to help you figure out the structure of the JSON blob you are dealing with.", "Print out the key names only, etc.", "Make a hierarchical tree and decide (yourself) how you can chunk it.", "This way you can do what @codeape suggests - break the file up into smaller chunks, etc"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Another idea is to try load it into a document-store database like MongoDB.", "It deals with large blobs of JSON well.", "Although you might run into the same problem loading the JSON - avoid the problem by loading the files one at a time."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If path works for you, then you can interact with the JSON data via their client and potentially not have to hold the entire blob in memory"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["http://www.mongodb.org/"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://www.mongodb.org/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.mongodb.org/"}]}], [{"text": ["\"the garbage collector should free the memory\"  "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Correct."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Since it doesn't, something else is wrong.", "Generally, the problem with infinite memory growth is global variables."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Remove all global variables."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Make all module-level code into smaller functions."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}]]