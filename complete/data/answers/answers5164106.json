[[{"text": ["Assuming you have a numpy matrix or ndarray, which your question and tags imply, there is a dump method and load function you can use:"], "childNum": 6, "tag": "p", "senID": 0, "childList": [{"text": "matrix", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "ndarray", "childNum": 0, "tag": "code", "childList": []}, {"href": "http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.dump.html", "text": "dump", "childNum": 1, "tag": "a", "childList": [{"text": "dump", "tag": "code"}]}, {"text": "dump", "childNum": 0, "tag": "code", "childList": []}, {"href": "http://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html", "text": "load", "childNum": 1, "tag": "a", "childList": [{"text": "load", "tag": "code"}]}, {"text": "load", "childNum": 0, "tag": "code", "childList": []}]}, {"code": "<pre>\n<code>\n your_matrix.dump('output.mat')\nanother_matrix = numpy.load('output.mat')\n</code>\n</pre>\n", "senID": 1}], [{"text": ["pyTables is the Python interface to HDF5 data model and is pretty popular choice for and well-integrated with NumPy and SciPy.", "pyTables will let you access slices of databased arrays without needing to load the entire array back into memory."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "pyTables", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.pytables.org/moin"}]}, {"text": ["I don't have any specific experience with sparse matrices per se and a quick Google search neither confirmed nor denied that sparse matrices are supported."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Adding on the HDF5 support, Python also has NetCDF support which is ideal for matrix form data storage and quick access both sparse and dense.", "It is included in Python-x,y for windows, which a lot of scientific users of python end up with."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "NetCDF support", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.google.com/p/netcdf4-python/"}, {"text": "Python-x,y", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://code.google.com/p/pythonxy/"}]}, {"text": ["More numpy based examples can be found in this cookbook."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "cookbook", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.scipy.org/Cookbook/InputOutput"}]}], [{"text": ["For very big sparse matrices on clusters, you might use pytrilinos, it has a HDF5 interface which can dump a sparse matrix to disk, and works also if the matrix is distributed on different nodes."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["http://trilinos.sandia.gov/packages/pytrilinos/development/EpetraExt.html#input-output-classes"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://trilinos.sandia.gov/packages/pytrilinos/development/EpetraExt.html#input-output-classes", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://trilinos.sandia.gov/packages/pytrilinos/development/EpetraExt.html#input-output-classes"}]}], [{"text": ["Depending on the size of the sparse matrix, I tend to just use cPickle to pickle the array:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "cPickle", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n import cPickle\nf = open('spmatrix.pkl','wb')\ncPickle.dump(your_matrix,f,-1)\nf.close()\n</code>\n</pre>\n", "senID": 1}, {"text": ["If I'm dealing with really large datasets then I tend to use netcdf4-python"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "netcdf4-python", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Edit:"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "Edit:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["To then access the file again you would:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n f = open('spmatrix.pkl','rb') # open the file in read binary mode\n# load the data in the .pkl file into a new variable spmat\nspmat = cPickle.load(f) \nf.close()\n</code>\n</pre>\n", "senID": 5}], [{"text": ["Note: This answer is in response to the revise question that now provides code. "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Note", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["You should not call cPickle.dump() in your function.", "Create the sparse matrix and then dump its contents to the file."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "cPickle.dump()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Try:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n def markov(L):\n   count=0\n   c=len(text1)\n   for i in range(0,c-2):\n       h=L.index(text1[i])\n       k=L.index(text1[i+1])\n       mat[h,k]=mat[h,k]+1 #matrix\n\n\ntext = [w for g in brown.categories() for w in brown.words(categories=g)]\ntext1=text[1:500]\narr=set(text1)\narr=list(arr)\nmat=lil_matrix((len(arr),len(arr)))\nmarkov(arr)\nf = open('spmatrix.pkl','wb')\ncPickle.dump(mat,f,-1)\nf.close()\n</code>\n</pre>\n", "senID": 3}]]