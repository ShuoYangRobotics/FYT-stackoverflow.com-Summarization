[[{"text": ["Beautiful Soup will save you a great deal of pain."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Beautiful Soup", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.crummy.com/software/BeautifulSoup/"}]}], [{"text": ["Another option is to use lxml.html.", "I've occasionally found this to handle some pages better than BeautifulSoup (odd HTML comment corner cases), and the API may be more familiar if you've worked with XML.", "If BeautifulSoup does handle certain pages better, you can still use it while retaining the same interface by using soupparser module."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "lxml", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://codespeak.net/lxml/lxml2.html"}, {"text": "html", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://codespeak.net/lxml/lxmlhtml.html"}, {"text": "soupparser", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://codespeak.net/lxml/elementsoup.html"}]}], [{"text": ["Use mechanize to automate browsing, and BeautifulSoup to parse the HTML.", "(I do lots of stuff like what you described."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "mechanize", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://wwwsearch.sourceforge.net/mechanize/"}]}], [{"text": ["Another option, if you don't mind learning \"yet another framework\", is Scrapy, which is a full-featured screen scraping environment for writing scrapers, in Python."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Scrapy", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://scrapy.org"}]}, {"text": ["The difference between Scrapy and lxml/BS or Mechanize is that Scrapy is a complete integrated solution, while lxml/BS only do the parsing side, and Mecanize the crawling side.", "There is no silver bullet, so you'll have to try for yourself and decide which technology fits better for your needs."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["While BeautifulSoup is a good piece of code, depending on what you are trying to extract from the web page, you may not need that much intelligence.", "The data you're looking for may be easily picked out by a regular expression, for example.  "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["This isn't answering you question directly, but you may want to think about getting your data from another service, such as Schedules Direct.", "They provide XML, and it's the recommended data provider for xmltv."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Schedules Direct", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.schedulesdirect.org/"}, {"text": "xmltv", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://wiki.xmltv.org/index.php/Main_Page"}]}], [{"code": "<pre>\n<code>\n import urllib\n</code>\n</pre>\n", "senID": 0}, {"text": ["Docs:\nurllib docs"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "urllib docs", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/urllib.html"}]}]]