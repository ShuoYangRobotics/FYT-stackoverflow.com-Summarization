[[{"text": ["Say you want to split the file into N pieces, then simply start reading from the back of the file (more or less) and repeatedly call truncate:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "truncate", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/stdtypes.html?highlight=truncate#file.truncate"}]}, {"code": "<pre>\n<code>\n import os\nimport stat\n\nBUF_SIZE = 4096\nsize = os.stat(\"large_file\")[stat.ST_SIZE]\nchunk_size = size / N \n# or simply set a fixed chunk size based on your free disk space\nc = 0\n\nin_ = open(\"large_file\", \"r+\")\n\nwhile size &gt; 0:\n    in_.seek(-min(size, chunk_size), 2)\n    # now you have to find a safe place to split the file at somehow\n    # just read forward until you found one\n    ...\n    old_pos = in_.tell()\n    with open(\"small_chunk%2d\" % (c, ), \"w\") as out:\n        b = in_.read(BUF_SIZE)\n        while len(b) &gt; 0:\n            out.write(b)\n            b = in_.read(BUF_SIZE)\n    in_.truncate(old_pos)\n    size = old_pos\n    c += 1\n</code>\n</pre>\n", "senID": 1}, {"text": ["Be careful, as I didn't test any of this.", "It might be needed to call flush after the truncate call, and I don't know how fast the file system is going to actually free up the space. "], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "flush", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}], [{"text": ["If you're on Linux/Unix, why not use the split command like this guy does?"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "this guy", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.techiecorner.com/107/how-to-split-large-file-into-several-smaller-files-linux/"}]}, {"code": "<pre>\n<code>\n split --bytes=100m /input/file /output/dir/prefix\n</code>\n</pre>\n", "senID": 1}, {"text": ["EDIT: then use csplit."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "csplit", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://linux.die.net/man/1/csplit"}]}], [{"text": ["I'm pretty sure there is, as I've even been able to edit/read from the source files of scripts I've run, but the biggest problem would probably be all the shifting that would be done if you started at the beginning of the file.", "On the other hand, if you go through the file and record all the starting positions of the lines, you could then go in reverse order of position to copy the lines out; once that's done, you could go back, take the new files, one at a time, and (if they're small enough), use readlines() to generate a list, reverse the order of the list, then seek to the beginning of the file and overwrite the lines in their old order with the lines in their new one."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["(You would truncate the file after reading the first block of lines from the end by using the truncate() method, which truncates all data past the current file position if used without any arguments besides that of the file object, assuming you're using one of the classes or a subclass of one of the classes from the io package to read your file.", "You'd just have to make sure that the current file position ends up at the beginning of the last line to be written to a new file."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "truncate()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "io", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"text": ["EDIT: Based on your comment about having to make the separations at the proper closing tags, you'll probably also have to develop an algorithm to detect such tags (perhaps using the peek method), possibly using a regular expression."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "peek", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["If time is not a major factor (or wear and tear on your disk drive):"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If Python does not give you this level of control, you may need to dive into C."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["You could always parse the XML file and write out say every 10000 elements to there own file.", "Look at the Incremental Parsing section of this link.", "http://effbot.org/zone/element-iterparse.htm"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://effbot.org/zone/element-iterparse.htm", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://effbot.org/zone/element-iterparse.htm"}]}], [{"text": ["Here is my script..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import string\nimport os\nfrom ftplib import FTP\n\n# make ftp connection\nftp = FTP('server')\nftp.login('user', 'pwd')\nftp.cwd('/dir')\n\nf1 = open('large_file.xml', 'r')\n\nsize = 0\nsplit = False\ncount = 0\n\nfor line in f1:\n  if not split:\n    file = 'split_'+str(count)+'.xml'\n    f2 = open(file, 'w')\n    if count &gt; 0:\n      f2.write('&lt;?xml version=\"1.0\"?&gt;\\n')\n      f2.write('&lt;StartTag xmlns=\"http://www.blah/1.2.0\"&gt;\\n')\n    size = 0\n    count += 1 \n    split = True    \n  if size &lt; 1073741824:\n      f2.write(line)\n      size += len(line)\n  elif str(line) == '&lt;/EndTag&gt;\\n':\n      f2.write(line)\n      f2.write('&lt;/EndEndTag&gt;\\n')\n      print('completed file %s' %str(count))\n      f2.close()\n      f2 = open(file, 'r')\n      print(\"ftp'ing file...\")\n      ftp.storbinary('STOR ' + file, f2)\n      print('ftp done.')\n      split = False\n      f2.close()\n      os.remove(file)\n  else:\n    f2.write(line)\n    size += len(line)\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Its a time to buy a new hard drive!"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["You can make backup before trying all other answers and don't get data lost :)"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}]]