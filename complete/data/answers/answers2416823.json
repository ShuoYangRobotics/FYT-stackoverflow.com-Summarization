[[{"text": ["Parse the HTML with Beautiful Soup."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Beautiful Soup", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.crummy.com/software/BeautifulSoup"}]}, {"text": ["To get all the text, without the tags, try:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n ''.join(soup.findAll(text=True))\n</code>\n</pre>\n", "senID": 2}], [{"text": ["The best modules for this task are lxml or html5lib; Beautifull Soap is imho not worth to use anymore.", "And for recursive models regular expressions are definitly the wrong method."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Personally, I use lxml because it's a swiss-army knife..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\nfrom lxml import html\n\nprint html.parse('http://someurl.at.domain').xpath('//body')[0].text_content()\n</pre>\n", "senID": 1}, {"text": ["This tells lxml to retrieve the page, locate the &lt;body&gt; tag then extract and print all the text."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["I do a lot of page parsing and a regex is the wrong solution most of the time, unless it's a one-time-only need.", "If the author of the page changes their HTML you run a good risk of your regex breaking.", "A parser is a lot more likely to continue working. "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["The big problem with a parser is learning how to access the sections of the document you are after, but there are a lot of XPATH tools you can use inside your browser that simplify the task."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["You want to look at Extracting data from HTML  documents - Dive into Python because HERE it does (almost)exactly what you want."], "childNum": 4, "tag": "p", "senID": 0, "childList": [{"text": "Extracting data from HTML  documents - Dive into Python", "tag": "a", "pos": 0, "childList": [{"text": "Extracting data from HTML  documents - Dive into Python", "tag": "strong"}], "childNum": 1, "href": "http://diveintopython.org/html_processing/index.html#dialect.divein"}, {"text": "Extracting data from HTML  documents - Dive into Python", "childNum": 0, "tag": "strong", "childList": []}, {"href": "http://diveintopython.org/html_processing/introducing_sgmllib.html", "text": "HERE", "childNum": 1, "tag": "a", "childList": [{"text": "HERE", "tag": "strong"}]}, {"text": "HERE", "childNum": 0, "tag": "strong", "childList": []}]}], [{"text": ["If I am getting your question correctly, this can simply be done by using urlopen function of urllib.", "Just have a look at this function to open an url and read the response which will be the html code of that page."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["The quickest way to get a usable sample of what a browser would display is to remove any tags from the html and print the rest.", "This can, for example, be done using python's re."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "re", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}]]