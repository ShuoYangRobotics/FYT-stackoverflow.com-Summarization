[[{"text": ["It may be proven through profiling that this isn't quite the fastest but..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import collections\n\na = {'x': 1.0, 'y': 0.5, 'z': 0.25 }\nb = {'w': 0.5, 'x': 0.2 }\ndicts = [a,b]\n\ntotals = collections.defaultdict(list)\navg = {}\n\nfor D in dicts:\n    for key,value in D.iteritems():\n        totals[key].append(value)\n\nfor key,values in totals.iteritems():\n   avg[key] = sum(values) / len(values)\n</code>\n</pre>\n", "senID": 1}, {"text": ["I'm guessing that allowing Python to use the built-ins sum() and len() is going to gain some performance over calculating the mean as you see new values, but I could sure be wrong about that."], "childNum": 3, "tag": "p", "senID": 2, "childList": [{"text": "guessing", "childNum": 0, "tag": "em", "pos": 0, "childList": []}, {"text": "sum()", "childNum": 0, "tag": "code", "childList": []}, {"text": "len()", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["This works:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import collections\n\ndata= [\n    {'x': 1.0, 'y': 0.5, 'z': 0.25 },\n    {'w': 0.5, 'x': 0.2 }\n    ]\n\ntally = collections.defaultdict(lambda: (0.0, 0))\n\nfor d in data:\n    for k,v in d.items():\n        sum, count = tally[k]\n        tally[k] = (sum+v, count+1)\n\nresults = {}\nfor k, v in tally.items():\n    t = tally[k]\n    results[k] = t[0]/t[1]\n\nprint results\n</code>\n</pre>\n", "senID": 1}, {"text": ["I don't know if it's faster than yours, since you haven't posted your code."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n {'y': 0.5, 'x': 0.59999999999999998, 'z': 0.25, 'w': 0.5}\n</code>\n</pre>\n", "senID": 3}, {"text": ["I tried in tally to avoid storing all the values again, simply accumulating the sum and count I'd need to compute the average at the end.", "Often, the time bottleneck in a Python program is in the memory allocator, and using less memory can help a lot with speed."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"code": "<pre>\n<code>\n &gt;&gt;&gt; def avg(items):\n...     return sum(items) / len(items)\n... \n&gt;&gt;&gt; hashes = [a, b]\n&gt;&gt;&gt; dict([(k, avg([h.get(k) or 0 for h in hashes])) for k in set(sum((h.keys() for h in hashes), []))])\n{'y': 0.25, 'x': 0.59999999999999998, 'z': 0.125, 'w': 0.25}\n</code>\n</pre>\n", "senID": 0}, {"text": ["Explanation:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["It is possible that your bottleneck might be due to excessive memory use.", "Consider using iteritems to leverage the power of generators."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Since you say your data is sparse, that will probably not be the most efficient.", "Consider this alternate usage of iterators:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n dicts = ... #Assume this is your dataset\ntotals = {}\nlengths = {}\nmeans = {}\nfor d in dicts:\n    for key,value in d.iteritems():\n        totals.setdefault(key,0)\n        lengths.setdefault(key,0)\n        totals[key] += value\n        length[key] += 1\nfor key,value in totals.iteritems():\n    means[key] = value / lengths[key]\n</code>\n</pre>\n", "senID": 2}, {"text": ["Here totals, lengths, and means are the only data structures you create.", "This ought to be fairly speedy, since it avoids having to create auxiliary lists and only loops through each dictionary exactly once per key it contains."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Here's a second approach that I doubt will be an improvement in performance over the first, but it theoretically could, depending on your data and machine, since it will require less memory allocation:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n dicts = ... #Assume this is your dataset\nkey_set = Set([])\nfor d in dicts: key_set.update(d.keys())\nmeans = {}\ndef get_total(dicts, key):\n    vals = (dict[key] for dict in dicts if dict.has_key(key))\n    return sum(vals)\ndef get_length(dicts, key):\n    vals = (1 for dict in dicts if dict.has_key(key))\n    return sum(vals)\ndef get_mean(dicts,key):\n    return get_total(dicts,key)/get_length(dicts,key)\nfor key in key_set:\n    means[key] = get_mean(dicts,key)\n</code>\n</pre>\n", "senID": 5}, {"text": ["You do end up looping through all dictionaries twice for each key, but need no intermediate data structures other than the key_set."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["scipy.sparse supports sparse matrices -- the dok_matrix form seems reasonably suited to your needs (you'll have to use integer coordinates, though, so a separate pass will be needed to collect and put in any arbitrary but definite order the string keys you currently have).", "If you have a huge number of very large and sparse \"arrays\", the performance gains might possibly be worth the complications."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "scipy.sparse", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.scipy.org/doc/api%5Fdocs/SciPy.sparse.sparse.html"}, {"text": "dok_matrix", "tag": "a", "pos": -1, "childList": [{"text": "dok_matrix", "tag": "code"}], "childNum": 1, "href": "http://www.scipy.org/doc/api%5Fdocs/SciPy.sparse.sparse.dok%5Fmatrix.html"}, {"text": "dok_matrix", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}], [{"text": ["It's simple but this could work:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n a = { 'x': 1.0, 'y': 0.5, 'z': 0.25 }\nb = { 'w': 0.5, 'x': 0.2 }\n\nds = [a, b]\nresult = {}\n\nfor d in ds:\n    for k, v in d.iteritems():\n        result[k] = v + result.get(k, 0)\n\nn = len(ds)\nresult = dict((k, amt/n) for k, amt in result.iteritems())\n\nprint result\n</code>\n</pre>\n", "senID": 1}, {"text": ["I have no idea how it compares to your method since you didn't post any code."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]]