[[{"text": ["It's certainly possible to keep a set of only hashes:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n done = set()\nwhile len(queue) &gt; 0 :\n   item = queue.pop()\n   h = hash(item)\n   if h not in done :\n      process(item)\n      done.add(h)\n</code>\n</pre>\n", "senID": 1}, {"text": ["Notice that because of hash collisions, there is a chance that you consider an item done even though it isn't. "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["If you cannot accept this risk, you really need to save the full strings to be able to tell whether you have seen it before.", "Alternatively: perhaps the processing itself would be able to tell?"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Yet alternatively: if you cannot accept to keep the strings in memory, keep them in a database, or create files in a directory with the same name as the string."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["You can use a data structure called Bloom Filter specifically for this purpose.", "A Python implementation can be found here."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "Bloom Filter", "tag": "a", "pos": 0, "childList": [{"text": "Bloom Filter", "tag": "strong"}], "childNum": 1, "href": "http://en.wikipedia.org/wiki/Bloom%5Ffilter"}, {"text": "Bloom Filter", "childNum": 0, "tag": "strong", "pos": -1, "childList": []}, {"text": "here", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://github.com/jaybaird/python-bloomfilter/tree/master"}]}, {"text": ["EDIT: Important notes:"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "EDIT", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["That said, the chances of this happening can be brought to a minimum if used properly and so I consider this data structure to be very useful."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["If you use a secure (like SHA-256, found in the hashlib module) hash function to hash the strings, it's very unlikely that you would found duplicate (and if you find some you can probably win a prize as with most cryptographic hash functions)."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "hashlib", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["The builtin __hash__() method does not guarantee you won't have duplicates (and since it only uses 32 bits, it's very likely you'll find some)."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "__hash__()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["You need to know the whole string to have 100% certainty.", "If you have lots of strings with similar prefixes you could save space by using a trie to store the strings.", "If your strings are long you could also save space by using a large hash function like SHA-1 to make the possibility of hash collisions so remote as to be irrelevant."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If you can make the process() function idempotent - i.e.", "having it called twice on an item is only a performance issue, then the problem becomes a lot simpler and you can use lossy datastructures, such as bloom filters."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "process()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["You would have to think about how to do the lookup, since there are two methods that the set needs, __hash__ and __eq__."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "__hash__", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "__eq__", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["The hash is a \"loose part\" that you can take away, but the __eq__ is not a loose part that you can save; you have to have two strings for the comparison."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "__eq__", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["If you only need negative confirmation (this item is not part of the set), you could fill a Set collection you implemented yourself with your strings, then you \"finalize\" the set by removing all strings, except those with collisions (those are kept around for eq tests), and you promise not to add more objects to your Set.", "Now you have an exclusive test available.. you can tell if an object is not in your Set.", "You can't be certain if \"obj in Set == True\" is a false positive or not."], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "eq", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "is not", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"text": ["Edit: This is basically a bloom filter that was cleverly linked, but a bloom filter might use more than one hash per element which is really clever."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Edit2: This is my 3-minute bloom filter:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n class BloomFilter (object):\n    \"\"\" \n    Let's make a bloom filter\n    http://en.wikipedia.org/wiki/Bloom_filter\n\n    __contains__ has false positives, but never false negatives\n    \"\"\" \n    def __init__(self, hashes=(hash, )): \n        self.hashes = hashes\n        self.data = set()\n    def __contains__(self, obj):\n        return all((h(obj) in self.data) for h in self.hashes)\n    def add(self, obj):\n        self.data.update(h(obj) for h in self.hashes)\n</code>\n</pre>\n", "senID": 5}], [{"text": ["As has been hinted already, if the answers offered here (most of which break down in the face of hash collisions) are not acceptable you would need to use a lossless representation of the strings.  "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Python's zlib module provides built-in string compression capabilities and could be used to pre-process the strings before you put them in your set.", "Note however that the strings would need to be quite long (which you hint that they are) and have minimal entropy in order to save much memory space.", "Other compression options might provide better space savings and some Python based implementations can be found here"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "here", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://www.inference.phy.cam.ac.uk/mackay/python/compress/"}]}]]