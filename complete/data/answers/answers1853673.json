[[{"text": ["You could use MapReduce like Google does, either via Hadoop (specifically with Python: 1 and 2), Disco, or Happy."], "childNum": 6, "tag": "p", "senID": 0, "childList": [{"text": "MapReduce", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/MapReduce"}, {"href": "http://hadoop.apache.org/", "text": "Hadoop", "childNum": 0, "tag": "a", "childList": []}, {"href": "http://www.michael-noll.com/wiki/Writing%5FAn%5FHadoop%5FMapReduce%5FProgram%5FIn%5FPython", "text": "1", "childNum": 0, "tag": "a", "childList": []}, {"href": "http://blog.last.fm/2008/05/29/python-hadoop-flying-circus-elephant", "text": "2", "childNum": 0, "tag": "a", "childList": []}, {"href": "http://discoproject.org/", "text": "Disco", "childNum": 0, "tag": "a", "childList": []}, {"href": "http://code.google.com/p/happy/", "text": "Happy", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["The traditional line of thought, is write your program in standard Python, if you find it is too slow, profile it, and optimize the specific slow spots.", "You can make these slow spots faster by dropping down to C, using C/C++ extensions or even ctypes."], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "profile it", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/profile.html"}, {"text": "C/C++", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.python.org/doc/ext/intro.html"}, {"href": "http://docs.python.org/library/ctypes.html", "text": "ctypes", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["If you are spidering just one site, consider using wget -r (an example)."], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "wget -r", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"href": "http://linuxreviews.org/quicktips/wget/", "text": "an example", "childNum": 0, "tag": "a", "childList": []}]}], [{"text": ["Spidering somebody's site with millions of requests isn't very polite.", "Can you instead ask the webmaster for an archive of the site?", "Once you have that, it's a simple matter of text searching."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["You waste a lot of time waiting for network requests when spidering, so you'll definitely want to make your requests in parallel.", "I would probably save the result data to disk and then have a second process looping over the files searching for the term.", "That phase could easily be distributed across multiple machines if you needed extra performance."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["As you are new to Python, I think the following may be helpful for you :)"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": "if you are writing regex to search for certain pattern in the page, compile your regex wherever you can and reuse the compiled object", "tag": "none", "senID": 1}, {"text": ["BeautifulSoup"], "childNum": 0, "tag": "a", "senID": 2, "childList": []}]}], [{"text": ["Where are you storing the results?", "You can use PiCloud's cloud library to parallelize your scraping easily across a cluster of servers."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "PiCloud", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.picloud.com"}]}], [{"text": ["What Adam said.", "I did this once to map out Xanga's network.", "The way I made it faster is by having a thread-safe set containing all usernames I had to look up.", "Then I had 5 or so threads making requests at the same time and processing them.", "You're going to spend way more time waiting for the page to DL than you will processing any of the text (most likely), so just find ways to increase the number of requests you can get at the same time."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}]]