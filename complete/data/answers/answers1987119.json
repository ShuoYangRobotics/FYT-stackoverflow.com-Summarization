[[{"text": ["A quick profiling of your code suggests that over 90% of the time is consumed in the FindFilesW() call alone.", "This means any improvements by tweaking the Python code would be minor."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "FindFilesW()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Tiny tweaks (if you were to stick with FindFilesW) could include ensuring DIR_EXCLUDES is a set instead of a list, avoiding the repeated lookups on other modules, and indexing into item[] lazily, as well as moving the sys.platform check outside.", "This incorporates these changes and others, but it won't give more than a 1-2% speedup."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "but it won't give more than a 1-2% speedup", "childNum": 0, "tag": "strong", "pos": 1, "childList": []}]}, {"code": "<pre>\n<code>\n DIR_EXCLUDES = set(['.', '..'])\nMASK = win32con.FILE_ATTRIBUTE_DIRECTORY | win32con.FILE_ATTRIBUTE_SYSTEM\nREQUIRED = win32con.FILE_ATTRIBUTE_DIRECTORY\nFindFilesW = win32file.FindFilesW\n\ndef get_dir_size(path):\n    total_size = 0\n    try:\n        items = FindFilesW(path + r'\\*')\n    except pywintypes.error, ex:\n        return total_size\n\n    for item in items:\n        total_size += item[5]\n        if (item[0] &amp; MASK == REQUIRED):\n            name = item[8]\n            if name not in DIR_EXCLUDES:\n                total_size += get_dir_size(path + '\\\\' + name)\n\n    return total_size\n</code>\n</pre>\n", "senID": 2}, {"text": ["The only significant speedup would come from using a different API, or a different technique.", "You mentioned in a comment doing this in the background, so you could structure it to do an incremental update using one of the packages for monitoring changes in folders.", "Possibly the FindFirstChangeNotification API or something like it.", "You could set up to monitor the entire tree, or depending on how that routine works (I haven't used it) you might be better off registering multiple requests on various subsets of the full tree, if that reduces the amount of searching you have to do (when notified) to figure out what actually changed and what size it is now."], "childNum": 2, "tag": "p", "senID": 3, "childList": [{"text": "significant", "childNum": 0, "tag": "em", "pos": 0, "childList": []}, {"text": "FindFirstChangeNotification API", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://timgolden.me.uk/python/win32_how_do_i/watch_directory_for_changes.html"}]}, {"text": ["Edit: I asked in a comment whether you were taking into account the heavy filesystem metadata caching that Windows XP and later do.", "I just checked performance of your code (and mine) against Windows itself, selecting all items in my C:\\ folder and hitting Alt-Enter to bring up the properties window.", "After doing this once (using your code) and getting a 40s elapsed time, I now get 20s elapsed from both methods.", "In other words, your code is actually just as fast as Windows itself, at least on my machine."], "childNum": 3, "tag": "p", "senID": 4, "childList": [{"text": "Edit:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "both methods", "childNum": 0, "tag": "em", "pos": 2, "childList": []}, {"text": "your code is actually just as fast as Windows itself", "childNum": 0, "tag": "strong", "pos": 3, "childList": []}]}], [{"text": ["You don't need to use a recursive algorithm if you use os.walk.", "Please check this question."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Please check this question", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/335078/whats-the-best-way-to-get-the-size-of-a-folder-and-all-the-files-inside-from-pyt"}]}, {"text": ["You should time both approaches, but this is supposed to be much faster:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n import os\n\ndef get_dir_size(root):\n    size = 0\n    for path, dirs, files in os.walk(root):\n        for f in files:\n            size +=  os.path.getsize( os.path.join( path, f ) )\n    return size\n</code>\n</pre>\n", "senID": 2}], [{"text": ["I don't have a Windows box to test on at the moment, but the documentation states that\nwin32file.FindFilesIterator is \"similar to win32file.FindFiles, but avoid the creation of the list for huge directories\".", "Does that help?"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "win32file.FindFilesIterator", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "win32file.FindFiles", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}], [{"text": ["It's a whopper of a directory tree.", "As others have said, I'm not sure you can speed it up... not like that, cold w/o data.", "And that means..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If you can cache data, somehow (not sure what the actual implication is), then you could speed things up (I think... as always, measure, measure, measure)."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "cache", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}, {"text": ["I don't think I have to tell you how to do caching, I guess, you seem like a knowledgeable person.", "And I wouldn't know off the cuff for Windows anyway.", ";-)"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["This jumps out at me:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n try:\n  items = win32file.FindFilesW(path + '\\\\*')\nexcept Exception, err:\n  return 0\n</code>\n</pre>\n", "senID": 1}, {"text": ["Exception handling can add significant time to your algorithm.", "If you can specify the path differently, in a way that you always know is safe, and thus prevent the need to capture exceptions (eg, checking first to see if the given path is a folder before finding files in that folder), you may find a significant speedup."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"code": "<pre>\n<code>\n # Size of File Folder/Directory in MBytes\n\nimport os\n\n# pick a folder you have ...\nfolder = 'D:\\\\zz1'\nfolder_size = 0\nfor (path, dirs, files) in os.walk(folder):\n  for file in files:\n    filename = os.path.join(path, file)\n    folder_size += os.path.getsize(filename)\n\nprint \"Folder = %0.1f MB\" % (folder_size/(1024*1024.0))\n</code>\n</pre>\n", "senID": 0}]]