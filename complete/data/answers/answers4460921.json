[[{"text": ["Some time ago I made two classes for get Wikipedia articles in plain text.", "I know that they aren't the best solution, but you can adapt it to your needs:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["&nbsp;&nbsp;&nbsp;&nbsp;wikipedia.py\n&nbsp;&nbsp;&nbsp;&nbsp;wiki2plain.py"], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "wikipedia.py", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://pastebin.com/FVDxLWNG"}, {"text": "", "childNum": 0, "tag": "br", "childList": []}, {"href": "http://pastebin.com/idw8vQQK", "text": "wiki2plain.py", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["You can use it like this:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n lang = 'simple'\nwiki = Wikipedia(lang)\n\ntry:\n    raw = wiki.article('Uruguay')\nexcept:\n    raw = None\n\nif raw:\n    wiki2plain = Wiki2Plain(raw)\n    content = wiki2plain.text\n</code>\n</pre>\n", "senID": 3}], [{"text": ["What I did is this:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import urllib\nimport urllib2\nfrom BeautifulSoup import BeautifulSoup\n\narticle= \"Albert Einstein\"\narticle = urllib.quote(article)\n\nopener = urllib2.build_opener()\nopener.addheaders = [('User-agent', 'Mozilla/5.0')] #wikipedia needs this\n\nresource = opener.open(\"http://en.wikipedia.org/wiki/\" + article)\ndata = resource.read()\nresource.close()\nsoup = BeautifulSoup(data)\nprint soup.find('div',id=\"bodyContent\").p\n</code>\n</pre>\n", "senID": 1}], [{"text": ["If you want library suggestions, BeautifulSoup, urllib2 come to mind.", "Answered on SO before: Web scraping with Python."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "BeautifulSoup", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.crummy.com/software/BeautifulSoup/"}, {"text": "urllib2", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/urllib2.html"}, {"text": "Web scraping with Python", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/2081586/web-scraping-with-python"}]}, {"text": ["I have tried urllib2 to get a page from Wikipedia.", "But, it was 403 (forbidden).", "MediaWiki provides API for Wikipedia, supporting various output formats.", "I haven't used python-wikitools, but may be worth a try.", "http://code.google.com/p/python-wikitools/"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://code.google.com/p/python-wikitools/", "tag": "a", "pos": 4, "childList": [], "childNum": 0, "href": "http://code.google.com/p/python-wikitools/"}]}], [{"text": ["First, I promise I am not being snarky."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Here's a previous question that might be of use:\nFetch a Wikipedia article with Python"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "Fetch a Wikipedia article with Python", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/120061/fetch-a-wikipedia-article-with-python"}]}, {"text": ["In this someone suggests using the wikipedia high level API, which leads to this question:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Is there a Wikipedia API?"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "Is there a Wikipedia API?", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/627594/is-there-a-wikipedia-api"}]}], [{"text": ["As others have said, one approach is to use the wikimedia API and urllib or urllib2.", "The code fragments below are part of what I used to extract what is called the \"lead\" section, which has the article abstract and the infobox.", "This will check if the returned text is a redirect instead of actual content, and also let you skip the infobox if present (in my case I used different code to pull out and format the infobox. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n contentBaseURL='http://en.wikipedia.org/w/index.php?title='\n\ndef getContent(title):\n    URL=contentBaseURL+title+'&amp;action=raw&amp;section=0'\n    f=urllib.urlopen(URL)\n    rawContent=f.read()\n    return rawContent\n\ninfoboxPresent = 0\n# Check if a redirect was returned.  If so, go to the redirection target\n    if rawContent.find('#REDIRECT') == 0:\n        rawContent = getFullContent(title)\n        # extract the redirection title\n        # Extract and format the Infobox\n        redirectStart=rawContent.find('#REDIRECT[[')+11   \n        count = 0\n        redirectEnd = 0\n        for i, char in enumerate(rawContent[redirectStart:-1]):\n            if char == \"[\": count += 1\n            if char == \"]}\":\n                count -= 1\n                if count == 0:\n                    redirectEnd = i+redirectStart+1\n                    break\n        redirectTitle = rawContent[redirectStart:redirectEnd]\n        print 'redirectTitle is: ',redirectTitle\n        rawContent = getContent(redirectTitle)\n\n    # Skip the Infobox\n    infoboxStart=rawContent.find(\"{{Infobox\")   #Actually starts at the double {'s before \"Infobox\"\n    count = 0\n    infoboxEnd = 0\n    for i, char in enumerate(rawContent[infoboxStart:-1]):\n        if char == \"{\": count += 1\n        if char == \"}\":\n            count -= 1\n            if count == 0:\n                infoboxEnd = i+infoboxStart+1\n                break\n\n    if infoboxEnd &lt;&gt; 0:\n        rawContent = rawContent[infoboxEnd:]\n</code>\n</pre>\n", "senID": 1}, {"text": ["You'll be getting back the raw text including wiki markup, so you'll need to do some clean up.", "If you just want the first paragraph, not the whole first section, look for the first new line character.       "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Try a combination of urllib to fetch the site and BeautifulSoup or lxml to parse the data."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "urllib", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "BeautifulSoup", "childNum": 0, "tag": "code", "childList": []}, {"text": "lxml", "childNum": 0, "tag": "code", "childList": []}]}]]