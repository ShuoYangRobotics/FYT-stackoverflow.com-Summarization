[[{"text": ["It could be because dicts in Python are much faster than hashes in Ruby"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I've just run a quick test, building a hash of 12345678 item in Ruby1.8.7 took 3 times as long as Python.", "Ruby1.9 was about twice as long as Python."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Here is how I tested\npython "], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "", "childNum": 0, "tag": "br", "pos": 0, "childList": []}, {"text": "python", "childNum": 0, "tag": "strong", "childList": []}]}, {"code": "<pre>\n<code>\n $ time python -c \"d={}\nfor i in xrange(12345678):d[i]=1\"\n</code>\n</pre>\n", "senID": 3}, {"text": ["ruby"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "ruby", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n $ time ruby -e \"d={};12345678.times{|i|d[i]=1}\"\n</code>\n</pre>\n", "senID": 5}, {"text": ["Not enough to account for your discrepancy though."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["Perhaps file I/O is worth looking into - comment out all the hash code and see how long the empty loops take to run over the files."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Here's another version in Python using defaultdict and context managers"], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"code": "<pre>\n<code>\n from collections import defaultdict\nhashes = defaultdict(int)\n\nwith open('c:\\\\file1.txt', 'r') as f:\n    for line in f:\n        hashes[line] += 1\n\nprint \"Done file 1\"\n\nwith open('c:\\\\file2.txt', 'r') as f:\n    for line in f:\n        if line in hashes:\n            hashes[line] -= 1\n        else:\n            print \"Hash not found!\"\n\nprint \"Done file 2\"\n\nnum_errors = 0\nfor key,value in hashes.items():  # hashes.iteritems() might be better here\n    if value != 0:\n        print \"Uneven hash count: %s\" % key\n        num_errors += 1\n\nprint \"Total of %d mismatches found\" % num_errors\n</code>\n</pre>\n", "senID": 9}], [{"text": ["I've found Ruby's reference implementation (well, Ruby) to be (unscientifically stated) dog slow."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If you have the opportunity, please try running your program under JRuby!", "Charles Nutter and other Sun folks claim to have sped Ruby up dramatically."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["I for one would be most interested in your results."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["On the python side, you could iterate over the dictionary items like this:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n for key, value in hashes.iteritems():\n    if value != 0:\n        print \"Uneven hash count: %s\" % key\n        num_errors += 1\n</code>\n</pre>\n", "senID": 1}, {"text": ["Also:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n for line in f.readlines():\n    hashes[line] = hashes.setdefault(line, 0) + 1\n</code>\n</pre>\n", "senID": 3}, {"text": ["... but I can't help you with the Ruby side, other than to suggest you hunt down a profiler."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["I'm not a Ruby expert, so someone please correct me if I'm wrong:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I see a small optimization potential."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["If you say"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n hashes = hash.new(0)\n</code>\n</pre>\n", "senID": 3}, {"text": ["then a reference to an undefined hash will return 0 and store the key; and you can do"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n hashes[line] += 1\n</code>\n</pre>\n", "senID": 5}, {"text": ["every time, without the enclosing if and else."], "childNum": 2, "tag": "p", "senID": 6, "childList": [{"text": "if", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "else", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Caveat: Untested!"], "childNum": 1, "tag": "p", "senID": 7, "childList": [{"text": "Untested!", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["If storing the key doesn't happen automatically, there's yet another hash constructor using a block where you can do it explicitly."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}], [{"text": ["Python's dictionary is brutally fast.", "See http://stackoverflow.com/questions/327311/how-are-pythons-built-in-dictionaries-implemented Perhaps Ruby's is not so crash hot."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://stackoverflow.com/questions/327311/how-are-pythons-built-in-dictionaries-implemented", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/327311/how-are-pythons-built-in-dictionaries-implemented"}]}, {"text": ["I doubt it's the hash functions.", "There's no way the Ruby devs would have a hash function that's an order of magnitude worse than Python's."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Perhaps Ruby 1.8 is slow at dynamically resizing large hash tables?", "How does your problem scale with smaller files?"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["I was able to speed up your ruby code a bit as follows:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n require 'benchmark'\n\nBenchmark.bm(10) do |x|\n\n  x.report(\"original version\") do\n    file = File.open(\"c:\\\\file1.txt\", \"r\")\n    hashes = {}\n\n    file.each_line { |line|\n      if hashes.has_key?(line)\n        hashes[line] += 1\n      else\n        hashes[line] = 1\n      end\n    }\n\n    file.close()\n\n    #puts \"Done file 1\"\n\n    not_founds = 0\n\n    file = File.open(\"c:\\\\file2.txt\", \"r\")\n\n    file.each_line { |line|\n      if hashes.has_key?(line)\n        hashes[line] -= 1\n      else\n        not_founds += 1        \n      end\n    }\n\n    file.close()\n\n    #puts \"Done file 2\"\n\n    num_errors = 0\n    hashes.each_key{ |key|\n      if hashes[key] != 0\n        num_errors += 1\n      end\n    }\n\n    puts \"Total of #{not_founds} lines not found in file2\"\n    puts \"Total of #{num_errors} mismatches found\"\n\n  end\n\n\n  x.report(\"my speedup\") do\n    hashes = {}\n    File.open(\"c:\\\\file1.txt\", \"r\") do |f|\n      lines = f.readlines\n      lines.each { |line|\n        if hashes.has_key?(line)\n          hashes[line] += 1\n        else\n          hashes[line] = 1\n        end\n      }\n    end  \n\n    not_founds = 0\n\n    File.open(\"c:\\\\file2.txt\", \"r\") do |f|\n      lines = f.readlines\n      lines.each { |line|\n        if hashes.has_key?(line)\n          hashes[line] -= 1\n        else\n          not_founds += 1\n        end\n      }\n    end\n\n    num_errors = hashes.values.to_a.select { |z| z != 0}.size   \n\n    puts \"Total of #{not_founds} lines not found in file2\"\n    puts \"Total of #{num_errors} mismatches found\"\n\n  end\n\nend\n</code>\n</pre>\n", "senID": 1}, {"text": ["so i read the files in one bug chunk, this is in my case a bit faster (i tested on Windows XP, ruby 1.8.6 and a file of 100000 lines).", "I benchmarked all different ways to read files (i could think off), and this was the fastest way.", "Also i did speed up the counting of the values in a hash a bit, but this is only visible if you did it for very large numbers :)"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["So i get a very small speed-increase here.", "The output on my machine is as follows:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n user     system      total        real\noriginal versionTotal of 16 lines not found in file2\nTotal of 4 mismatches found\n   1.000000   0.015000   1.015000 (  1.016000)\nmy speedup v1Total of 16 lines not found in file2\nTotal of 4 mismatches found\n   0.812000   0.047000   0.859000 (  0.859000)\n</code>\n</pre>\n", "senID": 4}, {"text": ["Who has any ideas to improve this further?"], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["If the f.readlines goes slower, because of the size, i found that "], "childNum": 1, "tag": "p", "senID": 6, "childList": [{"text": "f.readlines", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n File.open(\"c:\\\\file2.txt\", \"r\") do |f|\n  while (line=f.gets)\n    if hashes.has_key?(line)\n      hashes[line] -= 1\n    else\n      not_founds += 1\n    end\n  end\nend\n</code>\n</pre>\n", "senID": 7}, {"text": ["is just a tad quicker for me."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["I was thinking about about a way to improve the"], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"code": "<pre>\n<code>\n if hashes.has_key?(line) ...\n</code>\n</pre>\n", "senID": 10}, {"text": ["code a bit, but could not think of anything."], "childNum": 0, "tag": "p", "senID": 11, "childList": []}, {"text": ["Have you tried using Ruby 1.9?"], "childNum": 0, "tag": "p", "senID": 12, "childList": []}, {"text": ["I have a Windows 7 Virtual Machine with Ruby 1.9.1, and there the f.readlines was slower, and i needed to use the while (line=f.gets) because of the memory limitations :)"], "childNum": 2, "tag": "p", "senID": 13, "childList": [{"text": "f.readlines", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "while (line=f.gets)", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Since a lot uf Ruby users test mainly on Unix related platforms, i guess that could explain why the code is sub-optimal on Windows.", "Has anybody compared the above mentioned performance on Unix?", "Is this a ruby vs. python problem, or Ruby-windows vs. Ruby-Unix? "], "childNum": 0, "tag": "p", "senID": 14, "childList": []}], [{"text": ["I'd bet results of Ruby 1.9.x, which is faster or on par with Python in most areas, are caused by an additional overhead required by hashes/dictionaries implementation because the are ordered in Ruby contrary to Python."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "ordered", "childNum": 0, "tag": "b", "pos": 0, "childList": []}]}], [{"text": ["I'll try to do a benchmark in my copious free time, but try using group_by.", "It's not only more like functional programming, but I've found it to be a lot faster than the procedural version in MRI."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "group_by", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n def convert_to_hash(file)\n  values_hash = file.each_line.group_by {|line| line}\n  # Hash.[] converts an array of pairs into a hash\n  count_hash = Hash[ values_hash.map{|line, lines| [line, lines.length]}]\n  count_hash\nend\n\nhash1 = convert_to_hash(file)\nhash2 = convert_to_hash(file2)\n# compare if the two hashes are equal\n</code>\n</pre>\n", "senID": 1}]]