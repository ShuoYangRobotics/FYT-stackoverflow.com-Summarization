[[{"text": ["Use twisted!", "It makes this kind of thing absurdly easy compared to, say, using threads."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "twisted", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://twistedmatrix.com"}]}, {"code": "<pre>\n<code>\n from twisted.internet import defer, reactor\nfrom twisted.web.client import getPage\nimport time\n\ndef processPage(page, url):\n    # do somewthing here.\n    return url, len(page)\n\ndef printResults(result):\n    for success, value in result:\n        if success:\n            print 'Success:', value\n        else:\n            print 'Failure:', value.getErrorMessage()\n\ndef printDelta(_, start):\n    delta = time.time() - start\n    print 'ran in %0.3fs' % (delta,)\n    return delta\n\nurls = [\n    'http://www.google.com/',\n    'http://www.lycos.com/',\n    'http://www.bing.com/',\n    'http://www.altavista.com/',\n    'http://achewood.com/',\n]\n\ndef fetchURLs():\n    callbacks = []\n    for url in urls:\n        d = getPage(url)\n        d.addCallback(processPage, url)\n        callbacks.append(d)\n\n    callbacks = defer.DeferredList(callbacks)\n    callbacks.addCallback(printResults)\n    return callbacks\n\n@defer.inlineCallbacks\ndef main():\n    times = []\n    for x in xrange(5):\n        d = fetchURLs()\n        d.addCallback(printDelta, time.time())\n        times.append((yield d))\n    print 'avg time: %0.3fs' % (sum(times) / len(times),)\n\nreactor.callWhenRunning(main)\nreactor.run()\n</code>\n</pre>\n", "senID": 1}, {"text": ["This code also performs better than any of the other solutions posted (edited after I closed some things that were using a lot of bandwidth):"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n Success: ('http://www.google.com/', 8135)\nSuccess: ('http://www.lycos.com/', 29996)\nSuccess: ('http://www.bing.com/', 28611)\nSuccess: ('http://www.altavista.com/', 8378)\nSuccess: ('http://achewood.com/', 15043)\nran in 0.518s\nSuccess: ('http://www.google.com/', 8135)\nSuccess: ('http://www.lycos.com/', 30349)\nSuccess: ('http://www.bing.com/', 28611)\nSuccess: ('http://www.altavista.com/', 8378)\nSuccess: ('http://achewood.com/', 15043)\nran in 0.461s\nSuccess: ('http://www.google.com/', 8135)\nSuccess: ('http://www.lycos.com/', 30033)\nSuccess: ('http://www.bing.com/', 28611)\nSuccess: ('http://www.altavista.com/', 8378)\nSuccess: ('http://achewood.com/', 15043)\nran in 0.435s\nSuccess: ('http://www.google.com/', 8117)\nSuccess: ('http://www.lycos.com/', 30349)\nSuccess: ('http://www.bing.com/', 28611)\nSuccess: ('http://www.altavista.com/', 8378)\nSuccess: ('http://achewood.com/', 15043)\nran in 0.449s\nSuccess: ('http://www.google.com/', 8135)\nSuccess: ('http://www.lycos.com/', 30349)\nSuccess: ('http://www.bing.com/', 28611)\nSuccess: ('http://www.altavista.com/', 8378)\nSuccess: ('http://achewood.com/', 15043)\nran in 0.547s\navg time: 0.482s\n</code>\n</pre>\n", "senID": 3}, {"text": ["And using Nick T's code, rigged up to also give the average of five and show the output better: "], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n Starting threaded reads:\n...took 1.921520 seconds ([8117, 30070, 15043, 8386, 28611])\nStarting threaded reads:\n...took 1.779461 seconds ([8135, 15043, 8386, 30349, 28611])\nStarting threaded reads:\n...took 1.756968 seconds ([8135, 8386, 15043, 30349, 28611])\nStarting threaded reads:\n...took 1.762956 seconds ([8386, 8135, 15043, 29996, 28611])\nStarting threaded reads:\n...took 1.654377 seconds ([8117, 30349, 15043, 8386, 28611])\navg time: 1.775s\n\nStarting sequential reads:\n...took 1.389803 seconds ([8135, 30147, 28611, 8386, 15043])\nStarting sequential reads:\n...took 1.457451 seconds ([8135, 30051, 28611, 8386, 15043])\nStarting sequential reads:\n...took 1.432214 seconds ([8135, 29996, 28611, 8386, 15043])\nStarting sequential reads:\n...took 1.447866 seconds ([8117, 30028, 28611, 8386, 15043])\nStarting sequential reads:\n...took 1.468946 seconds ([8153, 30051, 28611, 8386, 15043])\navg time: 1.439s\n</code>\n</pre>\n", "senID": 5}, {"text": ["And using Wai Yip Tung's code:"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n Fetched 8117 from http://www.google.com/\nFetched 28611 from http://www.bing.com/\nFetched 8386 from http://www.altavista.com/\nFetched 30051 from http://www.lycos.com/\nFetched 15043 from http://achewood.com/\ndone in 0.704s\nFetched 8117 from http://www.google.com/\nFetched 28611 from http://www.bing.com/\nFetched 8386 from http://www.altavista.com/\nFetched 30114 from http://www.lycos.com/\nFetched 15043 from http://achewood.com/\ndone in 0.845s\nFetched 8153 from http://www.google.com/\nFetched 28611 from http://www.bing.com/\nFetched 8386 from http://www.altavista.com/\nFetched 30070 from http://www.lycos.com/\nFetched 15043 from http://achewood.com/\ndone in 0.689s\nFetched 8117 from http://www.google.com/\nFetched 28611 from http://www.bing.com/\nFetched 8386 from http://www.altavista.com/\nFetched 30114 from http://www.lycos.com/\nFetched 15043 from http://achewood.com/\ndone in 0.647s\nFetched 8135 from http://www.google.com/\nFetched 28611 from http://www.bing.com/\nFetched 8386 from http://www.altavista.com/\nFetched 30349 from http://www.lycos.com/\nFetched 15043 from http://achewood.com/\ndone in 0.693s\navg time: 0.715s\n</code>\n</pre>\n", "senID": 7}, {"text": ["I've gotta say, I do like that the sequential fetches performed better for me."], "childNum": 1, "tag": "p", "senID": 8, "childList": [{"text": "better", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}], [{"text": ["EDIT: I'm expanding the answer to include a more polished example.", "I have found a lot hostility and misinformation in this post regarding threading v.s.", "async I/O.", "Therefore I also adding more argument to refute certain invalid claim.", "I hope this will help people to choose the right tool for the right job."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "EDIT", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["This is a dup to a question 3 days ago."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Python urllib2.open is slow, need a better way to read several urls - Stack Overflow\n  http://stackoverflow.com/questions/3472515/python-urllib2-open-is-slow-need-a-better-way-to-read-several-urls/3472905#3472905"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://stackoverflow.com/questions/3472515/python-urllib2-open-is-slow-need-a-better-way-to-read-several-urls/3472905#3472905", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/3472515/python-urllib2-open-is-slow-need-a-better-way-to-read-several-urls/3472905#3472905"}]}, {"text": ["I'm polishing the code to show how to fetch multiple webpage in parallel using threads."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n import time\nimport threading\nimport Queue\n\n# utility - spawn a thread to execute target for each args\ndef run_parallel_in_threads(target, args_list):\n    result = Queue.Queue()\n    # wrapper to collect return value in a Queue\n    def task_wrapper(*args):\n        result.put(target(*args))\n    threads = [threading.Thread(target=task_wrapper, args=args) for args in args_list]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    return result\n\ndef dummy_task(n):\n    for i in xrange(n):\n        time.sleep(0.1)\n    return n\n\n# below is the application code\nurls = [\n    ('http://www.google.com/',),\n    ('http://www.lycos.com/',),\n    ('http://www.bing.com/',),\n    ('http://www.altavista.com/',),\n    ('http://achewood.com/',),\n]\n\ndef fetch(url):\n    return urllib2.urlopen(url).read()\n\nrun_parallel_in_threads(fetch, urls)\n</code>\n</pre>\n", "senID": 4}, {"text": ["As you can see, the application specific code has only 3 lines, which can be collapsed into 1 line if you are aggressive.", "I don't think anyone can justify their claim that this is complex and unmaintainable. "], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["Unfortunately most other threading code posted here has some flaws.", "Many of them do active polling to wait for the code to finish.", "join() is a better way to synchronize the code.", "I think this code has improved upon all the threading examples so far."], "childNum": 1, "tag": "p", "senID": 6, "childList": [{"text": "join()", "childNum": 0, "tag": "code", "pos": 2, "childList": []}]}, {"text": ["keep-alive connection"], "childNum": 1, "tag": "p", "senID": 7, "childList": [{"text": "keep-alive connection", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["WoLpH's suggestion about using keep-alive connection could be very useful if all you URLs are pointing to the same server."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["twisted"], "childNum": 1, "tag": "p", "senID": 9, "childList": [{"text": "twisted", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Aaron Gallagher is a fans of twisted framework and he is hostile any people who suggest thread.", "Unfortunately a lot of his claims are misinformation.", "For example he said \"-1 for suggesting threads.", "This is IO-bound; threads are useless here.", "\" This contrary to evidence as both Nick T and I have demonstrated speed gain from the using thread.", "In fact I/O bound application has the most to gain from using Python's thread (v.s.", "no gain in CPU bound application).", "Aaron's misguided criticism on thread shows he is rather confused about parallel programming in general."], "childNum": 1, "tag": "p", "senID": 10, "childList": [{"text": "twisted", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Right tool for the right job"], "childNum": 1, "tag": "p", "senID": 11, "childList": [{"text": "Right tool for the right job", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["I'm well aware of the issues pertain to parallel programming using threads, python, async I/O and so on.", "Each tool has their pros and cons.", "For each situation there is an appropriate tool.", "I'm not against twisted (though I have not deployed one myself).", "But I don't believe we can flat out say that thread is BAD and twisted is GOOD in all situations."], "childNum": 0, "tag": "p", "senID": 12, "childList": []}, {"text": ["For example, if the OP's requirement is to fetch 10,000 website in parallel, async I/O will be prefereable.", "Threading won't be appropriable (unless maybe with stackless Python)."], "childNum": 0, "tag": "p", "senID": 13, "childList": []}, {"text": ["Aaron's opposition to threads are mostly generalizations.", "He fail to recognize that this is a trivial parallelization task.", "Each task is independent and do not share resources.", "So most of his attack do not apply."], "childNum": 0, "tag": "p", "senID": 14, "childList": []}, {"text": ["Given my code has no external dependency, I'll call it right tool for the right job."], "childNum": 0, "tag": "p", "senID": 15, "childList": []}, {"text": ["Performance"], "childNum": 1, "tag": "p", "senID": 16, "childList": [{"text": "Performance", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["I think most people would agree that performance of this task is largely depend on the networking code and the external server, where the performance of platform code should have negligible effect.", "However Aaron's benchmark show an 50% speed gain over the threaded code.", "I think it is necessary to response to this apparent speed gain."], "childNum": 0, "tag": "p", "senID": 17, "childList": []}, {"text": ["In Nick's code, there is an obvious flaw that caused the inefficiency.", "But how do you explain the 233ms speed gain over my code?", "I think even twisted fans will refrain from jumping into conclusion to attribute this to the efficiency of twisted.", "There are, after all, a huge amount of variable outside of the system code, like the remote server's performance, network, caching, and difference implementation between urllib2 and twisted web client and so on."], "childNum": 0, "tag": "p", "senID": 18, "childList": []}, {"text": ["Just to make sure Python's threading will not incur a huge amount of inefficiency, I do a quick benchmark to spawn 5 threads and then 500 threads.", "I am quite comfortable to say the overhead of spawning 5 thread is negligible and cannot explain the 233ms speed difference."], "childNum": 0, "tag": "p", "senID": 19, "childList": []}, {"code": "<pre>\n<code>\n In [274]: %time run_parallel_in_threads(dummy_task, [(0,)]*5)\nCPU times: user 0.00 s, sys: 0.00 s, total: 0.00 s\nWall time: 0.00 s\nOut[275]: &lt;Queue.Queue instance at 0x038B2878&gt;\n\nIn [276]: %time run_parallel_in_threads(dummy_task, [(0,)]*500)\nCPU times: user 0.16 s, sys: 0.00 s, total: 0.16 s\nWall time: 0.16 s\n\nIn [278]: %time run_parallel_in_threads(dummy_task, [(10,)]*500)\nCPU times: user 1.13 s, sys: 0.00 s, total: 1.13 s\nWall time: 1.13 s       &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; This means 0.13s of overhead\n</code>\n</pre>\n", "senID": 20}, {"text": ["Further testing on my parallel fetching shows a huge variability in the response time in 17 runs.", "(Unfortunately I don't have twisted to verify Aaron's code)."], "childNum": 0, "tag": "p", "senID": 21, "childList": []}, {"code": "<pre>\n<code>\n 0.75 s\n0.38 s\n0.59 s\n0.38 s\n0.62 s\n1.50 s\n0.49 s\n0.36 s\n0.95 s\n0.43 s\n0.61 s\n0.81 s\n0.46 s\n1.21 s\n2.87 s\n1.04 s\n1.72 s\n</code>\n</pre>\n", "senID": 22}, {"text": ["My testing does not support Aaron's conclusion that threading is consistently slower than async I/O by a measurable margin.", "Given the number of variables involved, I have to say this is not a valid test to measure the systematic performance difference between async I/O and threading."], "childNum": 0, "tag": "p", "senID": 23, "childList": []}], [{"text": ["Here is an example using python Threads.", "The other threaded examples here launch a thread per url, which is not very friendly behaviour if it causes too many hits for the server to handle (for example it is common for spiders to have many urls on the same host)"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Threads", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n from threading import Thread\nfrom urllib2 import urlopen\nfrom time import time, sleep\n\nWORKERS=1\nurls = ['http://docs.python.org/library/threading.html',\n        'http://docs.python.org/library/thread.html',\n        'http://docs.python.org/library/multiprocessing.html',\n        'http://docs.python.org/howto/urllib2.html']*10\nresults = []\n\nclass Worker(Thread):\n    def run(self):\n        while urls:\n            url = urls.pop()\n            results.append((url, urlopen(url).read()))\n\nstart = time()\nthreads = [Worker() for i in range(WORKERS)]\nany(t.start() for t in threads)\n\nwhile len(results)&lt;40:\n    sleep(0.1)\nprint time()-start\n</code>\n</pre>\n", "senID": 1}, {"text": ["Note: The times given here are for 40 urls and will depend a lot on the speed of your internet connection and the latency to the server.", "Being in Australia, my ping is > 300ms"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["With WORKERS=1 it took 86 seconds to run\nWith WORKERS=4 it took 23 seconds to run\nwith WORKERS=10 it took 10 seconds to run  "], "childNum": 5, "tag": "p", "senID": 3, "childList": [{"text": "WORKERS=1", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "", "childNum": 0, "tag": "br", "childList": []}, {"text": "WORKERS=4", "childNum": 0, "tag": "code", "childList": []}, {"text": "", "childNum": 0, "tag": "br", "childList": []}, {"text": "WORKERS=10", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["so having 10 threads downloading is 8.6 times as fast as a single thread."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["Here is an upgraded version that uses a Queue.", "There are at least a couple of advantages.", "1.", "The urls are requested in the order that they appear in the list\n2.", "Can use q.join() to detect when the requests have all completed\n3.", "The results are kept in the same order as the url list"], "childNum": 4, "tag": "p", "senID": 5, "childList": [{"text": "", "childNum": 0, "tag": "br", "pos": 0, "childList": []}, {"text": "", "childNum": 0, "tag": "br", "pos": 1, "childList": []}, {"text": "q.join()", "childNum": 0, "tag": "code", "pos": 4, "childList": []}, {"text": "", "childNum": 0, "tag": "br", "pos": 5, "childList": []}]}, {"code": "<pre>\n<code>\n from threading import Thread\nfrom urllib2 import urlopen\nfrom time import time, sleep\nfrom Queue import Queue\n\nWORKERS=10\nurls = ['http://docs.python.org/library/threading.html',\n        'http://docs.python.org/library/thread.html',\n        'http://docs.python.org/library/multiprocessing.html',\n        'http://docs.python.org/howto/urllib2.html']*10\nresults = [None]*len(urls)\n\ndef worker():\n    while True:\n        i, url = q.get()\n        # print \"requesting \", i, url       # if you want to see what's going on\n        results[i]=urlopen(url).read()\n        q.task_done()\n\nstart = time()\nq = Queue()\nfor i in range(WORKERS):\n    t=Thread(target=worker)\n    t.daemon = True\n    t.start()\n\nfor i,url in enumerate(urls):\n    q.put((i,url))\nq.join()\nprint time()-start\n</code>\n</pre>\n", "senID": 6}], [{"text": ["The actual wait is probably not in urllib2 but in the server and/or your network connection to the server."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "urllib2", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["There are 2 ways of speeding this up."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Fetching webpages obviously will take a while as you're not accessing anything local.", "If you have several to access, you could use the threading module to run a couple at once."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "threading", "tag": "a", "pos": 1, "childList": [{"text": "threading", "tag": "code"}], "childNum": 1, "href": "http://docs.python.org/library/threading.html"}, {"text": "threading", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Here's a very crude example"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n import threading\nimport urllib2\nimport time\n\nurls = ['http://docs.python.org/library/threading.html',\n        'http://docs.python.org/library/thread.html',\n        'http://docs.python.org/library/multiprocessing.html',\n        'http://docs.python.org/howto/urllib2.html']\ndata1 = []\ndata2 = []\n\nclass PageFetch(threading.Thread):\n    def __init__(self, url, datadump):\n        self.url = url\n        self.datadump = datadump\n        threading.Thread.__init__(self)\n    def run(self):\n        page = urllib2.urlopen(self.url)\n        self.datadump.append(page.read()) # don't do it like this.\n\nprint \"Starting threaded reads:\"\nstart = time.clock()\nfor url in urls:\n    PageFetch(url, data2).start()\nwhile len(data2) &lt; len(urls): pass # don't do this either.\nprint \"...took %f seconds\" % (time.clock() - start)\n\nprint \"Starting sequential reads:\"\nstart = time.clock()\nfor url in urls:\n    page = urllib2.urlopen(url)\n    data1.append(page.read())\nprint \"...took %f seconds\" % (time.clock() - start)\n\nfor i,x in enumerate(data1):\n    print len(data1[i]), len(data2[i])\n</code>\n</pre>\n", "senID": 2}, {"text": ["This was the output when I ran it:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n Starting threaded reads:\n...took 2.035579 seconds\nStarting sequential reads:\n...took 4.307102 seconds\n73127 19923\n19923 59366\n361483 73127\n59366 361483\n</code>\n</pre>\n", "senID": 4}, {"text": ["Grabbing the data from the thread by appending to a list is probably ill-advised (Queue would be better) but it illustrates that there is a difference."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}], [{"text": ["Nowadays there is excellent Python lib that do this for you called requests."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "requests", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python-requests.org/"}]}, {"text": ["Use standard api of requests if you want solution based on threads or async api (using gevent under the hood) if you want solution based on non-blocking IO."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}]]