[[{"text": ["We've just launched a new natural language processing API over at repustate.com.", "Using a REST API, you can clean any HTML or PDF and get back just the text parts.", "Our API is free so feel free to use to your heart's content.", "And it's implemented in python.", "Check it out and compare the results to readability.js - I think you'll find they're almost 100% the same."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Please try my fork https://github.com/buriy/python-readability which is fast and has all features of latest javascript version."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "https://github.com/buriy/python-readability", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "https://github.com/buriy/python-readability"}]}], [{"text": ["hn.py via Readability's blog.", "Readable Feeds, an App Engine app, makes use of it."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "hn.py", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://nirmalpatel.com/fcgi/hn.py"}, {"text": "Readability's blog", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://blog.arc90.com/2009/06/20/readability-now-available-in-three-delicious-flavors/"}, {"text": "Readable Feeds", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://andrewtrusty.appspot.com/readability/"}]}, {"text": ["I have bundled it as a pip-installable module here: http://github.com/srid/readability"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://github.com/srid/readability", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://github.com/srid/readability"}]}], [{"text": ["I have done some research on this in the past and ended up implementing this approach [pdf] in Python.", "The final version I implemented also did some cleanup prior to applying the algorithm, like removing head/script/iframe elements, hidden elements, etc., but this was the core of it."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "this approach [pdf]", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.psl.cs.columbia.edu/crunch/WWWJ.pdf"}]}, {"text": ["Here is a function with a (very) naive implementation of the \"link list\" discriminator, which attempts to remove elements with a heavy link to text ratio (ie.", "navigation bars, menus, ads, etc.", "):"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n def link_list_discriminator(html, min_links=2, ratio=0.5):\n    \"\"\"Remove blocks with a high link to text ratio.\n\n    These are typically navigation elements.\n\n    Based on an algorithm described in:\n        http://www.psl.cs.columbia.edu/crunch/WWWJ.pdf\n\n    :param html: ElementTree object.\n    :param min_links: Minimum number of links inside an element\n                      before considering a block for deletion.\n    :param ratio: Ratio of link text to all text before an element is considered\n                  for deletion.\n    \"\"\"\n    def collapse(strings):\n        return u''.join(filter(None, (text.strip() for text in strings)))\n\n    # FIXME: This doesn't account for top-level text...\n    for el in html.xpath('//*'):\n        anchor_text = el.xpath('.//a//text()')\n        anchor_count = len(anchor_text)\n        anchor_text = collapse(anchor_text)\n        text = collapse(el.xpath('.//text()'))\n        anchors = float(len(anchor_text))\n        all = float(len(text))\n        if anchor_count &gt; min_links and all and anchors / all &gt; ratio:\n            el.drop_tree()\n</code>\n</pre>\n", "senID": 2}, {"text": ["On the test corpus I used it actually worked quite well, but achieving high reliability will require a lot of tweaking."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["Why not try using Google V8/Node.js instead of Rhino?", "It should be acceptably fast."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["I think BeautifulSoup is the best HTML parser for python.", "But you still need to figure out what the \"main\" part of the site is. "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "BeautifulSoup", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.crummy.com/software/BeautifulSoup/"}]}, {"text": ["If you're only parsing a single domain, it's fairly straight forward, but finding a pattern that works for any site is not so easy. "], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "any", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}, {"text": ["Maybe you can port the readability.js approach to python?"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]]