[[{"text": ["Sets don't have keys.", "The element is the key."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "is", "childNum": 0, "tag": "strong", "pos": 1, "childList": []}]}, {"text": ["If you think you want keys, you have a mapping.", "More-or-less by definition."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Sequential list lookup can be slow, even using a binary search.", "Mappings use hashes and are fast."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Are you talking about a dictionary like this?"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n { 'id1': [ ('description1a', 'type1'), ('description1b','type1') ], \n  'id2': [ ('description2', 'type2') ],\n...\n}\n</code>\n</pre>\n", "senID": 4}, {"text": ["This sure seems minimal.", "ID's are only represented once."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["Perhaps you have something like this?"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n { 'id1': ( ('description1a', 'description1b' ), 'type1' ),\n  'id2': ( ('description2',), 'type2' ),\n...\n}\n</code>\n</pre>\n", "senID": 7}, {"text": ["I'm not sure you can find anything more compact unless you resort to using the struct module."], "childNum": 1, "tag": "p", "senID": 8, "childList": [{"text": "struct", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["I'm assuming the problem you try to solve by cutting down on the memory you use is the address space limit of your process.", "Additionally you search for a data structure that allows you fast insertion and reasonable sequential read out."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Use less structures except strings (str)"], "childNum": 0, "tag": "h2", "senID": 1, "childList": []}, {"text": ["The question you ask is how to structure your data in one process to use less memory.", "The one canonical answer to this is (as long as you still need associative lookups), use as little other structures then python strings (str, not unicode) as possible.", "A python hash (dictionary) stores the references to your strings fairly efficiently (it is not a b-tree implementation)."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["However I think that you will not get very far with that approach, since what you face are huge datasets that might eventually just exceed the process address space and the physical memory of the machine you're working with altogether."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Alternative Solution"], "childNum": 0, "tag": "h2", "senID": 4, "childList": []}, {"text": ["I would propose a different solution that does not involve changing your data structure to something that is harder to insert or interprete."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"tag": "ul", "num": 3, "lis": [{"text": "Split your information up in multiple processes, each holding whatever datastructure is convinient for that. ", "tag": "none", "senID": 6}, {"text": "Implement inter process communication with sockets such that processes might reside on other machines altogether. ", "tag": "none", "senID": 7}, {"text": "Try to divide your data such as to minimize inter process communication (i/o is glacially slow compared to cpu cycles). ", "tag": "none", "senID": 8}]}, {"text": ["The advantage of the approach I outline is that"], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": "You get to use two ore more cores on a machine fully for performance", "tag": "none", "senID": 10}, {"text": "You are not limited by the address space of one process, or even the physical memory of one machine", "tag": "none", "senID": 11}]}, {"text": ["There are numerous packages and aproaches to distributed processing, some of which are"], "childNum": 0, "tag": "p", "senID": 12, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": ["linda"], "childNum": 0, "tag": "a", "senID": 13, "childList": []}, {"text": ["processing"], "childNum": 0, "tag": "a", "senID": 14, "childList": []}]}], [{"text": ["If you're doing an n-way merge with removing duplicates, the following may be what you're looking for."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["This generator will merge any number of sources.", "Each source must be a sequence.", "The key must be in position 0.", "It yields the merged sequence one item at a time."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n def merge( *sources ):\n    keyPos= 0\n    for s in sources:\n        s.sort()\n    while any( [len(s)&gt;0 for s in sources] ):\n        topEnum= enumerate([ s[0][keyPos] if len(s) &gt; 0 else None for s in sources ])\n        top= [ t for t in topEnum if t[1] is not None ]\n        top.sort( key=lambda a:a[1] )\n        src, key = top[0]\n        #print src, key\n        yield sources[ src ].pop(0)\n</code>\n</pre>\n", "senID": 2}, {"text": ["This generator removes duplicates from a sequence.  "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n def unique( sequence ):\n    keyPos= 0\n    seqIter= iter(sequence)\n    curr= seqIter.next()\n    for next in seqIter:\n        if next[keyPos] == curr[keyPos]:\n            # might want to create a sub-list of matches\n            continue\n        yield curr\n        curr= next\n    yield curr\n</code>\n</pre>\n", "senID": 4}, {"text": ["Here's a script which uses these functions to produce a resulting sequence which is the union of all the sources with duplicates removed."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"code": "<pre>\n<code>\n for u in unique( merge( source1, source2, source3, ... ) ):\n    print u\n</code>\n</pre>\n", "senID": 6}, {"text": ["The complete set of data in each sequence must exist in memory once because we're sorting in memory.", "However, the resulting sequence does not actually exist in memory.", "Indeed, it works by consuming the other sequences.  "], "childNum": 0, "tag": "p", "senID": 7, "childList": []}], [{"text": ["How about using {id: (description, id_type)} dictionary?", "Or {(id, id_type): description} dictionary if (id,id_type) is the key."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "{id: (description, id_type)}", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "{(id, id_type): description}", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}], [{"text": ["Sets in Python are implemented using hash tables.", "In earlier versions, they were actually implemented using sets, but that has changed AFAIK.", "The only thing you save by using a set would then be the size of a pointer for each entry (the pointer to the value). "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["To use only a part of a tuple for the hashcode, you'd have to subclass tuple and override the hashcode method:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n class ProteinTuple(tuple):\n     def __new__(cls, m1, m2, m3):\n         return tuple.__new__(cls, (m1, m2, m3))\n\n     def __hash__(self):\n         return hash(self[0])\n</code>\n</pre>\n", "senID": 2}, {"text": ["Keep in mind that you pay for the extra function call to __hash__ in this case, because otherwise it would be a C method."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "__hash__", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["I'd go for Constantin's suggestions and take out the id from the tuple and see how much that helps."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["It's still murky, but it sounds like you have some several lists of [(id, description, type)...]"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["The id's are unique within a list and consistent between lists."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You want to create a UNION: a single list, where each id occurs once, with possibly multiple descriptions."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["For some reason, you think a mapping might be too big.", "Do you have any evidence of this?", "Don't over-optimize without actual measurements.  "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["This may be (if I'm guessing correctly) the standard \"merge\" operation from multiple sources."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n source1.sort()\nsource2.sort()\nresult= []\nwhile len(source1) &gt; 0 or len(source2) &gt; 0:\n    if len(source1) == 0:\n        result.append( source2.pop(0) )\n    elif len(source2) == 0:\n        result.append( source1.pop(0) )\n    elif source1[0][0] &lt; source2[0][0]:\n        result.append( source1.pop(0) )\n    elif source2[0][0] &lt; source1[0][0]:\n        result.append( source2.pop(0) )\n    else:\n        # keys are equal\n        result.append( source1.pop(0) )\n        # check for source2, to see if the description is different.\n</code>\n</pre>\n", "senID": 5}, {"text": ["This assembles a union of two lists by sorting and merging.", "No mapping, no hash."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}]]