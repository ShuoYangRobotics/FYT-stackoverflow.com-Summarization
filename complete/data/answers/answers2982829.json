[[{"text": ["Copying files is an I/O bound process.", "It is unlikely that you will see any speed up from rewriting it in assembly, and even multithreading may just cause things to go slower as different threads requesting different files at the same time will result in more disk seeks."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Using a standard tool is probably the best way to go here.", "If there is anything to optimize, you might want to consider changing your file system or your hardware."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["There are 2 places for slowdown:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"tag": "ul", "num": 2, "lis": [{"text": ["Per-file copy is MUCH slower than a disk copy (where you literally clone 100% of each sector's data).", "Especially for 20mm files.", "You can't fix that one with the most tuned assembly, unless you switch from cloning files to cloning raw disk data.", "In the latter case, yes, Assembly is indeed your ticket (or C)."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "unless you switch from cloning files to cloning raw disk data. In the latter case, yes, Assembly is indeed your ticket (or C)", "childNum": 0, "tag": "strong", "pos": -1, "childList": []}]}, {"text": ["Simply storing 20mm files and recursively finding them may be less efficient in Python.", "But that's more likely a function of finding better algorithm and is not likely to be significantly improved by Assembly.", "Plus, that will NOT be the main contributor to 50 hrs"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]}, {"text": ["In summary - Assembly WILL help if you do raw disk sector copy, but will NOT help if you do filesystem level copy."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "In summary - Assembly WILL help if you do raw disk sector copy, but will NOT help if you do filesystem level copy.", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}], [{"text": ["As the other answers mention (+1 to mark), when copying files, disk i/o is the bottleneck.", "The language you use won't make much of a difference.", "How you've laid out your files will make a difference, how you're transferring data will make a difference."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["You mentioned copying to a DROBO.", "How is your DROBO connected?", "Check out this graph of connection speeds."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "graph of connection speeds", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://www.macspeedzone.com/archive/5.0/usbcomparison.html"}]}, {"text": ["Let's look at the max copy rates you can get over certain wire types:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"tag": "ul", "num": 4, "lis": [{"text": "USB = 97 days (", "tag": "none", "senID": 3}, {"text": "USB2.0 = ~7hrs (", "tag": "none", "senID": 4}, {"text": "Fast SCSI = ~40hrs (", "tag": "none", "senID": 5}, {"text": "100 Mbps ethernet = 1.4 days (", "tag": "none", "senID": 6}]}, {"text": ["So, depending on the constraints of your problem, it's possible you can't do better.", "But you may want to start doing a raw disk copy (like Unix's dd), which should be much faster than a file-system level copy (it's faster because there are no random disk seeks for directory walks or fragmented files)."], "childNum": 2, "tag": "p", "senID": 7, "childList": [{"text": "can't", "childNum": 0, "tag": "em", "pos": 0, "childList": []}, {"text": "Unix's dd", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Dd_(Unix)"}]}, {"text": ["To use dd, you could live boot linux onto your machine (or maybe use cygwin?).", "See this page for reference or this one about backing up from windows using a live-boot of Ubuntu."], "childNum": 3, "tag": "p", "senID": 8, "childList": [{"text": "dd", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "this page for reference", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.nilbus.com/linux/disk-copy.php"}, {"href": "http://www.howtogeek.com/howto/windows-vista/use-ubuntu-live-cd-to-backup-files-from-your-dead-windows-computer/", "text": "this one about backing up from windows using a live-boot of Ubuntu", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["If you were to organize your 1.5 TB data on a RAID, you could probably speed up the copy (because the disks will be reading in parallel), and (depending on the configuration) it'll have the added benefit of protecting you from drive failures."], "childNum": 1, "tag": "p", "senID": 9, "childList": [{"text": "RAID", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/RAID"}]}], [{"text": ["I don't think writing it in assembly will help you.", "Writing a routine in assembly could help you if you are processor-bound and think you can do something smarter than your compiler.", "But in a network copy, you will be IO bound, so shaving a cycle here or there almost certainly will not make a difference."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I think the genreal rule here is that it's always best to profile your process to see where you are spending the time before thinking about optimizations."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["I don't believe it will make a discernable difference which language you use for this purpose.", "The bottleneck here is not your application but the disk performance."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Just because a language is interpreted, it doesn't mean that every single operation in it is slow.", "As an example, it's a fairly safe bet that the lower-level code in Python will call assembly (or compiled) code to do copying."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Similarly, when you do stuff with collections and other libraries in Java, that's mostly compiled C, not interpreted Java."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["There are a couple of things you can do to possibly speed up the process."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "possibly", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}, {"tag": "ul", "num": 5, "lis": [{"text": "Buy faster hard disks (10K RPMs rather than 7.5K or less latency, larger caches and so forth).", "tag": "none", "senID": 4}, {"text": "Copying between two physical disks may be faster than copying on a single disk (due to the head movement).", "tag": "none", "senID": 5}, {"text": "If you're copying across the network, stage it. In other words, copy it fast to another local disk, then slow from there across the net.", "tag": "none", "senID": 6}, {"text": "You can also stage it in a different way. If you run a nightly (or even weekly) process to keep the copy up to date (only copying changed files) rather than three times a year, you won't find yourself in a situation where you have to copy a massive amount.", "tag": "none", "senID": 7}, {"text": "Also if you're using the network, run it on the box where the repository is. You don't want to copy all the data from a remote disk to another PC then back to yet ", "tag": "none", "senID": 8}]}, {"text": ["You may also want to be careful with Python.", "I may be mistaken (and no doubt the Pythonistas will set me straight if I'm mistaken on this count ) but I have a vague recollection that its threading may not fully utilise multi-core CPUs.", "In that case, you'd be better off with another solution. "], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"text": ["You may well be better off sticking with your current solution.", "I suspect a specialised copy program will already be optimised as much as possible since that's what they do."], "childNum": 1, "tag": "p", "senID": 10, "childList": [{"text": "do", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}], [{"text": ["There's no reason at all to write a copy program in assembly.", "The problem is with the amount of IO involved not CPU.", "Also, the copy function in python is already written in C by experts and you won't eek out any more speed writing one yourself in assembler."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Lastly, threading won't help either, especially in python.", "Go with with either Twisted or just use the new multiprocessing module in Python 2.6 and kick off a pool of processes to do the copies.", "Save yourself a lot of torment while getting the job done."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "Twisted", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://twistedmatrix.com/trac/"}, {"text": "multiprocessing module", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/multiprocessing.html"}]}], [{"text": ["Before you question the copying app, you should most likely question the data path.", "What are the theoretical limits and what are you achieving?", "What are the potential bottlenecks?", "If there is a single data path, you are probably not going to get a significant boost by parallelizing storage tasks.", "You may even exacerbate it.", "Most of the benefits you'll get with asynchronous I/O come at the block level - a level lower than the file system."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["One thing you could do to boost I/O is decouple the fetch from source and store to destination portions.", "Assuming that the source and destination are separate entities, you could theoretically halve the amount of time for the process.", "But are the standard tools already doing this?"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "theoretically", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"text": ["Oh - and on Python and the GIL - with I/O-bound execution, the GIL is really not quite that bad of a penalty."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["RICHCOPY is already copying files in parallel, and I expect the only way to beat it is to get in bed with the filesystem so that you minimize disk I/O, especially seeking.", "I suggest you try ntfsclone to see if it meets your needs.", "If not, my next suggestion would be to parallize ntfsclone."], "childNum": 4, "tag": "p", "senID": 0, "childList": [{"text": "get in bed with the filesystem so that you minimize disk I/O", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "ntfsclone", "tag": "a", "pos": 1, "childList": [{"text": "ntfsclone", "tag": "code"}], "childNum": 1, "href": "http://man.linux-ntfs.org/ntfsclone.8.html"}, {"text": "ntfsclone", "childNum": 0, "tag": "code", "pos": 2, "childList": []}, {"text": "ntfsclone", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["In any case, working directly with filesystem layout on disk is going to be easiest in C, not Python and certainly not assembly.", "Especially since you can get started by using the C code from the NTFS 3G project.", "This code is designed for reliability and ease of porting, not performance, but it's still probably the easiest way to get started."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "NTFS 3G", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/NTFS-3G"}]}, {"text": ["No.", "Or more accurately, at your current level of mastery of systems programming, achieving significant improvements in speed will be prohibitively expensive.", "What you're asking for requires very specialized expertise.", "Although I myself have prior experience in  implementing filesystems (much simpler ones than NTFS, XFS, or ext2), I would not tackle this job; I would hire it done."], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "significant", "childNum": 0, "tag": "em", "pos": 1, "childList": []}, {"text": "prohibitively expensive", "childNum": 0, "tag": "strong", "pos": -1, "childList": []}]}, {"text": ["Footnote:  if you have access to a Linux box, find out what raw write bandwidth you can get to the target drive:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n time dd if=/dev/zero of=/dev/sdc bs=1024k count=100\n</code>\n</pre>\n", "senID": 4}, {"text": ["will give you the time to write 100MB sequentially in the fastest possible way.", "That will give you an absolute limit on what is possible with your hardware.", "Don't try this without understanding the man page fordd!", "dd stands for \"destroy data\".", "(Actually it stands for \"copy and convert\", but cc was taken."], "childNum": 4, "tag": "p", "senID": 5, "childList": [{"text": "Don't try this without understanding the man page fordd!", "childNum": 1, "tag": "strong", "pos": 2, "childList": [{"text": "dd", "tag": "code"}]}, {"text": "dd", "childNum": 0, "tag": "code", "pos": 3, "childList": []}, {"text": "dd", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "cc", "childNum": 0, "tag": "code", "pos": 4, "childList": []}]}, {"text": ["A Windows programmer can probably point you to an equivalent test for Windows."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["Right, here the bottleneck is not in the execution of the copying software itself but rather the disk access."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Going lower level does not mean that you will have better performance.", "Take a simple example of open() and fopen() APIs where open is much lower level is is more direct and fopen() is a library wrapper for the system open() function."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["But in reality fopen has better berformance because it adds buffering and optimizes a lot of stuff that is not done in the raw open() function."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Implementing optimizations in assembly level is much harder and less efficient than in python."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["1,5 TB in approximately 50 hours gives a throughput of (1,5 * 1024^2) MB / (50 * 60^2) s = 8,7 MB/s.", "A theoretical 100 mbit/s bandwidth should give you 12,5 MB/s.", "It seems to me that your firewire connection is a problem.", "You should look at upgrading drivers, or upgrading  to a better firewire/esata/usb interface."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["That said, rather than the python/assembly question, you should look at acquiring a file syncing solution.", "It shouldn't be necessary copying that data over and over again."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["As already said, it is not the language here to make the difference; assembly could be cool or fast for computations, but when the processor have to \"speak\" to peripherals, the limit is given by these.", "In this case the speed is given by your hard disk speed, and this is a limit you hardly can change wiithout changing your hd and waiting for better hd in future, but also by the way data are organized on the disk, i.e.", "by the filesystem.", "AFAIK, most used filesystems are not optimized to handle fastly tons of \"small\" files, rather they are optimized to hold \"few\" huge files."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["So, changing the filesystem you're using could increase your copy speed, as far as it is more suitable to your case (and of course hd limits still apply!).", "If you want to \"taste\" the real limit of you hd, you should try a copy \"sector by sector\", replycating the exact image of your source hd to the dest hd.", "(But this option has some points to be aware of)"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "could", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}], [{"text": ["Since I posted the question I have been playing around with some things and I think first off, not to be argumentative but those of you that have been posting the response that I am i/o bound are only partially correct.", "It is seek time that is the constraint.", "Long story to test various options I built a new machine with an I-7 processor and a reasonably powerful/functional motherboard and then using the same two drives I was working with before I noted a fairly significant increase in speed.", "I also noted that when I am moving big files (one gigabyte or so) I get sustained transfer speeds of in excess of 50 mb/s and the speed drops significantly when moving small files.", "I think the speed difference is due to an unordered disk relative to the way the copy program reads the directory structure to determine the files to copy."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["What I think needs to be done  is to \n1: Read the MFT and sort by sector working from the outside to the inside of the platter\n   (it means I have to figure out how multi-platter disks work)\n2: Analyze and separate all contiguous versus non-contiguous files.", "I would handle the \n   contiguous files first and go back to handle the non-contiguous files\n3: start copying the contiguous files from the outside to inside \n4.", "When finished copy the non-contiguous files, by default they will end up on the inner\n   rings of the platter(s) and they will be contiguous.", "(I want to note that I do\n   regularly defragment and have less than 1% of my files/directories are fragmented)but\n   1% of 20 million is still 200K"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Why is this better than just running a copy program."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["I may not have to do this in A, I have been looking around for ways to play (read) the MFT and there are even Python tools for this see http://www.integriography.com"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://www.integriography.com", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.integriography.com"}]}], [{"text": ["Neither.", "If you want to take advantage of OS features to speed up I/O, you'll need to use some specialized system calls that are most easily accessed in C (or C++).", "You don't need to know a lot of C to write such a program, but you really need to know the system call interfaces."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["In all likelihood, you can solve the problem without writing any code by using an existing tool or tuning the operating system, but if you really do need to write a tool, C is the most straightforward way to do it."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}]]