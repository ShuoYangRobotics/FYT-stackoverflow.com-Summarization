[[{"text": ["Your problem is a conflict between the daemon and multiprocessing modules, in particular in its handling of the SIGCLD (child process terminated) signal.", "daemon sets SIGCLD to SIG_IGN when launching, which, at least on Linux, causes terminated children to immediately be reaped (rather than becoming a zombie until the parent invokes wait()).", "But multiprocessing's is_alive test invokes wait() to see if the process is alive, which fails if the process has already been reaped."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Simplest solution is just to set SIGCLD back to SIG_DFL (default behaviour -- ignore the signal and let the parent wait() for the terminated child process):"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n def run():\n    # ...\n\n    signal.signal(signal.SIGCLD, signal.SIG_DFL)\n\n    process = processing.Process(target=func)\n    process.start()\n\n    while True:\n        # ...\n</code>\n</pre>\n", "senID": 2}], [{"text": ["Ignoring SIGCLD also causes problems with the subprocess module, because of a bug in that module (issue 1731717, still open as of 2011-09-21)."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "SIGCLD", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "subprocess", "childNum": 0, "tag": "code", "childList": []}, {"href": "http://bugs.python.org/issue1731717", "text": "issue 1731717", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["This behaviour is addressed in version 1.4.8 of the python-daemon library; it now omits the default fiddling with SIGCLD, so no longer has this unpleasant interaction with other standard library modules."], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "version 1.4.8", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://pypi.python.org/pypi/python-daemon/1.4.8/"}, {"text": "python-daemon", "childNum": 0, "tag": "code", "childList": []}, {"text": "SIGCLD", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["I think there was a fix put into trunk and 2.6 maint a little while ago which should help with this can you try running your script in python-trunk or the latest 2.6-maint svn?", "I'm failing to pull up the bug information"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Looks like your error is coming at the very end of your process -- your clue's at the very start of your traceback, and I quote...:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n File \"/usr/local/lib/python2.6/atexit.py\", line 24, in _run_exitfuncs\n    func(*targs, **kargs)\n</code>\n</pre>\n", "senID": 1}, {"text": ["if atexit._run_exitfuncs is running, this clearly shows that your own process is terminating.", "So, the error itself is a minor issue in a sense -- just from some function that the multiprocessing module registered to run \"at-exit\" from your process.", "The really interesting issue is, WHY is your main process exiting?", "I think this may be due to some uncaught exception: try setting the exception hook and showing rich diagnostic info before it gets lost by the OTHER exception caused by whatever it is that multiprocessing's registered for at-exit running..."], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "atexit._run_exitfuncs", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "multiprocessing", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}], [{"text": ["I'm running into this also using the celery distributed task manager under RHEL 5.3 with Python 2.6.", "My traceback looks a little different but the error the same:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n File \"/usr/local/lib/python2.6/multiprocessing/pool.py\", line 334, in terminate\n    self._terminate()\n  File \"/usr/local/lib/python2.6/multiprocessing/util.py\", line 174, in __call__\n    res = self._callback(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python2.6/multiprocessing/pool.py\", line 373, in _terminate_pool\n    p.terminate()\n  File \"/usr/local/lib/python2.6/multiprocessing/process.py\", line 111, in terminate\n    self._popen.terminate()\n  File \"/usr/local/lib/python2.6/multiprocessing/forking.py\", line 136, in terminate\n    if self.wait(timeout=0.1) is None:\n  File \"/usr/local/lib/python2.6/multiprocessing/forking.py\", line 121, in wait\n    res = self.poll()\n  File \"/usr/local/lib/python2.6/multiprocessing/forking.py\", line 106, in poll\n    pid, sts = os.waitpid(self.pid, flag)\nOSError: [Errno 10] No child processes\n</code>\n</pre>\n", "senID": 1}, {"text": ["Quite frustrating..", "I'm running the code through pdb now,  but haven't spotted anything yet."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["The original sample script has \"import signal\" but no use of signals.", "However, I had a script causing this error message and it was due to my signal handling, so I'll explain here in case its what is happening for others.", "Within a signal handler, I was doing stuff with processes (e.g.", "creating a new process).", "Apparently this doesn't work, so I stopped doing that within the handler and fixed the error.", "(Note: sleep() functions wake up after signal handling so that can be an alternative approach to acting upon signals if you need to do things with processes)"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}]]