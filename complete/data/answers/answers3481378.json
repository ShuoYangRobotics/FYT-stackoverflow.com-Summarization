[[{"text": ["if you want to use, in my opinion, something more proper approach, than regexp:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from urlparse import *\nurlparsed = urlparse('www.example.com?u=userpage&amp;as=233&amp;p=1')\n# -&gt; ParseResult(scheme='', netloc='', path='www.example.com', params='', query='u=userpage&amp;as=233&amp;p=1', fragment='')\nqdict = dict(parse_qsl(urlparsed.query))\n# -&gt; {'as': '233', 'p': '1', 'u': 'userpage'}\nqdict.get('p') == '1' and qdict.get('u') == 'userpage'\n# -&gt; True\n</code>\n</pre>\n", "senID": 1}], [{"code": "<pre>\n<code>\n import lxml.html, urlparse\n\nd = lxml.html.parse(...)\nfor link in d.xpath('//a/@href'):\n    url = urlparse.urlparse(link)\n    if not url.query:\n        continue\n    params = urlparse.parse_qs(url.query)\n    if 'userpage' in params.get('u', []) and '1' in params.get('p', []):\n        print link\n</code>\n</pre>\n", "senID": 0}], [{"text": ["Regex is not a good choice for this because 1) the params could appear in either order, and 2) you need to do extra checks for query separators so that you don't match potential oddities like \"flu=userpage\", \"sp=1\", \"u=userpage%20haha\", or \"s=123\".", "(Note: I missed two of those cases in my first pass!", "So did others.", ") Also: 3) you already have a good URL parsing library in Python which does the work for you."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Note:", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"text": ["With regex you'd need something clumsy like:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n q = re.compile(r'([?&amp;]u=userpage&amp;(.*&amp;)?p=1(&amp;|$))|([?&amp;]p=1&amp;(.*&amp;)?u=userpage(&amp;|$))')\nreturn q.search(href) is not None\n</code>\n</pre>\n", "senID": 2}, {"text": ["With urlparse you can do this.", "urlparse gives you a little more than you want but you can use a helper function to keep the result simple:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n def has_qparam(qs, key, value):\n    return value in qs.get(key, [])\n\nqs = urlparse.parse_qs(urlparse.urlparse(href).query)\nreturn has_qparam(qs, 'u', 'userpage') and has_qparam(qs, 'p', '1')\n</code>\n</pre>\n", "senID": 4}], [{"text": ["/((u=userpage).*?(p=1))|((p=1).*?", "(u=userpage))/"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "/((u=userpage).*?(p=1))|((p=1).*?(u=userpage))/", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"text": ["This will get all strings that contain the two bits you're looking for."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["To make sure you don't accidentally match parts like bu=userpage, u=userpagezap, p=111 or zap=1, you need abundant use of the \\b \"word-boundary\" RE pattern element.", "I.e."], "childNum": 5, "tag": "p", "senID": 0, "childList": [{"text": "bu=userpage", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "u=userpagezap", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "p=111", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "zap=1", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "\\b", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n re.compile(r'\\bp=1\\b.*\\bu=userpage\\b|\\bu=userpage\\b.*\\bp=1\\b')\n</code>\n</pre>\n", "senID": 1}, {"text": ["The word-boundary elements in the RE's pattern prevent the above-mentioned, presumably-undesirable \"accidental\" matches.", "Of course, if in your application they're not \"undesirable\", i.e., if you positively want to match p=123 and the like, you can easily remove some or all of the word-boundary elements above!-)"], "childNum": 3, "tag": "p", "senID": 2, "childList": [{"text": "not", "childNum": 0, "tag": "em", "pos": 1, "childList": []}, {"text": "want", "childNum": 0, "tag": "strong", "childList": []}, {"text": "p=123", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["It is possible to do this with string hacking, but you shouldn't.", "It's already in the standard library:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; import urllib.parse\n&gt;&gt;&gt; urllib.parse.parse_qs(\"u=userpage&amp;as=233&amp;p=1\")\n{'u': ['userpage'], 'as': ['233'], 'p': ['1']}\n</code>\n</pre>\n", "senID": 1}, {"text": ["and hence"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n import urllib.parse\ndef filtered_urls( urls ):\n    for url in urls:\n        try:\n            attrs = urllib.parse.parse_qs( url.split( \"?\" )[ 1 ] )\n        except IndexError:\n            continue\n\n        if \"userpage\" in attrs.get( \"u\", \"\" ) and \"1\" in attrs.get( \"p\", \"\" ):\n            yield url\n\nfoo = [ \"www.example.com?u=userpage&amp;as=233&amp;p=1\", \"www.example.com?u=userpage&amp;as=233&amp;p=2\" ]\n\nprint( list( filtered_urls( foo ) ) )\n</code>\n</pre>\n", "senID": 3}, {"text": ["Note that this is Python 3 -- in Python parse_qs is in urlparse instead."], "childNum": 2, "tag": "p", "senID": 4, "childList": [{"text": "parse_qs", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "urlparse", "childNum": 0, "tag": "code", "childList": []}]}]]