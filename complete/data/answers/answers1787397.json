[[{"text": ["\"Each of my threads is using subprocess.Popen to run a separate command line [process]\"."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "subprocess.Popen", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Why have a bunch of threads manage a bunch of processes?", "That's exactly what an OS does that for you.", "Why micro-manage what the OS already manages?"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Rather than fool around with threads overseeing processes, just fork off processes.", "Your process table probably can't handle 2000 processes, but it can handle a few dozen (maybe a few hundred) pretty easily."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["You want to have more work than your CPU's can possibly handle queued up.", "The real question is one of memory -- not processes or threads.", "If the sum of all the active data for all the processes exceeds physical  memory, then data has to be swapped, and that will slow you down."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "more", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}, {"text": ["If your processes have a fairly small memory footprint, you can have lots and lots running.", "If your processes have a large memory footprint, you can't have very many running."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["If you're using the default \"cpython\" version then this won't help you, because only one thread can execute at a time; look up Global Interpreter Lock.", "Instead, I'd suggest looking at the multiprocessing module in Python 2.6 -- it makes parallel programming a cinch.", "You can create a Pool object with 2*num_threads processes, and give it a bunch of tasks to do.", "It will execute up to 2*num_threads tasks at a time, until all are done."], "childNum": 6, "tag": "p", "senID": 0, "childList": [{"text": "Global Interpreter Lock", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://google.com/search?q=global+interpreter+lock"}, {"text": "multiprocessing", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "module", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://docs.python.org/dev/library/multiprocessing.html#module-multiprocessing.pool"}, {"text": "Pool", "childNum": 0, "tag": "code", "pos": 2, "childList": []}, {"text": "2*num_threads", "childNum": 0, "tag": "code", "pos": 3, "childList": []}, {"text": "2*num_threads", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["At work I have recently migrated a bunch of Python XML tools (a differ, xpath grepper, and bulk xslt transformer) to use this, and have had very nice results with two processes per processor."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["It looks to me that what you want is a pool of some sort, and in that pool you would like the have n threads where n == the number of processors on your system.", "You would then have another thread whose only job was to feed jobs into a queue which the worker threads could pick up and process as they became free (so for a dual code machine, you'd have three threads but the main thread would be doing very little)."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["As you are new to Python though I'll assume you don't know about the GIL and it's side-effects with regard to threading.", "If you read the article I linked you will soon understand why traditional multithreading solutions are not always the best in the Python world.", "Instead you should consider using the multiprocessing module (new in Python 2.6, in 2.5 you can use this backport) to achieve the same effect.", "It side-steps the issue of the GIL by using multiple processes as if they were threads within the same application.", "There are some restrictions about how you share data (you are working in different memory spaces) but actually this is no bad thing: they just encourage good practice such as minimising the contact points between threads (or processes in this case)."], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "GIL", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://linuxgazette.net/107/pai.html"}, {"text": "multiprocessing", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/multiprocessing.html"}, {"text": "use this backport", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://code.google.com/p/python-multiprocessing/"}]}, {"text": ["In your case you are probably intersted in using a pool as specified here."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "here", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/multiprocessing.html#using-a-pool-of-workers"}]}], [{"text": ["Short answer: don't use threads."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["For a working example, you can look at something I've recently tossed together at work.", "It's a little wrapper around ssh which runs a configurable number of Popen() subprocesses.", "I've posted it at: Bitbucket: classh (Cluster Admin's ssh Wrapper)."], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "ssh", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "Popen()", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "Bitbucket: classh (Cluster Admin's ssh Wrapper)", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://bitbucket.org/jimd/classh/"}]}, {"text": ["As noted, I don't use threads; I just spawn off the children, loop over them calling their .poll() methods and checking for timeouts (also configurable) and replenish the pool as I gather the results.", "I've played with different sleep() values and in the past I've written a version (before the subprocess module was added to Python) which used the signal module (SIGCHLD and SIGALRM) and the os.fork() and os.execve() functions --- which my on pipe and file descriptor plumbing, etc)."], "childNum": 6, "tag": "p", "senID": 2, "childList": [{"text": ".poll()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "sleep()", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "subprocess", "childNum": 0, "tag": "em", "childList": []}, {"text": "signal", "childNum": 0, "tag": "em", "childList": []}, {"text": "os.fork()", "childNum": 0, "tag": "em", "childList": []}, {"text": "os.execve()", "childNum": 0, "tag": "em", "childList": []}]}, {"text": ["In my case I'm incrementally printing results as I gather them ... and remembering all of them to summarize at the end (when all the jobs have completed or been killed for exceeding the timeout)."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["I ran that, as posted, on a list of 25,000 internal hosts (many of which are down, retired, located internationally, not accessible to my test account etc).", "It completed the job in just over two hours and had no issues.", "(There were about 60 of them that were timeouts due to systems in degenerate/thrashing states -- proving that my timeout handling works correctly)."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["So I know this model works reliably.", "Running 100 current ssh processes with this code doesn't seem to cause any noticeable impact.", "(It's a moderately old FreeBSD box).", "I used to run the old (pre-subprocess) version with 100 concurrent processes on my old 512MB laptop without problems, too)."], "childNum": 2, "tag": "p", "senID": 5, "childList": [{"text": "ssh", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "subprocess", "childNum": 0, "tag": "em", "pos": 3, "childList": []}]}, {"text": ["(BTW: I plan to clean this up and add features to it; feel free to contribute or to clone off your own branch of it; that's what Bitbucket.org is for)."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["I am not an expert in this, but I have read something about \"Lock\"s. This article might help you out"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "This article", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://effbot.org/zone/thread-synchronization.htm"}]}, {"text": ["Hope this helps"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["If you want to limit the number of parallel threads, use a semaphore:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "semaphore", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/threading.html#semaphore-objects"}]}, {"code": "<pre>\n<code>\n threadLimiter = threading.BoundedSemaphore(maximumNumberOfThreads)\n\nclass EncodeThread(threading.Thread):\n\n    def run(self):\n        threadLimiter.acquire()\n        try:\n            &lt;your code here&gt;\n        finally:\n            threadLimiter.release()\n</code>\n</pre>\n", "senID": 1}, {"text": ["Start all threads at once.", "All but maximumNumberOfThreads will wait in threadLimiter.acquire() and a waiting thread will only continue once another thread goes through threadLimiter.release()."], "childNum": 3, "tag": "p", "senID": 2, "childList": [{"text": "maximumNumberOfThreads", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "threadLimiter.acquire()", "childNum": 0, "tag": "code", "childList": []}, {"text": "threadLimiter.release()", "childNum": 0, "tag": "code", "childList": []}]}]]