[[{"code": "<pre>\n<code>\n import re\nre.findall(\"\\?read\\.php=(\\d+)\",data)\n</code>\n</pre>\n", "senID": 0}], [{"text": ["\"If you have a problem, and decide to use regex, now you have two problems...\" "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If you are reading one particular web page and you know how it is formatted, then regex is fine - you can use S. Mark's answer.", "To parse a particular link, you can use Kimvai's answer.", "However, to get all the links from a page, you're better off using something more serious.", "Any regex solution you come up with will have flaws,"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["I recommend mechanize.", "If you notice, the Browser class there has a links method which gets you all the links in a page.", "It has the added benefit of being able to download the page for you =) ."], "childNum": 3, "tag": "p", "senID": 2, "childList": [{"text": "mechanize", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://wwwsearch.sourceforge.net/mechanize/"}, {"text": "Browser", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "links", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}], [{"text": ["While the other answers are sort of correct, you should probably use the urllib2 library instead;"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from urllib2 import urlparse\nimport re\nurlre = re.compile('&lt;a[^&gt;]+href=\"([^\"]+)\"[^&gt;]*&gt;',re.IGNORECASE)\nlinks = urlre.findall('&lt;a href=\"http://www.example.com?read.php=123\"&gt;')\nfor link in links:\n    url = urlparse.urlparse(link)\n    s = [x.split(\"=\") for x in url[4].split(';')]\n    d = {}\n    for k,v in s:\n        d[k]=v\n    print d[\"read.php\"]\n</code>\n</pre>\n", "senID": 1}, {"text": ["It's not as simple as some of the above, but guaranteed to work even with more complex urls."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["This will work irrespective of how your links are formatted (e.g.", "if some look like &lt;a href=\"foo=123\"/&gt; and some look like &lt;A TARGET=\"_blank\" HREF='foo=123'/&gt;)."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "&lt;a href=\"foo=123\"/&gt;", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "&lt;A TARGET=\"_blank\" HREF='foo=123'/&gt;", "childNum": 0, "tag": "code", "childList": []}]}, {"code": "<pre>\n<code>\n import re\nfrom BeautifulSoup import BeautifulSoup\nsoup = BeautifulSoup(html)\np = re.compile('^.*=([\\d]*)$')\nfor a in soup.findAll('a'):\n   m = p.match(a[\"href\"])\n   if m:\n      print m.groups()[0]\n</code>\n</pre>\n", "senID": 1}], [{"text": ["/[0-9]/"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["thats the regex sytax you want"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["for reference see"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["http://gnosis.cx/publish/programming/regular%5Fexpressions.html"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://gnosis.cx/publish/programming/regular%5Fexpressions.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://gnosis.cx/publish/programming/regular%5Fexpressions.html"}]}], [{"text": ["One without the need for regex"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; s='&lt;a href=\"http://www.example.com?read.php=123\"&gt;'\n&gt;&gt;&gt; for item in s.split(\"&gt;\"):\n...     if \"href\" in item:\n...         print item[item.index(\"a href\")+len(\"a href=\"): ]\n...\n\"http://www.example.com?read.php=123\"\n</code>\n</pre>\n", "senID": 1}, {"text": ["if you want to extract the numbers"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n item[item.index(\"a href\")+len(\"a href=\"): ].split(\"=\")[-1]\n</code>\n</pre>\n", "senID": 3}]]