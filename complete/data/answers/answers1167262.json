[[{"text": ["Your best bet really is to use Google's natural language detection api.", "It returns an iso code for the page language, with a probability index. "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Google's natural language detection", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.google.com/uds/samples/language/detect.html"}]}, {"text": ["See http://code.google.com/apis/ajaxlanguage/documentation/"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://code.google.com/apis/ajaxlanguage/documentation/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.google.com/apis/ajaxlanguage/documentation/"}]}], [{"text": ["This is usually accomplished by using character n-gram models.", "You can find here a state of the art language identifier for Java.", "If you need some help converting it to Python, just ask.", "Hope it helps."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "here", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://alias-i.com/lingpipe/demos/tutorial/langid/read-me.html"}]}], [{"text": ["There is nothing about the URL itself that will indicate language."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["One option would be to use a natural language toolkit to try to identify the language based on the content, but even if you can get the NLP part of it working, it'll be pretty slow.", "Also, it may not be reliable.", "Remember, most user agents pass something like"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "natural language toolkit", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.nltk.org/"}]}, {"code": "<pre>\n<code>\n Accept-Language: en-US\n</code>\n</pre>\n", "senID": 2}, {"text": ["with each request, and many large websites will serve different content based on that header.", "Smaller sites will be more reliable because they won't pay attention to the language headers. "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["You could also use server location  (i.e.", "which country the server is in) as a proxy for language using GeoIP.", "It's obviously not perfect, but it is much better than using the TLD."], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "GeoIP", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://code.google.com/p/python-geoip/"}]}], [{"text": ["You might want to try ngram based detection."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["TextCatDEMO (LGPL) seems to work pretty well (recognizes almost 70 languages).", "There is a python port provided by Thomas Mangin here using the same corpus."], "childNum": 4, "tag": "p", "senID": 1, "childList": [{"text": "TextCatDEMO", "tag": "a", "pos": 0, "childList": [{"text": "DEMO", "tag": "strong"}], "childNum": 1, "href": "http://www.let.rug.nl/~vannoord/TextCat/Demo/textcat%5Fsrc.html"}, {"text": "DEMO", "childNum": 0, "tag": "strong", "pos": -1, "childList": []}, {"text": "Thomas Mangin", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://thomas.mangin.me.uk/"}, {"href": "http://thomas.mangin.me.uk/data/source/ngram.py", "text": "here", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["Edit: TextCat competitors page provides some interesting links too. "], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "competitors page", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.let.rug.nl/~vannoord/TextCat/competitors.html"}]}, {"text": ["Edit2: I wonder if making a python wrapper for http://www.mnogosearch.org/guesser/ would be difficult..."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://www.mnogosearch.org/guesser/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.mnogosearch.org/guesser/"}]}], [{"text": ["nltk might help (if you have to get down to dealing with the page's text, i.e.", "if the headers and the url itself don't determine the language sufficiently well for your purposes); I don't think NLTK directly offers a \"tell me which language this text is in\" function (though NLTK is large and continuously growing, so it might in fact have it), but you can try parsing the given text according to various possible natural languages and checking which ones give the most sensible parse, wordset, &amp;c, according to the rules for each language."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "nltk", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.nltk.org/"}]}], [{"text": ["There's no general method that will work solely on URLs.", "You can check the top-level domain to get some idea, and look for portions of the URL that might be indicative of a language (like \"en\" or \"es\" between two slashes), and assume anything unknown is in English, but it isn't a perfect solution."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "top-level domain", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/List%5Fof%5FInternet%5Ftop-level%5Fdomains"}]}, {"text": ["So far as I know, the only general way to determine the natural language used by a page is to grab the page's text and check for certain common words in each language.", "For example, if \"a\", \"an\", and \"the\" appear several times in the page, it's likely that it includes English text; \"el\" and \"la\" might suggest Spanish; and so on."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Thanks for the replies so far.", "Just to clarify a bit, I'm still kind of new to web dev though not to software.", "I researched inspecting HTML meta tags, XML:Lang tag, and character set detection.", "Originally I thought this should be a simple problem, given that it only makes sense that each web page should follow some convention and explicitly declare  the language used."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["After all, Google only returns English results for me, so it must have some way of extracting the natural language during it's crawling.", "Some of those results are in the US, UK, Canada and other English speaking countries.", "But then Canada has French also, so how can it know?"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Looking for common words is probably the closest general answer thus far.", "Yet I can't wonder if there isn't a simple solution for what seems a common problem.", "Or is the web still a wild west?"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Also I'm ok with calling other libraries that use the URL to get more info like the geoip or HTML source."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["I looked at ntlk for another problem.", "I'll have to take another look.", "My only real concern then is possibly performance."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["Geo also seems fairly reliable excepting for the edge cases where someone posts say a Spanish web page on a Non-Spanish site. "], "childNum": 0, "tag": "p", "senID": 5, "childList": []}], [{"text": ["Here is a function that will do that"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n def LanguageUsed (url):\n  from urlparse import urlparse\n  o = urlparse(url)\n  return o.hostname.split('.')[-1]\n</code>\n</pre>\n", "senID": 1}, {"text": ["I recommend looking at the documentation found here if you want to do more url proccesing."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "here", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/urlparse.html"}]}]]