[[{"text": ["You've already gotten a fair variety of answers, from \"fake threads\" all the way to external frameworks, but I've seen nobody mention Queue.Queue -- the \"secret sauce\" of CPython threading."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Queue.Queue", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["To expand: as long as you don't need to overlap pure-Python CPU-heavy processing (in which case you need multiprocessing -- but it comes with its own Queue implementation, too, so you can with some needed cautions apply the general advice I'm giving;-), Python's built-in threading will do... but it will do it much better if you use it advisedly, e.g., as follows."], "childNum": 4, "tag": "p", "senID": 1, "childList": [{"text": "multiprocessing", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "Queue", "childNum": 0, "tag": "code", "childList": []}, {"text": "threading", "childNum": 0, "tag": "code", "childList": []}, {"text": "advisedly", "childNum": 0, "tag": "em", "childList": []}]}, {"text": ["\"Forget\" shared memory, supposedly the main plus of threading vs multiprocessing -- it doesn't work well, it doesn't scale well, never has, never will.", "Use shared memory only for data structures that are set up once before you spawn sub-threads and never changed afterwards -- for everything else, make a single thread responsible for that resource, and communicate with that thread via Queue."], "childNum": 3, "tag": "p", "senID": 2, "childList": [{"text": "before", "childNum": 0, "tag": "em", "pos": 1, "childList": []}, {"text": "single", "childNum": 0, "tag": "em", "childList": []}, {"text": "Queue", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Devote a specialized thread to every resource you'd normally think to protect by locks: a mutable data structure or cohesive group thereof, a connection to an external process (a DB, an XMLRPC server, etc), an external file, etc, etc.", "Get a small thread pool going for general purpose tasks that don't have or need a dedicated resource of that kind -- don't spawn threads as and when needed, or the thread-switching overhead will overwhelm you."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "don't", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"text": ["Communication between two threads is always via Queue.Queue -- a form of message passing, the only sane foundation for multiprocessing (besides transactional-memory, which is promising but for which I know of no production-worthy implementations except In Haskell)."], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "Queue.Queue", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Each dedicated thread managing a single resource (or small cohesive set of resources) listens for requests on a specific Queue.Queue instance.", "Threads in a pool wait on a single shared Queue.Queue (Queue is solidly threadsafe and won't fail you in this)."], "childNum": 1, "tag": "p", "senID": 5, "childList": [{"text": "won't", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"text": ["Threads that just need to queue up a request on some queue (shared or dedicated) do so without waiting for results, and move on.", "Threads that eventually DO need a result or confirmation for a request queue a pair (request, receivingqueue) with an instance of Queue.Queue they just made, and eventually, when the response or confirmation is indispensable in order to proceed, they get (waiting) from their receivingqueue.", "Be sure you're ready to get error-responses as well as real responses or confirmations (Twisted's deferreds are great at organizing this kind of structured response, BTW!", ")."], "childNum": 1, "tag": "p", "senID": 6, "childList": [{"text": "deferred", "childNum": 0, "tag": "code", "pos": 2, "childList": []}]}, {"text": ["You can also use Queue to \"park\" instances of resources which can be used by any one thread but never be shared among multiple threads at one time (DB connections with some DBAPI compoents, cursors with others, etc) -- this lets you relax the dedicated-thread requirement in favor of more pooling (a pool thread that gets from the shared queue a request needing a queueable resource will get that resource from the apppropriate queue, waiting if necessary, etc etc)."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Twisted is actually a good way to organize this minuet (or square dance as the case may be), not just thanks to deferreds but because of its sound, solid, highly scalable base architecture: you may arrange things to use threads or subprocesses only when truly warranted, while doing most things normally considered thread-worthy in a single event-driven thread."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["But, I realize Twisted is not for everybody -- the \"dedicate or pool resources, use Queue up the wazoo, never do anything needing a Lock or, Guido forbid, any synchronization procedure even more advanced, such as semaphore or condition\" approach can still be used even if you just can't wrap your head around async event-driven methodologies, and will still deliver more reliability and performance than any other widely-applicable threading approach I've ever stumbled upon."], "childNum": 0, "tag": "p", "senID": 9, "childList": []}], [{"text": ["In order of complexity:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["In all cases I'm assuming you already understand many of the issues involved with multitasking, specifically the tricky issue of how to share data between tasks.", "If for some reason you don't know when and how to use locks and conditions you have to start with those.", "Multitasking code is full of subtleties and gotchas, and it's really best to have a good understanding of concepts before you start."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "all", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}], [{"text": ["It depends on what you're trying to do, but I'm partial to just using the threading module in the standard library because it makes it really easy to take any function and just run it in a separate thread."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "threading", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n from threading import Thread\n\ndef f():\n    ...\n\ndef g(arg1, arg2, arg3=None):\n    ....\n\nThread(target=f).start()\nThread(target=g, args=[5, 6], kwargs={\"arg3\": 12}).start()\n</code>\n</pre>\n", "senID": 1}, {"text": ["And so on.", "I often have a producer/consumer setup using a synchronized queue provided by the Queue module"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "Queue", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"code": "<pre>\n<code>\n from Queue import Queue\nfrom threading import Thread\n\nq = Queue()\ndef consumer():\n    while True:\n        print sum(q.get())\n\ndef producer(data_source):\n    for line in data_source:\n        q.put( map(int, line.split()) )\n\nThread(target=producer, args=[SOME_INPUT_FILE_OR_SOMETHING]).start()\nfor i in range(10):\n    Thread(target=consumer).start()\n</code>\n</pre>\n", "senID": 3}], [{"text": ["Kamaelia is a python framework for building applications with lots of communicating processes."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Kamaelia", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.kamaelia.org/Home"}]}, {"text": ["Easy Concurrency with Kamaelia - Part 1 (59:08)\nEasy Concurrency with Kamaelia - Part 2 (18:15) "], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "Easy Concurrency with Kamaelia - Part 1", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://blip.tv/file/2022798"}, {"text": "", "childNum": 0, "tag": "br", "childList": []}, {"href": "http://blip.tv/file/2022853", "text": "Easy Concurrency with Kamaelia - Part 2", "childNum": 0, "tag": "a", "childList": []}]}], [{"text": ["Regarding Kamaelia, the answer above doesn't really cover the benefit here.", "Kamaelia's approach provides a unified interface, which is pragmatic not perfect, for dealing with threads, generators &amp; processes in a single system for concurrency."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Fundamentally it provides a metaphor of a running thing which has inboxes, and outboxes.", "You send messages to outboxes, and when wired together, messages flow from outboxes to inboxes.", "This metaphor/API remains the same whether you're using generators, threads or processes, or speaking to other systems."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["The \"not perfect\" part is due to syntactic sugar not being added as yet for inboxes and outboxes (though this is under discussion) - there is a focus on safety/usability in the system."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Taking the producer consumer example using bare threading above, this becomes this in Kamaelia:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n Pipeline(Producer(), Consumer() )\n</code>\n</pre>\n", "senID": 4}, {"text": ["In this example it doesn't matter if these are threaded components or otherwise, the only difference is between them from a usage perspective is the baseclass for the component.", "Generator components communicate using lists, threaded components using Queue.Queues and process based using os.pipes."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["The reason behind this approach though is to make it harder to make hard to debug bugs.", "In threading - or any shared memory concurrency you have, the number one problem you face is accidentally broken shared data updates.", "By using message passing you eliminate one class of bugs."], "childNum": 1, "tag": "p", "senID": 6, "childList": [{"text": "one", "childNum": 0, "tag": "strong", "pos": 1, "childList": []}]}, {"text": ["If you use bare threading and locks everywhere you're generally working on the assumption that when you write code that you won't make any mistakes.", "Whilst we all aspire to that, it's very rare that will happen.", "By wrapping up the locking behaviour in one place you simplify where things can go wrong.", "(Context handlers help, but don't help with accidental updates outside the context handler)"], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Obviously not every piece of code can be written as message passing and shared style which is why Kamaelia also has a simple software transactional memory (STM), which is a really neat idea with a nasty name - it's more like version control for variables - ie check out some variables, update them and commit back.", "If you get a clash you rinse and repeat."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["Relevant links:"], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"tag": "ul", "num": 6, "lis": [{"text": ["Europython 09 tutorial"], "childNum": 0, "tag": "a", "senID": 10, "childList": []}, {"text": ["Monthly releases"], "childNum": 0, "tag": "a", "senID": 11, "childList": []}, {"text": ["Mailing list"], "childNum": 0, "tag": "a", "senID": 12, "childList": []}, {"text": ["Examples"], "childNum": 0, "tag": "a", "senID": 13, "childList": []}, {"text": ["Example Apps"], "childNum": 0, "tag": "a", "senID": 14, "childList": []}, {"text": ["Reusable components (generator &amp; thread)"], "childNum": 0, "tag": "a", "senID": 15, "childList": []}]}, {"text": ["Anyway, I hope that's a useful answer.", "FWIW, the core reason behind Kamaelia's setup is to make concurrency safer &amp; easier to use in python systems, without the tail wagging the dog.", "(ie the big bucket of components"], "childNum": 0, "tag": "p", "senID": 16, "childList": []}, {"text": ["I can understand why the other Kamaelia answer was modded down, since even to me it looks more like an ad than an answer.", "As the author of Kamaelia it's nice to see enthusiasm though I hope this contains a bit more relevant content :-)"], "childNum": 0, "tag": "p", "senID": 17, "childList": []}, {"text": ["And that's my way of saying, please take the caveat that this answer is by definition biased, but for me, Kamaelia's aim is to try and wrap what is IMO best practice.", "I'd suggest trying a few systems out, and seeing which works for you.", "(also if this is inappropriate for stack overflow, sorry - I'm new to this forum :-)"], "childNum": 0, "tag": "p", "senID": 18, "childList": []}], [{"text": ["I would use the Microthreads (Tasklets) of Stackless Python, if I had to use threads at all."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["A whole online game (massivly multiplayer) is build around Stackless and its multithreading principle -- since the original is just to slow for the massivly multiplayer property of the game."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Threads in CPython are widely discouraged.", "One reason is the GIL -- a global interpreter lock -- that serializes threading for many parts of the execution.", "My experiance is, that it is really difficult to create fast applications this way.", "My example codings where all slower with threading -- with one core (but many waits for input should have made some performance boosts possible)."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["With CPython, rather use seperate processes if possible."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["If you really want to get your hands dirty, you can try using generators to fake coroutines.", "It probably isn't the most efficient in terms of work involved, but coroutines do offer you very fine control of co-operative multitasking rather than pre-emptive multitasking you'll find elsewhere.  "], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "using generators to fake coroutines", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.ibm.com/developerworks/library/l-pythrd.html"}, {"text": "co-operative", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"text": ["One advantage you'll find is that by and large, you will not need locks or mutexes when using co-operative multitasking, but the more important advantage for me was the nearly-zero switching speed between \"threads\".", "Of course, Stackless Python is said to be very good for that as well; and then there's Erlang, if it doesn't have to be Python."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "have", "childNum": 0, "tag": "em", "pos": 1, "childList": []}]}, {"text": ["Probably the biggest disadvantage in co-operative multitasking is the general lack of workaround for blocking I/O.", "And in the faked coroutines, you'll also encounter the issue that you can't switch \"threads\" from anything but the top level of the stack within a thread."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["After you've made an even slightly complex application with fake coroutines, you'll really begin to appreciate the work that goes into process scheduling at the OS level."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["there is no \"best approach\" to concurrency.", "Which approach you try depends on many factors.", "Are you i/o blocked a lot (threading)?", "Are you trying to spread the load across multiple processor cores (multiprocessing)?", "etc etc..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}]]