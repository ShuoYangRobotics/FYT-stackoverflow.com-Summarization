[[{"text": ["You should take a look at CUDAmat and Theano.", "Both are approaches to writing code that executes on the GPU without really having to know much about GPU programming."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "CUDAmat", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.google.com/p/cudamat/"}, {"text": "Theano", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://deeplearning.net/software/theano"}]}], [{"text": ["I believe that, with PyCUDA, your computational kernels will always have to be written as \"CUDA C Code\".", "PyCUDA takes charge of a lot of otherwise-tedious book-keeping, but does not build computational CUDA kernels from Python code."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["pyopencl offers an interesting alternative to PyCUDA.", "It is described as a \"sister project\" to PyCUDA.", "It is a complete wrapper around OpenCL's API."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "pyopencl", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://mathema.tician.de/software/pyopencl"}, {"text": "complete", "childNum": 0, "tag": "em", "pos": 2, "childList": []}]}, {"text": ["As far as I understand, OpenCL has the advantage of running on GPUs beyond Nvidia's."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["Great answers already, but another option is Clyther.", "It will let you write OpenCL programs without even using C, by compiling a subset of Python into OpenCL kernels. "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Clyther", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://clyther.sourceforge.net/"}]}], [{"text": ["There is a good, basic set of math constructs with compute kernels already written that can be accessed through pyCUDA's cumath module.", "If you want to do more involved or specific/custom stuff you will have to write a touch of C in the kernel definition, but the nice thing about pyCUDA is that it will do the heavy C-lifting for you; it does a lot of meta-programming on the back-end so you don't have to worry about serious C programming, just the little pieces.", "One of the examples given is a Map/Reduce kernel to calculate the dot product:"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "cumath", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "module", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://documen.tician.de/pycuda/array.html?highlight=get#module-pycuda.cumath"}]}, {"text": ["dot_krnl = ReductionKernel(np.float32, neutral=\"0\",\n                               reduce_expr=\"a+b\",\n                               map_expr=\"x[i]*y[i]\",\n                               arguments=\"float *x, float *y\")"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "dot_krnl = ReductionKernel(np.float32, neutral=\"0\",\n                               reduce_expr=\"a+b\",\n                               map_expr=\"x[i]*y[i]\",\n                               arguments=\"float *x, float *y\")", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["The little snippets of code inside each of those arguments are C lines, but it actually writes the program for you.", "the ReductionKernel is a custom kernel type for map/reducish type functions, but there are different types.", "The examples portion of the official pyCUDA  documentation goes into more detail."], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "ReductionKernel", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "documentation", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://documen.tician.de/pycuda/tutorial.html"}]}, {"text": ["Good luck!"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["A promising library is Copperhead, you just need to decorate the function that you want to be run by the GPU (and then you can opt-in / opt-out it to see what's best between cpu or gpu for that function)"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Copperhead", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.google.com/p/copperhead/"}]}]]