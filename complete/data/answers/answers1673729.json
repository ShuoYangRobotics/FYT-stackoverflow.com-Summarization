[[{"text": ["The first step to solving this problem is to analyze, in detail, how it is that humans solve this problem.", "I'd break the problem down into two parts."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I'd also take a good look at several hundred samples, to see if there are any COMMON patterns that can be easily identified and parsed.", "If, for example, 30% of your entries are simple comma-separated lists then a regular expression will trivially identify and parse them.", "Perhaps a small set of regular expressions will address a large part of your corpus."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Finally, I assume that currently the data is not only entered and recognized by humans but also consumed by humans.", "Is your reason for breaking items into lists so that humans can be removed from the loop, or just to make the work easier for them?", "If the latter, I'd recommend providing them with BOTH the broken-up list elements and, as a backup, the originally-entered text.", "In other words, hedge your bets in case you get it wrong."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["If you can't define your data (\"The words can be anything, I there is no way to know beforehand a dictionary of what any individual list can contain.", "They will not be only numbers... it could be a list of anything\") then you have serious problems."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Specifically, if you can't define your data, your problem cannot be solved."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You can try playing with nltk."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "nltk", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.nltk.org/"}]}, {"text": ["You may be able to discard the \"noise words\" (\",\", \".", "\", \"i\", \"start\", \"with\", \"then\", \"do\", etc.", ")  What's left may be this undefinable \"words can be anything\" that's left over. "], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Until you can better define your data, you're probably doomed to a lot of struggle."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["I don't know if I understand your problem.", "If you want to extract alpha-numeric strings from messed string in python it would be:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; import re\n&gt;&gt;&gt; re.split('\\W+','abaa, asodf ?. poasid - paosfi sec')\n['abaa', 'asodf', 'poasid', 'paosfi', 'sec']\n</code>\n</pre>\n", "senID": 1}, {"text": ["Or if you know the seperators:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; re.split('[,. -]+','abaa, asodf, poasid - paosfi sec')\n['abaa', 'asodf', 'poasid', 'paosfi', 'sec']\n</code>\n</pre>\n", "senID": 3}], [{"text": ["Rather than focusing on the code, how about the method.", "Building a little on what swillden said..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["If your lists are consumed by human users, you could ask them to correct you when you make a mistake (this correction is visible either to the person entering the text or to a later user viewing the text).", "If a given input looks a lot like a list but not enough to be sure, you show them the list and the raw input and ask them to choose."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["To automatically categorise inputs as lists or as text you could create several metrics to base your decision on :"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"tag": "ul", "num": 4, "lis": [{"text": "Given the separators (i.e ", "tag": "none", "senID": 3}, {"text": "Is the input composed of fragments (use some sort of grammar system) - fragments tend to indicate lists.", "tag": "none", "senID": 4}, {"text": "Does this input field (or context in your input) tend to have list items", "tag": "none", "senID": 5}, {"text": "The words in the list itself (some words might turn out to always mean a sentence or a list in your domain)", "tag": "none", "senID": 6}]}, {"text": ["You then pass this information into a Bayesian filter and train it using your user's suggestions.", "Most of the items I mention would boil into special \"keywords\" that you tag an item with before you pass it into the filter.", "If the filter has a clear answer either way, treat it as a list or string.", "If the filter is uncertain, ask the user and use their answer to train the filter."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Edit"], "childNum": 1, "tag": "p", "senID": 8, "childList": [{"text": "Edit", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["You could always train the system manually (i.e without exposing your system to the users) by first classifying lists using your existing scripts and then checking them by hand.", "Take a list of 500 inputs, run a filter looking for , or other easy lists and classify them as lists.", "Train the Bayesian filter on those (with everything else non-list) and then check the output by hand for all 500 for further training. "], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"text": ["Each day someone could receive an email with all the edge cases for that day and could clink links in the email to correct the system if necessary."], "childNum": 0, "tag": "p", "senID": 10, "childList": []}, {"text": ["As a side issue (relating to OP comment), in general Bayesian filters are much easier to implement, debug, test, analyse and scale than Neural networks. "], "childNum": 0, "tag": "p", "senID": 11, "childList": []}], [{"text": ["In java, a string tokenizer will do this (i.e.", "StringTokenizer(inputString, delimiterList))"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n StringTokenizer st = new StringTokenizer( \"A B|C-D\", \" |-\" );\nwhile ( st.hasMoreTokens() ) {\n    System.out.println( st.nextToken() );\n}\n</code>\n</pre>\n", "senID": 1}, {"text": ["prints "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": [], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": [], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": [], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": [], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["The following will \"parse\" your input string into sequences of \"word\" characters separated by non-word characters.  "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n String input = ...\nString[] parts = input.split(\"[^\\w]*\");\n</code>\n</pre>\n", "senID": 1}, {"text": ["I don't know how you are going to distinguish a list from gibberish.", "I think you will need to explain your problem domain some more ... "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["EDIT: If you cannot define the rules which you (as a human) use to distinguish a list from gibberish, then this problem is essentially unsolvable.", "Computers cannot do magic you know ..."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Maybe you should just use the program to deal with the subset that are \"definitely\" lists, and classify the other ones by hand."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["Either you know your dictionary of words or you have a precedence order for list delimiters.", "Otherwise the problem is too ill defined for a computer to handle. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I suppose your precedence could be commas, dots, hyphens, spaces.", "So, this means that you split by commas in preference to splitting by dots and so on."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Alternatively you could keep on splitting by each successive delimiter, until you hit a delimiter that isn't in the text."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["I'm not sure what the best answer really is, But if you need to have few false positives, then perhaps what you should do is define a few patterns that are very likely to be lists, and strictly reject every other datum.  "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n patterns = [\n    re.compile(r'^\\s*(\\w+)(\\s*,\\s*(\\w+))*\\s*$'), \n    re.compile(r'^\\s*(\\w+)(\\s*\\.\\s*(\\w+))*\\s*$'), \n    re.compile(r'^\\s*(\\w+)(\\s*,\\s*(\\w+))*\\s+and\\s+(\\w+)\\s*^$')\n]\nacceptSet = [ line for line in candidateSet if \n              any(pattern.match(line) for pattern in patterns)]\n</code>\n</pre>\n", "senID": 1}], [{"text": ["A pyparsing stab at sift wheat from the chaff..."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n rawdata = \"\"\"\\\none, two, three, four, five\none. two. three, four. five.\n\"I start with one, then do two, maybe three and four then five\"\none  \ntwo  \nthree  \nfour  \nfive.  \none, two. three four five\none two three four - five\n\"not even a list, no list-elements here! but list item separators may appear. grrr\"\na dog with a bone is a beautiful twosome\"\"\".splitlines()\n\nfrom pyparsing import oneOf, WordStart, CharsNotIn, alphas, LineEnd\noptions = (WordStart() + oneOf(\"one two three four five\") + (CharsNotIn(alphas)|LineEnd()))\n\nfor userinput in rawdata:\n    print userinput\n    print [opt[0] for opt in options.searchString(userinput)]\n    print\n</code>\n</pre>\n", "senID": 1}, {"text": ["Prints (note the added line with hidden 'one' and 'two' substrings that would not be desirable):"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n one, two, three, four, five\n['one', 'two', 'three', 'four', 'five']\n\none. two. three, four. five.\n['one', 'two', 'three', 'four', 'five']\n\n\"I start with one, then do two, maybe three and four then five\"\n['one', 'two', 'three', 'four', 'five']\n\none  \n['one']\n\ntwo  \n['two']\n\nthree  \n['three']\n\nfour  \n['four']\n\nfive.  \n['five']\n\none, two. three four five\n['one', 'two', 'three', 'four', 'five']\n\none two three four - five\n['one', 'two', 'three', 'four', 'five']\n\n\"not even a list, no list-elements here! but list item separators may appear. grrr\"\n[]\n\na dog with a bone is a beautiful twosome\n[]\n</code>\n</pre>\n", "senID": 3}]]