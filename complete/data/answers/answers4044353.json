[[{"text": ["When all you have is a hammer .", ".", "."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Conceptually, what you are trying to do is simple but because of the size of your data, it is computationally difficult.", "I tend to use R for it's analytic and graphics capacity, not it's data wrangling skills.", "When I need to move around a bunch of data, I usually just stick everything into a database."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Lately I have had quite a bit of success with SQLite and R. The best part is that you can actually use R to read in your data, which makes it easy to import large SPSS files or other sources of data that SQLite can't really handle but R can."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["http://cran.r-project.org/web/packages/RSQLite/index.html"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://cran.r-project.org/web/packages/RSQLite/index.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://cran.r-project.org/web/packages/RSQLite/index.html"}]}, {"text": ["Here's my recommended work flow."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["In R I can do this:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n N &lt;- 1000000\nx &lt;- sample(1:400,N,TRUE)\ny &lt;- sample(1:400,N,TRUE)\nz &lt;- sample(1:400,N,TRUE)\n\nw &lt;- table(x,y,z)\n</code>\n</pre>\n", "senID": 1}, {"text": ["And memory peak is lower then 800MB. "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["So what limitations you have?"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["EDIT.", "This peace of R-code:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n N &lt;- 1000000\nmydata &lt;- data.frame(\n    A=sample(runif(400),N,TRUE),\n    B=sample(runif(400),N,TRUE),\n    C=runif(N)\n)\n\nrequire(reshape)\nresults &lt;- cast(mydata, A~B, value=\"C\")\nwrite.table(as.matrix(results),na=\"\",sep=\"\\t\",file=\"results.txt\")\n</code>\n</pre>\n", "senID": 5}, {"text": ["create what you want with less then 300MB of RAM."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["On my data it gives warning cause there are non-unique A-B combinations but for yours should be ok."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}], [{"text": ["Whole new story deserves a whole new answer."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Don't need defaultdict, don't even want defaultdict, because using it carelessly would suck memory like the Death Star's tractor beam."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["This code is untested, may not even compile; I may have swapped rows and columns somewhere; fixes/explanations later ... must rush ..."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n d = {}\ncol_label_set = set()\nrow_label_set = set()\ninput =  open(\"input.txt\")\noutput = open(\"output.txt\",\"w\")\nfor line in input:\n    line = line.strip()\n    splat = line.split(',')\n    if len(splat) != 3:\n        break # error message???\n    k1, k2, v = splat\n    try:\n        subdict = d[k1]\n    except KeyError:\n        subdict = {}\n        d[k1] = subdict\n    subdict[k2] = v\n    row_label_set.add(k1)\n    col_label_set.add(k2)\ncol_labels = sorted(col_label_set)\nrow_labels = sorted(row_label_set\noutput.write(\"\\t\")\nfor v in col_labels::\n    output.write(v + \"\\t\")\noutput.write(\"\\n\")\nfor r in row_labels:\n    output.write(r + \"\\t\")\n    for c in col_labels:\n        output.write(d[r].get(c, \"\") + \"\\t\")\n    output.write(\"\\n\")\n</code>\n</pre>\n", "senID": 3}, {"text": ["Update Here's a fixed and refactored version, tested to the extent shown:"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "Update", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n class SparseTable(object):\n\n    def __init__(self, iterable):\n        d = {}\n        col_label_set = set()\n        for row_label, col_label, value in iterable:\n            try:\n                subdict = d[row_label]\n            except KeyError:\n                subdict = {}\n                d[row_label] = subdict\n            subdict[col_label] = value\n            col_label_set.add(col_label)\n        self.d = d\n        self.col_label_set = col_label_set\n\n    def tabulate(self, row_writer, corner_label=u\"\", missing=u\"\"):\n        d = self.d\n        col_labels = sorted(self.col_label_set)\n        row_labels = sorted(d.iterkeys())\n        orow = [corner_label] + col_labels\n        row_writer(orow)\n        for row_label in row_labels:\n            orow = [row_label]\n            subdict = d[row_label]\n            for col_label in col_labels:\n                orow.append(subdict.get(col_label, missing))\n            row_writer(orow)\n\nif __name__ == \"__main__\":\n\n    import sys\n\n    test_data = u\"\"\"\n    3277,4733,54.1\n    3278,4741,51.0\n    3278,4750,28.4\n    3278,4768,36.0\n    3278,4776,50.1\n    3278,4784,51.4\n    3279,4792,82.6\n    3279,4806,78.2\n    3279,4814,36.4\n    \"\"\".splitlines(True)\n\n    def my_writer(row):\n        sys.stdout.write(u\"\\t\".join(row))\n        sys.stdout.write(u\"\\n\")\n\n    def my_reader(iterable):\n        for line in iterable:\n            line = line.strip()\n            if not line: continue\n            splat = line.split(u\",\")\n            if len(splat) != 3:\n                raise ValueError(u\"expected 3 fields, found %d\" % len(splat))\n            yield splat\n\n    table = SparseTable(my_reader(test_data))\n    table.tabulate(my_writer, u\"A/B\", u\"....\")\n</code>\n</pre>\n", "senID": 5}, {"text": ["Here's the output:"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n A/B     4733    4741    4750    4768    4776    4784    4792    4806    4814\n3277    54.1    ....    ....    ....    ....    ....    ....    ....    ....\n3278    ....    51.0    28.4    36.0    50.1    51.4    ....    ....    ....\n3279    ....    ....    ....    ....    ....    ....    82.6    78.2    36.4\n</code>\n</pre>\n", "senID": 7}], [{"text": ["If you could use table(x,y,z) in R, then how about trying out the R out of memory packages that handle such huge data sets?", "Use the read.big.matrix function in the package bigmemory to read in the data set and the bigtable function in the package bigtabulate to create the table."], "childNum": 5, "tag": "p", "senID": 0, "childList": [{"text": "table(x,y,z)", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "read.big.matrix", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"href": "http://cran.r-project.org/web/packages/bigmemory/", "text": "bigmemory", "childNum": 0, "tag": "a", "childList": []}, {"text": "bigtable", "childNum": 0, "tag": "code", "childList": []}, {"href": "http://cran.r-project.org/web/packages/bigtabulate/index.html", "text": "bigtabulate", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["See vignettes."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "vignettes", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://cran.r-project.org/web/packages/bigmemory/vignettes/Overview.pdf"}]}], [{"text": ["Your example of desired output doesn't look like a 3-way contingency table to me.", "That would be a mapping from (key1, key2, key3) to a count of occurences.", "Your example looks like a mapping from (key1, key2) to some number.", "You don't say what to do when (key1, key2) is duplicated: average, total, something else?"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "You don't say what to do when (key1, key2) is duplicated: average, total, something else?", "childNum": 0, "tag": "em", "pos": 3, "childList": []}]}, {"text": ["Assuming that you want a total, here's one memory-saving approach in Python, using nested defaultdicts:"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "defaultdict", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; from collections import defaultdict as dd\n&gt;&gt;&gt; d = dd(lambda: dd(float))\n&gt;&gt;&gt; d[3277][4733] += 54.1\n&gt;&gt;&gt; d\ndefaultdict(&lt;function &lt;lambda&gt; at 0x00D61DF0&gt;, {3277: defaultdict(&lt;type 'float'&gt;, {4733: 54.1})})\n&gt;&gt;&gt; d[3278][4741] += 51.0\n&gt;&gt;&gt; d\ndefaultdict(&lt;function &lt;lambda&gt; at 0x00D61DF0&gt;, {3277: defaultdict(&lt;type 'float'&gt;, {4733: 54.1}), 3278: defaultdict(&lt;type 'float'&gt;, {4741: 51.0})})\n&gt;&gt;&gt;\n</code>\n</pre>\n", "senID": 2}, {"text": ["and another approach using a single defaultdict with a composite key:"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "defaultdict", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; d2 = dd(float)\n&gt;&gt;&gt; d2[3277,4733] += 54.1\n&gt;&gt;&gt; d2\ndefaultdict(&lt;type 'float'&gt;, {(3277, 4733): 54.1})\n&gt;&gt;&gt; d2[3278,4741] += 51.0\n&gt;&gt;&gt; d2\ndefaultdict(&lt;type 'float'&gt;, {(3277, 4733): 54.1, (3278, 4741): 51.0})\n&gt;&gt;&gt;\n</code>\n</pre>\n", "senID": 4}, {"text": ["It might help if you were to say what you want to do with this data after you've got it grouped together ..."], "childNum": 1, "tag": "p", "senID": 5, "childList": [{"text": "It might help if you were to say what you want to do with this data after you've got it grouped together ...", "childNum": 0, "tag": "em", "pos": 0, "childList": []}]}, {"text": ["If you want (for example) an average, you have two options: (1) two data structures, one for total, one for count, then do \"average = total - count\" (2) sort your data on the first 2 columns, user itertools.groupby to collect your duplicates together, do your calculation, and add the results into your \"average\" data structure.", "Which of these approaches would use less memory is hard to tell; Python being Python you could try both rather quickly."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["A small subclasse of dict can provide you a confortable object to work with the table.", "500.000 items should not be a problem on a desktop PC - if you happen to have 500.000.000 items, a similar class could map from the keys to positions in the file itself (that would be way more cool to implement :-)  )"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n import csv\nclass ContingencyTable(dict):\n    def __init__(self):\n        self.a_keys=set()\n        self.b_keys=set()\n        dict.__init__(self)\n    def __setitem__(self, key,value):\n        self.a_keys.add(key[0])\n        self.b_keys.add(key[1])\n        dict.__setitem__(self, key, value)\n    def feed(self, file):\n        reader = csv.reader(file)\n        reader.next()\n        for a, b, c in reader:\n            self[int(a),int(b)] = float(c)\n\ntable = ContingencyTable()\ntable.feed(open(\"yourfile.csv\"))\n</code>\n</pre>\n", "senID": 1}]]