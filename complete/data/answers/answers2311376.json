[[{"text": ["not to convert floats to floats would be the first step.", "I would suggest, however, to first profile your code and then try to optimize the bottleneck parts."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "profile your code", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/profile.html"}]}, {"text": ["I understand that you've changed your code from the original, but "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n values = [value for value in line.split()]\n</code>\n</pre>\n", "senID": 2}, {"text": ["is not a good thing either.", "just write values = line.split() if this is what you mean."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "values = line.split()", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"text": ["Seeing how you're using NumPy, I'd suggest some methods of file reading that are demonstrated in their docs."], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "methods of file reading that are demonstrated in their docs", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.scipy.org/Cookbook/InputOutput#head-8b33b550a3efcb0981f6720ba42677720325588c"}]}], [{"text": ["You are only reading every character exactly once, so there isn't any real performance to gain."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["You could combine strip and split if the empty lines contain a lot of whitespace."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You could also save some time initializing the numpy array from start, instead of first creating a python array and then converting."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["try increasing the read buffer, IO is probably the bottle neck of your code"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n open('file.txt', 'r', 1024 * 10)\n</code>\n</pre>\n", "senID": 1}, {"text": ["also if the data is fully sequential you can try to skip the line by line code and convert a bunch of lines at once"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Instead of :"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n if len(line) &lt;= 1: # only '\\n' in \u00abempty\u00bb lines\n    break\nvalues = line.split()\n</code>\n</pre>\n", "senID": 1}, {"text": ["try this:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n values = line.split()\nif not values: # line is wholly whitespace, end of segment\n    break\n</code>\n</pre>\n", "senID": 3}], [{"text": ["numpy.fromfile doesn't work for you?"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "numpy.fromfile", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.scipy.org/doc/numpy/reference/generated/numpy.fromfile.html"}]}, {"code": "<pre>\n<code>\n arr = fromfile('tmp.txt', sep=' ', dtype=int)\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Here's a variant that might be faster for few indices.", "It builds a string of only the desired values so that np.fromstring does less work."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "might", "childNum": 0, "tag": "em", "pos": 0, "childList": []}, {"text": "np.fromstring", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"code": "<pre>\n<code>\n def get_pos_nextvalues_fewindices(pos_file, indices):\n    result = ''\n    for line in pos_file:\n        if len(line) &gt; 1:\n            s = line.split()\n            for i in indices:\n                result += s[i] + ' '\n        else:\n            return np.array([])\n    result = np.fromstring(result, dtype=float, sep=' ')\n    result = result.reshape(result.size/len(indeces), len(indeces))\n    return result\n</code>\n</pre>\n", "senID": 1}, {"text": ["This trades off the overhead of split() and an added loop for less parsing.", "Or perhaps there's some clever regex trick you can do to extract the desired substrings directly?"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "split()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["Old Answer"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "Old Answer", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["np.mat('1.23 2.34 3.45 6\\n1.32 2.43 7 3.54') converts the string to a numpy matrix of floating point values.", "This might be a faster kernel for you to use.", "For instance:"], "childNum": 2, "tag": "p", "senID": 4, "childList": [{"text": "np.mat('1.23 2.34 3.45 6\\n1.32 2.43 7 3.54')", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "numpy", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n import numpy as np\ndef ReadFileChunk(pos_file):\n    chunktxt = \"\"\n    for line in pos_file:\n        if len(line) &gt; 1:\n            chunktxt = chunktxt + line\n        else:\n            break\n\n    return np.mat(chunktxt).tolist()\n    # or alternatively\n    #return np.array(np.mat(s))\n</code>\n</pre>\n", "senID": 5}, {"text": ["Then you can move your indexing stuff to another function.", "Hopefully having numpy parse the string internally is faster than calling float() repetitively. "], "childNum": 2, "tag": "p", "senID": 6, "childList": [{"text": "numpy", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "float()", "childNum": 0, "tag": "code", "childList": []}]}]]