[[{"text": ["What about using an in-memory SQLite database via the sqlite3 standard library module, using the special value :memory: for the connection?", "If you don't want to write your on SQL statements, you can always use an ORM, like SQLAlchemy, to access an in-memory SQLite database."], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "sqlite3 standard library module", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/sqlite3.html"}, {"text": ":memory:", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "SQLAlchemy", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.sqlalchemy.org/docs/dialects/sqlite.html#connect-strings"}]}, {"text": ["EDIT: I noticed you stated that the values may be Python objects, and also that you require avoiding serialization.", "Requiring arbitrary Python objects be stored in a database also necessitates serialization."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "EDIT", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Can I propose a practical solution if you must keep those two requirements?", "Why not just use Python dictionaries as indices into your collection of Python dictionaries?", "It sounds like you will have idiosyncratic needs for building each of your indices; figure out what values you're going to query on, then write a function to generate and index for each.", "The possible values for one key in your list of dicts will be the keys for an index; the values of the index will be a list of dictionaries.", "Query the index by giving the value you're looking for as the key."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n import collections\nimport itertools\n\ndef make_indices(dicts):\n    color_index = collections.defaultdict(list)\n    age_index = collections.defaultdict(list)\n    for d in dicts:\n        if 'favorite_color' in d:\n            color_index[d['favorite_color']].append(d)\n        if 'age' in d:\n            age_index[d['age']].append(d)\n    return color_index, age_index\n\n\ndef make_data_dicts():\n    ...\n\n\ndata_dicts = make_data_dicts()\ncolor_index, age_index = make_indices(data_dicts)\n# Query for those with a favorite color is simply values\nwith_color_dicts = list(\n        itertools.chain.from_iterable(color_index.values()))\n# Query for people over 16\nover_16 = list(\n        itertools.chain.from_iterable(\n            v for k, v in age_index.items() if age &gt; 16)\n)\n</code>\n</pre>\n", "senID": 3}], [{"text": ["If the in memory database solution ends up being too much work, here is a method for filtering it yourself that you may find useful."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["The get_filter function takes in arguments to define how you want to filter a dictionary, and returns a function that can be passed into the built in filter function to filter a list of dictionaries."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "get_filter", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "filter", "childNum": 0, "tag": "code", "childList": []}]}, {"code": "<pre>\n<code>\n import operator\n\ndef get_filter(key, op=None, comp=None, inverse=False):\n    # This will invert the boolean returned by the function 'op' if 'inverse == True'\n    result = lambda x: not x if inverse else x\n    if op is None:\n        # Without any function, just see if the key is in the dictionary\n        return lambda d: result(key in d)\n\n    if comp is None:\n        # If 'comp' is None, assume the function takes one argument\n        return lambda d: result(op(d[key])) if key in d else False\n\n    # Use 'comp' as the second argument to the function provided\n    return lambda d: result(op(d[key], comp)) if key in d else False\n\npeople = [{'age': 16, 'name': 'Joe'}, {'name': 'Jane', 'favourite_color': 'red'}]\n\nprint filter(get_filter(\"age\", operator.gt, 15), people)\n# [{'age': 16, 'name': 'Joe'}]\nprint filter(get_filter(\"name\", operator.eq, \"Jane\"), people)\n# [{'name': 'Jane', 'favourite_color': 'red'}]\nprint filter(get_filter(\"favourite_color\", inverse=True), people)\n# [{'age': 16, 'name': 'Joe'}]\n</code>\n</pre>\n", "senID": 2}, {"text": ["This is pretty easily extensible to more complex filtering, for example to filter based on whether or not a value is matched by a regex:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n p = re.compile(\"[aeiou]{2}\") # matches two lowercase vowels in a row\nprint filter(get_filter(\"name\", p.search), people)\n# [{'age': 16, 'name': 'Joe'}]\n</code>\n</pre>\n", "senID": 4}], [{"text": ["The only solution I know is a package I stumbled across a few years ago on PyPI, PyDbLite.", "It's okay, but there are few issues:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "PyDbLite", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.pydblite.net/en/PyDbLite.html"}]}, {"text": ["The author does seem to be working on it occasionally.", "There's some new features from when I used it, including some nice syntax for complex queries."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Assuming you rip out the pickling (and I can tell you what I did), your example would be (untested code):"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n from PyDbLite import Base\n\ndb = Base()\ndb.create(\"name\", \"age\", \"favourite_color\")\n\n# You can insert records as either named parameters\n# or in the order of the fields\ndb.insert(name=\"Joe\", age=16, favourite_color=None)\ndb.insert(\"Jane\", None, \"red\")\n\n# These should return an object you can iterate over\n# to get the matching records.  These are unindexed queries.\n#\n# The first might throw because of the None in the second record\nover_16 = db(\"age\") &gt; 16\nwith_favourite_colors = db(\"favourite_color\") != None\n\n# Or you can make an index for faster queries\ndb.create_index(\"favourite_color\")\nwith_favourite_color_red = db._favourite_color[\"red\"]\n</code>\n</pre>\n", "senID": 3}, {"text": ["Hopefully it will be enough to get you started."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}], [{"text": ["As far as \"identity\" anything that is hashable you should be able to compare, to keep track of object identity."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Zope Object Database (ZODB):\nhttp://www.zodb.org/"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://www.zodb.org/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.zodb.org/"}]}, {"text": ["PyTables works well:\nhttp://www.pytables.org/moin"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://www.pytables.org/moin", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.pytables.org/moin"}]}, {"text": ["Also Metakit for Python works well: \nhttp://equi4.com/metakit/python.html\nsupports columns, and sub-columns but not unstructured data"], "childNum": 3, "tag": "p", "senID": 3, "childList": [{"text": "http://equi4.com/metakit/python.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://equi4.com/metakit/python.html"}, {"text": "", "childNum": 0, "tag": "br", "childList": []}, {"text": "supports columns, and sub-columns but not unstructured data", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["Research \"Stream Processing\", if your data sets are extremely large this may be useful:\nhttp://www.trinhhaianh.com/stream.py/"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "http://www.trinhhaianh.com/stream.py/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.trinhhaianh.com/stream.py/"}]}, {"text": ["Any in-memory database, that can be serialized (written to disk) is going to have your identity problem.", "I would suggest representing the data you want to store as native types (list, dict) instead of objects if at all possible."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["Keep in mind NumPy was designed to perform complex operations on in-memory data structures, and could possibly be apart of your solution if you decide to roll your own."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["If you are willing to work around serializing, MongoDB could work for you.", "PyMongo provides an interface almost identical to what you describe.", "If you decide to serialize, the hit won't be as bad since Mongodb is memory mapped. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["It should be possible to do what you are wanting to do with just isinstance(), hasattr(), getattr() and setattr()."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["However, things are going to get fairly complicated before you are done! "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["I suppose one could store all the objects in a big list, then run a query on each object, determining what it is and looking for a given attribute or value, then return the value and the object as a list of tuples.", "Then you could sort on your return values pretty easily.", "copy.deepcopy will be your best friend and your worst enemy. "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Sounds like fun!", "Good luck!"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}]]