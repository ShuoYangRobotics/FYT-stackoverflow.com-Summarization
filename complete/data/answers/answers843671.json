[[{"text": ["I almost always view the output of the cProfile module using Gprof2dot, basically it converts the output into a graphvis graph (a .dot file), for example:"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Gprof2dot", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://code.google.com/p/jrfonseca/wiki/Gprof2Dot"}, {"text": ".dot", "childNum": 0, "tag": "code", "childList": []}]}, {"senID": 1}, {"text": ["It makes it very easy to determine which function is slowest, and which function[s] called it."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Usage is:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n python -m cProfile -o output.pstats path/to/your/script arg1 arg2\ngprof2dot.py -f pstats output.pstats | dot -Tpng -o output.png\n</code>\n</pre>\n", "senID": 4}], [{"text": ["That may not answer your question directly, but will definitely help.", "If use the profiler with option --sort cumulative it will sort the functions by cumulative time.", "Which is helpful to detect not only heavy functions but the functions that call them."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n python -m cProfile --sort cumulative myScript.py\n</code>\n</pre>\n", "senID": 1}, {"text": ["There is a workaround to get the caller function:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n import inspect\nprint inspect.getframeinfo(inspect.currentframe().f_back)[2]\n</code>\n</pre>\n", "senID": 3}, {"text": ["You can add as many f_back as you want in case you want the caller caller etc\nIf you want to calculate frequent calls you can do this:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n record = {}\n\ncaller = inspect.getframeinfo(inspect.currentframe().f_back)[2]\nrecord[caller] = record.get(caller, 0) + 1\n</code>\n</pre>\n", "senID": 5}, {"text": ["Then print them by order of frequency:"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n print sorted(record.items(), key=lambda a: a[1])\n</code>\n</pre>\n", "senID": 7}], [{"text": ["inspect.stack() will give you the current caller stack."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "inspect.stack()", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/inspect.html#inspect.stack"}]}], [{"text": ["I have not used cProfile myself, but most profilers give you a call hierarchy.", "Googling I found this slides about cProfile.", "Maybe that helps.", "Page 6 looks like cProfile does provide a hierarchy."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "", "childNum": 0, "tag": "br", "pos": 0, "childList": []}, {"text": "slides", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://us.pycon.org/media/2009/talkdata/PyCon2009/015/fletcher-profiling-2009.pdf"}]}], [{"text": ["You might want to take a look at pycallgraph."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "pycallgraph", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://pycallgraph.slowchop.com/"}]}], [{"text": ["Sorry I'm not familiar with Python, but there's a general method that works, assuming you can manually interrupt execution at a random time."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "general method", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/375913/what-can-i-use-to-profile-c-code-in-linux/378024#378024"}]}, {"text": ["Just do so, and display the call stack.", "It will tell you, with high probability, what you want to know.", "If you want to be more certain, just do it several times."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["It works because the guilty caller has to be on the call stack for the fraction of time that's being wasted, which exposes it to your interrupts for that much of the time, whether it is spread over many short calls or a few lengthy ones."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["NOTE: This process is more like diagnosis than measurement.", "Suppose that bad call is wasting 90% of the time.", "Then each time you halt it, the probability is 90% that the bad call statement is right there on the call stack for you to see, and you will be able to see that it's bad.", "However, if you want to exactly measure the wastage, that's a different problem.", "For that, you will need a lot more samples, to see what % of them contain that call.", "Or alternatively, just fix the guilty call, clock the speedup, and that will tell you exactly what the wastage was."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}]]