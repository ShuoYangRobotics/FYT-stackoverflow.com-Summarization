[[{"text": ["Threads are absolutely not the answer here.", "They will provide both process and kernel bottlenecks, as well as throughput limits that are not acceptable if the overall goal is \"the fastest way\"."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["A little bit of twisted and its asynchronous HTTP client would give you much better results."], "childNum": 2, "tag": "p", "senID": 1, "childList": [{"text": "twisted", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "HTTP", "childNum": 0, "tag": "code", "childList": []}]}], [{"text": ["Twistedless solution:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from urlparse import urlparse\nfrom threading import Thread\nimport httplib, sys\nfrom Queue import Queue\n\nconcurrent = 200\n\ndef doWork():\n    while True:\n        url=q.get()\n        status,url=getStatus(url)\n        doSomethingWithResult(status,url)\n        q.task_done()\n\ndef getStatus(ourl):\n    try:\n        url = urlparse(ourl)\n        conn = httplib.HTTPConnection(url.netloc)   \n        conn.request(\"HEAD\", url.path)\n        res = conn.getresponse()\n        return res.status, ourl\n    except:\n        return \"error\", ourl\n\ndef doSomethingWithResult(status, url):\n    print status, url\n\nq=Queue(concurrent*2)\nfor i in range(concurrent):\n    t=Thread(target=doWork)\n    t.daemon=True\n    t.start()\ntry:\n    for url in open('urllist.txt'):\n        q.put(url.strip())\n    q.join()\nexcept KeyboardInterrupt:\n    sys.exit(1)\n</code>\n</pre>\n", "senID": 1}, {"text": ["This one is slighty faster than the twisted solution and uses less cpu."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["A good approach to solving this problem is to first write the code required to get one result, then incorporate threading code to parallelize the application."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["In a perfect world this would simply mean simultaneously starting 100,000 threads which output their results into a dictionary or list for later processing, but in practice you are limited in how many parallel HTTP requests you can issue in this fashion.", "Locally, you have limits in how many sockets you can open concurrently, how many threads of execution your Python interpreter will allow.", "Remotely, you may be limited in the number of simultaneous connections if all the requests are against one server, or many.", "These limitations will probably necessitate that you write the script in such a way as to only poll a small fraction of the URLs at any one time (100, as another poster mentioned, is probably a decent thread pool size, although you may find that you can successfully deploy many more)."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["You can follow this design pattern to resolve the above issue:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["I would suggest you use the threading module.", "You can use it to launch and track running threads.", "Python's threading support is bare, but the description of your problem suggests that it is completely sufficient for your needs."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "threading", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/threading.html"}]}, {"text": ["Finally, if you'd like to see a pretty straightforward application of a parallel network application written in Python, check out ssh.py.", "It's a small library which uses Python threading to parallelize many SSH connections.", "The design is close enough to your requirements that you may find it to be a good resource."], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "ssh.py", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://github.com/ekg/ssh.py/blob/master/ssh.py"}]}], [{"text": ["Use the requests library: it has native support for sending multiple HTTP requests concurrently using gevent.", "Simple, easy, powerful!"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "requests", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://python-requests.org"}, {"text": "sending multiple HTTP requests concurrently", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://docs.python-requests.org/en/latest/user/advanced/#asynchronous-requests"}]}], [{"text": ["The easiest way would be to use Python's built-in threading library.", "They're not \"real\" / kernel threads, but are good enough.", "You'd want a queue &amp; thread pool.", "One option is here, but it's trivial to write your own.", "You can't parallelize all 100,000 calls, but you can fire off 100 (or so) of them at the same time."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "here", "tag": "a", "pos": 3, "childList": [], "childNum": 0, "href": "http://pypi.python.org/pypi/threadpool/1.2.5"}]}], [{"text": ["For your case, threading will probably do the trick as you'll probably be spending most time waiting for a response.", "There are helpful modules like Queue in the standard library that might help."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Queue", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/queue.html"}]}, {"text": ["I did a similar thing with parallel downloading of files before and it was good enough for me, but it wasn't on the scale you are talking about."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["If your task was more CPU-bound, you might want to look at the multiprocessing module, which will allow you to utilize more CPUs/cores/threads (more processes that won't block each other since the locking is per process)"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "multiprocessing", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/multiprocessing.html"}]}], [{"text": ["If you're looking to get the best performance possible, you might want to consider using Asynchronous I/O rather than threads.", "The overhead associated with thousands of OS threads is non-trivial and the context switching within the Python interpreter adds even more on top of it.", "Threading will certainly get the job done but I suspect that an asynchronous route will provide better overall performance."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Specifically, I'd suggest the async web client in the Twisted library (http://www.twistedmatrix.com).", "It has an admittedly steep learning curve but it quite easy to use once you get a good handle on Twisted's style of asynchronous programming."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["A HowTo on Twisted's asynchronous web client API is available at:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["http://twistedmatrix.com/documents/current/web/howto/client.html"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://twistedmatrix.com/documents/current/web/howto/client.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://twistedmatrix.com/documents/current/web/howto/client.html"}]}], [{"text": ["A solution:"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n from twisted.internet import reactor, threads\nfrom urlparse import urlparse\nimport httplib\nimport itertools\n\n\nconcurrent = 200\nfinished=itertools.count(1)\nreactor.suggestThreadPoolSize(concurrent)\n\ndef getStatus(ourl):\n    url = urlparse(ourl)\n    conn = httplib.HTTPConnection(url.netloc)   \n    conn.request(\"HEAD\", url.path)\n    res = conn.getresponse()\n    return res.status\n\ndef processResponse(response,url):\n    print response, url\n    processedOne()\n\ndef processError(error,url):\n    print \"error\", url#, error\n    processedOne()\n\ndef processedOne():\n    if finished.next()==added:\n        reactor.stop()\n\ndef addTask(url):\n    req = threads.deferToThread(getStatus, url)\n    req.addCallback(processResponse, url)\n    req.addErrback(processError, url)   \n\nadded=0\nfor url in open('urllist.txt'):\n    added+=1\n    addTask(url.strip())\n\ntry:\n    reactor.run()\nexcept KeyboardInterrupt:\n    reactor.stop()\n</code>\n</pre>\n", "senID": 1}, {"text": ["Testtime:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n [kalmi@ubi1:~] wc -l urllist.txt\n10000 urllist.txt\n[kalmi@ubi1:~] time python f.py &gt; /dev/null \n\nreal    1m10.682s\nuser    0m16.020s\nsys 0m10.330s\n[kalmi@ubi1:~] head -n 6 urllist.txt\nhttp://www.google.com\nhttp://www.bix.hu\nhttp://www.godaddy.com\nhttp://www.google.com\nhttp://www.bix.hu\nhttp://www.godaddy.com\n[kalmi@ubi1:~] python f.py | head -n 6\n200 http://www.bix.hu\n200 http://www.bix.hu\n200 http://www.bix.hu\n200 http://www.bix.hu\n200 http://www.bix.hu\n200 http://www.bix.hu\n</code>\n</pre>\n", "senID": 3}, {"text": ["Pingtime:"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n bix.hu is ~10 ms away from me\ngodaddy.com: ~170 ms\ngoogle.com: ~30 ms\n</code>\n</pre>\n", "senID": 5}], [{"text": ["Using a thread pool is a good option, and will make this fairly easy.", "Unfortunately, python doesn't have a standard library that makes thread pools ultra easy.", "But here is a decent library that should get you started:\nhttp://www.chrisarndt.de/projects/threadpool/"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "thread pool", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Thread_pool"}, {"text": "http://www.chrisarndt.de/projects/threadpool/", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://www.chrisarndt.de/projects/threadpool/"}]}, {"text": ["Code example from their site:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n pool = ThreadPool(poolsize)\nrequests = makeRequests(some_callable, list_of_args, callback)\n[pool.putRequest(req) for req in requests]\npool.wait()\n</code>\n</pre>\n", "senID": 2}, {"text": ["Hope this helps."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["Consider using Windmill , although Windmill probably cant do that many threads.  "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Windmill", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.getwindmill.com/"}]}, {"text": ["You could do it with a hand rolled Python script on 5 machines, each one connecting outbound using ports 40000-60000,   opening 100,000 port connections.  "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Also, it might help to do a sample test with a nicely threaded QA app such as OpenSTA  in order to get an idea of how much each server can handle."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "OpenSTA", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.opensta.org/"}]}, {"text": ["Also, try looking into just using simple Perl with the LWP::ConnCache  class.", "You'll probably get more performance (more connections) that way."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}]]