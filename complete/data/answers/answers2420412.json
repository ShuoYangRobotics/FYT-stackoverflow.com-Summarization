[[{"text": ["Before you read on, have you looked at biopython?"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "Before you read on", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"href": "http://biopython.org/wiki/Main_Page", "text": "biopython", "childNum": 0, "tag": "a", "childList": []}]}, {"text": ["It appears that you want to find approximate matches with one substitution error, and zero insertion/deletion errors i.e.", "a Hamming distance of 1."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["If you have a Hamming distance match function (see e.g.", "the link provided by Ignacio), you could use it like this to do a search for the first match:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n any(Hamming_distance(genome[x:x+25], sequence) == 1 for x in xrange(len(genome)))\n</code>\n</pre>\n", "senID": 3}, {"text": ["but this would be rather slow, because (1) the Hamming distance function would keep on grinding after the 2nd substitution error (2) after failure, it advances the cursor by one rather than skipping ahead based on what it saw (like a Boyer-Moore search does)."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["You can overcome (1) with a function like this:"], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"code": "<pre>\n<code>\n def Hamming_check_0_or_1(genome, posn, sequence):\n    errors = 0\n    for i in xrange(25):\n        if genome[posn+i] != sequence[i]:\n            errors += 1\n            if errors &gt;= 2:\n                return errors\n    return errors\n</code>\n</pre>\n", "senID": 6}, {"text": ["Note: that's intentionally not Pythonic, it's Cic, because you'd need to use C (perhaps via Cython) to get reasonable speed."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Some work on bit-parallel approximate Levenshtein searches with skipping has been done by Navarro and Raffinot (google \"Navarro Raffinot nrgrep\") and this could be adapted to Hamming searches.", "Note that bit-parallel methods have limitations on length of query string and alphabet size but yours are 25 and 4 respectively so no problems there.", "Update: skipping probably not much help with an alphabet size of 4."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["When you google for Hamming distance search, you will notice lots of stuff about implementing it in hardware, and not much in software.", "This is a big hint that maybe whatever algorithm you come up with ought to be implemented in C or some other compiled language."], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"text": ["Update: Working code for a bit-parallel method"], "childNum": 2, "tag": "p", "senID": 10, "childList": [{"text": "Update:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "Working code for a bit-parallel method", "childNum": 0, "tag": "strong", "childList": []}]}, {"text": ["I've also supplied a simplistic method for helping with the correctness checking, and I've packaged a variation of Paul's re code for some comparisons.", "Note that using re.finditer() delivers non-overlapping results, and this can cause a distance-1 match to shadow an exact match; see my last test case."], "childNum": 0, "tag": "p", "senID": 11, "childList": []}, {"text": ["The bit-parallel method has these features: guaranteed linear behaviour O(N) where N is text length.", "Note naive method is O(NM) as is the regex method (M is the pattern length).", "A Boyer-Moore-style method would be worst case O(NM) and expected O(N).", "Also the bit-parallel method can be used easily when input has to be buffered: it can be fed a byte or a megabyte at a time; no look-ahead, no problems with buffer boundaries.", "The big advantage: the speed of that simple per-input-byte code when coded in C."], "childNum": 0, "tag": "p", "senID": 12, "childList": []}, {"text": ["Downsides: the pattern length is effectively limited to the number of bits in a fast register e.g.", "32 or 64.", "In this case the pattern length is 25; no problem.", "It uses extra memory (S_table) proportional to the number of distinct characters in the pattern.", "In this case, the \"alphabet size\" is only 4; no problem."], "childNum": 0, "tag": "p", "senID": 13, "childList": []}, {"text": ["Details from this technical report.", "The algorithm there is for approximate search usin Levenshtein distance.", "To convert to using Hamming distance, I simply (!", ") removed the pieces of statement 2.1 that handle insertion and deletion.", "You'll notice lots of reference to \"R\" with a \"d\" superscript.", "\"d\" is distance.", "We need only 0 and 1.", "These \"R\"s become the R0 and R1 variables in the code below."], "childNum": 1, "tag": "p", "senID": 14, "childList": [{"text": "this technical report", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.8854"}]}, {"code": "<pre>\n<code>\n # coding: ascii\n\nfrom collections import defaultdict\nimport re\n\n_DEBUG = 0\n\n\n# \"Fast Text Searching with Errors\" by Sun Wu and Udi Manber\n# TR 91-11, Dept of Computer Science, University of Arizona, June 1991.\n# http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.8854\n\ndef WM_approx_Ham1_search(pattern, text):\n    \"\"\"Generate (Hamming_dist, start_offset)\n    for matches with distance 0 or 1\"\"\"\n    m = len(pattern)\n    S_table = defaultdict(int)\n    for i, c in enumerate(pattern):\n        S_table[c] |= 1 &lt;&lt; i\n    R0 = 0\n    R1 = 0\n    mask = 1 &lt;&lt; (m - 1)\n    for j, c in enumerate(text):\n        S = S_table[c]\n        shR0 = (R0 &lt;&lt; 1) | 1\n        R0 = shR0 &amp; S\n        R1 = ((R1 &lt;&lt; 1) | 1) &amp; S | shR0\n        if _DEBUG:\n            print \"j= %2d msk=%s S=%s R0=%s R1=%s\" \\\n                % tuple([j] + map(bitstr, [mask, S, R0, R1]))\n        if R0 &amp; mask: # exact match\n            yield 0, j - m + 1\n        elif R1 &amp; mask: # match with one substitution\n            yield 1, j - m + 1\n\nif _DEBUG:\n\n    def bitstr(num, mlen=8):\n       wstr = \"\"\n       for i in xrange(mlen):\n          if num &amp; 1:\n             wstr = \"1\" + wstr\n          else:\n             wstr = \"0\" + wstr\n          num &gt;&gt;= 1\n       return wstr\n\ndef Ham_dist(s1, s2):\n    \"\"\"Calculate Hamming distance between 2 sequences.\"\"\"\n    assert len(s1) == len(s2)\n    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n\ndef long_check(pattern, text):\n    \"\"\"Naively and understandably generate (Hamming_dist, start_offset)\n    for matches with distance 0 or 1\"\"\"\n    m = len(pattern)\n    for i in xrange(len(text) - m + 1):\n        d = Ham_dist(pattern, text[i:i+m])\n        if d &lt; 2:\n            yield d, i\n\ndef Paul_McGuire_regex(pattern, text):\n    searchSeqREStr = (\n        '('\n        + pattern\n        + ')|('\n        + ')|('.join(\n            pattern[:i]\n            + \"[ACTGN]\".replace(c,'')\n            + pattern[i+1:]\n            for i,c in enumerate(pattern)\n            )\n        + ')'\n        )\n    searchSeqRE = re.compile(searchSeqREStr)\n    for match in searchSeqRE.finditer(text):\n        locn = match.start()\n        dist = int(bool(match.lastindex - 1))\n        yield dist, locn\n\n\nif __name__ == \"__main__\":\n\n    genome1 = \"TTTACGTAAACTAAACTGTAA\"\n    #         01234567890123456789012345\n    #                   1         2\n\n    tests = [\n        (genome1, \"ACGT ATGT ACTA ATCG TTTT ATTA TTTA\"),\n        (\"T\" * 10, \"TTTT\"),\n        (\"ACGTCGTAAAA\", \"TCGT\"), # partial match can shadow an exact match\n        ]\n\n    nfailed = 0\n    for genome, patterns in tests:\n        print \"genome:\", genome\n        for pattern in patterns.split():\n            print pattern\n            a1 = list(WM_approx_Ham1_search(pattern, genome))\n            a2 = list(long_check(pattern, genome))\n            a3 = list(Paul_McGuire_regex(pattern, genome))\n            print a1\n            print a2\n            print a3\n            print a1 == a2, a2 == a3\n            nfailed += (a1 != a2 or a2 != a3)\n    print \"***\", nfailed\n</code>\n</pre>\n", "senID": 15}], [{"text": ["You might find the various routines in Python-Levenshtein of some use."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "Python-Levenshtein", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.michael-noll.com/wiki/Python-Levenshtein"}]}], [{"code": "<pre>\n<code>\n &gt;&gt;&gt; import re\n&gt;&gt;&gt; seq=\"AGCCTCCCATGATTGAACAGATCAT\"\n&gt;&gt;&gt; genome = \"CATGGGAGGCTTGCGGAGCCTGAGGGCGGAGCCTGAGGTGGGAGGCTTGCGGAGTGCGGAGCCTGAGCCTGAGGGCGGAGCCTGAGGTGGGAGGCTT...\"\n&gt;&gt;&gt; seq_re=re.compile('|'.join(seq[:i]+'.'+seq[i+1:] for i in range(len(seq))))\n\n&gt;&gt;&gt; seq_re.findall(genome)  # list of matches\n[]  \n\n&gt;&gt;&gt; seq_re.search(genome) # None if not found, otherwise a match object\n</code>\n</pre>\n", "senID": 0}, {"text": ["This one stops a the first match, so may be a bit faster when there are multiple matches"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; print \"found\" if any(seq_re.finditer(genome)) else \"not found\"\nnot found\n\n&gt;&gt;&gt; print \"found\" if seq_re.search(genome) else \"not found\" \nnot found\n\n&gt;&gt;&gt; seq=\"CAT\"\n&gt;&gt;&gt; seq_re=re.compile('|'.join(seq[:i]+'.'+seq[i+1:] for i in range(len(seq))))\n&gt;&gt;&gt; print \"found\" if seq_re.search(genome) else \"not found\"\nfound\n</code>\n</pre>\n", "senID": 2}, {"text": ["for a genome of length 10,000,000 you are looking at about 2.5 days for a single thread to scan 230,000 sequences, so you may want to split up the task onto a few cores/cpus."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["You can always start implementing a more efficient algorithm while this one is running :)"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["If you should wish to search for single dropped or added elements change the regexp to this"], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"code": "<pre>\n<code>\n &gt;&gt;&gt; seq_re=re.compile('|'.join(seq[:i]+'.{0,2}'+seq[i+1:] for i in range(len(seq))))\n</code>\n</pre>\n", "senID": 6}], [{"text": ["I googled for \"toxoplasma gondii parasite genome\" to find some of these genome files online.", "I found what I think was close, a file titled \"TgondiiGenomic_ToxoDB-6.0.fasta\" at http://toxodb.org, about 158Mb in size.", "I used the following pyparsing expression to extract the gene sequences, it took just under 2 minutes:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://toxodb.org", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://toxodb.org"}]}, {"code": "<pre>\n<code>\n fname = \"TgondiiGenomic_ToxoDB-6.0.fasta\"\nfastasrc = open(fname).read()   # yes! just read the whole dang 158Mb!\n\n\"\"\"\nSample header:\n&gt;gb|scf_1104442823584 | organism=Toxoplasma_gondii_VEG | version=2008-07-23 | length=1448\n\"\"\"\ninteger = Word(nums).setParseAction(lambda t:int(t[0]))\ngenebit = Group(\"&gt;gb|\" + Word(printables)(\"id\") + SkipTo(\"length=\") + \n                \"length=\" + integer(\"genelen\") + LineEnd() + \n                Combine(OneOrMore(Word(\"ACGTN\")),adjacent=False)(\"gene\"))\n\n# read gene data from .fasta file - takes just under a couple of minutes\ngenedata = OneOrMore(genebit).parseString(fastasrc)\n</code>\n</pre>\n", "senID": 1}, {"text": ["(Surprise!", "some of the gene sequences include runs of 'N's!", "What the heck is that about?!"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Then I wrote this class as a subclass of the pyparsing Token class, for doing close matches:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n class CloseMatch(Token):\n    def __init__(self, seq, maxMismatches=1):\n        super(CloseMatch,self).__init__()\n        self.name = seq\n        self.sequence = seq\n        self.maxMismatches = maxMismatches\n        self.errmsg = \"Expected \" + self.sequence\n        self.mayIndexError = False\n        self.mayReturnEmpty = False\n\n    def parseImpl( self, instring, loc, doActions=True ):\n        start = loc\n        instrlen = len(instring)\n        maxloc = start + len(self.sequence)\n\n        if maxloc &lt;= instrlen:\n            seq = self.sequence\n            seqloc = 0\n            mismatches = []\n            throwException = False\n            done = False\n            while loc &lt; maxloc and not done:\n                if instring[loc] != seq[seqloc]:\n                    mismatches.append(seqloc)\n                    if len(mismatches) &gt; self.maxMismatches:\n                        throwException = True\n                        done = True\n                loc += 1\n                seqloc += 1\n        else:\n            throwException = True\n\n        if throwException:\n            exc = self.myException\n            exc.loc = loc\n            exc.pstr = instring\n            raise exc\n\n        return loc, (instring[start:loc],mismatches)\n</code>\n</pre>\n", "senID": 4}, {"text": ["For every match, this will return a tuple containing the actual string that was matched, and a list of the mismatch locations.", "Exact matches would of course return an empty list for the second value.", "(I like this class, I think I'll add it to the next release of pyparsing."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["I then ran this code to search for \"up-to-2-mismatch\" matches in all of the sequences read from the .fasta file (recall that genedata is a sequence of ParseResults groups, each containing an id, an integer length, and a sequence string):"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"code": "<pre>\n<code>\n searchseq = CloseMatch(\"ATCATCGAATGGAATCTAATGGAAT\", 2)\nfor g in genedata:\n    print \"%s (%d)\" % (g.id, g.genelen)\n    print \"-\"*24\n    for t,startLoc,endLoc in searchseq.scanString(g.gene):\n        matched, mismatches = t[0]\n        print \"MATCH:\", searchseq.sequence\n        print \"FOUND:\", matched\n        if mismatches:\n            print \"      \", ''.join(' ' if i not in mismatches else '*' \n                            for i,c in enumerate(searchseq.sequence))\n        else:\n            print \"&lt;exact match&gt;\"\n        print \"at location\", startLoc\n        print\n    print\n</code>\n</pre>\n", "senID": 7}, {"text": ["I took the search sequence at random from one of the gene bits, to be sure I could find an exact match, and just out of curiosity to see how many 1- and 2-element mismatches there were."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["This took a little while to run.", "After 45 minutes, I had this output, listing each id and gene length, and any partial matches found:"], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"code": "<pre>\n<code>\n scf_1104442825154 (964)\n------------------------\n\nscf_1104442822828 (942)\n------------------------\n\nscf_1104442824510 (987)\n------------------------\n\nscf_1104442823180 (1065)\n------------------------\n...\n</code>\n</pre>\n", "senID": 10}, {"text": ["I was getting discouraged, not to see any matches until:"], "childNum": 0, "tag": "p", "senID": 11, "childList": []}, {"code": "<pre>\n<code>\n scf_1104442823952 (1188)\n------------------------\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAACGGAATCGAATGGAAT\n                *      *        \nat location 33\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCGAATGGAAT\n                       *        \nat location 175\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCGAATGGAAT\n                       *        \nat location 474\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCGAATGGAAT\n                       *        \nat location 617\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCGAATAGAAT\n                       *   *    \nat location 718\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGATTCGAATGGAAT\n                    *  *        \nat location 896\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCGAATGGTAT\n                       *     *  \nat location 945\n</code>\n</pre>\n", "senID": 12}, {"text": ["And finally my exact match at:"], "childNum": 0, "tag": "p", "senID": 13, "childList": []}, {"code": "<pre>\n<code>\n scf_1104442823584 (1448)\n------------------------\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGACTCGAATGGAAT\n                    *  *        \nat location 177\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCAAATGGAAT\n                       *        \nat location 203\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCAAATGGAATCGAATGGAAT\n             *         *        \nat location 350\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCGAATGGAAA\n                       *       *\nat location 523\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCAAATGGAATCGAATGGAAT\n             *         *        \nat location 822\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCATCGAATGGAATCTAATGGAAT\n&lt;exact match&gt;\nat location 848\n\nMATCH: ATCATCGAATGGAATCTAATGGAAT\nFOUND: ATCGTCGAATGGAGTCTAATGGAAT\n          *         *           \nat location 969\n</code>\n</pre>\n", "senID": 14}, {"text": ["So while this didn't set any speed records, I got the job done, and found some 2-matches too, in case they might be of interest."], "childNum": 0, "tag": "p", "senID": 15, "childList": []}, {"text": ["For comparison, here is an RE-based version, that finds 1-mismatch matches only:"], "childNum": 0, "tag": "p", "senID": 16, "childList": []}, {"code": "<pre>\n<code>\n import re\nseqStr = \"ATCATCGAATGGAATCTAATGGAAT\"\nsearchSeqREStr = seqStr + '|' + \\\n    '|'.join(seqStr[:i]+\"[ACTGN]\".replace(c,'') +seqStr[i+1:] \n             for i,c in enumerate(seqStr))\n\nsearchSeqRE = re.compile(searchSeqREStr)\n\nfor g in genedata:\n    print \"%s (%d)\" % (g.id, g.genelen)\n    print \"-\"*24\n    for match in searchSeqRE.finditer(g.gene):\n        print \"MATCH:\", seqStr\n        print \"FOUND:\", match.group(0)\n        print \"at location\", match.start()\n        print\n    print\n</code>\n</pre>\n", "senID": 17}, {"text": ["(At first, I tried searching the raw FASTA file source itself, but was puzzled why so few matches compared to the pyparsing version.", "Then I realized that some of the matches must cross the line breaks, since the fasta file output is wrapped at n characters."], "childNum": 0, "tag": "p", "senID": 18, "childList": []}, {"text": ["So after the first pyparsing pass to extract the gene sequences to match against, this RE-based searcher then took about another 1-1/2 minutes to scan all of the un-textwrapped sequences, to find all of the same 1-mismatch entries that the pyparsing solution did."], "childNum": 0, "tag": "p", "senID": 19, "childList": []}], [{"text": ["This hints of the longest common subsequence problem.", "The problem with string similarity here is that you need to test against a continuous string of 230000 sequences; so if you are comparing one of your 25 sequences to the continuous string you'll get a very low similarity."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "longest common subsequence problem", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Longest_common_subsequence_problem"}]}, {"text": ["If you compute the longest common subsequence between your 25 sequences and the continuous string, you'll know if it is in the string if the lengths are the same."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["You could make a trie out of all the different sequences that you want to match.", "Now is the tricky part of making a depth first search function down the trie that allows at most one mismatch."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "trie", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://en.wikipedia.org/wiki/Trie"}]}, {"text": ["The advantage of this method is that you are searching through all of the sequences at once.", "This will save you a lot of comparisons.", "For instance, when you start at the top node and go down the 'A' branch, you have just saved yourself many thousands of comparisons because have just instantly matched with all sequences that start with 'A'.", "For a different argument, consider a slice of the genome that matches exactly with a given sequence.", "If you have a different sequence in your list of sequences that differs only in the last symbol, then using a trie has just saved you 23 comparison operations."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Here is one way of implementing this.", "Convert 'A','C',T',G' to 0,1,2,3 or a variant of that.", "Then use tuples of tuples as your structure for your trie.", "At each node, the first element in your array corresponds with 'A', the second with 'C' and so on.", "If 'A' is a branch of this node, then there is another tuple of 4 elements as the first item of this node's tuple.", "If there isn't an 'A' branch, then set the first item to 0.", "At the bottom of the trie are nodes that have the id of that sequence so that it can be put into the list of matches."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Here are recursive search functions allowing one mismatch for this sort of trie:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n def searchnomismatch(node,genome,i):\n    if i == 25:\n        addtomatches(node)\n    else:\n        for x in range(4):\n            if node[x]:\n                if x == genome[i]:\n                    searchnomismatch(node[x],genome,i+1)\n                else:\n                    searchmismatch(node[x],genome,i+1,i)\n\ndef searchmismatch(node,genome,i,where):\n    if i == 25:\n        addtomatches(node,where)\n    else:\n        if node[genome[i]]:\n            searchmismatch(node[genome[i]],genome,i+1,where)\n</code>\n</pre>\n", "senID": 4}, {"text": ["Here, I start out the search with something like"], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"code": "<pre>\n<code>\n searchnomismatch(trie,genome[ind:ind+25],0)\n</code>\n</pre>\n", "senID": 6}, {"text": ["and addtomatches is something similar to"], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"code": "<pre>\n<code>\n def addtomatches(id,where=-1):\n    matches.append(id,where)\n</code>\n</pre>\n", "senID": 8}, {"text": ["where equal to -1 means there wasn't a mismatch.", "Anyway, I hope that I was clear enough so that you get the picture."], "childNum": 0, "tag": "p", "senID": 9, "childList": []}], [{"text": ["You could use Pythons built in capability to do the search with regular expression matching. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["re module in python\nhttp://docs.python.org/library/re.html"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "http://docs.python.org/library/re.html", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://docs.python.org/library/re.html"}]}, {"text": ["regular expression primer\nhttp://www.regular-expressions.info/"], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "http://www.regular-expressions.info/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.regular-expressions.info/"}]}], [{"text": ["I ask this question on the biopython mailing list and got pointed to a great solution/program.", "@Michiel de Hoon\nNexalign can do exactly what you are trying to do.", "See http://genome.gsc.riken.jp/osc/english/dataresource/."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://genome.gsc.riken.jp/osc/english/dataresource/", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://genome.gsc.riken.jp/osc/english/dataresource/"}]}, {"text": ["It is amazing that is can find all 1 mismatch sequences from the 230,000 sequences I have in only 30sec."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["While this is the solution to my problem to be fair it is not the answer to my stackoverflow question.", "So I will make one of the solutions as the correct solution.", "Thanks for all the great input."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["I guess this may come a bit late, but there is a tool named PatMaN that does exactly what you want:\nhttp://bioinf.eva.mpg.de/patman/"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://bioinf.eva.mpg.de/patman/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://bioinf.eva.mpg.de/patman/"}]}], [{"text": ["I tried some of the solutions, but as already written they are slow when dealing with a large amount of sequences (strings)."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["I came up with using bowtie and mapping the substring of interest (soi) against a reference file which contains the strings in FASTA format.", "You can provide the number of allowed mismatches (0..3) and you get back the strings to which the soi mapped given the allowed mismatches.", "This works well and pretty fast."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "bowtie", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://bowtie-bio.sourceforge.net/"}]}]]