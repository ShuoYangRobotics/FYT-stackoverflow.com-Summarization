[[{"text": ["Here's a simple solution using BeautifulSoup:"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "BeautifulSoup", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.crummy.com/software/BeautifulSoup/"}]}, {"code": "<pre>\n<code>\n from BeautifulSoup import BeautifulSoup\n\nVALID_TAGS = ['strong', 'em', 'p', 'ul', 'li', 'br']\n\ndef sanitize_html(value):\n\n    soup = BeautifulSoup(value)\n\n    for tag in soup.findAll(True):\n        if tag.name not in VALID_TAGS:\n            tag.hidden = True\n\n    return soup.renderContents()\n</code>\n</pre>\n", "senID": 1}, {"text": ["If you want to remove the contents of the invalid tags as well, substitute tag.extract() for tag.hidden."], "childNum": 2, "tag": "p", "senID": 2, "childList": [{"text": "tag.extract()", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "tag.hidden", "childNum": 0, "tag": "code", "childList": []}]}, {"text": ["You might also look into using lxml and Tidy."], "childNum": 2, "tag": "p", "senID": 3, "childList": [{"text": "lxml", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://codespeak.net/lxml/"}, {"href": "http://utidylib.berlios.de/", "text": "Tidy", "childNum": 0, "tag": "a", "childList": []}]}], [{"text": ["Use lxml.html.clean!", "It's VERY easy!"], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "lxml.html.clean", "tag": "a", "pos": 0, "childList": [{"text": "lxml.html.clean", "tag": "code"}], "childNum": 1, "href": "http://codespeak.net/lxml/lxmlhtml.html#cleaning-up-html"}, {"text": "lxml.html.clean", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n from lxml.html.clean import clean_html\nprint clean_html(html)\n</code>\n</pre>\n", "senID": 1}, {"text": ["Suppose the following html:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n html = '''\\\n&lt;html&gt;\n &lt;head&gt;\n   &lt;script type=\"text/javascript\" src=\"evil-site\"&gt;&lt;/script&gt;\n   &lt;link rel=\"alternate\" type=\"text/rss\" src=\"evil-rss\"&gt;\n   &lt;style&gt;\n     body {background-image: url(javascript:do_evil)};\n     div {color: expression(evil)};\n   &lt;/style&gt;\n &lt;/head&gt;\n &lt;body onload=\"evil_function()\"&gt;\n    &lt;!-- I am interpreted for EVIL! --&gt;\n   &lt;a href=\"javascript:evil_function()\"&gt;a link&lt;/a&gt;\n   &lt;a href=\"#\" onclick=\"evil_function()\"&gt;another link&lt;/a&gt;\n   &lt;p onclick=\"evil_function()\"&gt;a paragraph&lt;/p&gt;\n   &lt;div style=\"display: none\"&gt;secret EVIL!&lt;/div&gt;\n   &lt;object&gt; of EVIL! &lt;/object&gt;\n   &lt;iframe src=\"evil-site\"&gt;&lt;/iframe&gt;\n   &lt;form action=\"evil-site\"&gt;\n     Password: &lt;input type=\"password\" name=\"password\"&gt;\n   &lt;/form&gt;\n   &lt;blink&gt;annoying EVIL!&lt;/blink&gt;\n   &lt;a href=\"evil-site\"&gt;spam spam SPAM!&lt;/a&gt;\n   &lt;image src=\"evil!\"&gt;\n &lt;/body&gt;\n&lt;/html&gt;'''\n</code>\n</pre>\n", "senID": 3}, {"text": ["The results..."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n &lt;html&gt;\n  &lt;body&gt;\n    &lt;div&gt;\n      &lt;style&gt;/* deleted */&lt;/style&gt;\n      &lt;a href=\"\"&gt;a link&lt;/a&gt;\n      &lt;a href=\"#\"&gt;another link&lt;/a&gt;\n      &lt;p&gt;a paragraph&lt;/p&gt;\n      &lt;div&gt;secret EVIL!&lt;/div&gt;\n      of EVIL!\n      Password:\n      annoying EVIL!\n      &lt;a href=\"evil-site\"&gt;spam spam SPAM!&lt;/a&gt;\n      &lt;img src=\"evil!\"&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code>\n</pre>\n", "senID": 5}, {"text": ["You can customize the elements you want to clean and whatnot."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}], [{"text": ["The above solutions via Beautiful Soup will not work.", "You might be able to hack something with Beautiful Soup above and beyond them, because Beautiful Soup provides access to the parse tree.", "In a while, I think I'll try to solve the problem properly, but it's a week-long project or so, and I don't have a free week soon. "], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Just to be specific, not only will Beautiful Soup throw exceptions for some parsing errors which the above code doesn't catch; but also, there are plenty of very real XSS vulnerabilities that aren't caught, like:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n &lt;&lt;script&gt;script&gt; alert(\"Haha, I hacked your page.\"); &lt;/&lt;/script&gt;script&gt;\n</code>\n</pre>\n", "senID": 2}, {"text": ["Probably the best thing that you can do is instead to strip out the &lt; element as &amp;lt;, to prohibit all HTML, and then use a restricted subset like Markdown to render formatting properly.", "In particular, you can also go back and re-introduce common bits of HTML with a regex.", "Here's what the process looks like, roughly:"], "childNum": 3, "tag": "p", "senID": 3, "childList": [{"text": "&lt;", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "&amp;lt;", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "all", "childNum": 0, "tag": "em", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n _lt_     = re.compile('&lt;')\n_tc_ = '~(lt)~'   # or whatever, so long as markdown doesn't mangle it.     \n_ok_ = re.compile(_tc_ + '(/?(?:u|b|i|em|strong|sup|sub|p|br|q|blockquote|code))&gt;', re.I)\n_sqrt_ = re.compile(_tc_ + 'sqrt&gt;', re.I)     #just to give an example of extending\n_endsqrt_ = re.compile(_tc_ + '/sqrt&gt;', re.I) #html syntax with your own elements.\n_tcre_ = re.compile(_tc_)\n\ndef sanitize(text):\n    text = _lt_.sub(_tc_, text)\n    text = markdown(text)\n    text = _ok_.sub(r'&lt;\\1&gt;', text)\n    text = _sqrt_.sub(r'&amp;radic;&lt;span style=\"text-decoration:overline;\"&gt;', text)\n    text = _endsqrt_.sub(r'&lt;/span&gt;', text)\n    return _tcre_.sub('&amp;lt;', text)\n</code>\n</pre>\n", "senID": 4}, {"text": ["I haven't tested that code yet, so there may be bugs.", "But you see the general idea: you have to blacklist all HTML in general before you whitelist the ok stuff."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}], [{"text": ["Here is what i use in my own project.", "The acceptable_elements/attributes come from feedparser and BeautifulSoup does the work."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "feedparser", "tag": "a", "pos": 1, "childList": [], "childNum": 0, "href": "http://www.feedparser.org/docs/html-sanitization.html"}]}, {"code": "<pre>\n<code>\n from BeautifulSoup import BeautifulSoup\n\nacceptable_elements = ['a', 'abbr', 'acronym', 'address', 'area', 'b', 'big',\n      'blockquote', 'br', 'button', 'caption', 'center', 'cite', 'code', 'col',\n      'colgroup', 'dd', 'del', 'dfn', 'dir', 'div', 'dl', 'dt', 'em',\n      'font', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'hr', 'i', 'img', \n      'ins', 'kbd', 'label', 'legend', 'li', 'map', 'menu', 'ol', \n      'p', 'pre', 'q', 's', 'samp', 'small', 'span', 'strike',\n      'strong', 'sub', 'sup', 'table', 'tbody', 'td', 'tfoot', 'th',\n      'thead', 'tr', 'tt', 'u', 'ul', 'var']\n\nacceptable_attributes = ['abbr', 'accept', 'accept-charset', 'accesskey',\n  'action', 'align', 'alt', 'axis', 'border', 'cellpadding', 'cellspacing',\n  'char', 'charoff', 'charset', 'checked', 'cite', 'clear', 'cols',\n  'colspan', 'color', 'compact', 'coords', 'datetime', 'dir', \n  'enctype', 'for', 'headers', 'height', 'href', 'hreflang', 'hspace',\n  'id', 'ismap', 'label', 'lang', 'longdesc', 'maxlength', 'method',\n  'multiple', 'name', 'nohref', 'noshade', 'nowrap', 'prompt', \n  'rel', 'rev', 'rows', 'rowspan', 'rules', 'scope', 'shape', 'size',\n  'span', 'src', 'start', 'summary', 'tabindex', 'target', 'title', 'type',\n  'usemap', 'valign', 'value', 'vspace', 'width']\n\ndef clean_html( fragment ):\n    while True:\n        soup = BeautifulSoup( fragment )\n        removed = False        \n        for tag in soup.findAll(True): # find all tags\n            if tag.name not in acceptable_elements:\n                tag.extract() # remove the bad ones\n                removed = True\n            else: # it might have bad attributes\n                # a better way to get all attributes?\n                for attr in tag._getAttrMap().keys():\n                    if attr not in acceptable_attributes:\n                        del tag[attr]\n\n        # turn it back to html\n        fragment = unicode(soup)\n\n        if removed:\n            # we removed tags and tricky can could exploit that!\n            # we need to reparse the html until it stops changing\n            continue # next round\n\n        return fragment\n</code>\n</pre>\n", "senID": 1}, {"text": ["Some small tests to make sure this behaves correctly:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n tests = [   #text should work\n            ('&lt;p&gt;this is text&lt;/p&gt;but this too', '&lt;p&gt;this is text&lt;/p&gt;but this too'),\n            # make sure we cant exploit removal of tags\n            ('&lt;&lt;script&gt;&lt;/script&gt;script&gt; alert(\"Haha, I hacked your page.\"); &lt;&lt;script&gt;&lt;/script&gt;/script&gt;', ''),\n            # try the same trick with attributes, gives an Exception\n            ('&lt;div on&lt;script&gt;&lt;/script&gt;load=\"alert(\"Haha, I hacked your page.\");\"&gt;1&lt;/div&gt;',  Exception),\n             # no tags should be skipped\n            ('&lt;script&gt;bad&lt;/script&gt;&lt;script&gt;bad&lt;/script&gt;&lt;script&gt;bad&lt;/script&gt;', ''),\n            # leave valid tags but remove bad attributes\n            ('&lt;a href=\"good\" onload=\"bad\" onclick=\"bad\" alt=\"good\"&gt;1&lt;/div&gt;', '&lt;a href=\"good\" alt=\"good\"&gt;1&lt;/a&gt;'),\n]\n\nfor text, out in tests:\n    try:\n        res = clean_html(text)\n        assert res == out, \"%s =&gt; %s != %s\" % (text, res, out)\n    except out, e:\n        assert isinstance(e, out), \"Wrong exception %r\" % e\n</code>\n</pre>\n", "senID": 3}], [{"text": ["I modified Bryan's solution with BeautifulSoup to address the problem raised by Chris Drost.", "A little crude, but does the job:"], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "Bryan", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/users/73049/bryan"}, {"text": "solution with BeautifulSoup", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter/699483#699483"}, {"text": "problem raised by Chris Drost", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter/812785#812785"}]}, {"code": "<pre>\n<code>\n from BeautifulSoup import BeautifulSoup, Comment\n\nVALID_TAGS = {'strong': [],\n              'em': [],\n              'p': [],\n              'ol': [],\n              'ul': [],\n              'li': [],\n              'br': [],\n              'a': ['href', 'title']\n              }\n\ndef sanitize_html(value, valid_tags=VALID_TAGS):\n    soup = BeautifulSoup(value)\n    comments = soup.findAll(text=lambda text:isinstance(text, Comment))\n    [comment.extract() for comment in comments]\n    # Some markup can be crafted to slip through BeautifulSoup's parser, so\n    # we run this repeatedly until it generates the same output twice.\n    newoutput = soup.renderContents()\n    while 1:\n        oldoutput = newoutput\n        soup = BeautifulSoup(newoutput)\n        for tag in soup.findAll(True):\n            if tag.name not in valid_tags:\n                tag.hidden = True\n            else:\n                tag.attrs = [(attr, value) for attr, value in tag.attrs if attr in valid_tags[tag.name]]\n        newoutput = soup.renderContents()\n        if oldoutput == newoutput:\n            break\n    return newoutput\n</code>\n</pre>\n", "senID": 1}, {"text": ["Edit: Updated to support valid attributes."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "Edit:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}], [{"text": ["I prefer the lxml.html.clean solution, like nosklo points out.", "Here's to also remove some empty tags:"], "childNum": 3, "tag": "p", "senID": 0, "childList": [{"text": "lxml.html.clean", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "nosklo", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/users/17160/nosklo"}, {"text": "points out", "tag": "a", "pos": -1, "childList": [], "childNum": 0, "href": "http://stackoverflow.com/questions/699468/python-html-sanitizer-scrubber-filter/2702587#2702587"}]}, {"code": "<pre>\n<code>\n from lxml import etree\nfrom lxml.html import clean, fromstring, tostring\n\nremove_attrs = ['class']\nremove_tags = ['table', 'tr', 'td']\nnonempty_tags = ['a', 'p', 'span', 'div']\n\ncleaner = clean.Cleaner(remove_tags=remove_tags)\n\ndef squeaky_clean(html):\n    clean_html = cleaner.clean_html(html)\n    # now remove the useless empty tags\n    root = fromstring(clean_html)\n    context = etree.iterwalk(root) # just the end tag event\n    for action, elem in context:\n        clean_text = elem.text and elem.text.strip(' \\t\\r\\n')\n        if elem.tag in nonempty_tags and \\\n        not (len(elem) or clean_text): # no children nor text\n            elem.getparent().remove(elem)\n            continue\n        elem.text = clean_text # if you want\n        # and if you also wanna remove some attrs:\n        for badattr in remove_attrs:\n            if elem.attrib.has_key(badattr):\n                del elem.attrib[badattr]\n    return tostring(root)\n</code>\n</pre>\n", "senID": 1}], [{"text": ["Have you tried with BeautifulSoup?"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "BeautifulSoup", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.crummy.com/software/BeautifulSoup/"}]}]]