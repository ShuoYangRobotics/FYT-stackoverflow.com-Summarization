[[{"text": ["Reading and writing a single character at a time is almost always going to be slow, because disks are block-based devices, rather than character-based devices - it will read a lot more than just the one byte you're after, and the surplus parts need to be discarded."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Try reading and writing more at a time, say, 8192 bytes (8KB) and then finding and adding newlines in that string before writing it out - you should save a lot in performance because a lot less I/O is required."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["As LBushkin points out, your I/O library may be doing buffering, but unless there is some form of documentation that shows this does indeed happen (for reading AND writing), it's a fairly easy thing to try before rewriting in a different language."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["Why don't you just use sed?", "cat giant.xml | sed 's/>/>\\x0a\\x0d/g' > giant-with-linebreaks.xml"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}], [{"text": ["Rather than reading byte by byte, which incurs a disk access for each byte read, try reading ~20 MB at a time and doing your search + replace on that :)"], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["You can probably do this in Notepad...."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Billy3"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["For the type of problem you describe, I suspect the algorithm you employ for comparing the data will have a much more significant effect than the I/O model or language.", "In fact, string allocation and search may be more expensive here than anything else."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Some general suggestions before you write this yourself:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["If are are going to write this in C# (or Java or C/C++), I would do the following:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Additionally, you could also write such a program to run on multiple threads, so that while once thread is perform CRLF insertions in memory, a separate thread is read blocks in from disk.", "This type of parallelization is complicated ... so I would only do so if you really need maximum performance."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Here's a really simple C# program to get you started, if you need it.", "It accepts an input file path and an output path on the command line, and performs the substitution you are looking for ('>' ==> CRLF).", "This sample leaves much to be improved (parallel processing, streaming, some validation, etc)... but it should be a decent start."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"code": "<pre>\n<code>\n using System;\nusing System.IO;\n\nnamespace ExpandBrackets\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            if (args.Length == 2)\n            {\n                using( StreamReader input = new StreamReader( args[0] ) )\n                using( StreamWriter output = new StreamWriter( args[1] ) )\n                {\n                    int readSize = 0;\n                    int blockSize = 100000;\n                    char[] inBuffer = new char[blockSize];\n                    char[] outBuffer = new char[blockSize*3];\n                    while( ( readSize = input.ReadBlock( inBuffer, 0, blockSize ) ) &gt; 0 )\n                    {\n                        int writeSize = TransformBlock( inBuffer, outBuffer, readSize );\n                        output.Write( outBuffer, 0, writeSize );\n                    }\n                }\n            }\n            else\n            {\n                Console.WriteLine( \"Usage:  repchar {inputfile} {outputfile}\" );\n            }\n        }\n\n        private static int TransformBlock( char[] inBuffer, char[] outBuffer, int size )\n        {\n            int j = 0;\n            for( int i = 0; i &lt; size; i++ )\n            {\n                outBuffer[j++] = inBuffer[i];\n                if (inBuffer[i] == '&gt;') // append CR LF\n                {\n                    outBuffer[j++] = '\\r';\n                    outBuffer[j++] = '\\n';\n                }\n            }\n            return j;\n        }\n    }\n}\n</code>\n</pre>\n", "senID": 5}], [{"text": ["All of the languages mentioned typically, at some point, revert to the C runtime library for byte by byte file access.", "Writing this in C will probably be the fastest option."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["However, I doubt it will provide a huge speed boost.", "Python is fairly speedy, if you're doing things correctly."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["The main way to really get a big speed improvement would be to introduce threading.", "If you read the data in from the file in a large block in one thread, and had a separate thread that did your newline processing + diff processing, you could dramatically improve the speed of this algorithm.", "This would probably be easier to implement in C++, C#, or IronPython than in C or CPython directly, since they provide very easy, high-level synchronization tools for handling the threading issues (especially when using .NET)."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}], [{"text": ["you could try xmldiff - http://msdn.microsoft.com/en-us/library/aa302294.aspx "], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://msdn.microsoft.com/en-us/library/aa302294.aspx", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://msdn.microsoft.com/en-us/library/aa302294.aspx"}]}, {"text": ["I haven't used it for such huge data but I think it would be reasonably optimized"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}], [{"text": ["I put this as a comment on another answer, but in case you miss it--you might want to look at The Shootout.", "It's a highly optimized set of code for various problems in many languages."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "The Shootout", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&lang=all&lang2=python&box=1"}]}, {"text": ["According to those results, Python tends to be about 50x slower than c (but it is faster than the other interpreted languages).", "In comparison Java is about 2x slower than c.  If you went to one of the faster compiled languages, I don't see why you wouldn't see a similar increase."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["By the way, the figures attained from the shootout are wonderfully un-assailable, you can't really challenge them, instead if you don't believe the numbers are fair because the code to solve a problem in your favorite language isn't optimized properly, then you can submit better code yourself.", "The act of many people doing this means most of the code on there is pretty damn optimized for every popular language.", "If you show them a more optimized compiler or interpreter, they may include the results from it as well."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Oh: except C#, that's only represented by MONO so if Microsoft's compiler is more optimized, it's not shown.", "All the tests seem to run on Linux machines.", "My guess is Microsoft's C# should run at about the same speed as Java, but the shootout lists mono as a bit slower (about 3x as slow as C).."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}], [{"text": ["As others said, if you do it in C it will be pretty much unbeatable, because C buffers I/O, and getc() is inlined (in my memory)."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["Your real performance issue will be in the diff."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Maybe there's a pretty good one out there, but for those size files I doubt it.", "For fun, I'm a do-it-yourselfer.", "The strategy I would use is to have a rolling window in each file, several megabytes long.", "The search strategy for mismatches is diagonal search, which is if you are at lines i and j, compare in this sequence:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n line(i+0) == line(j+0)\n\nline(i+0) == line(j+1)\nline(i+1) == line(j+0)\n\nline(i+0) == line(j+2)\nline(i+1) == line(j+1)\nline(i+2) == line(j+0)\n</code>\n</pre>\n", "senID": 3}, {"text": ["and so on.", "No doubt there's a better way, but if I'm going to code it myself and manage the rolling windows, that's what I'd try."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}]]