[[{"text": ["Wow, already 6 answers and not a single one actually does what mgj wanted.", "jkp comes close, but then drops the ball by deleting the da\u1e47\u1e0da."], "childNum": 2, "tag": "p", "senID": 0, "childList": [{"text": "mgj", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "jkp", "childNum": 0, "tag": "strong", "pos": 1, "childList": []}]}, {"text": ["Perl to the rescue.", "Less code, fewer bugs."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n use utf8; use strict; use warnings;\nuse Encode qw(decode);\nmy $index;\njoin ' ', map { $index++; \"$_($index)\" } split /\\s+|(?=\u0964)/, decode 'UTF-8', &lt;&gt;;\n# returns \u092d\u093e\u0930\u0924(1) \u0915\u093e(2) \u0907\u0924\u093f\u0939\u093e\u0938(3) \u0915\u093e\u092b\u0940(4) \u0938\u092e\u0926\u0927(5) \u090f\u0935(6) \u0935\u093f\u0938\u0924\u0924(7) \u0939(8) \u0964(9)\n</code>\n</pre>\n", "senID": 2}, {"text": ["edit: changed to read from STDIN as per comment, added best practices pragmas"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "STDIN", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}], [{"text": ["If you are working in C++ and decide that UTF-8 is a viable encoding for your application you could look at utfcpp which is a library that provides many equivalents for types found in the stdlib (such as streams and string processing functions) but abstracts away the difficulties of dealing with a variable length encoding like UTF8."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "utfcpp", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://utfcpp.sourceforge.net/"}]}, {"text": ["If on the other hand you are free to use any language, I would say that doing something like this in something like Python would be far easier: it's unicode support is very good as are the bundled string processing routines."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n #!/usr/bin/env python\n# encoding: utf-8\n\nstring = u\"\u092d\u093e\u0930\u0924 \u0915\u093e \u0907\u0924\u093f\u0939\u093e\u0938 \u0915\u093e\u092b\u0940 \u0938\u092e\u0943\u0926\u094d\u0927 \u090f\u0935\u0902 \u0935\u093f\u0938\u094d\u0924\u0943\u0924 \u0939\u0948\u0964\"\nparts = []\nfor part in string.split():\n    parts.extend(part.split(u\"\u0964\"))\nprint \"No of Parts: %d\" % len(parts)\nprint \"Parts: %s\" % parts\n</code>\n</pre>\n", "senID": 2}, {"text": ["Outputs:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n No of Parts: 9\nParts: [u'\\u092d\\u093e\\u0930\\u0924', u'\\u0915\\u093e', u'\\u0907\\u0924\\u093f\\u0939\\u093e\\u0938', u'\\u0915\\u093e\\u092b\\u0940', u'\\u0938\\u092e\\u0943\\u0926\\u094d\\u0927', u'\\u090f\\u0935\\u0902', u'\\u0935\\u093f\\u0938\\u094d\\u0924\\u0943\\u0924', u'\\u0939\\u0948', u'']\n</code>\n</pre>\n", "senID": 4}, {"text": ["Also, since you are doing natural language processing, you may want to take a look at the NLTK library for Python which has a wealth of tools for just this kind of job."], "childNum": 1, "tag": "p", "senID": 5, "childList": [{"text": "NLTK", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://www.nltk.org/"}]}], [{"text": ["ICU - International Components for Unicode is IBM supported C++ library that is starting to become a standard for handling of characters of all languages.", "I see more and more projects using it.", "It does the job really well.", "Here are the features (copy/pasted from the website):"], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "ICU - International Components for Unicode", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://site.icu-project.org/"}]}, {"tag": "ul", "num": 8, "lis": [{"text": ["Code Page Conversion: Convert text data to or from Unicode and nearly any other character set or encoding.", "ICU's conversion tables are based on charset data collected by IBM over the course of many decades, and is the most complete available anywhere."], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "Code Page Conversion", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Collation: Compare strings according to the conventions and standards of a particular language, region or country.", "ICU's collation is based on the Unicode Collation Algorithm plus locale-specific comparison rules from the Common Locale Data Repository, a comprehensive source for this type of data."], "childNum": 1, "tag": "p", "senID": 2, "childList": [{"text": "Collation", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Formatting: Format numbers, dates, times and currency amounts according the conventions of a chosen locale.", "This includes translating month and day names into the selected language, choosing appropriate abbreviations, ordering fields correctly, etc.", "This data also comes from the Common Locale Data Repository."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "Formatting", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Time Calculations: Multiple types of calendars are provided beyond the traditional Gregorian calendar.", "A thorough set of timezone calculation APIs are provided."], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "Time Calculations", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Unicode Support: ICU closely tracks the Unicode standard, providing easy access to all of the many Unicode character properties, Unicode Normalization, Case Folding and other fundamental operations as specified by the Unicode Standard."], "childNum": 1, "tag": "p", "senID": 5, "childList": [{"text": "Unicode Support", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Regular Expression: ICU's regular expressions fully support Unicode while providing very competitive performance."], "childNum": 1, "tag": "p", "senID": 6, "childList": [{"text": "Regular Expression", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Bidi: support for handling text containing a mixture of left to right (English) and right to left (Arabic or Hebrew) data."], "childNum": 1, "tag": "p", "senID": 7, "childList": [{"text": "Bidi", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Text Boundaries: Locate the positions of words, sentences, paragraphs within a range of text, or identify locations that would be suitable for line wrapping when displaying the text."], "childNum": 1, "tag": "p", "senID": 8, "childList": [{"text": "Text Boundaries", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}]}], [{"text": ["Take a look at http://site.icu-project.org/, a C++ library to process unicode strings."], "childNum": 1, "tag": "p", "senID": 0, "childList": [{"text": "http://site.icu-project.org/", "tag": "a", "pos": 0, "childList": [], "childNum": 0, "href": "http://site.icu-project.org/"}]}], [{"text": ["The easiest way to do the processing is to get your input into a std::wstring (which is logically an array of wchar_t) Now, you still won't have \"characters\" because that concept is a bit more complex in Hindi.", "You will however have substrings seperated by L' ', and the L'\u0964' will also be separate.", "E.g.", "you can call input.find_first_of(L\" \u0964\")"], "childNum": 4, "tag": "p", "senID": 0, "childList": [{"text": "std::wstring", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "wchar_t", "childNum": 0, "tag": "code", "pos": -1, "childList": []}, {"text": "L' '", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "input.find_first_of(L\" \u0964\")", "childNum": 0, "tag": "code", "pos": 3, "childList": []}]}], [{"text": ["The first thing to do is determine whether or not your input is in UNICODE.", "Do this by attempting to read your input as UNICODE and see if the results are garbled."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"code": "<pre>\n<code>\n FILE * fp = _wfopen( L\"fname\",L\"r\" );\nwchar_t buf[1000];\nwhile( fgetws(buf,999, fp ) )   {\n    fwprintf(L\"%s\",buf);\n}\n</code>\n</pre>\n", "senID": 1}, {"text": ["If the output is OK, you have a UNICODE file, if garbled it is UTF-8"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["If you have UTF-8 you will have to convert to Unicode to make processing straightforward."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"code": "<pre>\n<code>\n // convert UTF-8 to UNICODE\n\n    void String2WString( std::wstring&amp; ws, const std::string&amp; s )\n    {\n        ws.clear();\n        int nLenOfWideCharStr = MultiByteToWideChar(CP_ACP, 0, \n            s.c_str(), s.length(), NULL, 0); \n        PWSTR pWideCharStr = (PWSTR)HeapAlloc(GetProcessHeap(), 0, \n            nLenOfWideCharStr * sizeof(wchar_t)+2); \n        if (pWideCharStr == NULL)         \n            return; \n        MultiByteToWideChar(CP_ACP, 0, \n            s.c_str(), s.length(), \n            pWideCharStr, nLenOfWideCharStr);\n        *(pWideCharStr+nLenOfWideCharStr ) = L'\\0';\n        ws = pWideCharStr ;\n        HeapFree(GetProcessHeap(), 0, pWideCharStr); \n\n    }\n\n    // read UTF-8\nFILE * fp = fopen( \"fname\",\"r\" );\nchar buf[1000];\nstd::string aline;\nstd::wstring wline;\nstd::vector&lt; std::wstring&gt; vline;\nwhile( fgets(buf,999, fp ) )    {\n    aline = buf;\n    String2WString( wline, aline );\n    vline.push_back( wline );\n}\n</code>\n</pre>\n", "senID": 4}, {"text": ["The above assumes that you are on Windows.", "On Unix, the same idea applies and the code is quite similar.", "However, I do not find it quite so straightforward, so I will let a UNIX expert provide the details."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}], [{"text": ["I would seriously suggest that you'd use Python for an applicatin like this.", "It will lift the burden of decoding the strigns (not to mention allocating memory for them and the like).", "You will be free to concentrate on your problem, instead of problems of the language."], "childNum": 0, "tag": "p", "senID": 0, "childList": []}, {"text": ["For example, if the sentence above is contained in an utf-8 file, and you are uisng python2.x.", "If you use python 3.x it is even more readible, as you don't have to prefix the unicode strings with 'u\" ', as in this example (but you will be missing a lot of 3rd party libraries:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n separators = [u\"\u0964\", u\",\", u\".\"]\ntext = open(\"indiantext.txt\").read()\n#This converts the encoded text to an internal unicode object, where\n# all characters are properly recognized as an entity:\ntext = text.decode(\"utf-8\")\n\n#this breaks the text on the white spaces, yielding a list of words:\nwords = text.split()\n\ncounter = 1\n\noutput = \"\"\nfor word in words:\n    #if the last char is a separator, and is joined to the word:\n    if word[-1] in separators and len(word) &gt; 1:\n        #word up to the second to last char:\n        output += word[:-1] + u\"(%d) \" % counter\n        counter += 1\n        #last char\n        output += word[-1] +  u\"(%d) \" % counter\n    else:\n        output += word + u\"(%d) \" % counter\n    counter += 1\n\nprint output\n</code>\n</pre>\n", "senID": 2}, {"text": ["This is an \"unfolded\" example, As you get more used to Python there are shorer ways to express this.", "You can learn the basics of teh language in just a couple of hours, following a tutorial.", "(for example, the one at http://python.org itself)"], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "http://python.org", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://python.org"}]}]]