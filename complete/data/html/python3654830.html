<h3>Question (ID-3654830):</h3><h2>Why there are no ++ and -- operators in Python?</h2><p>Why there are no <code>++</code> and <code>--</code> operators in Python?</p>
<br /><h3>Answers (Total-9):</h3><b>#0</b><br /><p>It's not because it doesn't make sense; it makes perfect sense to define "x++" as "x += 1, evaluating to the previous binding of x".</p>

<p>If you want to know the original reason, you'll have to either wade through old Python mailing lists or ask somebody who was there (eg. Guido), but it's easy enough to justify after the fact:</p>

<p>Simple increment and decrement aren't needed as much as in other languages.  You don't write things like <code>for(int i = 0; i &lt; 10; ++i)</code> in Python very often; instead you do things like <code>for i in range(0, 10)</code>.</p>

<p>Since it's not needed nearly as often, there's much less reason to give it its own special syntax; when you do need to increment, <code>+=</code> is usually just fine.</p>

<p>It's not a decision of whether it makes sense, or whether it can be done--it does, and it can.  It's a question of whether the benefit is worth adding to the core syntax of the language.  Remember, this is <em>four</em> operators--postinc, postdec, preinc, predec, and each of these would need to have its own class overloads; they all need to be specified, and tested; it would add opcodes to the language (implying a larger, and therefore slower, VM engine); every class that supports a logical increment would need to implement them (on top of <code>+=</code> and <code>-=</code>).</p>

<p>This is all redundant with <code>+=</code> and <code>-=</code>, so it would become a net loss.</p>
<br /><b>#1</b><br /><p>The C increment/decrement operators were invented at a time when the C compiler wasn't very smart and the authors wanted to be able to specify the direct intent that a machine language operator should be used which saved a handful of cycles for a compiler which might do a </p>

<pre><code>load memory
load 1
add
store memory
</code></pre>

<p>instead of </p>

<pre><code>inc memory 
</code></pre>

<p>and the PDP-11 even supported "autoincrement" and "autoincrement deferred" instructions corresponding to <code>*++p</code> and <code>*p++</code>, respectively. See section 5.3 of <a href="http://computer-refuge.org/bitsavers/pdf/dec/pdp11/rsx11/RSX11M_V2/DEC-11-OIMRA-A-D_MACRO_75.pdf" rel="nofollow">the manual</a> if horribly curious.</p>

<p>As compilers are smart enough to handle the high-level optimization tricks built into the syntax of C, they are just a syntactic convenience now. </p>

<p>Python doesn't have tricks to convey intentions to the assembler because it doesn't use one.</p>
<br /><b>#2</b><br /><p>It was just designed that way.  Increment and decrement operators are just shortcuts for <code>x = x + 1</code>.  Python has typically adopted a design strategy which reduces the number of alternative means of performing an operation.  <a href="http://www.python.org/download/releases/2.0/new-python.htm#SECTION000700000000000000000" rel="nofollow">Augmented assignment</a> is the closest thing to increment/decrement operators in Python, and they weren't even added until Python 2.0.</p>
<br /><b>#3</b><br /><p>I'm very new to python but I suspect the reason is because of the emphasis between mutable and immutable objects within the language.  Now, I know that x++ can easily be interpreted as x = x + 1, but it LOOKS like you're incrementing <em>in-place</em> an object which could be immutable.</p>

<p>Just my guess/feeling/hunch.</p>
<br /><b>#4</b><br /><p>Of course, we could say "Guido just decided that way", but I think the question is really about the reasons for that decision. I think there are several reasons:</p>

<ul>
<li>It mixes together statements and expressions, which is not good practice. See <a href="http://norvig.com/python-iaq.html" rel="nofollow">http://norvig.com/python-iaq.html</a></li>
<li>It generally encourages people to write less readable code</li>
<li>Extra complexity in the language implementation, which is unnecessary in Python, as already mentioned</li>
</ul>
<br /><b>#5</b><br /><p>I always assumed it had to do with this line of the zen of python:</p>

<pre><code>There should be one-- and preferably only one --obvious way to do it.
</code></pre>

<p>x++ and x+=1 do the exact same thing, so there is no reason to have both. </p>
<br /><b>#6</b><br /><p>Because, in Python, integers are immutable (int's += actually returns a different object).</p>

<p>Also, with ++/-- you need to worry about pre- versus post- increment/decrement, and it takes only one more keystroke to write <code>x+=1</code>.  In other words, it avoids potential confusion at the expense of very little gain.</p>
<br /><b>#7</b><br /><p>Maybe a better question would be to ask why do these operators exist in C. K&amp;R calls increment and decrement operators 'unusual' (Section 2.8page 46). The Introduction calls them 'more concise and often more efficient'. I suspect that the fact that these operations always come up in pointer manipulation also has played a part in their introduction.
In Python it has been probably decided that it made no sense to try to optimise increments (in fact I just did a test in C, and it seems that the gcc-generated assembly uses addl instead of incl in both cases) and there is no pointer arithmetic; so it would have been just One More Way to Do It and we know Python loathes that.</p>
<br /><b>#8</b><br /><p>I believe it stems from the Python creed that "explicit is better than implicit".</p>
<br />