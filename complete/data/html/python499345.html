<h3>Question (ID-499345):</h3><h2>Regular expression to extract URL from an HTML link</h2><p>I’m a newbie in Python. I’m learning regexes, but I need help here.</p>

<p>Here comes the HTML source:</p>

<pre><code>&lt;a href="http://www.ptop.se" target="_blank"&gt;http://www.ptop.se&lt;/a&gt;
</code></pre>

<p>I’m trying to code a tool that only prints out <code>http://ptop.se</code>. Can you help me please?</p>
<br /><h3>Answers (Total-8):</h3><b>#0</b><br /><p>If you're only looking for one:</p>

<pre><code>import re
match = re.search(r'href=[\'"]?([^\'" &gt;]+)', s)
if match:
    print match.group(0)
</code></pre>

<p>If you have a long string, and want every instance of the pattern in it:</p>

<pre><code>import re
urls = re.findall(r'href=[\'"]?([^\'" &gt;]+)', s)
print ', '.join(urls)
</code></pre>

<p>Where <code>s</code> is the string that you're looking for matches in.</p>

<p><em>Quick explanation of the regexp bits:</em></p>

<blockquote>
  <p><code>r'...'</code> is a "raw" string. It stops you having to worry about escaping characters quite as much as you normally would. (<code>\</code> especially -- in a raw string a <code>\</code> is just a <code>\</code>.  In a regular string you'd have to do <code>\\</code> every time, and that gets <em>old</em> in regexps.)</p>
  
  <p>"<code>href=[\'"]?</code>" says to match "href=", possibly followed by a <code>'</code> or <code>"</code>.  "Possibly" because it's hard to say how horrible the HTML you're looking at is, and the quotes aren't strictly required.</p>
  
  <p>Enclosing the next bit in "<code>()</code>" says to make it a "group", which means to split it out and return it separately to us. It's just a way to say "this is the part of the pattern I'm interested in."</p>
  
  <p>"<code>[^\'" &gt;]+</code>" says to match any characters that <em>aren't</em> <code>'</code>, <code>"</code>, <code>&gt;</code>, or a space. Essentially this is a list of characters that are an end to the URL. It lets us avoid trying to write a regexp that reliably matches a full URL, which can be a bit complicated.</p>
</blockquote>

<p>The suggestion in another answer to use BeautifulSoup isn't bad, but it does introduce a higher level of external requirements. Plus it doesn't help you in your stated goal of learning regexps, which I'd assume this specific html-parsing project is just a part of.</p>

<p>It's pretty easy to do:</p>

<pre><code>from BeautifulSoup import BeautifulSoup
soup = BeautifulSoup(html_to_parse)
for tag in soup.findAll('a', href=True):
    print tag['href']
</code></pre>

<p>Once you've installed BeautifulSoup, anyway.</p>
<br /><b>#1</b><br /><p>Don't use regexes, use <a href="http://www.crummy.com/software/BeautifulSoup/" rel="nofollow">BeautifulSoup</a>. That, or be so crufty as to spawn it out to, say, w3m/lynx and pull back in what w3m/lynx renders. First is more elegant probably, second just worked a heck of a lot faster on some unoptimized code I wrote a while back.</p>
<br /><b>#2</b><br /><p>John Gruber (who wrote Markdown, which is made of regular expressions and is used right here on Stack Overflow) had a go at producing a regular expression that recognises URLs in text:</p>

<p><a href="http://daringfireball.net/2009/11/liberal%5Fregex%5Ffor%5Fmatching%5Furls" rel="nofollow">http://daringfireball.net/2009/11/liberal_regex_for_matching_urls</a></p>

<p>If you just want to grab the URL (i.e. you’re not really trying to parse the HTML), this might be more lightweight than an HTML parser.</p>
<br /><b>#3</b><br /><p>Regexes are fundamentally bad at parsing HTML (see <a href="http://stackoverflow.com/questions/701166">Can you provide some examples of why it is hard to parse XML and HTML with a regex?</a> for why).  What you need is an HTML parser.  See <a href="http://stackoverflow.com/questions/773340">Can you provide an example of parsing HTML with your favorite parser?</a> for examples using a variety of parsers.</p>

<p>In particular you will want to look at the Python answers: <a href="http://stackoverflow.com/questions/773340/can-you-provide-an-example-of-parsing-html-with-your-favorite-parser/773565#773565">BeautifulSoup</a>, <a href="http://stackoverflow.com/questions/773340/can-you-provide-an-example-of-parsing-html-with-your-favorite-parser/773344#773344">HTMLParser</a>, and <a href="http://stackoverflow.com/questions/773340/can-you-provide-an-example-of-parsing-html-with-your-favorite-parser/774062#774062">lxml</a>.</p>
<br /><b>#4</b><br /><p>There's tonnes of them on <a href="http://regexlib.com/default.aspx" rel="nofollow">regexlib</a></p>
<br /><b>#5</b><br /><p>Yes, there are tons of them on <a href="http://regexlib.com/" rel="nofollow">regexlib</a>. That only proves that RE's should not be used to do that. Use SGMLParser or BeautifulSoup or write a parser - but don't use RE's. The ones that seems to work are extremely compliated and still don't cover all cases.</p>
<br /><b>#6</b><br /><p>this should work, although there might be more elegant ways.</p>

<pre><code>import re
url='&lt;a href="http://www.ptop.se" target="_blank"&gt;http://www.ptop.se&lt;/a&gt;'
r = re.compile('(?&lt;=href=").*?(?=")')
r.findall(url)
</code></pre>
<br /><b>#7</b><br /><p>This improved version should work as reliably as a parser.</p>

<pre><code>   // Applies to URI, not just URL or URN:
   //    http://en.wikipedia.org/wiki/Uniform_Resource_Identifier#Relationship_to_URL_and_URN
   //
   // http://labs.apache.org/webarch/uri/rfc/rfc3986.html#regexp
   //
   // (?:([^:/?#]+):)?(?://([^/?#]*))?([^?#]*)(?:\?([^#]*))?(?:#(.*))?
   //
   // http://en.wikipedia.org/wiki/URI_scheme#Generic_syntax
   //
   // $@ matches the entire uri
   // $1 matches scheme (ftp, http, mailto, mshelp, ymsgr, etc)
   // $2 matches authority (host, user:pwd@host, etc)
   // $3 matches path
   // $4 matches query (http GET REST api, etc)
   // $5 matches fragment (html anchor, etc)
   //
   // Match specific schemes, non-optional authority, disallow white-space so can delimit in text, and allow 'www.' w/o scheme
   // Note the schemes must match ^[^\s|:/?#]+(?:\|[^\s|:/?#]+)*$
   //
   // (?:()(www\.[^\s/?#]+\.[^\s/?#]+)|(schemes)://([^\s/?#]*))([^\s?#]*)(?:\?([^\s#]*))?(#(\S*))?
   //
   // Validate the authority with an orthogonal RegExp, so the RegExp above won’t fail to match any valid urls.
   function uriRegExp( flags, schemes/* = null*/, noSubMatches/* = false*/ )
   {
      if( !schemes )
         schemes = '[^\\s:\/?#]+'
      else if( !RegExp( /^[^\s|:\/?#]+(?:\|[^\s|:\/?#]+)*$/ ).test( schemes ) )
         throw TypeError( 'expected URI schemes' )
      return noSubMatches ? new RegExp( '(?:www\\.[^\\s/?#]+\\.[^\\s/?#]+|' + schemes + '://[^\\s/?#]*)[^\\s?#]*(?:\\?[^\\s#]*)?(?:#\\S*)?', flags ) :
         new RegExp( '(?:()(www\\.[^\\s/?#]+\\.[^\\s/?#]+)|(' + schemes + ')://([^\\s/?#]*))([^\\s?#]*)(?:\\?([^\\s#]*))?(?:#(\\S*))?', flags )
   }

   // http://en.wikipedia.org/wiki/URI_scheme#Official_IANA-registered_schemes
   function uriSchemesRegExp()
   {
      return 'about|callto|ftp|gtalk|http|https|irc|ircs|javascript|mailto|mshelp|sftp|ssh|steam|tel|view-source|ymsgr'
   }
</code></pre>
<br />