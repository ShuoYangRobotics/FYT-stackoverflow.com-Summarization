<h3>Question (ID-5435367):</h3><h2>Best matches for a partially specified word in Python</h2><p>I have a file dict.txt that has all words in the English language.</p>

<p>The user will input their word:</p>

<p><code>x = raw_input("Enter partial word: ")</code></p>

<p>Example inputs would be: r-n, --n, -u-, he--o, h-llo and so on, unknown characters would be specified by a underscore preferably instead of (-).</p>

<p>I want the program to come up with a list, of all the best matches that are found in the dictionary.</p>

<p>Example: If partial word was r--, the list would contain run, ran, rat, rob and so on.</p>

<p>Is there any way to do this using for loops?</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>One easy way to do this would be by using <a href="http://docs.python.org/library/re.html" rel="nofollow">regular expressions</a>. Since it is unclear whether this question is homework, the details are left as an exercise for the reader.</p>
<br /><b>#1</b><br /><p>Instead of using _ to denote wildcards, use \w instead. Add \b to the beginning and end of the pattern, then just run the dictionary through a regexp matcher. So -un--- becomes:</p>

<pre><code>&gt;&gt;&gt; import re
&gt;&gt;&gt; re.findall(r'\b\wun\w\w\w\b', "run runner bunt bunter bunted bummer")
['runner', 'bunter', 'bunted']
</code></pre>

<p>\w matches any 'word character'. \b matches any word boundary.</p>
<br /><b>#2</b><br /><p>If you want to do this repeatedly you should create a index:</p>

<pre><code>wordlist = [word.strip() for word in "run, ran, rat, rob, fish, tree".split(',')]

from collections import defaultdict

class Index(object):

    def __init__(self, wordlist=()):
        self.trie = defaultdict(set)
        for word in wordlist:
            self.add_word(word)

    def add_word(self, word):
        """ adds word to the index """
        # save the length of the word
        self.trie[len(word)].add(word)    
        for marker in enumerate(word):
            # add word to the set of words with (pos,char)
            self.trie[marker].add(word)


    def find(self, pattern, wildcard='-' ):
        # get all word with matching length as candidates
        candidates = self.trie[len(pattern)]

        # get all words with all the markers
        for marker in enumerate(pattern):            
            if marker[1] != wildcard:
                candidates &amp;= self.trie[marker]

            # exit early if there are no candicates
            if not candidates:                
                return None

        return candidates


with open('dict.txt', 'rt') as lines:
    wordlist = [word.strip() for word in lines]

s = Index(wordlist)
print s.find("r--")
</code></pre>

<p><a href="http://en.wikipedia.org/wiki/Trie" rel="nofollow">Tries</a> are made for searching strings. This is a simple prefix trie, using a single dict.</p>
<br /><b>#3</b><br /><p>A few approaches occur to me;</p>

<p>The first is to preprocess your dictionary into words[wordlength][offset][charAtOffset] = set(matching words); then your query becomes an intersection of all relevant word-sets. Very fast, but memory-intensive and a lot of set-up work.</p>

<p>Ex:</p>

<pre><code># search for 'r-n'
matches = list(words[3][0]['r'] &amp; words[3][2]['n'])
</code></pre>

<p>The second is a linear scan of the dictionary using regular expressions; much slower, but minimal memory footprint.</p>

<p>Ex:</p>

<pre><code>import re

foundMatch = re.compile('r.n').match
matches = [word for word in allWords if foundMatch(word)]
</code></pre>

<p>Third would be a recursive search into a word-Trie;</p>

<p>Fourth - and it sounds like what you want - is a naive word-matcher:</p>

<pre><code>with open('dictionary.txt') as inf:
    all_words = [word.strip().lower() for word in inf]  # one word per line

find_word = 'r-tt-r'
matching_words = []
for word in all_words:
    if len(word)==len(find_word):
        if all(find==ch or find=='-' for find,ch in zip(find_word, word)):
            matching_words.append(word)
</code></pre>

<p><strong>Edit</strong>: full code for the first option follows:</p>

<pre><code>from collections import defaultdict
import operator

try:
    inp = raw_input    # Python 2.x
except NameError:
    inp = input        # Python 3.x

class Words(object):
    @classmethod
    def fromFile(cls, fname):
        with open(fname) as inf:
            return cls(inf)

    def __init__(self, words=None):
        super(Words,self).__init__()
        self.words = set()
        self.index = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))
        _addword = self.addWord
        for word in words:
            _addword(word.strip().lower())

    def addWord(self, word):
        self.words.add(word)
        _ind = self.index[len(word)]
        for ind,ch in enumerate(word):
            _ind[ind][ch].add(word)

    def findAll(self, pattern):
        pattern = pattern.strip().lower()
        _ind = self.index[len(pattern)]
        return reduce(operator.__and__, (_ind[ind][ch] for ind,ch in enumerate(pattern) if ch!='-'), self.words)

def main():
    print('Loading dict... ')
    words = Words.fromFile('dict.txt')
    print('done.')

    while True:
        seek = inp('Enter partial word ("-" is wildcard, nothing to exit): ').strip()
        if seek:
            print("Matching words: "+' '.join(words.findAll(seek))+'\n')
        else:
            break

if __name__=="__main__":
    main()
</code></pre>
<br /><b>#4</b><br /><p>Sounds like homework involving searching algorithms or something, but I'll give you a start.</p>

<p>One solution might be to index the file (if this can be done in a reasonable time) into a tree structure with  each character representing a node value and each child being all subsequent characters.  You could then traverse the tree using the input as a map.  A character represents the next node to go to and a dash represents that it should include all child nodes.  Every time you hit a leaf n levels deeps with n being the length of the input you know you've found a match.</p>

<p>The nice thing is that once you index, your search will speed up considerably.  It's the indexing that can take forever...</p>
<br /><b>#5</b><br /><p>Takes a bit of memory but this does the trick:</p>

<pre><code>import re
import sys

word = '\\b' + sys.argv[1].replace('-', '\\w') + '\\b'
print word

with open('data.txt', 'r') as fh:
    print re.findall(word, fh.read())
</code></pre>
<br />