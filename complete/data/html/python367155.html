<h3>Question (ID-367155):</h3><h2>Splitting a string into words and punctuation</h2><p>I'm trying to split a string up into words and punctuation, adding the punctuation to the list produced by the split.</p>

<p>For instance:</p>

<pre><code>&gt;&gt;&gt; c = "help, me"
&gt;&gt;&gt; print c.split()
['help,', 'me']
</code></pre>

<p>What I really want the list to look like is:</p>

<pre><code>['help', ',', 'me']
</code></pre>

<p>So, I want the string split at whitespace with the punctuation split from the words.</p>

<p>I've tried to parse the string first and then run the split:</p>

<pre><code>&gt;&gt;&gt; for character in c:
...     if character in ".,;!?":
...             outputCharacter = " %s" % character
...     else:
...             outputCharacter = character
...     separatedPunctuation += outputCharacter
&gt;&gt;&gt; print separatedPunctuation
help , me
&gt;&gt;&gt; print separatedPunctuation.split()
['help', ',', 'me']
</code></pre>

<p>This produces the result I want, but is painfully slow on large files.</p>

<p>Is there a way to do this more efficiently?</p>
<br /><h3>Answers (Total-8):</h3><b>#0</b><br /><p>This is more or less the way to do it:</p>

<pre><code>&gt;&gt;&gt; import re
&gt;&gt;&gt; re.findall(r"[\w']+|[.,!?;]", "Hello, I'm a string!")
['Hello', ',', "I'm", 'a', 'string', '!']
</code></pre>

<p>The trick is, not to think about where to split the string, but what to include in the tokens.</p>

<p>Caveats:</p>

<ul>
<li>The underscore (_) is considered an inner-word character. Replace \w, if you don't want that.</li>
<li>This will not work with (single) quotes in the string.</li>
<li>Put any additional punctuation marks you want to use in the right half of the regular expression.</li>
<li>Anything not explicitely mentioned in the re is silently dropped.</li>
</ul>
<br /><b>#1</b><br /><p>Here's my entry.</p>

<p>I have my doubts as to how well this will hold up in the sense of efficiency, or if it catches all cases (note the "!!!" grouped together; this may or may not be a good thing).</p>

<pre><code>&gt;&gt;&gt; import re
&gt;&gt;&gt; import string
&gt;&gt;&gt; s = "Helo, my name is Joe! and i live!!! in a button; factory:"
&gt;&gt;&gt; l = [item for item in map(string.strip, re.split("(\W+)", s)) if len(item) &gt; 0]
&gt;&gt;&gt; l
['Helo', ',', 'my', 'name', 'is', 'Joe', '!', 'and', 'i', 'live', '!!!', 'in', 'a', 'button', ';', 'factory', ':']
&gt;&gt;&gt;
</code></pre>

<p>One obvious optimization would be to compile the regex before hand (using re.compile) if you're going to be doing this on a line-by-line basis. </p>
<br /><b>#2</b><br /><p>Have you tried using a regex?</p>

<p><a href="http://docs.python.org/library/re.html#re-syntax" rel="nofollow">http://docs.python.org/library/re.html#re-syntax</a></p>

<p><hr /></p>

<p>By the way. Why do you need the "," at the second one? You will know that after each text is written i.e. </p>

<p>[0]</p>

<p>","</p>

<p>[1]</p>

<p>","</p>

<p>So if you want to add the "," you can just do it after each iteration when you use the array..</p>
<br /><b>#3</b><br /><p>Thanks Filip, I'll look into the regex library.</p>

<p>On the second point, maybe I should have used a better example.</p>

<p>If I had the string:</p>

<pre><code>d = "Hello, I'm a string!"
</code></pre>

<p>I'd want the output:</p>

<pre><code>['Hello', ',', 'I'm', 'a', 'string', "!"]
</code></pre>

<p>So, I want to separate all different sorts of punctuation from the alphanumerics, splitting at the whitespace.</p>
<br /><b>#4</b><br /><p>In perl-style regular expression syntax, <code>\b</code> matches a word boundary.  This should come in handy for doing a regex-based split.</p>

<p><em>edit:</em> I have been informed by hop that "empty matches" do not work in the split function of Python's re module.  I will leave this here as information for anyone else getting stumped by this "feature".</p>
<br /><b>#5</b><br /><p>I think you can find all the help you can imagine in the <a href="http://nltk.org" rel="nofollow">NLTK</a>, especially since you are using python. There's a good comprehensive discussion of this issue in the tutorial.</p>
<br /><b>#6</b><br /><p>Here's a minor update to your implementation.  If your trying to doing anything more detailed I suggest looking into the NLTK that le dorfier suggested.</p>

<p>This might only be a little faster since ''.join() is used in place of +=, which is <a href="http://www.skymind.com/~ocrow/python_string/" rel="nofollow">known to be faster</a>.</p>

<pre><code>import string

d = "Hello, I'm a string!"

result = []
word = ''

for char in d:
    if char not in string.whitespace:
        if char not in string.ascii_letters + "'":
            if word:
                    result.append(word)
            result.append(char)
            word = ''
        else:
            word = ''.join([word,char])

    else:
        if word:
            result.append(word)
            word = ''
print result
['Hello', ',', "I'm", 'a', 'string', '!']
</code></pre>
<br /><b>#7</b><br /><p>Here is a Unicode-aware version:</p>

<pre><code>re.findall(r"\w+|[^\w\s]", text, re.UNICODE)
</code></pre>

<p>The first alternative catches sequences of word characters (as defined by unicode, so "résumé" won't turn into <code>['r', 'sum']</code>); the second catches individual non-word characters, ignoring whitespace.</p>

<p>Note that, unlike the top answer, this treats the single quote as separate punctuation (e.g. "I'm" -> <code>['I', "'", 'm']</code>). This appears to be standard in NLP, so I consider it a feature.</p>
<br />