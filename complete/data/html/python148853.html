<h3>Question (ID-148853):</h3><h2>Caching in urllib2?</h2><p>Is there an easy way to cache things when using urllib2 that I am over-looking, or do I have to roll my own?</p>
<br /><h3>Answers (Total-7):</h3><b>#0</b><br /><p>This ActiveState Python recipe might be helpful:
<a href="http://code.activestate.com/recipes/491261/" rel="nofollow">http://code.activestate.com/recipes/491261/</a></p>
<br /><b>#1</b><br /><p>If you don't mind working at a slightly lower level, httplib2 (<a href="http://code.google.com/p/httplib2/" rel="nofollow">http://code.google.com/p/httplib2/</a>) is an excellent HTTP library that includes caching functionality.</p>
<br /><b>#2</b><br /><p>You could use a decorator function such as:</p>

<pre><code>class cache(object):
    def __init__(self, fun):
        self.fun = fun
        self.cache = {}

    def __call__(self, *args, **kwargs):
        key  = str(args) + str(kwargs)
        try:
            return self.cache[key]
        except KeyError:
            self.cache[key] = rval = self.fun(*args, **kwargs)
            return rval
        except TypeError: # incase key isn't a valid key - don't cache
            return self.fun(*args, **kwargs)
</code></pre>

<p>and define a function along the lines of:</p>

<pre><code>@cache
def get_url_src(url):
    return urllib.urlopen(url).read()
</code></pre>

<p>This is assuming you're not paying attention to HTTP Cache Controls, but just want to cache the page for the duration of the application</p>
<br /><b>#3</b><br /><p>I've always been torn between using httplib2, which does a solid job of handling HTTP caching and authentication, and urllib2, which is in the stdlib, has an extensible interface, and supports HTTP Proxy servers.</p>

<p>The <a href="http://code.activestate.com/recipes/491261/" rel="nofollow">ActiveState recipe</a> starts to add caching support to urllib2, but only in a very primitive fashion. It fails to allow for extensibility in storage mechanisms, hard-coding the file-system-backed storage. It also does not honor HTTP cache headers.</p>

<p>In an attempt to bring together the best features of httplib2 caching and urllib2 extensibility, I've adapted the ActiveState recipe to implement most of the same caching functionality as is found in httplib2. The module is in jaraco.net as <a href="http://bitbucket.org/jaraco/jaraco.net/src/65af6e442d21/jaraco/net/http/caching.py" rel="nofollow">jaraco.net.http.caching</a>. The link points to the module as it exists at the time of this writing. While that module is currently part of the larger jaraco.net package, it has no intra-package dependencies, so feel free to pull the module out and use it in your own projects.</p>

<p>Alternatively, if you have Python 2.6 or later, you can <code>easy_install jaraco.net&gt;=1.3</code> and then utilize the CachingHandler with something like the code in <code>caching.quick_test()</code>.</p>

<pre><code>"""Quick test/example of CacheHandler"""
import logging
import urllib2
from httplib2 import FileCache
from jaraco.net.http.caching import CacheHandler

logging.basicConfig(level=logging.DEBUG)
store = FileCache(".cache")
opener = urllib2.build_opener(CacheHandler(store))
urllib2.install_opener(opener)
response = opener.open("http://www.google.com/")
print response.headers
print "Response:", response.read()[:100], '...\n'

response.reload(store)
print response.headers
print "After reload:", response.read()[:100], '...\n'
</code></pre>

<p>Note that jaraco.util.http.caching does not provide a specification for the backing store for the cache, but instead follows the interface used by httplib2. For this reason, the httplib2.FileCache can be used directly with urllib2 and the CacheHandler. Also, other backing caches designed for httplib2 should be usable by the CacheHandler.</p>
<br /><b>#4</b><br /><p>I was looking for something similar, and came across <a href="http://code.activestate.com/recipes/491261/" rel="nofollow">"Recipe 491261: Caching and throttling for urllib2"</a> which danivo posted. The problem is I <em>really</em> dislike the caching code (lots of duplication, lots of manually joining of file paths instead of using os.path.join, uses staticmethods, non very PEP8'sih, and other things that I try to avoid)</p>

<p>The code is a bit nicer (in my opinion anyway) and is functionally much the same, with a few additions - mainly the "recache" method (example usage <a href="http://github.com/dbr/tvdb%5Fapi/blob/f72c4ad3e53a934c4bade21876b4f7185b645866/tvdb%5Fapi.py#L412-453" rel="nofollow">can be seem here</a>, or in the <code>if __name__ == "__main__":</code> section at the end of the code).</p>

<p>The latest version can be found at <a href="http://github.com/dbr/tvdb_api/blob/master/cache.py" rel="nofollow">http://github.com/dbr/tvdb_api/blob/master/cache.py</a>, and I'll paste it here for posterity (with my application specific headers removed):</p>

<pre><code>#!/usr/bin/env python
"""
urllib2 caching handler
Modified from http://code.activestate.com/recipes/491261/ by dbr
"""

import os
import time
import httplib
import urllib2
import StringIO
from hashlib import md5

def calculate_cache_path(cache_location, url):
    """Checks if [cache_location]/[hash_of_url].headers and .body exist
    """
    thumb = md5(url).hexdigest()
    header = os.path.join(cache_location, thumb + ".headers")
    body = os.path.join(cache_location, thumb + ".body")
    return header, body

def check_cache_time(path, max_age):
    """Checks if a file has been created/modified in the [last max_age] seconds.
    False means the file is too old (or doesn't exist), True means it is
    up-to-date and valid"""
    if not os.path.isfile(path):
        return False
    cache_modified_time = os.stat(path).st_mtime
    time_now = time.time()
    if cache_modified_time &lt; time_now - max_age:
        # Cache is old
        return False
    else:
        return True

def exists_in_cache(cache_location, url, max_age):
    """Returns if header AND body cache file exist (and are up-to-date)"""
    hpath, bpath = calculate_cache_path(cache_location, url)
    if os.path.exists(hpath) and os.path.exists(bpath):
        return(
            check_cache_time(hpath, max_age)
            and check_cache_time(bpath, max_age)
        )
    else:
        # File does not exist
        return False

def store_in_cache(cache_location, url, response):
    """Tries to store response in cache."""
    hpath, bpath = calculate_cache_path(cache_location, url)
    try:
        outf = open(hpath, "w")
        headers = str(response.info())
        outf.write(headers)
        outf.close()

        outf = open(bpath, "w")
        outf.write(response.read())
        outf.close()
    except IOError:
        return True
    else:
        return False

class CacheHandler(urllib2.BaseHandler):
    """Stores responses in a persistant on-disk cache.

    If a subsequent GET request is made for the same URL, the stored
    response is returned, saving time, resources and bandwidth
    """
    def __init__(self, cache_location, max_age = 21600):
        """The location of the cache directory"""
        self.max_age = max_age
        self.cache_location = cache_location
        if not os.path.exists(self.cache_location):
            os.mkdir(self.cache_location)

    def default_open(self, request):
        """Handles GET requests, if the response is cached it returns it
        """
        if request.get_method() is not "GET":
            return None # let the next handler try to handle the request

        if exists_in_cache(
            self.cache_location, request.get_full_url(), self.max_age
        ):
            return CachedResponse(
                self.cache_location,
                request.get_full_url(),
                set_cache_header = True
            )
        else:
            return None

    def http_response(self, request, response):
        """Gets a HTTP response, if it was a GET request and the status code
        starts with 2 (200 OK etc) it caches it and returns a CachedResponse
        """
        if (request.get_method() == "GET"
            and str(response.code).startswith("2")
        ):
            if 'x-local-cache' not in response.info():
                # Response is not cached
                set_cache_header = store_in_cache(
                    self.cache_location,
                    request.get_full_url(),
                    response
                )
            else:
                set_cache_header = True
            #end if x-cache in response

            return CachedResponse(
                self.cache_location,
                request.get_full_url(),
                set_cache_header = set_cache_header
            )
        else:
            return response

class CachedResponse(StringIO.StringIO):
    """An urllib2.response-like object for cached responses.

    To determine if a response is cached or coming directly from
    the network, check the x-local-cache header rather than the object type.
    """
    def __init__(self, cache_location, url, set_cache_header=True):
        self.cache_location = cache_location
        hpath, bpath = calculate_cache_path(cache_location, url)

        StringIO.StringIO.__init__(self, file(bpath).read())

        self.url     = url
        self.code    = 200
        self.msg     = "OK"
        headerbuf = file(hpath).read()
        if set_cache_header:
            headerbuf += "x-local-cache: %s\r\n" % (bpath)
        self.headers = httplib.HTTPMessage(StringIO.StringIO(headerbuf))

    def info(self):
        """Returns headers
        """
        return self.headers

    def geturl(self):
        """Returns original URL
        """
        return self.url

    def recache(self):
        new_request = urllib2.urlopen(self.url)
        set_cache_header = store_in_cache(
            self.cache_location,
            new_request.url,
            new_request
        )
        CachedResponse.__init__(self, self.cache_location, self.url, True)


if __name__ == "__main__":
    def main():
        """Quick test/example of CacheHandler"""
        opener = urllib2.build_opener(CacheHandler("/tmp/"))
        response = opener.open("http://google.com")
        print response.headers
        print "Response:", response.read()

        response.recache()
        print response.headers
        print "After recache:", response.read()
    main()
</code></pre>
<br /><b>#5</b><br /><p>This article on Yahoo Developer Network - <a href="http://developer.yahoo.com/python/python-caching.html" rel="nofollow">http://developer.yahoo.com/python/python-caching.html</a> - describes how to cache http calls made through urllib to either memory or disk.</p>
<br /><b>#6</b><br /><p>@dbr: you may need to add also https responses caching with :
    def https_response(self, request, response):
        return self.http_response(request,response)</p>
<br />