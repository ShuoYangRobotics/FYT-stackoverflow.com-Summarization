<h3>Question (ID-2239888):</h3><h2>Does the Python "open" function save its content in memory or in a temp file?</h2><p>For the following Python code:</p>

<pre><code>fp = open('output.txt', 'wb')
# Very big file, writes a lot of lines, n is a very large number
for i in range(1, n):
    fp.write('something' * n)
fp.close()
</code></pre>

<p>The writing process above can last more than 30 min. Sometimes I get the error <code>MemoryError</code>. Is the content of the file before closing stored in memory or written in a temp file?  If it's in a temporary file, what is its general location on a Linux OS?</p>

<p><strong>Edit:</strong></p>

<p>Added fp.write in a for loop</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>It's stored in the operating system's disk cache in memory until it is flushed to disk, either implicitly due to timing or space issues, or explicitly via <a href="http://docs.python.org/library/stdtypes.html#file.flush" rel="nofollow"><code>fp.flush()</code></a>.</p>
<br /><b>#1</b><br /><p>There will be write buffering in the Linux kernel, but at (ir)regular intervals they will be flushed to disk. Running out of such buffer space should never cause an application-level memory error; the buffers should empty before that happens, pausing the application while doing so.</p>
<br /><b>#2</b><br /><p>If you a writing out a large file for which the writes might fail you a better off flushing the file to disk yourself at regular intervals using <code>fp.flush()</code>. This way the file will be in a location of your choosing that you can easily get to rather than being at the mercy of the OS:</p>

<pre><code>fp = open('output.txt', 'wb')
counter = 0
for line in many_lines:
    file.write(line)
    counter += 1
    if counter &gt; 999:
        fp.flush()
fp.close()
</code></pre>

<p>This will flush the file to disk every 1000 lines.</p>
<br /><b>#3</b><br /><p>Building on ataylor's comment to the question: </p>

<p>You might want to nest your loop. Something like </p>

<pre><code>for i in range(1,n):
    for each in range n:
        fp.write('something')
fp.close()
</code></pre>

<p>That way, the only thing that gets put into memory is the string <code>"something"</code>, not <code>"something" * n</code>.</p>
<br /><b>#4</b><br /><p>If you write line by line, it should not be a problem. You should show the code of what you are doing before the write. For a start you can try to delete objects where not necessary, use <code>fp.flush()</code> etc..</p>
<br /><b>#5</b><br /><p>File writing should never give a memory error; with all probability, you have some bug in another place.</p>

<p>If you have a loop, and a memory error, then I would look if you are "leaking" references to objects.<br>
Something like:</p>

<pre><code>def do_something(a, b = []):
    b.append(a)
    return b

fp = open('output.txt', 'wb') 

for i in range(1, n): 
    something = do_something(i)
    fp.write(something)

fp.close()
</code></pre>

<p>I am now picking just an example, but in your actual case the reference leak may be much more difficult to find; however this case will just leak memory inside <code>do_something</code> because of the way Python handles default parameters of functions.</p>
<br />