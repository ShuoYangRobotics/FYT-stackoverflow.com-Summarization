<h3>Question (ID-1322380):</h3><h2>gotchas where Numpy differs from straight python?</h2><p>Folks,</p>

<p>is there a collection of gotchas where Numpy differs from python,
points that have puzzled and cost time ?</p>

<blockquote>
  <p>"The horror of that moment I shall
  never never forget !"<br />
  "You will, though," the Queen said, "if you don't
  make a memorandum of it."</p>
</blockquote>

<p>For example, NaNs are always trouble, anywhere.
If you can explain this without running it, give yourself a point --</p>

<pre><code>from numpy import array, NaN, isnan

pynan = float("nan")
print pynan is pynan, pynan is NaN, NaN is NaN
a = (0, pynan)
print a, a[1] is pynan, any([aa is pynan for aa in a])

a = array(( 0, NaN ))
print a, a[1] is NaN, isnan( a[1] )
</code></pre>

<p>(I'm not knocking numpy, lots of good work there, just think a FAQ or Wiki of gotchas would be useful.)</p>

<p>Edit: I was hoping to collect half a dozen gotchas (surprises for people learning Numpy).<br />
Then, if there are common gotchas or, better, common explanations,
we could talk about adding them to a community Wiki (where ?)
It doesn't look like we have enough so far.</p>
<br /><h3>Answers (Total-11):</h3><b>#0</b><br /><p><code>NaN</code> is not a singleton like <code>None</code>, so you can't really use the is check on it. What makes it a bit tricky is that <code>NaN == NaN</code> is <code>False</code> as IEEE-754 requires. That's why you need to use the <code>numpy.isnan()</code> function to check if a float is not a number. Or the standard library <code>math.isnan()</code> if you're using Python 2.6+.</p>
<br /><b>#1</b><br /><p>I think this one is funny:</p>

<pre><code>&gt;&gt;&gt; import numpy as n
&gt;&gt;&gt; a = n.array([[1,2],[3,4]])
&gt;&gt;&gt; a[1], a[0] = a[0], a[1]
&gt;&gt;&gt; a
array([[1, 2],
       [1, 2]])
</code></pre>

<p>For Python lists on the other hand this works as intended:</p>

<pre><code>&gt;&gt;&gt; b = [[1,2],[3,4]]
&gt;&gt;&gt; b[1], b[0] = b[0], b[1]
&gt;&gt;&gt; b
[[3, 4], [1, 2]]
</code></pre>

<p>Funny side note: numpy itself had a bug in the <code>shuffle</code> function, because it used that notation :-) (see <a href="http://mail.scipy.org/pipermail/numpy-discussion/2006-November/024783.html">here</a>).</p>

<p>The reason is that in the first case we are dealing with <em>views</em> of the array, so the values are overwritten in-place.</p>
<br /><b>#2</b><br /><p>The biggest gotcha for me was that almost every standard operator is overloaded to distribute across the array.</p>

<p>Define a list and an array</p>

<pre><code>&gt;&gt;&gt; l = range(10)
&gt;&gt;&gt; l
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
&gt;&gt;&gt; import numpy
&gt;&gt;&gt; a = numpy.array(l)
&gt;&gt;&gt; a
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
</code></pre>

<p>Multiplication duplicates the python list, but distributes over the numpy array</p>

<pre><code>&gt;&gt;&gt; l * 2
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
&gt;&gt;&gt; a * 2
array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])
</code></pre>

<p>Addition and division are not defined on python lists</p>

<pre><code>&gt;&gt;&gt; l + 2
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: can only concatenate list (not "int") to list
&gt;&gt;&gt; a + 2
array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
&gt;&gt;&gt; l / 2.0
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: unsupported operand type(s) for /: 'list' and 'float'
&gt;&gt;&gt; a / 2.0
array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5])
</code></pre>

<p>Numpy overloads to treat lists like arrays sometimes</p>

<pre><code>&gt;&gt;&gt; a + a
array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])
&gt;&gt;&gt; a + l
array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])
</code></pre>
<br /><b>#3</b><br /><p>Because <code>__eq__</code> does not return a bool, using numpy arrays in any kind of containers prevents equality testing without a container-specific work around.</p>

<p>Example:</p>

<pre><code>&gt;&gt;&gt; import numpy
&gt;&gt;&gt; a = numpy.array(range(3))
&gt;&gt;&gt; b = numpy.array(range(3))
&gt;&gt;&gt; a == b
array([ True,  True,  True], dtype=bool)
&gt;&gt;&gt; x = (a, 'banana')
&gt;&gt;&gt; y = (b, 'banana')
&gt;&gt;&gt; x == y
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
</code></pre>

<p>This is a horrible problem.  For example, you cannot write unittests for containers which use <code>TestCase.assertEqual()</code> and must instead write custom comparison functions.  Suppose we write a work-around function <code>special_eq_for_numpy_and_tuples</code>.  Now we can do this in a unittest:</p>

<pre><code>x = (array1, 'deserialized')
y = (array2, 'deserialized')
self.failUnless( special_eq_for_numpy_and_tuples(x, y) )
</code></pre>

<p>Now we must do this for every container type we might use to store numpy arrays.  Furthermore, <code>__eq__</code> might return a bool rather than an array of bools:</p>

<pre><code>&gt;&gt;&gt; a = numpy.array(range(3))
&gt;&gt;&gt; b = numpy.array(range(5))
&gt;&gt;&gt; a == b
False
</code></pre>

<p>Now each of our container-specific equality comparison functions must also handle that special case.</p>

<p>Maybe we can patch over this wart with a subclass?</p>

<pre><code>&gt;&gt;&gt; class SaneEqualityArray (numpy.ndarray):
...   def __eq__(self, other):
...     return isinstance(other, SaneEqualityArray) and self.shape == other.shape and (numpy.ndarray.__eq__(self, other)).all()
... 
&gt;&gt;&gt; a = SaneEqualityArray( (2, 3) )
&gt;&gt;&gt; a.fill(7)
&gt;&gt;&gt; b = SaneEqualityArray( (2, 3) )
&gt;&gt;&gt; b.fill(7)
&gt;&gt;&gt; a == b
True
&gt;&gt;&gt; x = (a, 'banana')
&gt;&gt;&gt; y = (b, 'banana')
&gt;&gt;&gt; x == y
True
&gt;&gt;&gt; c = SaneEqualityArray( (7, 7) )
&gt;&gt;&gt; c.fill(7)
&gt;&gt;&gt; a == c
False
</code></pre>

<p>That seems to do the right thing.  The class should also explicitly export elementwise comparison, since that is often useful.</p>
<br /><b>#4</b><br /><p>The truth value of a Numpy array differs from that of a python sequence type, where any non-empty sequence is true.</p>

<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; l = [0,1,2,3]
&gt;&gt;&gt; a = np.arange(4)
&gt;&gt;&gt; if l: print "Im true"
... 
Im true
&gt;&gt;&gt; if a: print "Im true"
... 
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
ValueError: The truth value of an array with more than one element is ambiguous. Use
a.any() or a.all()
&gt;&gt;&gt;
</code></pre>

<p>The numerical types are true when they are non-zero and as a collection of numbers, the Nupy array inherits this definition.  But with a collection of numbers, truth could reasonably mean "all elements are non-zero" or "at least one element is non-zero".  Numpy refuses to guess which definition is meant and raises the above exception.  Using the .any() and .all() methods allows one to specify which meaning of true is meant.</p>

<pre><code>&gt;&gt;&gt; if a.any(): print "Im true"
... 
Im true
&gt;&gt;&gt; if a.all(): print "Im true"
... 
&gt;&gt;&gt;
</code></pre>
<br /><b>#5</b><br /><pre><code>print pynan is pynan, pynan is NaN, NaN is NaN
</code></pre>

<p>This tests identity, that is if it is the same object. The result should therefore obviously be True, False, True, because when you do float(whatever) you are creating a new float object.</p>

<pre><code>a = (0, pynan)
print a, a[1] is pynan, any([aa is pynan for aa in a])
</code></pre>

<p>I don't know what it is that you find surprising with this.</p>

<pre><code>a = array(( 0, NaN ))
print a, a[1] is NaN, isnan( a[1] )
</code></pre>

<p>This I did have to run. :-) When you stick NaN into an array it's converted into a numpy.float64 object, which is why a[1] is NaN fails.</p>

<p>This all seems fairly unsurprising to me. But then I don't really know anything much about NumPy. :-)</p>
<br /><b>#6</b><br /><p>Slicing creates views, not copies.</p>

<pre><code>&gt;&gt;&gt; l = [1, 2, 3, 4]
&gt;&gt;&gt; s = l[2:3]
&gt;&gt;&gt; s[0] = 5
&gt;&gt;&gt; l
[1, 2, 3, 4]

&gt;&gt;&gt; a = array([1, 2, 3, 4])
&gt;&gt;&gt; s = a[2:3]
&gt;&gt;&gt; s[0] = 5
&gt;&gt;&gt; a
array([1, 2, 5, 4])
</code></pre>
<br /><b>#7</b><br /><p>from Neil Martinsen-Burrell in <a href="http://mail.scipy.org/pipermail/numpy-discussion/2009-September/045041.html" rel="nofollow">numpy-discussion</a> 7 Sept  --</p>

<blockquote>
  <p>The ndarray type available in Numpy is
  not conceptually an extension of 
  Python's iterables.  If you'd like to
  help other Numpy users with this 
  issue, you can edit the documentation
  in the online documentation editor  at
  <a href="http://docs.scipy.org/numpy/docs/numpy-docs/user/index.rst" rel="nofollow">numpy-docs</a></p>
</blockquote>
<br /><b>#8</b><br /><p>I found the fact that multiplying up lists of elements just creates view of elements caught me out.</p>

<pre><code>&gt;&gt;&gt; a=[0]*5
&gt;&gt;&gt;a
[0,0,0,0,0]
&gt;&gt;&gt;a[2] = 1
&gt;&gt;&gt;a
[0,0,1,0,0]
&gt;&gt;&gt;b = [np.ones(3)]*5
&gt;&gt;&gt;b
[array([ 1.,  1.,  1.]), array([ 1.,  1.,  1.]), array([ 1.,  1.,  1.]), array([ 1.,  1.,  1.]), array([ 1.,  1.,  1.])]
&gt;&gt;&gt;b[2][1] = 2
&gt;&gt;&gt;b
[array([ 1.,  2.,  1.]), array([ 1.,  2.,  1.]), array([ 1.,  2.,  1.]), array([ 1.,  2.,  1.]), array([ 1.,  2.,  1.])]
</code></pre>

<p>So if you create a list of elements like this and intend to do different operations on them you are scuppered ...</p>

<p>A straightforward solution is to iteratively create each of the arrays (using a 'for loop' or list comprehension) or use a higher dimensional array (where e.g. each of these 1D arrays is a row in your 2D array, which is generally faster).</p>
<br /><b>#9</b><br /><p>(Related, but a NumPy vs. SciPy gotcha, rather than NumPy vs Python)</p>

<hr>

<p>Slicing beyond an array's real size works differently:</p>

<pre><code>&gt;&gt;&gt; import numpy, scipy.sparse

&gt;&gt;&gt; m = numpy.random.rand(2, 5) # create a 2x5 dense matrix
&gt;&gt;&gt; print m[:3, :] # works like list slicing in Python: clips to real size
[[ 0.12245393  0.20642799  0.98128601  0.06102106  0.74091038]
[ 0.0527411   0.9131837   0.6475907   0.27900378  0.22396443]]

&gt;&gt;&gt; s = scipy.sparse.lil_matrix(m) # same for csr_matrix and other sparse formats
&gt;&gt;&gt; print s[:3, :] # doesn't clip!
IndexError: row index out of bounds
</code></pre>

<p>So when slicing <code>scipy.sparse</code> arrays, you must make manually sure your slice bounds are within range. This differs from how both NumPy and plain Python work.</p>
<br /><b>#10</b><br /><p>Not such a big gotcha:   With boolean slicing, I sometimes wish I could do </p>

<blockquote>
  <p>x[ 3&lt;= y &lt; 7 ]</p>
</blockquote>

<p>like the python double comparison.   Instead, I have to write </p>

<blockquote>
  <p>x[ np.logical_and( 3&lt;=y, y&lt;7) ]</p>
</blockquote>

<p>(Unless you know something better?)</p>

<p>Also, np.logical_and and np.logical_or only take two arguments each, I would like them to take a variable number, or a list, so I could feed in more than just two logical clauses.</p>

<p>(numpy 1.3, maybe this has all changed in later versions.)</p>
<br />