<h3>Question (ID-7876453):</h3><h2>Minimum and maximum of the last 1000 values of the changing list</h2><p>I'm creating an iterative algorithm (Monte Carlo method).
The algorithm returns a value on every iteration, creating a stream of values.</p>

<p>I need to analyze these values and stop the algorithm when say <code>1000</code> returned values are withing some <code>epsilon</code>.</p>

<p>I decided to implement it calculation the <code>max</code> and <code>min</code> values of the last <code>1000</code> values, and then calculate the <code>error</code> using this formula <code>(max-min)/min</code> and compare it to <code>epsilon</code>: <code>error&lt;=epsilon</code>. And if this condition is reached, stop the iterations and return the result.</p>

<ol>
<li><p>The first hare-brained idea was to use a <code>list</code> and <code>append</code> new values to it, calculating the <code>max</code> and <code>min</code> values for the last <code>1000</code> values of it after each appending.</p></li>
<li><p>Then I decided there is no use of keeping more that <code>1000</code> last values. So I remembered of <a href="http://docs.python.org/library/collections.html#collections.deque" rel="nofollow"><code>deque</code></a>. It was a very good idea since the complexity on adding and deleting on both ends of <code>deque</code> object is <code>O(1)</code>. But it didn't solve the problem of needing to go through all the last 1000 values on each iteration to calculate <code>min</code> and <code>max</code>.</p></li>
<li><p>Then I remembered there is the <a href="http://docs.python.org/library/heapq.html#module-heapq" rel="nofollow"><code>heapq</code> module</a>. It keeps the data in such a way as to efficiently return the smallest one at every moment. But I need both the smallest and the largest ones. Furthermore I need to preserve the order of the elements so that I can keep <code>1000</code> last returned elements of the algorithm, and I don't see how I can achieve it with <code>heapq</code>.</p></li>
</ol>

<p>Having all those thoughts in mind I decided to ask here:</p>

<p>How can I solve this task the most efficiently? </p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>If you are free / willing to change your definition of <code>error</code>, you might want to consider using the <code>variance</code> instead of <code>(max-min)/min</code>. </p>

<p>You can <a href="http://stackoverflow.com/questions/5543651/computing-standard-deviation-in-a-stream/5544108#5544108">compute the variance incrementally</a>.
True, using this method, you are not deleting any values from your stream -- the variance will depend on all the values. But so what? With enough values, the first few won't matter a great deal to the variance, and the variance of the average, <code>variance/n</code>, will become small when enough values cluster around some fixed value.</p>

<p>So, you can choose to halt when the <code>variance/n &lt; epsilon</code>.</p>
<br /><b>#1</b><br /><p>As a refinement of @unutbu's excellent idea, you could consider using <em>exponentially-weighted</em> moving variance. It can be computed in <code>O(1)</code> time per observation, requires <code>O(1)</code> space, and has the advantage of automatically reducing the observation's weight as the observation gets older.</p>

<p>The following paper has the relevant formulae: <a href="http://www-uxsup.csx.cam.ac.uk/~fanf2/hermes/doc/antiforgery/stats.pdf" rel="nofollow">link</a>. See equations (140)-(143) therein.</p>

<p>Finally, you might want to work with the standard deviation instead of variance. It is simply the square root of variance, and has the advantage of having the same units as the original data. This should make it easier to formulate a meaningful stopping criterion.</p>
<br /><b>#2</b><br /><p>How about numpy?</p>

<p>Just to compare the speed:</p>

<pre><code>import numpy as np
a = range(1000)
b = np.arange(1000)

max(a) # 29.7us
b.max() # 7.29us
</code></pre>

<p>and you can write to this array infinitely:</p>

<pre><code>i = 0
b = np.empty([1000]) + np.nan

your loop:
    b[i % 1000] = value
    i += 1
</code></pre>

<p>The values older than 1000 iterations will get overwritten. You get the minimum/maximum with <code>np.nanmin(b)</code> and <code>np.nanmax(b)</code>.</p>

<p>The idea behind the <code>nan</code> is that you initialize this array with 1000 nan's and you overwrite them one after another. The <code>nanmin</code> and <code>nanmax</code> methods ignore these nan's.</p>
<br /><b>#3</b><br /><p>I'm afraid I'm not in a position to provide a nice Python answer now, but I'll give you the outline of the data structure you'll need to use:</p>

<p>Keep your 1000 items in an FIFO queue. Keep pointers to the largest and smallest items in the queue. If one of these leaves the queue, search the queue for the new largest/smallest (Amortized cost dependent on your data). If a new largest/smallest value enters the queue, just update the pointer (O(1)). Assuming your data is converging, this should work well.</p>
<br /><b>#4</b><br /><p>Create a subclass of deque that has minvalue and maxvalue properties. When adding or removing entries, compare them to the current min and maxvalues - then you only need to rescan the deque for min/max if the value you are removing is the current min or max. And when adding, just compare the new value with the current min and max, and update accordingly. This will optimize the scanning of your deque for min/max values.</p>
<br /><b>#5</b><br /><p>You could use two <a href="http://en.wikipedia.org/wiki/Fibonacci_heap" rel="nofollow">fibonacci heaps</a>. Adding values is in O(1), deleting is in O(log(n)). In your question you already suggest the heapq module. I am not sure what kind of heap it provides, but a normal one will also work very smoothly. </p>

<p>The problem that you can only extract the minimum from one heap but not the maximum can be solved by keeping two heaps. Since I do not know the heapq module, you either might be able to provide it your own comparison function, or you can just use <code>-value</code> instead of <code>value</code> for the key of the second heap.</p>
<br />