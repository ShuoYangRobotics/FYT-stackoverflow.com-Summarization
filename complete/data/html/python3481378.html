<h3>Question (ID-3481378):</h3><h2>regex that matches a string that contains some text</h2><p>I need a regex that matches</p>

<pre><code>re.compile('userpage')


href="www.example.com?u=userpage&amp;as=233&amp;p=1"
href="www.example.com?u=userpage&amp;as=233&amp;p=2"
</code></pre>

<p>I want to get all urls that have u=userpage and p=1</p>

<p>How can I modify the regex above to find both u=userpage and p=1?</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>if you want to use, in my opinion, something more proper approach, than regexp:</p>

<pre><code>from urlparse import *
urlparsed = urlparse('www.example.com?u=userpage&amp;as=233&amp;p=1')
# -&gt; ParseResult(scheme='', netloc='', path='www.example.com', params='', query='u=userpage&amp;as=233&amp;p=1', fragment='')
qdict = dict(parse_qsl(urlparsed.query))
# -&gt; {'as': '233', 'p': '1', 'u': 'userpage'}
qdict.get('p') == '1' and qdict.get('u') == 'userpage'
# -&gt; True
</code></pre>
<br /><b>#1</b><br /><pre><code>import lxml.html, urlparse

d = lxml.html.parse(...)
for link in d.xpath('//a/@href'):
    url = urlparse.urlparse(link)
    if not url.query:
        continue
    params = urlparse.parse_qs(url.query)
    if 'userpage' in params.get('u', []) and '1' in params.get('p', []):
        print link
</code></pre>
<br /><b>#2</b><br /><p>Regex is not a good choice for this because 1) the params could appear in either order, and 2) you need to do extra checks for query separators so that you don't match potential oddities like "flu=userpage", "sp=1", "u=userpage%20haha", or "s=123". (<em>Note:</em> I missed two of those cases in my first pass! So did others.) Also: 3) you already have a good URL parsing library in Python which does the work for you.</p>

<p>With regex you'd need something clumsy like:</p>

<pre><code>q = re.compile(r'([?&amp;]u=userpage&amp;(.*&amp;)?p=1(&amp;|$))|([?&amp;]p=1&amp;(.*&amp;)?u=userpage(&amp;|$))')
return q.search(href) is not None
</code></pre>

<p>With urlparse you can do this. urlparse gives you a little more than you want but you can use a helper function to keep the result simple:</p>

<pre><code>def has_qparam(qs, key, value):
    return value in qs.get(key, [])

qs = urlparse.parse_qs(urlparse.urlparse(href).query)
return has_qparam(qs, 'u', 'userpage') and has_qparam(qs, 'p', '1')
</code></pre>
<br /><b>#3</b><br /><p><code>/((u=userpage).*?(p=1))|((p=1).*?(u=userpage))/</code></p>

<p>This will get all strings that contain the two bits you're looking for.</p>
<br /><b>#4</b><br /><p>To make sure you don't accidentally match parts like <code>bu=userpage</code>, <code>u=userpagezap</code>, <code>p=111</code> or <code>zap=1</code>, you need abundant use of the <code>\b</code> "word-boundary" RE pattern element.  I.e.:</p>

<pre><code>re.compile(r'\bp=1\b.*\bu=userpage\b|\bu=userpage\b.*\bp=1\b')
</code></pre>

<p>The word-boundary elements in the RE's pattern prevent the above-mentioned, presumably-undesirable "accidental" matches.  Of course, if in your application they're <em>not</em> "undesirable", i.e., if you positively <strong>want</strong> to match <code>p=123</code> and the like, you can easily remove some or all of the word-boundary elements above!-)</p>
<br /><b>#5</b><br /><p>It is possible to do this with string hacking, but you shouldn't. It's already in the standard library:</p>

<pre><code>&gt;&gt;&gt; import urllib.parse
&gt;&gt;&gt; urllib.parse.parse_qs("u=userpage&amp;as=233&amp;p=1")
{'u': ['userpage'], 'as': ['233'], 'p': ['1']}
</code></pre>

<p>and hence</p>

<pre><code>import urllib.parse
def filtered_urls( urls ):
    for url in urls:
        try:
            attrs = urllib.parse.parse_qs( url.split( "?" )[ 1 ] )
        except IndexError:
            continue

        if "userpage" in attrs.get( "u", "" ) and "1" in attrs.get( "p", "" ):
            yield url

foo = [ "www.example.com?u=userpage&amp;as=233&amp;p=1", "www.example.com?u=userpage&amp;as=233&amp;p=2" ]

print( list( filtered_urls( foo ) ) )
</code></pre>

<p>Note that this is Python 3 -- in Python <code>parse_qs</code> is in <code>urlparse</code> instead.</p>
<br />