<h3>Question (ID-284043):</h3><h2>Outputting data from unit test in python</h2><p>If I'm writing unit tests in python (using the unittest module), is it possible to output data from a failed test, so I can examine it to help deduce what caused the error? I am aware of the ability to create a customized message, which can carry some information, but sometimes you might deal with more complex data, that can't easily be represented as a string.</p>

<p>For example, suppose you had a class Foo, and were testing a method bar, using data from a list called testdata:</p>

<pre><code>class TestBar(unittest.TestCase):
    def runTest(self):
        for t1, t2 in testdata:
            f = Foo(t1)
            self.assertEqual(f.bar(t2), 2)
</code></pre>

<p>If the test failed, I might want to output t1, t2 and/or f, to see why this particular data resulted in a failure. By output, I mean that the variables can be accessed like any other variables, after the test has been run.</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>We use the logging module for this.</p>

<pre><code>class SomeTest( unittest.TestCase ):
    def testSomething( self ):
        log= logging.getLogger( "SomeTest.testSomething" )
        log.debug( "this= %r", self.this )
        log.debug( "that= %r", self.that )
        # etc.
        self.assertEquals( 3.14, pi )

if __name__ == "__main__":
    logging.basicConfig( stream=sys.stderr )
    logging.getLogger( "SomeTest.testSomething" ).setLevel( logging.DEBUG )
    unittest.main()
</code></pre>

<p>That allows us to turn on debugging for specific tests which we know are failing and for which we want additional debugging information.</p>

<p>My preferred method, however, isn't to spent a lot of time on debugging, but spend it writing more fine-grained tests to expose the problem.</p>
<br /><b>#1</b><br /><p>You can use simple print statements, or any other way of writing to stdout.  You can also invoke the Python debugger anywhere in your tests.</p>

<p>If you use <a href="http://somethingaboutorange.com/mrl/projects/nose/" rel="nofollow">nose</a> to run your tests (which I recommend), it will collect the stdout for each test and only show it to you if the test failed, so you don't have to live with the cluttered output when the tests pass.</p>

<p>nose also has switches to automatically show variables mentioned in asserts, or to invoke the debugger on failed tests.</p>
<br /><b>#2</b><br /><p>I don't think this is quite what your looking for, there's no way to display variable values that don't fail, but this may help you get closer to outputting the results the way you want.</p>

<p>You can use the <strong><a href="http://docs.python.org/library/unittest.html#id3">TestResult object</a></strong> returned by the <strong>TestRunner.run()</strong> for results analysis and processing.  Particularly, TestResult.errors and TestResult.failures</p>

<p>About the TestResults Object:</p>

<p><a href="http://docs.python.org/library/unittest.html#id3">http://docs.python.org/library/unittest.html#id3</a></p>

<p>And some code to point you in the right direction:</p>

<pre><code>&gt;&gt;&gt; import random
&gt;&gt;&gt; import unittest
&gt;&gt;&gt;
&gt;&gt;&gt; class TestSequenceFunctions(unittest.TestCase):
...     def setUp(self):
...         self.seq = range(5)
...     def testshuffle(self):
...         # make sure the shuffled sequence does not lose any elements
...         random.shuffle(self.seq)
...         self.seq.sort()
...         self.assertEqual(self.seq, range(10))
...     def testchoice(self):
...         element = random.choice(self.seq)
...         error_test = 1/0
...         self.assert_(element in self.seq)
...     def testsample(self):
...         self.assertRaises(ValueError, random.sample, self.seq, 20)
...         for element in random.sample(self.seq, 5):
...             self.assert_(element in self.seq)
...
&gt;&gt;&gt; suite = unittest.TestLoader().loadTestsFromTestCase(TestSequenceFunctions)
&gt;&gt;&gt; testResult = unittest.TextTestRunner(verbosity=2).run(suite)
testchoice (__main__.TestSequenceFunctions) ... ERROR
testsample (__main__.TestSequenceFunctions) ... ok
testshuffle (__main__.TestSequenceFunctions) ... FAIL

======================================================================
ERROR: testchoice (__main__.TestSequenceFunctions)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 11, in testchoice
ZeroDivisionError: integer division or modulo by zero

======================================================================
FAIL: testshuffle (__main__.TestSequenceFunctions)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 8, in testshuffle
AssertionError: [0, 1, 2, 3, 4] != [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

----------------------------------------------------------------------
Ran 3 tests in 0.031s

FAILED (failures=1, errors=1)
&gt;&gt;&gt;
&gt;&gt;&gt; testResult.errors
[(&lt;__main__.TestSequenceFunctions testMethod=testchoice&gt;, 'Traceback (most recent call last):\n  File "&lt;stdin&gt;"
, line 11, in testchoice\nZeroDivisionError: integer division or modulo by zero\n')]
&gt;&gt;&gt;
&gt;&gt;&gt; testResult.failures
[(&lt;__main__.TestSequenceFunctions testMethod=testshuffle&gt;, 'Traceback (most recent call last):\n  File "&lt;stdin&gt;
", line 8, in testshuffle\nAssertionError: [0, 1, 2, 3, 4] != [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n')]
&gt;&gt;&gt;
</code></pre>
<br /><b>#3</b><br /><p>I think I might have been overthinking this. One way I've come up with that does the job, is simply to have a global variable, that accumulates the diagnostic data.</p>

<p>Somthing like this:</p>

<pre><code>log1 = dict()
class TestBar(unittest.TestCase):
    def runTest(self):
        for t1, t2 in testdata:
            f = Foo(t1) 
            if f.bar(t2) != 2: 
                log1("TestBar.runTest") = (f, t1, t2)
                self.fail("f.bar(t2) != 2")
</code></pre>

<p>Thanks for the resplies. They have given me some alternative ideas for how to record information from unit tests.              </p>
<br /><b>#4</b><br /><p>Another option - start a debugger where the test fails.</p>

<p>Try running your tests with Testoob (it will run your unittest suite without changes), and you can use the '--debug' command line switch to open a debugger when a test fails.</p>

<p>Here's a terminal session on windows:</p>

<pre><code>C:\work&gt; testoob tests.py --debug
F
Debugging for failure in test: test_foo (tests.MyTests.test_foo)
&gt; c:\python25\lib\unittest.py(334)failUnlessEqual()
-&gt; (msg or '%r != %r' % (first, second))
(Pdb) up
&gt; c:\work\tests.py(6)test_foo()
-&gt; self.assertEqual(x, y)
(Pdb) l
  1     from unittest import TestCase
  2     class MyTests(TestCase):
  3       def test_foo(self):
  4         x = 1
  5         y = 2
  6  -&gt;     self.assertEqual(x, y)
[EOF]
(Pdb)
</code></pre>
<br /><b>#5</b><br /><p>How about catching the exception that gets generated from the assertion failure?  In your catch block you could output the data however you wanted to wherever.  Then when you were done you could re-throw the exception.  The test runner probably wouldn't know the difference. </p>

<p>Disclaimer: I haven't tried this with python's unit test framework but have with other unit test frameworks.</p>
<br />