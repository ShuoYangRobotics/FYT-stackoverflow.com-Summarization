<h3>Question (ID-419260):</h3><h2>Grabbing text from a webpage</h2><p>I would like to write a program that will find bus stop times and update my personal webpage accordingly.</p>

<p>If I were to do this manually I would </p>

<ol>
<li>Visit www.calgarytransit.com</li>
<li>Enter a stop number. ie) 9510</li>
<li>Click the button "next bus"</li>
</ol>

<p>The results may look like the following:</p>

<blockquote>
  <p>10:16p    Route 154	 
  10:46p Route 154	
  11:32p    Route 154</p>
</blockquote>

<p>Once I've grabbed the time and routes then I will update my webpage accordingly. </p>

<p>I have no idea where to start. I know diddly squat about web programming but can write some C and Python. What are some topics/libraries I could look into?</p>
<br /><h3>Answers (Total-8):</h3><b>#0</b><br /><p><a href="http://www.crummy.com/software/BeautifulSoup/documentation.html#Quick%20Start" rel="nofollow">Beautiful Soup</a> is a Python library designed for parsing web pages. Between it and <a href="http://docs.python.org/library/urllib2.html" rel="nofollow">urllib2</a> (<a href="http://docs.python.org/dev/3.0/library/urllib.request.html" rel="nofollow">urllib.request</a> in Python 3) you should be able to figure out what you need. <code>:)</code></p>
<br /><b>#1</b><br /><p>Since you write in C, you may want to check out <a href="http://curl.haxx.se/" rel="nofollow" title="cURL">cURL</a>; in particular, take a look at libcurl. It's great.</p>
<br /><b>#2</b><br /><p>What you're asking about is called "web scraping."  I'm sure if you google around you'll find some stuff, but the core notion is that you want to open a connection to the website, slurp in the HTML, parse it and identify the chunks you want.</p>

<p>The <a href="http://wiki.python.org/moin/WebProgramming" rel="nofollow">Python Wiki</a> has a good lot of stuff on this.</p>
<br /><b>#3</b><br /><p>You can use the mechanize library that is available for Python <a href="http://wwwsearch.sourceforge.net/mechanize/" rel="nofollow">http://wwwsearch.sourceforge.net/mechanize/</a></p>
<br /><b>#4</b><br /><p>That site doesnt offer an API for you to be able to get the appropriate data that you need. In that case you'll need to parse the actual HTML page returned by, for example, a CURL request .</p>
<br /><b>#5</b><br /><p>This is called <strong>Web scraping</strong>, and it even has its own <a href="http://en.wikipedia.org/wiki/Web_scraping" rel="nofollow">Wikipedia article</a> where you can find more information.</p>

<p>Also, you might find more details in this <a href="http://stackoverflow.com/questions/419235/anyone-know-of-a-good-python-based-web-crawler-that-i-could-use">SO discussion</a>.</p>
<br /><b>#6</b><br /><p>You can use Perl to help you complete your task.</p>

<pre><code>use strict;
use LWP;

my $browser = LWP::UserAgent-&gt;new;

my $responce = $browser-&gt;get("http://google.com");
print $responce-&gt;content;
</code></pre>

<p>Your responce object can tell you if it suceeded as well as returning the content of the page.You can also use this same library to post to a page.</p>

<p>Here is some documentation. <a href="http://search.cpan.org/~gaas/libwww-perl-5.822/lib/LWP/UserAgent.pm" rel="nofollow">http://search.cpan.org/~gaas/libwww-perl-5.822/lib/LWP/UserAgent.pm</a></p>
<br /><b>#7</b><br /><p>As long as the layout of the web page your trying to 'scrape' doesnt regularly change, you should be able to parse the html with any modern day programming language.</p>
<br />