<h3>Question (ID-5916097):</h3><h2>Iterate within directory to zip files with python</h2><p>I need to iterate through a folder and find every instance where the filenames are identical (except for extension) and then zip (preferably using tarfile) each of these into one file.</p>

<p>So I have 5 files named: "example1" each with different file extensions.  I need to zip them up together and output them as "example1.tar" or something similar.  </p>

<p>This would be easy enough with a simple for loop such as:</p>

<blockquote>
  <p>tar = tarfile.open('example1.tar',"w")</p>
  
  <blockquote>
    <p>for output in glob ('example1*'):</p>
    
    <blockquote>
      <p>tar.add(output)</p>
      
      <blockquote>
        <p>tar.close()</p>
      </blockquote>
    </blockquote>
  </blockquote>
</blockquote>

<p>however, there are 300 "example" files and I need to iterate through each one and their associated 5 files in order to make this work.  This is way over my head.  Any advice greatly appreciated.</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>You could do this:</p>

<ul>
<li>list all files in the directory</li>
<li>create a dictionary where the basename is the key and all the extensions are values</li>
<li>then tar all the files by dictionary key</li>
</ul>

<p>Something like this:</p>

<pre><code>import os
import tarfile
from collections import defaultdict

myfiles = os.listdir(".")   # List of all files
totar = defaultdict(list)

# now fill the defaultdict with entries; basename as keys, extensions as values
for name in myfiles:
    base, ext = os.path.splitext(name)
    totar[base].append(ext)

# iterate through all the basenames
for base in totar:
    files = [base+ext for ext in totar[base]]
    # now tar all the files in the list "files"
    tar = tarfile.open(base+".tar", "w")
    for item in files:    
        tar.add(item)
    tar.close()
</code></pre>
<br /><b>#1</b><br /><p>The pattern you're describing generalizes to MapReduce.  I found <a href="http://code.activestate.com/recipes/577676-dirt-simple-mapreduce/" rel="nofollow">a simple implementation</a> of MapReduce online, from which an even-simpler version is:</p>

<pre><code>def map_reduce(data, mapper, reducer):
    d = {}
    for elem in data:
        key, value = mapper(elem)
        d.setdefault(key, []).append(value)
    for key, grp in d.items():
        d[key] = reducer(key, grp)
    return d
</code></pre>

<p>You want to group all files by their name without the extension, which you can get from <code>os.path.splitext(fname)[0]</code>.  Then, you want to make a tarball out of each group by using the <code>tarfile</code> module.  In code, that is:</p>

<pre><code>import os
import tarfile

def make_tar(basename, files):
    tar = tarfile.open(basename + '.tar', 'w')
    for f in files:
        tar.add(f)
    tar.close()

map_reduce(os.listdir('.'),
           lambda x: (os.path.splitext(x)[0], x),
           make_tar)
</code></pre>

<p><strong>Edit</strong>: If you want to group files in different ways, you just need to modify the second argument to <code>map_reduce</code>.  The code above groups files that have the same value for the expression <code>os.path.splitext(x)[0]</code>.  So to group by the base file name with <em>all</em> the extensions stripped off, you could replace that expression with <code>strip_all_ext(x)</code> and add:</p>

<pre><code>def strip_all_ext(path):
    head, tail = os.path.split(path)
    basename = tail.split(os.extsep)[0]
    return os.path.join(head, basename)
</code></pre>
<br /><b>#2</b><br /><p>You have to problems.  Solve the separately.</p>

<ol>
<li><p>Finding matching names.  Use a <code>collections.defaultict</code></p></li>
<li><p>Creating tar files after you find the matching names.  You've got that pretty well covered.</p></li>
</ol>

<p>So.  Solve problem 1 first.</p>

<p>Use <code>glob</code> to get all the names.  Use <code>os.path.basename</code> to split the path and basename.  Use <code>os.path.splitext</code> to split the name and extension.</p>

<p>A dictionary of lists can be used to save all files that have the same name.</p>

<p>Is that what you're doing in part 1?</p>

<hr>

<p>Part 2 is putting the files into tar archives.  For that, you've got most of the code you need.</p>
<br /><b>#3</b><br /><p>Try using the glob module: <a href="http://docs.python.org/library/glob.html" rel="nofollow">http://docs.python.org/library/glob.html</a></p>
<br /><b>#4</b><br /><pre><code>#! /usr/bin/env python

import os
import tarfile

tarfiles = {}
for f in os.listdir ('files'):
    prefix = f [:f.rfind ('.') ]
    if prefix in tarfiles: tarfiles [prefix] += [f]
    else: tarfiles [prefix] = [f]

for k, v in tarfiles.items ():
    tf = tarfile.open ('%s.tar.gz' % k, 'w:gz')
    for f in v: tf.addfile (tarfile.TarInfo (f), file ('files/%s' % f) )
    tf.close ()
</code></pre>
<br /><b>#5</b><br /><pre><code>import os
import tarfile

allfiles = {}

for filename in os.listdir("."):
    basename = '.'.join (filename.split(".")[:-1] )
    if not basename in all_files:
        allfiles[basename] = [filename]
    else:
        allfiles[basename].append(filename)

for basename, filenames in allfiles.items():
    if len(filenames) &lt; 2:
        continue
    tardata = tarfile.open(basename+".tar", "w")
    for filename in filenames:
        tardata.add(filename)
    tardata.close()
</code></pre>
<br />