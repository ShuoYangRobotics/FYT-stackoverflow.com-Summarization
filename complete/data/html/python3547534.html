<h3>Question (ID-3547534):</h3><h2>What encoding do normal python strings use?</h2><p>i know that django uses unicode strings all over the framework instead of normal python strings. what encoding are normal python strings use ? and why don't they use unicode?</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>Normal Python strings (Python 2.x <code>str</code>) don't have an encoding: they are raw data. In Python 3 these are called "bytes" which is an accurate description, as they are simply sequences of bytes, which can be text encoded in <em>any</em> encoding (several are common!) or non-textual data altogether.</p>

<p><strong>For representing <em>text</em>, you want unicode strings, not byte strings.</strong> <code>unicode</code> instances are sequences of unicode codepoints represented abstractly without an encoding; this is well-suited for representing text.</p>

<p>Bytestrings are important because to represent data for transmission over a network or writing to a file or whatever, you cannot have an abstract representation of unicode, you need a concrete representation of bytes. Though they are often used to store and represent text, this is at least a little naughty.</p>

<p>This whole situation is complicated by the fact that while you <em>should</em> turn unicode into bytes by calling <code>encode</code> and turn bytes into unicode using <code>decode</code>, Python will try to do this automagically for you using a global encoding you can set that is by default ASCII, which is the safest choice. Never depend on this for your code and never ever change this to a more flexible encoding--explicitly decode when you get a bytestring and encode if you need to send a string somewhere external.</p>
<br /><b>#1</b><br /><p>Hey! I'd like to add some stuff to other answers, unfortunately I don't have enough rep yet to do that properly :-(</p>

<p>FWIW, Mike Graham's post is pretty good and that's probably what you should be reading first.</p>

<p>Here's a few comments:</p>

<ol>
<li>The need to prefix unicode literals with "u" in 2.x is pretty easily removed in recent (2.6+) 2.x Pythons. <code>from __future__ import unicode_literals</code></li>
<li>Simialrly, ASCII is only the default source encoding. Python understands a variety of coding hints including the emacs-style <code># -*- coding: utf-8 -*-</code>. For more information see <a href="http://www.python.org/dev/peps/pep-0263/" rel="nofollow">PEP 0263</a>. Changing the source encoding affects how Unicode literals (regardless of their prefix or lack of prefix, as affected by point 1) are interpreted. In Py3k, the default file encoding is UTF-8.</li>
<li>Python of course does use an encoding internally for Unicode strings (<code>str</code> in py3k, <code>unicode</code> in 2.x) because at some point in time stuff's going to have to be written to memory. Ideally, this would never be evident to the end-user. Unfortunately nothing's perfect and you can occasionally run into problems with this: specifically if you use funky squiggles outside of the Unicode Base Multilingual Plane. Since Python 2.2, we've had what's called <em>wide</em> builds and <em>narrow</em> builds; these names refer to the type used internally to store Unicode code points. Wide builds use UCS-4, which uses 4 bytes to store a Unicode code point. (This means UCS-4's code unit size is 4 bytes, or 32 bits.) Narrow builds use UCS-2. UCS-2 only has 16 bits, and therefore can not encode all Unicode code points accurately (it's like UTF-16, except without the surrogate pairs). To check, test the value of <code>sys.maxunicode</code>. If it's <code>1114111</code>, you've got a wide build (which can correctly represent all of Unicode). If it's less, well, don't fret too much. The BMP (code points <code>0x0000</code> to <code>0xFFFF</code>) covers most people's needs. For more information, see <a href="http://www.python.org/dev/peps/pep-0261/" rel="nofollow">PEP 0261</a>.</li>
</ol>
<br /><b>#2</b><br /><p>Python 2.x strings are 8-bit, nothing more. The encoding may vary (though ASCII is assumed). I guess the reasons are historical. Few languages, especially languages that date back to the last century, use unicode right away.</p>

<p>In Python 3, all strings are unicode.</p>
<br /><b>#3</b><br /><p>From Python 3.0 on all strings are unicode by default, there is also the bytes datatype (<a href="http://docs.python.org/release/3.0.1/whatsnew/3.0.html#text-vs-data-instead-of-unicode-vs-8-bit" rel="nofollow">Python documentation</a>).</p>

<p>So the python developers think that using unicode is a good idea, that it is not used universally in python 2 is mostly due to backwards compatibility. It also has performance implications.</p>
<br /><b>#4</b><br /><p>Before Python 3.0, string encoding was <code>ascii</code> by default, but could be changed. Unicode string literals were <code>u"..."</code>. This was silly.</p>
<br /><b>#5</b><br /><blockquote>
  <p>what encoding are normal python
  strings use?</p>
</blockquote>

<p><strong>In Python 3.x</strong></p>

<p><code>str</code> is Unicode.  This may be either UTF-16 or UTF-32 depending on whether your Python interpreter was built with "narrow" or "wide" Unicode characters.</p>

<p>The Windows version of CPython uses UTF-16.  On Unix-like systems, UTF-32 tends to be preferred.</p>

<p><strong>In Python 2.x</strong></p>

<p><code>str</code> is a byte string type like C <code>char</code>.  The encoding isn't defined by the language, but is whatever your locale's default encoding is.  Or whatever the MIME charset of the document you got off the Internet is.  Or, if you get a string from a function like <code>struct.pack</code>, it's binary data, and doesn't meaningfully have a character encoding at all.</p>

<p><code>unicode</code> strings in 2.x are equivalent to <code>str</code> in 3.x.</p>

<blockquote>
  <p>and why don't they use unicode?</p>
</blockquote>

<p>Because Python (slightly) predates Unicode.  And because Guido wanted to save all the major backwards-incompatible changes for 3.0.  Strings in 3.x <em>do</em> use Unicode by default.</p>
<br />