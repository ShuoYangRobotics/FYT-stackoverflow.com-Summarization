<h3>Question (ID-2247205):</h3><h2>Python returning the wrong length of string when using special characters</h2><p>I have a string ë́aúlt that I want to get the length of a manipulate based on character positions and so on. The problem is that the first ë́ is being counted twice, or I guess ë is in position 0 and ´ is in position 1.</p>

<p>Is there any possible way in Python to have a character like ë́ be represented as 1?</p>

<p>I'm using UTF-8 encoding for the actual code and web page it is being outputted to.</p>

<p>edit: Just some background on why I need to do this. I am working on a project that translates English to Seneca (a form of Native American language) and ë́ shows up quite a bit. Some rewrite rules for certain words require knowledge of letter position (itself and surrounding letters) and other characteristics, such as accents and other diacritic markings.</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>UTF-8 is an unicode encoding which uses more than one byte for special characters. If you don't want the length of the encoded string, simple decode it and use <code>len()</code> on the <code>unicode</code> object (and not the <code>str</code> object!).</p>

<p>Here are some examples:</p>

<pre><code>&gt;&gt;&gt; # creates a str literal (with utf-8 encoding, if this was
&gt;&gt;&gt; # specified on the beginning of the file):
&gt;&gt;&gt; len('ë́aúlt') 
9
&gt;&gt;&gt; # creates a unicode literal (you should generally use this
&gt;&gt;&gt; # version if you are dealing with special characters):
&gt;&gt;&gt; len(u'ë́aúlt') 
6
&gt;&gt;&gt; # the same str literal (written in an encoded notation):
&gt;&gt;&gt; len('\xc3\xab\xcc\x81a\xc3\xbalt') 
9
&gt;&gt;&gt; # you can convert any str to an unicode object by decoding() it:
&gt;&gt;&gt; len('\xc3\xab\xcc\x81a\xc3\xbalt'.decode('utf-8')) 
6
</code></pre>

<p>Of course, you can also access single characters in an <code>unicode</code> object like you would do in a <code>str</code> object (they are both inheriting from <code>basestring</code> and therefore have the same methods):</p>

<pre><code>&gt;&gt;&gt; test = u'ë́aúlt'
&gt;&gt;&gt; print test[0]
ë
</code></pre>

<p>If you develop localized applications, it's generally a good idea to use only <code>unicode</code>-objects internally, by decoding all inputs you get. After the work is done, you can encode the result again as 'UTF-8'. If you keep to this principle, you will never see your server crashing because of any internal <code>UnicodeDecodeError</code>s you might get otherwise ;)</p>

<p>PS: Please note, that the <code>str</code> and <code>unicode</code> datatype have changed significantly in Python 3. In Python 3 there are only unicode strings and plain byte strings which can't be mixed anymore. That should help to avoid common pitfalls with unicode handling...</p>

<p>Regards,
Christoph</p>
<br /><b>#1</b><br /><blockquote>
  <p>The problem is that the first ë́ is being counted twice, or I guess ë is in position 0 and ´ is in position 1.</p>
</blockquote>

<p>Yes. That's how code points are defined by Unicode. In general, you can ask Python to convert a letter and a separate ‘combining’ diacritical mark like U+0301 COMBINING ACUTE ACCENT using Unicode normalisation:</p>

<pre><code>&gt;&gt;&gt; unicodedata.normalize('NFC', u'a\u0301')
u'\xe1' # single character: á
</code></pre>

<p>However, there is no single character in Unicode for “e with diaeresis and acute accent” because no language in the world has ever used the letter ‘ë́’. (Pinyin transliteration has “u with diaeresis and acute accent”, but not ‘e’.) Consequently font support is poor; it renders really badly in many cases and is a messy blob on my web browser.</p>

<p>To work out where the ‘editable points’ in a string of Unicode code points are is a tricky job that requires quite a bit of domain knowledge of languages. It's part of the issue of “complex text layout”, an area which also includes issues such as bidirectional text and contextual glpyh shaping and ligatures. To do complex text layout you'll need a library such as Uniscribe on Windows, or Pango generally (for which there is a Python interface).</p>

<p>If, on the other hand, you merely want to completely ignore all combining characters when doing a count, you can get rid of them easily enough:</p>

<pre><code>def withoutcombining(s):
    return ''.join(c for c in s if unicodedata.combining(c)==0)

&gt;&gt;&gt; withoutcombining(u'ë́aúlt')
'\xeba\xfalt' # ëaúlt
&gt;&gt;&gt; len(_)
5
</code></pre>
<br /><b>#2</b><br /><p>The best you can do is to use <a href="http://docs.python.org/library/unicodedata.html#unicodedata.normalize" rel="nofollow"><code>unicodedata.normalize()</code></a> to decompose the character and then filter out the accents.</p>

<p>Don't forget to use <code>unicode</code> and unicode literals in your code.</p>
<br /><b>#3</b><br /><p>Rather than guessing, let's work out why you're getting those results. Where are you getting the string from? If you're loading it from a file, what does it look like in binary?</p>

<p>It sounds like it could be due to combining characters - you <em>may</em> be able to normalize to a form which uses a single character for the combined glyph, but I don't think that's <em>always</em> possible.</p>
<br /><b>#4</b><br /><p>which Python version are you using?
Python 3.1 doesn't have this issue.</p>

<pre><code>&gt;&gt;&gt; print(len("ë́aúlt"))
6
</code></pre>

<p>Regards
Djoudi</p>
<br /><b>#5</b><br /><p>You said: I have a string ë́aúlt that I want to get the length of a manipulate based on character positions and so on. The problem is that the first ë́ is being counted twice, or I guess ë is in position 0 and ´ is in position 1.</p>

<p>The first step in working on any Unicode problem is to know exactly what is in your data; don't guess. In this case your guess is correct; it won't always be.</p>

<p>"Exactly what is in your data": use the repr() built-in function (for lots more things apart from unicode). A useful advantage of showing the repr() output in your question is that answerers then have exactly what you have. Note that your text displays in only FOUR positions instead of 5 with some browsers/fonts -- the 'e' and its diacritics and the 'a' are mangled together in one position.</p>

<p>You can use the unicodedata.name() function to tell you what each component is.</p>

<p>Here's an example:</p>

<pre><code># coding: utf8
import unicodedata
x = u"ë́aúlt"
print(repr(x))
for c in x:
    try:
        name = unicodedata.name(c)
    except:
        name = "&lt;no name&gt;"
    print "U+%04X" % ord(c), repr(c), name
</code></pre>

<p>Results:</p>

<pre><code>u'\xeb\u0301a\xfalt'
U+00EB u'\xeb' LATIN SMALL LETTER E WITH DIAERESIS
U+0301 u'\u0301' COMBINING ACUTE ACCENT
U+0061 u'a' LATIN SMALL LETTER A
U+00FA u'\xfa' LATIN SMALL LETTER U WITH ACUTE
U+006C u'l' LATIN SMALL LETTER L
U+0074 u't' LATIN SMALL LETTER T
</code></pre>

<p>Now read @bobince's answer :-)</p>
<br />