<h3>Question (ID-6602678):</h3><h2>I have a very big list of dictionaries and I want to sum the insides</h2><p>Something like</p>

<pre><code>{A: 3, 45, 34, 4, 2, 5, 94, 2139, 230345, 283047, 230847}, {B: 92374, 324, 345, 345, 45879, 34857987, 3457938457), {C: 23874923874987, 2347}
</code></pre>

<p>How can I reduce that to </p>

<pre><code>{A: 2304923094820398}, {B: 2374923784897}, {C: 29348239847239847}
</code></pre>

<p>Values obviously not exact. I just want to add up all the values in a non-time consuming manner.</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><pre><code>d = [{'A': [3, 45, 34, 4, 2, 5, 94, 2139, 230345, 283047, 230847]}, {'B': [92374, 324, 345, 345, 45879, 34857987, 3457938457]}, {'C': [23874923874987, 2347]}]
[{x.keys()[0]:sum(x.values()[0])} for x in d]
</code></pre>
<br /><b>#1</b><br /><p>Something like this:</p>

<pre><code>a={'a':range(100), 'b':range(200)}
b={}

for k,v in a.iteritems():
    b[k]=sum(v)

print b
</code></pre>

<p>gives</p>

<pre><code>{'a': 4950, 'b': 19900}
</code></pre>
<br /><b>#2</b><br /><p>Assuming the values are in a list,  like: </p>

<pre><code>d = {A: [3, 45, 34, 4, 2, 5, 94, 2139, 230345, 283047, 230847]}, {B: [92374, 324, 345, 345, 45879, 34857987, 3457938457]), {C: [23874923874987, 2347]}
</code></pre>

<p>then:</p>

<pre><code>new_d = []
for i in d:
    new_d.append(dict([(k,sum(v)) for k,v in i.itervalues()]))
</code></pre>
<br /><b>#3</b><br /><p>If you have lots and lots and lots of values, something like this might work (assuming by "list of dictionaries" you mean "dictionary of lists", as having a big list of one-key/value-pair dictionaries would be silly, and thus the values are stored in a <code>dict</code> like <code>{'A': [3, 45, 34, 4, 2, 5, 94, 2139, 230345, 283047, 230847], 'B': [92374, 324, 345, 345, 45879, 34857987, 3457938457], ...}</code>):</p>

<pre><code>from multiprocessing import Process, Lock

def sumfunc(lock, key, values):
    total = sum(values)

    lock.acquire()
    print(key + ':', total)   # The actual code would be better off utilizing shared multiprocessing.Array objects, but I haven't used them before so am not sure quite how you set them up so decided to leave that aside for now as this is just a theoretical example.
    lock.release()

if __name__ == '__main__':
    lock = Lock()

    for key, values in dict_of_values_to_sum.items():
        Process(target=sumfunc, args=(lock, key, values)).start()
</code></pre>
<br /><b>#4</b><br /><p>If you have a real big number of values i'll probably use numpy and do a vector addition.</p>

<p>So, something like</p>

<pre><code> a = numpy.arange(10, 2000000)
 total = numpy.sum(a)
</code></pre>

<p>Nothing more, nothing less :)</p>
<br /><b>#5</b><br /><pre><code>d = [{'A': [3, 45, 34, 4, 2, 5, 94, 2139, 230345, 283047, 230847]}, {'B': [92374, 324, 345, 345, 45879, 34857987, 3457938457]}, {'C': [23874923874987, 2347]}]
abc = {}
for x in d:
    for k, v in x.iteritems():
        abc[k] = reduce(lambda x,y: x+y, v)
</code></pre>
<br />