<h3>Question (ID-6197409):</h3><h2>Ordered Sets Python 2.7.1</h2><p>I have a list that I'm attempting to remove duplicate items from. I'm using python 2.7.1 so I can simply use the <strong>set()</strong> function. However, this reorders my list. Which for my particular case is unacceptable. </p>

<p>Below is a function I wrote; which does this. However I'm wondering if there's a better/faster way. Also any comments on it would be appreciated. </p>

<pre><code>    def ordered_set (_list) :

        newlist = []
        lastitem = None
        for item in _list :

            if item != lastitem :
                newlist.append(item)
                lastitem = item

        return newlist
</code></pre>

<p>The above function assumes that none of the items will be <strong>None</strong>, and that the items are in order (ie, <strong>['a', 'a', 'a', 'b', 'b', 'c', 'd']</strong>)</p>

<p>The above function returns <strong>['a', 'a', 'a', 'b', 'b', 'c', 'd']</strong> as <strong>['a', 'b', 'c', 'd']</strong>.</p>
<br /><h3>Answers (Total-7):</h3><b>#0</b><br /><p>Use an OrderedDict:</p>

<pre><code>from collections import OrderedDict

l = ['a', 'a', 'a', 'b', 'b', 'c', 'd']
d = OrderedDict()

for x in l:
    d[x] = True

# prints a b c d
for x in d:
    print x,
print
</code></pre>
<br /><b>#1</b><br /><p>I think this is perfectly OK. You get O(n) performance which is the best you could hope for.</p>

<p>If the list were unordered, then you'd need a helper <code>set</code> to contain the items you've already visited, but in your case that's not necessary.</p>
<br /><b>#2</b><br /><p>Looks ok to me. If you really want to use sets do something like this:</p>

<pre><code>def ordered_set (_list) :
    result = set()
    lastitem = None
    for item in _list :
        if item != lastitem :
            result.add(item)
            lastitem = item
    return sorted(tuple(result))
</code></pre>

<p>I don't know what performance you will get, you should test it; probably the same because of method's overheat!</p>

<p>If you really are paranoid, just like me, read here:</p>

<p><a href="http://wiki.python.org/moin/HowTo/Sorting/" rel="nofollow">http://wiki.python.org/moin/HowTo/Sorting/</a></p>

<p><a href="http://wiki.python.org/moin/PythonSpeed/PerformanceTips" rel="nofollow">http://wiki.python.org/moin/PythonSpeed/PerformanceTips</a></p>

<p>Just remembered this(it contains the answer):</p>

<p><a href="http://www.peterbe.com/plog/uniqifiers-benchmark" rel="nofollow">http://www.peterbe.com/plog/uniqifiers-benchmark</a></p>
<br /><b>#3</b><br /><p>if your list isn't sorted then your question doesn't make sense.
e.g. [1,2,1] could become [1,2] or [2,1]</p>

<p><strong>if your list is large you may want to write your result back into the same list using a SLICE to save on memory</strong>:</p>

<pre><code>&gt;&gt;&gt; x=['a', 'a', 'a', 'b', 'b', 'c', 'd']
&gt;&gt;&gt; x[:]=[x[i] for i in range(len(x)) if i==0 or x[i]!=x[i-1]]
&gt;&gt;&gt; x
['a', 'b', 'c', 'd']
</code></pre>

<p>for inline deleting see <a href="http://stackoverflow.com/questions/1207406/remove-items-from-a-list-while-iterating-in-python">Remove items from a list while iterating in Python</a> or <a href="http://stackoverflow.com/questions/2629198/python-remove-items-from-a-list-while-iterating-in-python">Python: Remove items from a list while iterating in Python</a></p>

<p>one trick you can use is that if you know x is sorted, and you know x[i]=x[i+j] then you don't need to check anything between x[i] and x[i+j] (and if you don't need to delete these j values, you can just copy the values you want into a new list)</p>

<p>So while you can't beat n operations if everything in the set is unique i.e. len(set(x))=len(x)
There is probably an algorithm that has n comparisons as its worst case but can have n/2 comparisons as its best case (or lower than n/2 as its best case if you know somehow know in advance that len(x)/len(set(x))>2 because of the data you've generated):</p>

<p>The optimal algorithm would probably use binary search to find maximum j for each minimum i in a divide and conquer type approach. Initial divisions would probably be of length len(x)/approximated(len(set(x))). Hopefully it could be carried out such that even if len(x)=len(set(x)) it still uses only n operations.</p>
<br /><b>#4</b><br /><p>Another very fast method with set:</p>

<pre><code>def remove_duplicates(lst):
    dset = set()
    # relies on the fact that dset.add() always returns None.
    return [ l for l in lst if 
             l not in dset and not dset.add(l) ] 
</code></pre>
<br /><b>#5</b><br /><p>Assuming the input sequence is unordered, here's <code>O(N)</code> solution (both in space and time).
It produces a sequence with duplicates removed, while leaving unique items in the same relative order as they appeared in the input sequence.</p>

<pre><code>&gt;&gt;&gt; def remove_dups_stable(s):
...   seen = set()
...   for i in s:
...     if i not in seen:
...       yield i
...       seen.add(i)

&gt;&gt;&gt; list(remove_dups_stable(['q', 'w', 'e', 'r', 'q', 'w', 'y', 'u', 'i', 't', 'e', 'p', 't', 'y', 'e']))
['q', 'w', 'e', 'r', 'y', 'u', 'i', 't', 'p']
</code></pre>
<br /><b>#6</b><br /><p>I know this has already been answered, but here's a one-liner (plus import):</p>

<pre><code>from collections import OrderedDict
def dedupe(_list):
    return OrderedDict((item,None) for item in _list).keys()

&gt;&gt;&gt; dedupe(['q', 'w', 'e', 'r', 'q', 'w', 'y', 'u', 'i', 't', 'e', 'p', 't', 'y', 'e'])
['q', 'w', 'e', 'r', 'y', 'u', 'i', 't', 'p']
</code></pre>
<br />