<h3>Question (ID-1174984):</h3><h2>How to efficiently calculate a running standard deviation?</h2><p>I have an array of lists of numbers, e.g.:</p>

<pre><code>[0] (0.01, 0.01, 0.02, 0.04, 0.03)
[1] (0.00, 0.02, 0.02, 0.03, 0.02)
[2] (0.01, 0.02, 0.02, 0.03, 0.02)
     ...
[n] (0.01, 0.00, 0.01, 0.05, 0.03)
</code></pre>

<p>What I would like to do is efficiently calculate the mean and standard deviation at each index of a list, across all array elements.</p>

<p>To do the mean, I have been looping through the array and summing the value at a given index of a list. At the end, I divide each value in my "averages list" by <code>n</code>.</p>

<p>To do the standard deviation, I loop through again, now that I have the mean calculated.</p>

<p>I would like to avoid going through the array twice, once for the mean and then once for the SD (after I have a mean). </p>

<p>Is there an efficient method for calculating both values, only going through the array once? Any code in an interpreted language (e.g. Perl or Python) or pseudocode is fine.</p>
<br /><h3>Answers (Total-9):</h3><b>#0</b><br /><p>The basic answer is to accumulate the sum of both <em>x</em> (call it 'sum_x1') and <em>x</em><sup>2</sup> (call it 'sum_x2') as you go.  The value of the standard deviation is then:</p>

<pre><code>stdev = sqrt((sum_x2 / n) - (mean * mean)) 
</code></pre>

<p>where</p>

<pre><code>mean = sum_x / n
</code></pre>

<p>This is the sample standard deviation; you get the population standard deviation using 'n' instead of 'n - 1' as the divisor.</p>

<p>You may need to worry about the numerical stability of taking the difference between two large numbers if you are dealing with large samples.  Go to the external references in other answers (Wikipedia, etc) for more information.</p>
<br /><b>#1</b><br /><p>The answer is to use Welford's algorithm, which is very clearly defined after the "naive methods" in:</p>

<ul>
<li>Wikipedia: <a href="http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance" rel="nofollow">Algorithms for calculating variance</a>
</ul>

<p>It's more numerically stable than either the two-pass or online simple sum of squares collectors suggested in other responses.  The stability only really matters when you have lots of values that are close to each other as they lead to what is known as "<a href="http://www.cs.princeton.edu/introcs/lectures/9scientific.pdf" rel="nofollow">catastrophic cancellation</a>" in the floating point literature.</p>

<p>You might also want to brush up on the difference between dividing by the number of samples (N) and N-1 in the variance calculation (squared deviation).  Dividing by N-1 leads to an unbiased estimate of variance from the sample, whereas dividing by N on average underestimates variance (because it doesn't take into account the variance between the sample mean and the true mean).</p>

<p>I wrote two blog entries on the topic which go into more details, including how to delete previous values online:</p>

<ul>
<li><a href="http://lingpipe-blog.com/2009/03/19/computing-sample-mean-variance-online-one-pass/" rel="nofollow">Computing Sample Mean and Variance Online in One Pass</a>
<li><a href="http://lingpipe-blog.com/2009/07/07/welford-s-algorithm-delete-online-mean-variance-deviation/" rel="nofollow">Deleting Values in Welfordâ€™s Algorithm for Online Mean and Variance</a>
</ul>

<p>You can also take a look at my Java implement; the javadoc, source, and unit tests are all online:</p>

<ul>
<li><a href="http://alias-i.com/lingpipe/docs/api/com/aliasi/stats/OnlineNormalEstimator.html" rel="nofollow">Javadoc: <code>stats.OnlineNormalEstimator</code></a>
<li><a href="http://alias-i.com/lingpipe/src/com/aliasi/stats/OnlineNormalEstimator.java" rel="nofollow">Source: <code>stats.OnlineNormalEstimator.java</code></a>
<li><a href="http://alias-i.com/lingpipe/src/com/aliasi/test/unit/stats/OnlineNormalEstimatorTest.java" rel="nofollow">JUnit Source: <code>test.unit.stats.OnlineNormalEstimatorTest.java</code></a>
<li><a href="http://alias-i.com/lingpipe" rel="nofollow">LingPipe Home Page</a>
</ul>
<br /><b>#2</b><br /><p>Perhaps not what you were asking, but ... If you use a numpy array, it will do the work for you, efficiently:</p>

<pre><code>from numpy import array

nums = array(((0.01, 0.01, 0.02, 0.04, 0.03),
              (0.00, 0.02, 0.02, 0.03, 0.02),
              (0.01, 0.02, 0.02, 0.03, 0.02),
              (0.01, 0.00, 0.01, 0.05, 0.03)))

print nums.std(axis=1)
# [ 0.0116619   0.00979796  0.00632456  0.01788854]

print nums.mean(axis=1)
# [ 0.022  0.018  0.02   0.02 ]
</code></pre>

<p>By the way, there's some interesting discussion in this blog post and comments on one-pass methods for computing means and variances:</p>

<ul>
<li><a href="http://lingpipe-blog.com/2009/03/19/computing-sample-mean-variance-online-one-pass/" rel="nofollow">http://lingpipe-blog.com/2009/03/19/computing-sample-mean-variance-online-one-pass/</a></li>
</ul>
<br /><b>#3</b><br /><p><a href="http://search.cpan.org/perldoc/Statistics::Descriptive" rel="nofollow">Statistics::Descriptive</a> is a very decent Perl module for these types of calculations:</p>

<pre><code>#!/usr/bin/perl

use strict; use warnings;

use Statistics::Descriptive qw( :all );

my $data = [
    [ 0.01, 0.01, 0.02, 0.04, 0.03 ],
    [ 0.00, 0.02, 0.02, 0.03, 0.02 ],
    [ 0.01, 0.02, 0.02, 0.03, 0.02 ],
    [ 0.01, 0.00, 0.01, 0.05, 0.03 ],
];

my $stat = Statistics::Descriptive::Full-&gt;new;
# You also have the option of using sparse data structures

for my $ref ( @$data ) {
    $stat-&gt;add_data( @$ref );
    printf "Running mean: %f\n", $stat-&gt;mean;
    printf "Running stdev: %f\n", $stat-&gt;standard_deviation;
}
__END__
</code></pre>

<p>Output:</p>

<pre><code>C:\Temp&gt; g
Running mean: 0.022000
Running stdev: 0.013038
Running mean: 0.020000
Running stdev: 0.011547
Running mean: 0.020000
Running stdev: 0.010000
Running mean: 0.020000
Running stdev: 0.012566
</code></pre>
<br /><b>#4</b><br /><p>Have a look at <a href="http://search.cpan.org/dist/PDL/" rel="nofollow">PDL</a> (pronounced "piddle!"). </p>

<p>This is the Perl Data Language which is designed for high precision mathematics and scientific computing.</p>

<p>Here is an example using your figures....</p>

<pre><code>use strict;
use warnings;
use PDL;

my $figs = pdl [
    [0.01, 0.01, 0.02, 0.04, 0.03],
    [0.00, 0.02, 0.02, 0.03, 0.02],
    [0.01, 0.02, 0.02, 0.03, 0.02],
    [0.01, 0.00, 0.01, 0.05, 0.03],
];

my ( $mean, $prms, $median, $min, $max, $adev, $rms ) = statsover( $figs );

say "Mean scores:     ", $mean;
say "Std dev? (adev): ", $adev;
say "Std dev? (prms): ", $prms;
say "Std dev? (rms):  ", $rms;
</code></pre>

<p><br />
Which produces:</p>

<pre><code>Mean scores:     [0.022 0.018 0.02 0.02]
Std dev? (adev): [0.0104 0.0072 0.004 0.016]
Std dev? (prms): [0.013038405 0.010954451 0.0070710678 0.02]
Std dev? (rms):  [0.011661904 0.009797959 0.0063245553 0.017888544]
</code></pre>

<p><br />
Have a look at <a href="http://search.cpan.org/dist/PDL/Basic/Primitive/primitive.pd" rel="nofollow">PDL::Primitive</a> for more information on the <i>statsover</i> function.  This seems to suggest that ADEV is the "standard deviation".  </p>

<p>However it maybe PRMS (which Sinan's Statistics::Descriptive example show) or RMS (which ars's NumPy example shows).  I guess one of these three must be right ;-)</p>

<p>For more PDL information have a look at:</p>

<ul>
<li><a href="http://pdl.perl.org" rel="nofollow">pdl.perl.org</a>  (official PDL page).</li>
<li><a href="http://www.perlmonks.org/?node%5Fid=587436" rel="nofollow">PDL quick reference guide on PerlMonks</a></li>
<li><a href="http://www.ddj.com/184410442" rel="nofollow">Dr. Dobb's article on PDL</a></li>
<li><a href="http://sourceforge.net/apps/mediawiki/pdl/index.php?title=Main%5FPage" rel="nofollow">PDL Wiki</a></li>
<li><a href="http://en.wikipedia.org/wiki/Perl%5FData%5FLanguage" rel="nofollow">Wikipedia entry for PDL</a></li>
<li><a href="http://sourceforge.net/projects/pdl/" rel="nofollow">Sourceforge project page for PDL</a></li>
</ul>

<p>/I3az/</p>
<br /><b>#5</b><br /><p>How big is your array? Unless it is zillions of elements long, don't worry about looping through it twice. The code is simple and easily tested.</p>

<p>My preference would be to use the <a href="http://numpy.scipy.org/" rel="nofollow">numpy</a> array maths extension to convert your array of arrays into a numpy 2D array and get the standard deviation directly:</p>

<pre><code>&gt;&gt;&gt; x = [ [ 1, 2, 4, 3, 4, 5 ], [ 3, 4, 5, 6, 7, 8 ] ] * 10
&gt;&gt;&gt; import numpy
&gt;&gt;&gt; a = numpy.array(x)
&gt;&gt;&gt; a.std(axis=0) 
array([ 1. ,  1. ,  0.5,  1.5,  1.5,  1.5])
&gt;&gt;&gt; a.mean(axis=0)
array([ 2. ,  3. ,  4.5,  4.5,  5.5,  6.5])
</code></pre>

<p>If that's not an option and you need a pure Python solution, keep reading...</p>

<p>If your array is </p>

<pre><code>x = [ 
      [ 1, 2, 4, 3, 4, 5 ],
      [ 3, 4, 5, 6, 7, 8 ],
      ....
]
</code></pre>

<p>Then the standard deviation is:</p>

<pre><code>d = len(x[0])
n = len(x)
sum_x = [ sum(v[i] for v in x) for i in range(d) ]
sum_x2 = [ sum(v[i]**2 for v in x) for i in range(d) ]
std_dev = [ sqrt((sx2 - sx**2)/N)  for sx, sx2 in zip(sum_x, sum_x2) ]
</code></pre>

<p>If you are determined to loop through your array only once, the running sums can be combined.</p>

<pre><code>sum_x  = [ 0 ] * d
sum_x2 = [ 0 ] * d
for v in x:
   for i, t in enumerate(v):
   sum_x[i] += t
   sum_x2[i] += t**2
</code></pre>

<p>This isn't nearly as elegant as the list comprehension solution above.</p>
<br /><b>#6</b><br /><p>You could look at the Wikipedia article on <a href="http://en.wikipedia.org/wiki/Standard%5Fdeviation" rel="nofollow">Standard Deviation</a>, in particular the section about Rapid calculation methods.</p>

<p>There's also an article I found that uses Python, you should be able to use the code in it without much change: <a href="http://subluminal.wordpress.com/2008/07/31/running-standard-deviations/" rel="nofollow">Subliminal Messages - Running Standard Deviations</a>.</p>
<br /><b>#7</b><br /><p>I think this issue will help you. <a href="http://www.johndcook.com/standard%5Fdeviation.html" rel="nofollow">Standard deviation</a></p>
<br /><b>#8</b><br /><p>Here's one way to do it in Java:</p>

<pre><code>package statistics;

public class Statistics
{
    private double sum;
    private double sumOfSquares;
    private int numPoints;

    public static void main(String[] args)
    {
        double [] values = new double[args.length];

        for (int i = 0; i &lt; args.length; ++i)
        {
            values[i] = Double.parseDouble(args[i]);
        }

        Statistics statistics = new Statistics(values);
        System.out.println(statistics);
    }

    public Statistics(double [] values)
    {
        for (int i = 0; i &lt; values.length; ++i)
        {
            sum += values[i];
            sumOfSquares += values[i]*values[i];
            ++numPoints;
        }
    }

    public synchronized double getAverage()
    {
        double average = 0.0;

        if (numPoints &gt; 0)
        {
            average = sum/numPoints;            
        }

        return average;
    }

    public synchronized double getStandardDeviation()
    {
        double standardDeviation = 0.0;

        if (numPoints &gt; 1)
        {
            double average = getAverage();
            standardDeviation = Math.sqrt(sumOfSquares/numPoints - average*average);
        }

        return standardDeviation;
    }

    public  synchronized void addValue(double newValue)
    {
        sum += newValue;
        sumOfSquares += newValue*newValue;
        ++numPoints;
    }

    public String toString()
    {
        return new StringBuilder().append("Statistics{").append("sum=").append(sum).append(", sumOfSquares=").append(sumOfSquares).append(", numPoints=").append(numPoints).append(", average=").append(getAverage()).append(", std dev=").append(getStandardDeviation()).append('}').toString();
    }
</code></pre>

<p>I'm not as happy with this version, because it doesn't check for overflow in the event of a value that's equal to sqrt(Double.MAX_VALUE), but it demonstrates how to calculate mean and standard deviation using running totals instead of arrays.</p>
<br />