<h3>Question (ID-684629):</h3><h2>Looking for a recommendation of a good tutorial on best practices for a web scraping project?</h2><p>I need to do a fairly extensive project involving web scraping and am considering using Hpricot or Beautiful Soup (i.e. Ruby or Python). Has anyone come across a tutorial that they thought was particularly good on this subject that would help me start the project off on the right foot?</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>Two of my favorite tools for Python web scraping are <a href="http://scrapy.org/" rel="nofollow">Scrapy</a> and <a href="http://wwwsearch.sourceforge.net/mechanize/" rel="nofollow">Mechanize</a>. Each of these projects has its own tutorial and best practices.</p>
<br /><b>#1</b><br /><p>Not a tool, really, but a good discussion is Michael Shrenk's book, <a href="http://rads.stackoverflow.com/amzn/click/1593271204" rel="nofollow">Webbots, Spiders, and Screen Scrapers</a>.</p>

<p>The book succeeds very well in its stated mission: explaining how to build simple web bots and operate them in accordance with community standards. It’s not everything you need to know, but it’s the best introduction I’ve seen. The focus is on simple, single-threaded, bots. There’s some small mention of using multiple bots that store data in a central repository, but there’s no discussion of the issues involved in writing multi-threaded or distributed bots that can process hundreds of pages per second.</p>

<p>I recommend that you read this book if you’re at all interested in writing Web bots, even if you’re not familiar with or intending to use PHP. But be sure not to expect more than the book offers.</p>
<br /><b>#2</b><br /><p>Look into using <a href="http://codespeak.net/lxml/" rel="nofollow">lxml</a> instead of BeautifulSoup. Despite its name, it is also for parsing and scraping HTML. It's much, much faster than BeautifulSoup, and it even handles "broken" HTML better than BeautifulSoup (their claim to fame - lxml just isn't as vocal about it). It has a compatibility API for BeautifulSoup too if you don't want to learn the lxml API.</p>

<p><a href="http://blog.ianbicking.org/2008/12/10/lxml-an-underappreciated-web-scraping-library/" rel="nofollow">Ian Blicking agrees</a>.</p>

<p>There's no reason to use BeautifulSoup anymore, unless you're on Google App Engine or something where anything not purely Python isn't allowed.</p>
<br /><b>#3</b><br /><p>Take a look at the following screencasts:</p>

<ul>
<li><a href="http://railscasts.com/episodes/190-screen-scraping-with-nokogiri" rel="nofollow">http://railscasts.com/episodes/190-screen-scraping-with-nokogiri</a></li>
<li><a href="http://railscasts.com/episodes/191-mechanize" rel="nofollow">http://railscasts.com/episodes/191-mechanize</a></li>
</ul>

<p>Or if you like it plain, the corresponding asciicasts:</p>

<ul>
<li><a href="http://asciicasts.com/episodes/190-screen-scraping-with-nokogiri" rel="nofollow">http://asciicasts.com/episodes/190-screen-scraping-with-nokogiri</a></li>
<li><a href="http://asciicasts.com/episodes/191-mechanize" rel="nofollow">http://asciicasts.com/episodes/191-mechanize</a></li>
</ul>
<br /><b>#4</b><br /><p>There's an excellent <a href="http://railscasts.com/episodes/173-screen-scraping-with-scrapi" rel="nofollow">Railscasts episode</a> on ScrAPI.</p>
<br /><b>#5</b><br /><p>For Ruby, the <a href="http://scrubyt.org/" rel="nofollow">Scrubyt</a> web-scraping toolkit is excellent. Here's <a href="http://www.rubyrailways.com/data-extraction-for-web-20-screen-scraping-in-rubyrails-episode1/" rel="nofollow">an extensive introduction</a> to it, which is worth reading even if you'll be using some other tool.</p>
<br />