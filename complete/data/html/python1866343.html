<h3>Question (ID-1866343):</h3><h2>Removing an element from a list based on a predicate</h2><p>I want to remove an element from list, such that the element contains <code>'X'</code> or <code>'N'</code>. I have to apply for a large genome. Here is an example:</p>

<p>input:</p>

<pre><code>codon=['AAT','XAC','ANT','TTA']
</code></pre>

<p>expected output:  </p>

<pre><code>codon=['AAT','TTA']
</code></pre>
<br /><h3>Answers (Total-9):</h3><b>#0</b><br /><p>For basis purpose</p>

<pre><code>&gt;&gt;&gt; [x for x in ['AAT','XAC','ANT','TTA'] if "X" not in x and "N" not in x]
['AAT', 'TTA']
</code></pre>

<p>But if you have huge amount of data, I suggest you to use dict or set</p>

<p>And If you have many characters other than X and N, you may do like this</p>

<pre><code>&gt;&gt;&gt; [x for x in ['AAT','XAC','ANT','TTA'] if not any(ch for ch in list(x) if ch in ["X","N","Y","Z","K","J"])]
['AAT', 'TTA']
</code></pre>

<p>NOTE: <code>list(x)</code> can be just <code>x</code>, and <code>["X","N","Y","Z","K","J"]</code> can be just <code>"XNYZKJ"</code>, and refer gnibbler answer, He did the best one.</p>
<br /><b>#1</b><br /><p>Another not fastest way but I think it reads nicely</p>

<pre><code>&gt;&gt;&gt; [x for x in ['AAT','XAC','ANT','TTA'] if not any(y in x for y in "XN")]
['AAT', 'TTA']

&gt;&gt;&gt; [x for x in ['AAT','XAC','ANT','TTA'] if not set("XN")&amp;set(x)]
['AAT', 'TTA']
</code></pre>

<p>This way will be faster for long codons (assuming there is some repetition)</p>

<pre><code>codon = ['AAT','XAC','ANT','TTA']
def pred(s,memo={}):
    if s not in memo:
        memo[s]=not any(y in s for y in "XN")
    return memo[s]

print filter(pred,codon)
</code></pre>

<p>Here is the method suggested by James Brooks, you'd have to test to see which is faster for your data</p>

<pre><code>codon = ['AAT','XAC','ANT','TTA']
def pred(s,memo={}):
    if s not in memo:
        memo[s]= not set("XN")&amp;set(s)
    return memo[s]

print filter(pred,codon)
</code></pre>

<p>For this sample codon, the version using sets is about 10% slower</p>
<br /><b>#2</b><br /><p>There is also the method of doing it using filter</p>

<pre><code>    list = filter(lambda x: 'X' not in x and 'N' not in x, list)
</code></pre>
<br /><b>#3</b><br /><ol>
<li><code>filter(lambda x: 'N' not in x or 'X' not in x, your_list)</code></li>
<li><code>your_list = [x for x in your_list if 'N' not in x or 'X' not in x]</code></li>
</ol>
<br /><b>#4</b><br /><p>If you're dealing with extremely large lists, you want to use methods that don't involve traversing the entire list any more than you absolutely need to.  </p>

<p>Your best bet is likely to be creating a filter function, and using <code>itertools.ifilter</code>, e.g.:</p>

<pre><code>new_seq = itertools.ifilter(lambda x: 'X' in x or 'N' in x, seq)
</code></pre>

<p>This defers actually testing every element in the list until you actually iterate over it.  Note that you can filter a filtered sequence just as you can the original sequence:</p>

<pre><code>new_seq1 = itertools.ifilter(some_other_predicate, new_seq)
</code></pre>

<p><strong>Edit:</strong></p>

<p>Also, a little testing shows that memoizing found entries in a set is likely to provide enough of an improvement to be worth doing, and using a regular expression is probably not the way to go:</p>

<pre><code>seq = ['AAT','XAC','ANT','TTA']
&gt;&gt;&gt; p = re.compile('[X|N]')
&gt;&gt;&gt; timeit.timeit('[x for x in seq if not p.search(x)]', 'from __main__ import p, seq')
3.4722548536196314
&gt;&gt;&gt; timeit.timeit('[x for x in seq if "X" not in x and "N" not in x]', 'from __main__ import seq')
1.0560532134670666
&gt;&gt;&gt; s = set(('XAC', 'ANT'))
&gt;&gt;&gt; timeit.timeit('[x for x in seq if x not in s]', 'from __main__ import s, seq')
0.87923730529996647
</code></pre>
<br /><b>#5</b><br /><p>As S.Mark requested here is my version. It's probably slower but does make it easier to change what gets removed.</p>

<pre><code>def filter_genome(genome, killlist = set("X N".split()):
    return [codon for codon in genome if 0 == len(set(codon) | killlist)]
</code></pre>
<br /><b>#6</b><br /><p>Any reason for duplicating the entire list?  How about:</p>

<pre><code>&gt;&gt;&gt; def pred(item, haystack="XN"):
...     return any(needle in item for needle in haystack)
...
&gt;&gt;&gt; lst = ['AAT', 'XAC', 'ANT', 'TTA']
&gt;&gt;&gt; idx = 0
&gt;&gt;&gt; while idx &lt; len(lst):
...     if pred(lst[idx]):
...         del lst[idx]
...     else:
...         idx = idx + 1
...
&gt;&gt;&gt; lst
['AAT', 'TTA']
</code></pre>

<p>I know that list comprehensions are <em>all the rage</em> these days, but if the list is long we don't want to duplicate it without any reason right?  You can take this to the next step and create a nice utility function:</p>

<pre><code>&gt;&gt;&gt; def remove_if(coll, predicate):
...     idx = len(coll) - 1
...     while idx &gt;= 0:
...         if predicate(coll[idx]):
...             del coll[idx]
...         idx = idx - 1
...     return coll
...
&gt;&gt;&gt; lst = ['AAT', 'XAC', 'ANT', 'TTA']
&gt;&gt;&gt; remove_if(lst, pred)
['AAT', 'TTA']
&gt;&gt;&gt; lst
['AAT', 'TTA']
</code></pre>
<br /><b>#7</b><br /><p>I like gnibbler’s memoization approach a lot. Either method using memoization should be identically fast in the big picture on large data sets, as the memo dictionary should quickly be filled and the actual test should be rarely performed. With this in mind, we should be able to improve the performance even more for large data sets. (This comes at some cost for very small ones, but who cares about those?) The following code only has to look up an item in the memo dict once when it is present, instead of twice (once to determine membership, another to extract the value).</p>

<pre><code>codon = ['AAT', 'XAC', 'ANT', 'TTA']
def pred(s,memo={}):
    try:
        return memo[s]
    except KeyError:
        memo[s] = not any(y in s for y in "XN")
    return memo[s]

filtered = filter(pred, codon)
</code></pre>

<p>As I said, this should be noticeably faster when the genome is large (or at least not extremely small).</p>

<p>If you don’t want to duplicate the list, but just iterate over the filtered list, do something like:</p>

<pre><code>for item in (item for item in codon if pred):
    do_something(item)
</code></pre>
<br /><b>#8</b><br /><p>It is (asympotically) faster to use a regular expression than searching many times in the same string for a certain character: in fact, with a regular expression the sequences is only be read at most once (instead of twice when the letters are not found, in gnibbler's original answer, for instance).  With gnibbler's memoization, the regular expression approach reads:</p>

<pre><code>import re
remove = re.compile('[XN]').search

codon = ['AAT','XAC','ANT','TTA']
def pred(s,memo={}):
    if s not in memo:
        memo[s]= not remove(s)
    return memo[s]

print filter(pred,codon)
</code></pre>

<p>This should be (asymptotically) faster than using the "in s" or the "set" checks (i.e., the code above should be faster for long enough strings <code>s</code>).</p>

<p>I originally thought that gnibbler's answer could be written in a faster and more compact way with dict.setdefault():</p>

<pre><code>codon = ['AAT','XAC','ANT','TTA']
def pred(s,memo={}):
    return memo.setdefault(s, not any(y in s for y in "XN"))

print filter(pred,codon)
</code></pre>

<p>However, as gnibbler noted, the value in setdefault is always evaluated (even though, in principle, it could be evaluated only when the dictionary key is not found).</p>
<br />