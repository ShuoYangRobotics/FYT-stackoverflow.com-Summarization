<h3>Question (ID-196345):</h3><h2>How to check if a string in Python is in ASCII?</h2><p>I am fighting with Python to understand how do I check whether a string is in ASCII or not.</p>

<p>I am aware of ord(), however when I try ord('é'), I have TypeError: ord() expected a character, but string of length 2 found. I understood it is caused by the way I built Python (as explained in <a href="http://docs.python.org/library/functions.html#ord" rel="nofollow">the <code>ord()</code>'s documentation</a>). </p>

<p>So my question is simple: is there another way to check for this?</p>
<br /><h3>Answers (Total-9):</h3><b>#0</b><br /><p>I think you are not  asking the right question--</p>

<p>A string in python has no property corresponding to 'ascii', utf-8, or any other encoding. The source of your string (whether you read it from a file, input from a keyboard, etc.) may have encoded a unicode string in ascii to produce your string, but that's where you need to go for an answer.</p>

<p>Perhaps the question you can ask is: "Is this string the result of encoding a unicode string in ascii?" -- This you can answer
    by trying:</p>

<pre><code>try:
    mystring.decode('ascii')
except UnicodeDecodeError:
    print "it was not a ascii-encoded unicode string"
else:
    print "It may have been an ascii-encoded unicode string"
</code></pre>
<br /><b>#1</b><br /><pre><code>def is_ascii(s):
    return all(ord(c) &lt; 128 for c in s)
</code></pre>
<br /><b>#2</b><br /><p>Your question is incorrect; the error you see is not a result of how you built python, but of a confusion between byte strings and unicode strings.</p>

<p>Byte strings (e.g. "foo", or 'bar', in python syntax) are sequences of octets; numbers from 0-255.  Unicode strings (e.g. u"foo" or u'bar') are sequences of unicode code points; numbers from 0-1112064.  But you appear to be interested in the character é, which (in your terminal) is a multi-byte sequence that represents a single character.</p>

<p>Instead of <code>ord(u'é')</code>, try this:</p>

<pre><code>&gt;&gt;&gt; [ord(x) for x in u'é']
</code></pre>

<p>That tells you which sequence of code points "é" represents.  It may give you [233], or it may give you [101, 770].</p>

<p>Instead of <code>chr()</code> to reverse this, there is <code>unichr()</code>:</p>

<pre><code>&gt;&gt;&gt; unichr(233)
u'\xe9'
</code></pre>

<p>This character may actually be represented either a single or multiple unicode "code points", which themselves represent either graphemes or characters.  It's either "e with an acute accent (i.e., code point 233)", or "e" (code point 101), followed by "an acute accent on the previous character" (code point 770).  So this exact same character may be presented as the Python data structure <code>u'e\u0301'</code> or <code>u'\u00e9'</code>.</p>

<p>Most of the time you shouldn't have to care about this, but it can become an issue if you are iterating over a unicode string, as iteration works by code point, not by decomposable character.  In other words, <code>len(u'e\u0301') == 2</code> and <code>len(u'\u00e9') == 1</code>.  If this matters to you, you can convert between composed and decomposed forms by using <a href="http://docs.python.org/library/unicodedata.html#unicodedata.normalize" rel="nofollow"><code>unicodedata.normalize</code></a>.</p>

<p><a href="http://unicode.org/glossary/" rel="nofollow">The Unicode Glossary</a> can be a helpful guide to understanding some of these issues, by pointing how how each specific term refers to a different part of the representation of text, which is far more complicated than many programmers realize.</p>
<br /><b>#3</b><br /><p>How about doing this?</p>

<pre><code>import string

def isAscii(s):
    for c in s:
        if c not in string.ascii_letters:
            return False
    return True
</code></pre>
<br /><b>#4</b><br /><p>You could use the regular expression library which accepts the Posix standard [[:ASCII:]] definition.</p>
<br /><b>#5</b><br /><p>A sting (<code>str</code>-type) in Python is a series of bytes. There is <strong>no way</strong> of telling just from looking at the string whether this series of bytes represent an ascii string, a string in a 8-bit charset like ISO-8859-1 or a string encoded with UTF-8 or UTF-16 or whatever.</p>

<p>However if you know the encoding used, then you can <code>decode</code> the str into a unicode string and then use a regular expression (or a loop) to check if it contains characters outside of the range you are concerned about.</p>
<br /><b>#6</b><br /><p>Ran into something like this recently - for future reference</p>

<pre><code>import chardet

encoding = chardet.detect(string)
if encoding['encoding'] == 'ascii':
    print 'string is in ascii'
</code></pre>

<p>which you could use with:</p>

<pre><code>string_ascii = string.decode(encoding['encoding']).encode('ascii')
</code></pre>
<br /><b>#7</b><br /><p>Use the 'type' function:</p>

<pre><code>&gt;&gt;&gt; type('é')
&lt;type 'str'&gt;
&gt;&gt;&gt; type('é'.decode('utf-8'))
&lt;type 'unicode'&gt;
</code></pre>
<br /><b>#8</b><br /><p>I use the following to determine if the string is ascii or unicode:</p>

<pre><code>&gt;&gt; print 'test string'.__class__.__name__
str
&gt;&gt;&gt; print u'test string'.__class__.__name__
unicode
&gt;&gt;&gt; 
</code></pre>

<p>Then just use a conditional block to define the function:</p>

<pre><code>def is_ascii(input):
    if input.__class__.__name__ == "str":
        return True
    return False
</code></pre>
<br />