<h3>Question (ID-5139249):</h3><h2>python url unquote unicode </h2><p>i have a unicode string like <code>'%C3%A7%C3%B6asd+fjkls%25asd'</code> and i want to decode this string.<br>
I used urllib.unquote_plus(str) but it works wrong.</p>

<pre><code>- expected : 'çöasd+fjkls%asd '
- result : 'Ã§Ã¶asd fjkls%asd'
</code></pre>

<p>double coded utf-8 characters<code>(%C3%A7 and %C3%B6)</code> are decoded wrong.<br>
my python version is 2.7 under a linux distro<br>
what is the best way to get expected result ?</p>

<p>thanks in advance</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>You have 3 or 4 or 5 problems ... but <code>repr()</code> and <code>unicodedata.name()</code> are your friends; they unambiguously show you exactly what you have got, without the confusion engendered by people with different console encodings communicating the results of <code>print fubar</code>.</p>

<p>Summary: either (a) you start with a unicode object and apply the unquote function to that or (b) you start off with a str object and your console encoding is not UTF-8.</p>

<p>If as you say you start off with a unicode object:</p>

<pre><code>&gt;&gt;&gt; s0 = u'%C3%A7%C3%B6asd+fjkls%25asd'
&gt;&gt;&gt; print repr(s0)
u'%C3%A7%C3%B6asd+fjkls%25asd'
</code></pre>

<p>this is an accidental nonsense. If you apply <code>urllibX.unquote_YYYY()</code> to it, you get another nonsense unicode object (<code>u'\xc3\xa7\xc3\xb6asd+fjkls%asd'</code>) which would cause your shown symptoms when printed. You should convert your original unicode object to a str object immediately:</p>

<pre><code>&gt;&gt;&gt; s1 = s0.encode('ascii')
&gt;&gt;&gt; print repr(s1)
'%C3%A7%C3%B6asd+fjkls%25asd'
</code></pre>

<p>then you should unquote it:</p>

<pre><code>&gt;&gt;&gt; import urllib2
&gt;&gt;&gt; s2 = urllib2.unquote(s1)
&gt;&gt;&gt; print repr(s2)
'\xc3\xa7\xc3\xb6asd+fjkls%asd'
</code></pre>

<p>Looking at the first 4 bytes of that, it's encoded in UTF-8. If you do <code>print s2</code>, it will look OK if your console is expecting UTF-8, but if it's expecting ISO-8859-1 (aka latin1) you'll see your symptomatic rubbish (first char will be A-tilde). Let's park that thought for a moment and convert it to a Unicode object:</p>

<pre><code>&gt;&gt;&gt; s3 = s2.decode('utf8')
&gt;&gt;&gt; print repr(s3)
u'\xe7\xf6asd+fjkls%asd'
</code></pre>

<p>and inspect it to see what we've actually got:</p>

<pre><code>&gt;&gt;&gt; import unicodedata
&gt;&gt;&gt; for c in s3[:6]:
...     print repr(c), unicodedata.name(c)
...
u'\xe7' LATIN SMALL LETTER C WITH CEDILLA
u'\xf6' LATIN SMALL LETTER O WITH DIAERESIS
u'a' LATIN SMALL LETTER A
u's' LATIN SMALL LETTER S
u'd' LATIN SMALL LETTER D
u'+' PLUS SIGN
</code></pre>

<p>Looks like what you said you expected. Now we come to the question of displaying it on your console. Note: don't freak out when you see "cp850"; I'm doing this portably and just happen to be doing this in a Command Prompt on Windows.</p>

<pre><code>&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.stdout.encoding
'cp850'
&gt;&gt;&gt; print s3
çöasd+fjkls%asd
</code></pre>

<p>Note: the unicode object was explicitly decoded using sys.stdout.encoding. Fortunately all the unicode characters are representable in that encoding (and cp1252 and latin1).</p>
<br /><b>#1</b><br /><p>Try <code>urllib2</code> once more:</p>

<pre><code>print urllib2.unquote('%C3%A7%C3%B6asd+fjkls%25asd')
</code></pre>
<br /><b>#2</b><br /><p>'%C3%A7%C3%B6asd+fjkls%25asd' - this is not a unicode string. </p>

<p>This is a url-encoded string. Use urllib2.unquote() instead.</p>
<br /><b>#3</b><br /><p>You are using <code>unquote_plus</code> method which is taking <code>space</code> into account and converting to <code>+</code>. Just use <code>unquote</code> method and you should be fine.</p>

<pre><code>&gt;&gt;&gt; import urllib
&gt;&gt;&gt; print urllib.unquote('%C3%A7%C3%B6asd+fjkls%25asd')
çöasd+fjkls%asd
&gt;&gt;&gt; print urllib.unquote_plus('%C3%A7%C3%B6asd+fjkls%25asd')
çöasd fjkls%asd
</code></pre>
<br /><b>#4</b><br /><p>You have a double problem: your string is unicode encoded and contains caracter urlencoded. Some match. You can normalize your string to ascci to be sure it won't be interpreted incorrectly:</p>

<pre><code>&gt;&gt;&gt; s = '%C3%A7%C3%B6asd+fjkls%25asd' # ascii string
&gt;&gt;&gt; print urllib2.unquote(s) # works as expected
çöasd+fjkls%asd
&gt;&gt;&gt; s = u'%C3%A7%C3%B6asd+fjkls%25asd' # unicode string
&gt;&gt;&gt; print urllib2.unquote(s) # decode stuff that it shouldn't
Ã§Ã¶asd+fjkls%asd
&gt;&gt;&gt; print urllib2.unquote(s.encode('ascii')) # encode the unicode string to ascii: works!
çöasd+fjkls%asd
</code></pre>
<br /><b>#5</b><br /><p>Using either <code>unquote</code> or <code>unquote_plus</code> will give you a byte string. If you want a Unicode string then you have to decode the byte string to unicode:</p>

<pre><code>&gt;&gt;&gt; print(urllib.unquote_plus('%C3%A7%C3%B6asd+fjkls%25asd').decode('utf8'))
çöasd fjkls%asd
&gt;&gt;&gt; 
</code></pre>

<p>Compared with:</p>

<pre><code>&gt;&gt;&gt; print(urllib.unquote_plus('%C3%A7%C3%B6asd+fjkls%25asd'))
Ã§Ã¶asd fjkls%asd
&gt;&gt;&gt; 
</code></pre>

<p>Note that your input string must be a byte string: if you pass unicode to <code>unquote/unquote_plus</code> then you'll get a bit of a mess. If this is the case then encode it first:</p>

<pre><code>&gt;&gt;&gt; print(urllib.unquote_plus(u'%C3%A7%C3%B6asd+fjkls%25asd'.encode('ascii')).decode('utf8'))
çöasd fjkls%asd
</code></pre>
<br />