<h3>Question (ID-7908800):</h3><h2>Generating random numbers under very specific constraints</h2><p>I am faced with the following programming problem. I need to generate <code>n</code> <code>(a, b)</code> tuples for which the sum of all <code>a</code>'s is a given <code>A</code> and sum of all <code>b</code>'s is a given <code>B</code> and for each tuple the ratio of <code>a / b</code> is in the range <code>(c_min, c_max)</code>. <code>A / B</code> is within the same range, too. I am also trying to make sure there is no bias in the result other than what is introduced by the constraints and the <code>a / b</code> values are more-or-less uniformly distributed in the given range.</p>

<p>Some clarifications and meta-constraints:</p>

<ul>
<li><code>A</code>, <code>B</code>, <code>c_min</code>, and <code>c_max</code> are given. </li>
<li>The ratio <code>A / B</code> is in the <code>(c_min, c_max)</code> range. This has to be so if the problem is to have a solution given the other constraints.</li>
<li>a and b are <code>&gt;0</code> and non-integer.</li>
</ul>

<p>I am trying to implement this in Python but ideas in any language (English included) are much appreciated.</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>Start by generating as many identical tuples, n, as you need:</p>

<p><code>(A/n, B/n)</code></p>

<p>Now pick two tuples at random.  Make a random change to the <code>a</code> value of one, and a compensating change to the <code>a</code> value of the other, keeping everything within the given constraints.  Put the two tuples back.</p>

<p>Now pick another random pair.  This times twiddle with the <code>b</code> values.</p>

<p>Lather, rinse repeat.</p>
<br /><b>#1</b><br /><p>I think the simplest thing is to</p>

<ol>
<li><p>Use your favorite method to throw <code>n-1</code> values such that <code>\sum_i=0,n-1 a_i &lt; A</code>, and set a_n to get the right total. There are several SO question about doing that, though I've never seen a answer I'm really happy with yet. Maybe I'll write a paper or something.</p></li>
<li><p>Get the <code>n-1</code> <code>b</code>'s by throwing the <code>c_i</code> uniformly on the allowed range, and set final <code>b</code> to get the right total and check on the final c (I think it must be OK, but I haven't proven it yet).</p></li>
</ol>

<p>Note that since we have 2 hard constrains we should expect to throw <code>2n-2</code> random numbers, and this method does exactly that (on the assumption that you can do step 1 with <code>n-1</code> throws.</p>
<br /><b>#2</b><br /><p>We look for tuples a_i and b_i such that</p>

<ul>
<li>(a_1, ... a_n) and (b_1, ... b_n) have a distribution which is invariant under permutation of indices (what you would call "unbiased")</li>
<li>the ratios a_i / b_i are uniformly distributed on [cmin, cmax]</li>
<li>sum(a_i) = A, sum(b_i) = B</li>
</ul>

<p>If <code>c_min</code> and <code>c_max</code> are not too ill conditioned (ie they are not very close to another), and <code>n</code> is not very large, the following works:</p>

<ul>
<li>Generate <code>a_i</code> "uniformly" such that <code>sum a_i = A</code>: 
<ul>
<li>Draw <code>n</code> samples <code>aa_i</code> (<code>i = 1..n</code>) from some distribution (eg. uniform)</li>
<li>Divide them by their sum and multiply by A: <code>a_i = A * aa_i / sum(aa_i)</code> has desired properties.</li>
</ul></li>
<li>Generate <code>b_i</code> such that <code>sum b_i = B</code> by the same method.</li>
<li>If there exists <code>i</code> such that <code>a_i / b_i</code> is not in the interval <code>[cmin, cmax]</code>, throw away <em>all</em> the <code>a_i</code> and <code>b_i</code> and try again from the beginning.</li>
</ul>

<p>It <strong>doesn't</strong> scale well with <code>n</code>, because the set of <code>a_i</code> and <code>b_i</code> satisfying the constraints gets more and more narrow as <code>n</code> increases (and so you reject more candidates).</p>

<p>To be honest, I don't see any other simple solution. If <code>n</code> gets large and <code>cmin ~ cmax</code>, then you will have to use a sledgehammer (eg. MCMC) to generate samples from your distribution, unless there is some trick we did not see.</p>

<hr>

<p>If you really want to use MCMC algorithms, note that you can change <code>cmin</code> to <code>cmin * B / A</code> (likewise for <code>cmax</code>) and assume <code>A == B == 1</code>. The problem is then to draw uniformly on the product of two unit n-simplices (u_1...u_n, v_1...v_n) such that</p>

<pre><code>u_i / v_i \in [cmin, cmax].
</code></pre>

<p>So you have to use a MCMC algorithm (Metropolis-Hastings seems more suited) on the product of two unit n-simplices with the density</p>

<pre><code>f(u_1, ..., u_n, v_1, ..., v_n) = \prod indicator_{u_i/v_i \in [cmin, cmax]}
</code></pre>

<p>which is definitely doable (albeit involved).</p>
<br /><b>#3</b><br /><p>Blocked Gibbs sampling is pretty simple and converges to the right distribution (this is along the lines of what Alexandre is proposing).</p>

<ol>
<li>For all i, initialize a<sub>i</sub> = A / n and b<sub>i</sub> = B / n.</li>
<li>Select i â‰  j uniformly at random. With probability 1/2, update a<sub>i</sub> and a<sub>j</sub> with uniform random values satisfying the constraints. The rest of the time, do the same for b<sub>i</sub> and b<sub>j</sub>.</li>
<li>Repeat Step 2 as many times as seems to be necessary for your application. I have no idea what the convergence rate is.</li>
</ol>
<br /><b>#4</b><br /><p>So here's what I think from mathematical point of view. We have sequences <code>a_i</code> and <code>b_i</code> such that sum of <code>a_i</code> is <code>A</code> and sum of <code>b_i</code> is <code>B</code>. Furthermore <code>A/B</code> is in <code>(x,y)</code> and so is <code>a_i/b_i</code> for each <code>i</code>. Furthermore you want <code>a_i/b_i</code> to be uniformly distributed in <code>(x,y)</code>. </p>

<p>So do it starting from the end. Choose <code>c_i</code> from <code>(x,y)</code> such that they are uniformly distributed. Then we want to have the following equality <code>a_i/b_i = c_i</code>, so <code>a_i = b_i*c_i</code>.</p>

<p>Therefore we only need to find <code>b_i</code>. But we have the following system of linear equations:</p>

<pre><code>A = (sum)b_i*c_i
B = (sum)b_i
</code></pre>

<p>where <code>b_i</code> are variables. Solve it (some fancy linear algebra tricks) and you're done! </p>

<p>Note that for large enough <code>n</code> this system will have lots of solutions. They will be dependent on some parameters which you can choose randomly.</p>

<hr>

<p>Enough of the theoretical approach, let's see some practical solution.</p>

<p>// EDIT 1: Here's some hard core Python code :D</p>

<pre><code>import random
min = 0.0
max = 10.0
A = 500.0
B = 100.0

def generate(n):
    C = [min + i*(max-min)/(n+1) for i in range(1, n+1)]
    Y = [0]
    for i in range(1,n-1):
        # This line should be changed in order to always get positive numbers
        # It should be relatively easy to figure out some good random generator
        Y.append(random.random())
    val = A - C[0]*B
    for i in range(1, n-1):
        val -= Y[i] * (C[i] - C[0])
    val /= (C[n-1] - C[0])
    Y.append(val)
    val = B
    for i in range(1, n):
        val -= Y[i]
    Y[0] = val
    result = []
    for i in range(0, n):
        result.append([ Y[i]*C[i], Y[i] ])
    return result
</code></pre>

<p>The result is a list of pairs <code>(X,Y)</code> satisfying your conditions with the exception that they may be negative (see the random generator line in code) i.e. the first and the last pair may contain negative numbers.</p>

<p>// EDIT 2:</p>

<p>Too ensure that they are positive you may try something like</p>

<pre><code>Y.append(random.random() * B / n)
</code></pre>

<p>instead of</p>

<pre><code>Y.append(random.random())
</code></pre>

<p>I'm not sure though.</p>

<p>// EDIT 3:</p>

<p>In order to have better results try something like this:</p>

<pre><code>avrg = B / n
ran = avrg / 20
for i in range(1, n-1):
    Y.append(random.gauss(avrg, ran))
</code></pre>

<p>instead of </p>

<pre><code>for i in range(1, n-1):
    Y.append(random.random())
</code></pre>

<p>This will make all <code>b_i</code> to be near <code>B / n</code>. Unfortunetly the last term will still sometimes jump high. I'm sorry, but there is no way to avoid this (mathematics) since the last and the first terms depend on the others. For small <code>n</code> (~100) it looks good though. Unfortunetly some negative values may appear.</p>

<p>The choice of a correct generator is not so simple if you additionally want <code>b_i</code> to be uniformly distributed.</p>
<br /><b>#5</b><br /><p>Lots of good ideas here. Thanks! <strong>Rossum</strong>'s idea seemed the most straightforward implementation-wise so I went for it. Here is the code for posterity:</p>

<pre><code>c_min = 0.25
c_max = 0.75
a_sum = 100.0
b_sum = 200.0
n = 1000 

a = [a_sum / n] * n
b = [b_sum / n] * n

while not good_enough(a, b):
    i, j = random.sample(range(n), 2)
    li, ui = c_min * b[i] - a[i], c_max * b[i] - a[i]
    lj, uj = a[j] - c_min * b[j], a[j] - c_max * b[j]
    llim = max((li, uj))
    ulim = min((ui, lj))
    q = random.uniform(llim, ulim)
    a[i] += q
    a[j] -= q

    i, j = random.sample(range(n), 2)
    li, ui = a[i] / c_max - b[i], a[i] / c_min - b[i]
    lj, uj = b[j] - a[j] / c_max, b[j] - a[j] / c_min
    llim = max((li, uj))
    ulim = min((ui, lj))
    q = random.uniform(llim, ulim)
    b[i] += q
    b[j] -= q
</code></pre>

<p>The <code>good_enough(a, b)</code> function can be a lot of things. I tried:</p>

<ul>
<li>Standard deviation, which is hit or miss, as you don't know what is a good enough value.</li>
<li>Kurtosis, where a large negative value would be nice. However, it is relatively slow to calculate and is undefined with the seed values of <code>(a_sum / n, b_sum / n)</code> (though that's trivial to fix).</li>
<li>Skewness, where a value close to <code>0</code> is desirable. But it has the same drawbacks as kurtosis.</li>
<li>A number of iterations proportional to <code>n</code>. <code>2n</code> sometimes wasn't enough, <code>n ^ 2</code> is a little bit of overkill and is, well, exponential.</li>
</ul>

<p>Ideally, a heuristic using a combination of skewness and kurtosis would be best but I settled for making sure each value has been changed from the initial (again, as <strong>rossum</strong> suggested in a comment). Though there is no theoretical guarantee that the loop will complete, it seemed to work well enough for me.</p>
<br />