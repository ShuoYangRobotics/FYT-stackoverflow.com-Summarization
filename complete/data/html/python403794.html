<h3>Question (ID-403794):</h3><h2>Optimization in Python - do's, don'ts and rules of thumb</h2><p>Well I was reading this <a href="http://handyfloss.wordpress.com/2008/02/17/summary-of-my-python-optimization-adventures/" rel="nofollow">post</a> and then I came across a code which was:</p>

<pre><code>jokes=range(1000000)
domain=[(0,(len(jokes)*2)-i-1) for i in range(0,len(jokes)*2)]
</code></pre>

<p>I thought wouldn't it be better to calculate the value of len(jokes) once outside the list comprehension?</p>

<p>Well I tried it and timed three codes</p>

<pre><code>jv@Pioneer:~$ python -m timeit -s 'jokes=range(1000000);domain=[(0,(len(jokes)*2)-i-1) for i in range(0,len(jokes)*2)]'
10000000 loops, best of 3: 0.0352 usec per loop
jv@Pioneer:~$ python -m timeit -s 'jokes=range(1000000);l=len(jokes);domain=[(0,(l*2)-i-1) for i in range(0,l*2)]'
10000000 loops, best of 3: 0.0343 usec per loop
jv@Pioneer:~$ python -m timeit -s 'jokes=range(1000000);l=len(jokes)*2;domain=[(0,l-i-1) for i in range(0,l)]'
10000000 loops, best of 3: 0.0333 usec per loop
</code></pre>

<p>Observing the marginal difference 2.55% between the first and the second made me think - is the first list comprehension </p>

<pre><code>domain=[(0,(len(jokes)*2)-i-1) for i in range(0,len(jokes)*2)]
</code></pre>

<p>optimized internally by python? or is 2.55% a big enough optimization (given that the len(jokes)=1000000)?</p>

<p>If this is - What are the other implicit/internal optimizations in Python ?</p>

<p>What are the <code>developer's rules of thumb for optimization in Python</code>?</p>

<p><strong>Edit1</strong>: Since most of the answers are "don't optimize, do it later if its slow" and I got some tips and links from <code>Triptych</code> and <code>Ali A</code> for the <strong>do's</strong>.
I will change the question a bit and request for <strong>don'ts</strong>. </p>

<p>Can we have some experiences from people who faced the '<strong>slowness</strong>', what was the problem and how it was corrected? </p>

<p><strong>Edit2</strong>: For those who haven't here is an <a href="http://www.python.org/doc/essays/list2str/" rel="nofollow">interesting read</a></p>

<p><strong>Edit3:</strong> Incorrect usage of <code>timeit</code> in question please see <strong>dF's</strong> answer for correct usage and hence timings for the three codes.</p>
<br /><h3>Answers (Total-8):</h3><b>#0</b><br /><p>You're not using <a href="http://docs.python.org/library/timeit.html" rel="nofollow"><code>timeit</code></a> correctly: the argument to <code>-s</code> (setup) is a statement to be executed once initially, so you're really just testing an empty statement. You want to do</p>

<pre><code>$ python -m timeit -s "jokes=range(1000000)" "domain=[(0,(len(jokes)*2)-i-1) for i in range(0, len(jokes)*2)]"
10 loops, best of 3: 1.08 sec per loop
$ python -m timeit -s "jokes=range(1000000)" "l=len(jokes);domain=[(0,(l*2)-i-1) for i in range(0, l*2)]"
10 loops, best of 3: 908 msec per loop
$ python -m timeit -s "jokes=range(1000000)" "l=len(jokes*2);domain=[(0,l-i-1) for i in range(0, l)]"
10 loops, best of 3: 813 msec per loop
</code></pre>

<p>While the speedup is still not dramatic, it's more significant (16% and 25% respectively). So since it doesn't make the code any more complicated, this simple optimization is probably worth it.</p>

<p>To address the actual question... the usual rule of thumb in Python is to </p>

<ol>
<li><p>Favor straightforward and readable code over optimization when coding. </p></li>
<li><p>Profile your code (<a href="http://docs.python.org/library/profile.html" rel="nofollow"><code>profile / cProfile</code> and <code>pstats</code></a> are your friends) to figure out what you need to optimize (usually things like tight loops). </p></li>
<li><p>As a last resort, re-implement these as C extensions, which is made much easier with tools like <a href="http://www.cosc.canterbury.ac.nz/greg.ewing/python/Pyrex/" rel="nofollow">pyrex</a> and <a href="http://www.cython.org/" rel="nofollow">cython</a>.</p></li>
</ol>

<p>One thing to watch out for: compared to many other languages, function calls are relatively expensive in Python which is why the optimization in your example made a difference even though <code>len</code> is O(1) for lists.</p>
<br /><b>#1</b><br /><p>Read this: <a href="http://wiki.python.org/moin/PythonSpeed/PerformanceTips" rel="nofollow">Python Speed / Performance Tips</a></p>

<p>Also, in your example, the total time is so short that the margin of error will outweigh any actual difference in speed.</p>
<br /><b>#2</b><br /><p>This applies to all programming, not just Python:</p>

<ol>
<li>Profile</li>
<li>Identify bottlenecks</li>
<li>Optimize</li>
</ol>

<p>And I would even add not to bother doing any of that unless you have a slowness issue that is causing you pain.</p>

<p>And perhaps most important is that Unit tests will help you during the actual process.</p>
<br /><b>#3</b><br /><p>On a tangentially related note, chaining together generators is much more efficient than chaining together list comprehensions, and often more intuitive.</p>

<p>As for the developer's rules of thumb for optimization in Python, they're the same as they are in all languages.</p>

<ol>
<li>Don't optimize.</li>
<li>(advanced) Optimize later.</li>
</ol>
<br /><b>#4</b><br /><p>len for lists is O(1).  It doesn't need to scan the whole list to find the length, because the size of the list is stored for lookup.  But apparently, it is still slightly faster to extract it into a local variable.  </p>

<p>To answer your question though, I would never care about performance variations on the order of 5%, unless I was doing some crazy tight inner loop optimizations in some simulation or something.  And in that case, you could speed this up much more by not using range at all.</p>
<br /><b>#5</b><br /><p>The most important thing to do is to write idiomatic, clear, and beautiful Python code. Many common tasks are already found in the stdlib, so you don't have to rewrite a slower version. (I'm thinking of string methods and itertools specifically here.) Make liberal use of Python's builtin containers, too. dict for example has had "the snot optimized" out of it, and it's said that Python code using dicts will be faster than plain C!</p>

<p>If that's not already fast enough, there are some hacks you can use, but it's also signal that you probably should be offloading some work to C extension modules.</p>

<p>Regarding list comprehensions: CPython is able to do a few optimizations over regular accumulator loops. Namely the LIST_APPEND opcode makes appending to a list native operation.</p>
<br /><b>#6</b><br /><p>I have a program that parses log files and generates a data warehouse. A typical run involves around 200M log file lines, and runs for the better part of a day. Well worth optimizing!</p>

<p>Since it's a parser, and parsing some rather variable and idiosyncratic and untrustworthy text at that, there are around 100 regular expressions, dutifully re.compiled() in advance, and applied to each of the 200M log file lines. I was pretty sure they were my bottleneck, and had been pondering how to improve that situation. Had some ideas: on the one hand, make fewer, fancier REs; on the other, more and simpler; stuff like that.</p>

<p>I profiled with CProfile, and looked at the result in "runsnake".</p>

<p>RE processing was only about 10% of code execution time. That's not it!</p>

<p>In fact, a large square blob in the runsnake display instantly told me that about 60% of my time was spent in one of those infamous "one line changes" I'd added one day, eliminating non-printing characters (which appear occasionally, but always represent something so bogus I really don't care about it). These were confusing my parse and throwing exceptions, which I <em>did</em> care about because it halted my day of log file analysis.</p>

<blockquote>
  <p>line = ''.join([c for c in line if curses.ascii.isprint(c) ])</p>
</blockquote>

<p>There you go: that line touches every <strong>byte</strong> of every one of those 200M lines (and the lines average a couple hundred bytes long). No wonder it's 60% of my execution time!</p>

<p>There are better ways to handle this, I now know, such as str.translate(). But such lines are rare, and I don't care about them anyway, and they end up throwing an exception: now I just catch the exception at the right spot and skip the line. Voila! the program's around 3X faster, instantly!</p>

<p>So the profiling</p>

<ol>
<li>highlighted, in around one second, where the problem actually was</li>
<li>drew my attention away from a mistaken assumption about where the problem was (which might be the even greater pay-off)</li>
</ol>
<br /><b>#7</b><br /><blockquote>
  <p>Can we have some experiences from
  people who faced the 'slowness', what
  was the problem and how it was
  corrected?</p>
</blockquote>

<p>The problem was slow data retrieval in a GUI app.  I gained a 50x speedup by adding an index to the table, and was widely hailed as a hero and savior.</p>
<br />