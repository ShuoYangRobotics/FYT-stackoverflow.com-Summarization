<h3>Question (ID-818402):</h3><h2>Letting users upload Python scripts for execution</h2><p>I understand that letting any anonymous user upload any sort of file in general can be dangerous, especially if it's code. However, I have an idea to let users upload custom AI scripts to my website. I would provide the template so that the user could compete with other AI's in an online web game I wrote in Python. I either need a solution to ensure a user couldn't compromise any other files or inject malicious code via their uploaded script or a solution for client-side execution of the game. Any suggestions? (I'm looking for a solution that will work with my Python scripts)</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>Using PyPy you can create a python sandbox.  The sandbox is a separate and supposedly secure python environment where you can execute their scripts.  More info here</p>

<p><a href="http://codespeak.net/pypy/dist/pypy/doc/sandbox.html" rel="nofollow">http://codespeak.net/pypy/dist/pypy/doc/sandbox.html</a></p>

<p>"In theory it's impossible to do anything bad or read a random file on the machine from this prompt."</p>

<p>"This is safe to do even if script.py comes from some random untrusted source, e.g. if it is done by an HTTP server."</p>
<br /><b>#1</b><br /><p>I am in no way associated with this site and I'm only linking it because it tries to achieve what you are getting after: jailing of python.  The site is <a href="http://codepad.org/about" rel="nofollow">code pad</a>.</p>

<p>According to the about page it is ran under <a href="http://www.xs4all.nl/~weegen/eelis/geordi/" rel="nofollow">geordi</a> and traps all sys calls with ptrace.  In addition to be chroot'ed they are on a virtual machine with firewalls in place to disallow outbound connections.</p>

<p>Consider it a starting point but I do have to chime in on the whole danger thing.  Gotta CYA myself. :)</p>
<br /><b>#2</b><br /><p>Along with other safeguards, you can also incorporate human review of the code.  Assuming part of the experience is reviewing other members' solutions, and everyone is a python developer, don't allow new code to be activated until a certain number of members vote for it.  Your users aren't going to approve malicious code. </p>
<br /><b>#3</b><br /><p>Yes.</p>

<p>Allow them to script their client, not your server.</p>
<br /><b>#4</b><br /><p>PyPy is probably a decent bet on the server side as suggested, but I'd look into having your python backend provide well defined APIs and data formats and have the users implement the AI and logic in Javascript so it can run in their browser. So the interaction would look like: For each match/turn/etc, pass data to the browser in a well defined format, provide a javascript template that receives the data and can implement logic, and provide web APIs that can be invoked by the client (browser) to take the desired actions. That way you don't have to worry about security or server power.</p>
<br /><b>#5</b><br /><p>Have an extensive API for the users and strip all other calls upon upload (such as import statements).  Also, strip everything that has anything to do with file i/o.</p>

<p>(You might want to do multiple passes to ensure that you didn't miss anything.)</p>
<br />