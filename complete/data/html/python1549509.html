<h3>Question (ID-1549509):</h3><h2>Remove duplicates in a list while keeping its order (Python)</h2><p>This is actually an extension of this question. The answers of that question did not keep the "order" of the list after removing duplicates. <a href="http://stackoverflow.com/questions/1534736/how-to-remove-these-duplicates-in-a-list-python">http://stackoverflow.com/questions/1534736/how-to-remove-these-duplicates-in-a-list-python</a></p>

<pre><code>biglist = 

[ 

    {'title':'U2 Band','link':'u2.com'}, 
    {'title':'Live Concert by U2','link':'u2.com'},
    {'title':'ABC Station','link':'abc.com'}

]
</code></pre>

<p>In this case, the 2nd element should be removed because a previous "u2.com" element already exists.  However, the order should be kept.</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>My answer to your other question, which you completely ignored!, shows you're wrong in claiming that  </p>

<blockquote>
  <p>The answers of that question did not
  keep the "order"</p>
</blockquote>

<ul>
<li>my answer <strong>did</strong> keep order, and it clearly <strong>said</strong> it did.  Here it is again, with added emphasis to see if you can just keep ignoring it...:</li>
</ul>

<p>Probably the fastest approach, for a really big list, <strong>if you want to preserve the exact order of the items that remain</strong>, is the following...:</p>

<pre><code>biglist = [ 
    {'title':'U2 Band','link':'u2.com'}, 
    {'title':'ABC Station','link':'abc.com'}, 
    {'title':'Live Concert by U2','link':'u2.com'} 
]

known_links = set()
newlist = []

for d in biglist:
  link = d['link']
  if link in known_links: continue
  newlist.append(d)
  known_links.add(link)

biglist[:] = newlist
</code></pre>
<br /><b>#1</b><br /><p>Generators are great.</p>

<pre><code>def unique( seq ):
    seen = set()
    for item in seq:
        if item not in seen:
            seen.add( item )
            yield item

biglist[:] = unique( biglist )
</code></pre>
<br /><b>#2</b><br /><p>This page discusses different methods and their speeds:
<a href="http://www.peterbe.com/plog/uniqifiers-benchmark" rel="nofollow">http://www.peterbe.com/plog/uniqifiers-benchmark</a></p>

<p>The recommended* method:</p>

<pre><code>def f5(seq, idfun=None):  
    # order preserving 
    if idfun is None: 
        def idfun(x): return x 
    seen = {} 
    result = [] 
    for item in seq: 
        marker = idfun(item) 
        # in old Python versions: 
        # if seen.has_key(marker) 
        # but in new ones: 
        if marker in seen: continue 
        seen[marker] = 1 
        result.append(item) 
    return result

f5(biglist,lambda x: x['link'])
</code></pre>

<p>*by that page</p>
<br /><b>#3</b><br /><pre><code>dups = {}
newlist = []
for x in biglist:
    if x['link'] not in dups:
      newlist.append(x)
      dups[x['link']] = None

print newlist
</code></pre>

<p>produces</p>

<pre><code>[{'link': 'u2.com', 'title': 'U2 Band'}, {'link': 'abc.com', 'title': 'ABC Station'}]
</code></pre>

<p>Note that here I used a dictionary. This makes the test <code>not in dups</code> much more efficient than using a list.</p>
<br /><b>#4</b><br /><p>A super easy way to do this is:</p>

<pre><code>def uniq(a):
    if len(a) == 0:
        return []
    else:
        return [a[0]] + uniq([x for x in a if x != a[0]])
</code></pre>

<p>This is not the most efficient way, because:</p>

<ul>
<li>it searches through the whole list for every element in the list, so it's O(n^2)</li>
<li>it's recursive so uses a stack depth equal to the length of the list</li>
</ul>

<p>However, for simple uses (no more than a few hundred items, not performance critical) it is sufficient.</p>
<br /><b>#5</b><br /><p>I think using a set should be pretty efficent.</p>

<pre><code>seen_links = set()
for index in len(biglist):
    link = biglist[index]['link']
    if link in seen_links:
        del(biglist[index])
    seen_links.add(link)
</code></pre>

<p>I think this should come in at O(nlog(n))</p>
<br />