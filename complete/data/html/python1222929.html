<h3>Question (ID-1222929):</h3><h2>GIL in Python 3.1</h2><p>Does anybody knows fate of Global Interpreter Lock in Python 3.1 against C++ multithreading integration</p>
<br /><h3>Answers (Total-7):</h3><b>#0</b><br /><p>GIL is still there in CPython 3.1; the <a href="http://code.google.com/p/unladen-swallow/" rel="nofollow">Unladen Swallow</a> projects aims (among many other performance boosts) to eventually remove it, but it's still a way from its goals, and is working on 2.6 first with the intent of eventually porting to 3.x for whatever x will be current by the time the 2.y version is considered to be done. For now, multiprocessing (instead of threading) remains the way of choice for using multiple cores in CPython (IronPython and Jython are fine too, but they don't support Python 3 currently, nor do they make C++ integration all that easy either;-).</p>
<br /><b>#1</b><br /><p>The GIL is a good thing.</p>

<p>Just make your C++ application release the GIL while it is doing its multithreaded work. Python code will continue to run in the other threads, unspoiled. Only acquire the GIL when you have to touch python objects.</p>
<br /><b>#2</b><br /><p>The GIL will not affect your code which does not use python objects. In Numpy, we release the GIL for computational code (linear algebra calls, etc...), and the underlying code can use multithreading freely (in fact, those are generally 3rd party libraries which do not know anything about python)</p>
<br /><b>#3</b><br /><p>Significant changes will occur in the GIL for Python 3.2. Take a look at the <a href="http://docs.python.org/dev/py3k/whatsnew/3.2.html#multi-threading" rel="nofollow">What's New for Python 3.2</a>, and <a href="http://mail.python.org/pipermail/python-dev/2009-October/093359.html" rel="nofollow">the thread that initiated it in the mailing list</a>.</p>

<p>While the changes don't signify the end of the GIL, they herald potentially enormous performance gains.</p>

<h2>Update0</h2>

<ul>
<li>The general performance gains with the new GIL in 3.2 by Antoine Pitrou were negligible, and instead focused on <a href="http://bugs.python.org/issue7316" rel="nofollow">improving contention issues</a> that arise in certain corner cases.</li>
<li>An <a href="http://bugs.python.org/issue7946" rel="nofollow">admirable effort</a> by David Beazley was made to implement a scheduler to significantly improve performance when CPU and IO bound threads are mixed, which was unfortunately shot down.</li>
<li>The Unladen Swallow work was <a href="http://www.python.org/dev/peps/pep-3146/" rel="nofollow">proposed for merging</a> in Python 3.3, but this has been withdrawn due to lack of results in that project. <a href="http://pypy.org/" rel="nofollow">PyPy</a> is now the preferred project and is currently <a href="http://pypy.org/py3donate.html" rel="nofollow">requesting funding</a> to add Python3k support. There's very little chance that PyPy will become the default at present.</li>
</ul>

<p>Efforts have been made for the last 15 years to remove the GIL from CPython but for the foreseeable future it is here to stay.</p>
<br /><b>#4</b><br /><p>I guess there will always be a GIL.
The reason is performance. Making all the low level access thread safe - means putting a mutex around each hash operation etc. is heavy. Remember that a simple statement like</p>

<pre><code>self.foo(self.bar, 3, val)
</code></pre>

<p>Might already have at least 3 (if val is a global) hashtable lookups at the moment and maybe even much more if the method cache is not hot (depending on the inheritance depth of the class)</p>

<p>It's expensive - that's why Java dropped the idea and introduced hashtables which do not use a monitor call to get rid of its "Java Is Slow" trademark.</p>
<br /><b>#5</b><br /><p>As I understand it the "brainfuck" scheduler will replace the GIL from python 3.2</p>

<p><a href="http://bugs.python.org/issue7946" rel="nofollow">BFS bainfuck scheduler</a></p>
<br /><b>#6</b><br /><p>If the GIL is getting in the way, just use the <a href="http://docs.python.org/dev/library/multiprocessing.html" rel="nofollow">multiprocessing</a> module. It spawns new processes but uses the threading model and (most of the) api. In other words, you can do process-based parallelism in a thread-like way.</p>
<br />