<h3>Question (ID-4132207):</h3><h2>Massive Python set of integers using too much memory</h2><p><strong>Setup</strong></p>

<ul>
<li>Python 2.6</li>
<li>Ubuntu x64</li>
</ul>

<p>I have a set of unique integers with values between 1 and 50 million. New integers are added at random e.g. <code>numberset.add(random.randint(1, 50000000))</code>. I need to be able to quickly add new integers and quickly check if an integer is already present.</p>

<p><strong>Problem</strong></p>

<p>After a while, the set grows too large for my low memory system and I experience <code>MemoryError</code>s.</p>

<p><strong>Question</strong></p>

<p>How can I achieve this while using less memory? What's the fastest way to do this using the disk without reconfiguring the system e.g. swapfiles? Should I use a database file like sqlite? Is there a library that will compress the integers in memory?</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>Use a <a href="http://pypi.python.org/pypi/bitarray/0.3.2" rel="nofollow">bit-array</a>.This will reduce the need for huge space requirement.</p>

<p><strong>Realted SO Question:</strong></p>

<ul>
<li><a href="http://stackoverflow.com/q/3946086/306855">Python equivalent to Java's BitSet</a></li>
</ul>
<br /><b>#1</b><br /><p>You can avoid dependencies on 3rd-party bit-array modules by writing your own -- the functionality required is rather minimal:</p>

<pre><code>import array

BITS_PER_ITEM = array.array('I').itemsize * 8

def make_bit_array(num_bits, initially=0):
    num_items = (num_bits + BITS_PER_ITEM - 1) // BITS_PER_ITEM
    return array.array('I', [initially]) * num_items

def set_bit(bit_array, offset):
    item_index = offset // BITS_PER_ITEM
    bit_index = offset % BITS_PER_ITEM
    bit_array[item_index] |= 1 &lt;&lt; bit_index

def clear_bit(bit_array, offset):
    item_index = offset // BITS_PER_ITEM
    bit_index = offset % BITS_PER_ITEM
    bit_array[item_index] &amp;= ~(1 &lt;&lt; bit_index)

def get_bit(bit_array, offset):
    item_index = offset // BITS_PER_ITEM
    bit_index = offset % BITS_PER_ITEM
    return (bit_array[item_index] &gt;&gt; bit_index) &amp; 1
</code></pre>
<br /><b>#2</b><br /><p>Try to use <strong>array</strong> module.</p>
<br /><b>#3</b><br /><p>Use an array of bits as flags for each integer - the memory needed will be only 50 million bits (about 6 MB). There are a few modules that can help. This example uses <a href="http://python-bitstring.googlecode.com" rel="nofollow">bitstring</a>, another option is <a href="http://pypi.python.org/pypi/bitarray" rel="nofollow">bitarray</a>:</p>

<pre><code>from bitstring import BitArray
i = BitArray(50000000) # initialise 50 million zero bits
for x in xrange(100):
    v = random.randint(1, 50000000)
    if not i[v]: # Test if it's already present
        i.set(1, v) # Set a single bit
</code></pre>

<p>Setting and checking bits is very fast and it uses very little memory.</p>
<br /><b>#4</b><br /><p>If integers are unique then use bits. Example: binary <code>01011111</code> means that there are: 1, 3, 4, 5, 6 and 7. This way every bit is used to check if its integer index is used (value 1) or not (value 0).</p>

<p>It was described in <a href="http://www.cs.bell-labs.com/cm/cs/pearls/sec014.html" rel="nofollow">one chapter of "Programming Pearls" by Jon Bentley</a> (look for "The file contains at most ten million records; each record is a seven-digit integer.")</p>

<p>It seems that there is <a href="http://pypi.python.org/pypi/bitarray/" rel="nofollow"><code>bitarray</code></a> module mentioned by Emil that works this way.</p>
<br /><b>#5</b><br /><p>Depending on your requirements, you might also consider a <a href="http://en.wikipedia.org/wiki/Bloom_filter" rel="nofollow">bloom filter</a>. It is a memory-efficient data structure for testing if an element is in a set. The catch is that it it can give false-positives, though it will never give false-negatives.</p>
<br />