<h3>Question (ID-3094498):</h3><h2>How can I check if a Python unicode string contains non-Western letters?</h2><p>I have a Python Unicode string. I want to make sure it only contains letters from the Roman alphabet (A through Z), as well as letters commonly found in European alphabets, such as ß, ü, ø, é, à, and î. It should <em>not</em> contain characters from other alphabets (Chinese, Japanese, Korean, Arabic, Cyrillic, Hebrew, etc.). What's the best way to go about doing this?</p>

<p>Currently I am using this bit of code, but I don't know if it's the best way:</p>

<pre><code>def only_roman_chars(s):
    try:
        s.encode("iso-8859-1")
        return True
    except UnicodeDecodeError:
        return False
</code></pre>

<p>(I am using Python 2.5. I am also doing this in Django, so if the Django framework happens to have a way to handle such strings, I can use that functionality -- I haven't come across anything like that, however.)</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><pre><code>import unicodedata as ud

latin_letters= {}

def is_latin(uchr):
    try: return latin_letters[uchr]
    except KeyError:
         return latin_letters.setdefault(uchr, 'LATIN' in ud.name(uchr))

def only_roman_chars(unistr):
    return all(is_latin(uchr)
           for uchr in unistr
           if uchr.isalpha()) # isalpha suggested by John Machin

&gt;&gt;&gt; only_roman_chars(u"ελληνικά means greek")
False
&gt;&gt;&gt; only_roman_chars(u"frappé")
True
&gt;&gt;&gt; only_roman_chars(u"hôtel lœwe")
True
&gt;&gt;&gt; only_roman_chars(u"123 ångstrom ð áß")
True
&gt;&gt;&gt; only_roman_chars(u"russian: гага")
False
</code></pre>
<br /><b>#1</b><br /><p>For what you say you want to do, your approach is about right. If you are running on Windows, I'd suggest using <code>cp1252</code> instead of <code>iso-8859-1</code>. You might also allow <code>cp1250</code> as well -- this would pick up eastern European countries like Poland, Czech Republic, Slovakia, Romania, Slovenia, Hungary, Croatia, etc where the alphabet is Latin-based. Other cp125x would include Turkish and Maltese ...</p>

<p>You may also like to consider transcription from Cyrillic to Latin; as far as I know there are several systems, one of which may be endorsed by the UPU (Universal Postal Union).</p>

<p>I'm a little intrigued by your comment "Our shipping department doesn't want to have to fill out labels with, e.g., Chinese addresses" ... three questions: (1) do you mean "addresses in country X" or "addresses written in X-ese characters" (2) wouldn't it be better for your system to print the labels? (3) how does the order get shipped if it fails your test?</p>
<br /><b>#2</b><br /><p>check the code in <code>django.template.defaultfilters.slugify</code></p>

<pre><code>import unicodedata
value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore')
</code></pre>

<p>is what you are looking for, you can then compare the resulting string with the original</p>
<br /><b>#3</b><br /><p>Checking for ISO-8559-1 would miss reasonable Western characters like 'œ' and '€'.  The solution depends on how you define "Western", and how you want to handle non-letters.  Here's one approach:</p>

<pre><code>import unicodedata

def is_permitted_char(char):
    cat = unicodedata.category(char)[0]
    if cat == 'L': # Letter
        return 'LATIN' in unicodedata.name(char, '').split()
    elif cat == 'N': # Number
        # Only DIGIT ZERO - DIGIT NINE are allowed
        return '0' &lt;= char &lt;= '9'
    elif cat in ('S', 'P', 'Z'): # Symbol, Punctuation, or Space
        return True
    else:
        return False

def is_valid(text):
    return all(is_permitted_char(c) for c in text)
</code></pre>
<br /><b>#4</b><br /><p>Maybe this will do if you're a django user?</p>

<pre><code>from django.template.defaultfilters import slugify 

def justroman(s):
  return len(slugify(s)) == len(s)
</code></pre>
<br /><b>#5</b><br /><p>You can use unicodedata to check <a href="http://www.fileformat.info/info/unicode/category/index.htm" rel="nofollow">character category</a></p>

<pre><code>import unicodedata
unicodedata.category(u'a') # returns 'Ll'
unicodedata.category(u'א') # returns 'Lo'
</code></pre>
<br />