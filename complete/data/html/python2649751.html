<h3>Question (ID-2649751):</h3><h2>python remove everything between <div class="comment> .. any... </div></h2><p>how do you use python 2.6 to remove everything including the <code>&lt;div class="comment"&gt; ....remove all ....&lt;/div&gt;</code></p>

<p>i tried various way using re.sub without any success</p>

<p>Thank you</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>This can be done easily and reliably using an HTML parser like <a href="http://www.crummy.com/software/BeautifulSoup/" rel="nofollow">BeautifulSoup</a>:</p>

<pre><code>&gt;&gt;&gt; from BeautifulSoup import BeautifulSoup
&gt;&gt;&gt; soup = BeautifulSoup('&lt;body&gt;&lt;div&gt;1&lt;/div&gt;&lt;div class="comment"&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/div&gt;&lt;/body&gt;')
&gt;&gt;&gt; for div in soup.findAll('div', 'comment'):
...   div.extract()
... 
&lt;div class="comment"&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/div&gt;
&gt;&gt;&gt; soup
&lt;body&gt;&lt;div&gt;1&lt;/div&gt;&lt;/body&gt;
</code></pre>

<p>See this question for examples on <a href="http://stackoverflow.com/questions/701166/can-you-provide-some-examples-of-why-it-is-hard-to-parse-xml-and-html-with-a-rege">why parsing HTML using regular expressions is a bad idea</a>.</p>
<br /><b>#1</b><br /><p>You cannot properly parse HTML with regular expressions. Use a HTML parser such as <a href="http://codespeak.net/lxml/" rel="nofollow">lxml</a> or <a href="http://www.crummy.com/software/BeautifulSoup/" rel="nofollow">BeautifulSoup</a>.</p>
<br /><b>#2</b><br /><p>With <a href="http://codespeak.net/lxml/lxmlhtml.html" rel="nofollow">lxml.html</a>:</p>

<pre><code>from lxml import html
doc = html.fromstring(input)
for el in doc.cssselect('div.comment'):
    el.drop_tree()
result = html.tostring(doc)
</code></pre>
<br /><b>#3</b><br /><p>For the record, it is usually a bad idea to process XML with regular expressions. Nevertheless:</p>

<pre><code>&gt;&gt;&gt; re.sub('&gt;[^&lt;]*', '&gt;', '&lt;div class="comment&gt; .. anyâ€¦ &lt;/div&gt;')
'&lt;div class="comment&gt;&lt;/div&gt;'
</code></pre>
<br /><b>#4</b><br /><p>non regex way</p>

<pre><code>pat='&lt;div class="comment"&gt;'
for chunks in htmlstring.split("&lt;/div&gt;"):
    m=chunks.find(pat)
    if m!=-1:
       chunks=chunks[:m]
    print chunks
</code></pre>

<p>output</p>

<pre><code>$ cat file
one two &lt;tag&gt; ....&lt;/tag&gt;
 adsfh asdf &lt;div class="comment"&gt; ....remove
all ....&lt;/div&gt;s sdfds
&lt;div class="blah" .......
.....
blah &lt;/div&gt;

$ ./python.py
one two &lt;tag&gt; ....&lt;/tag&gt;
 adsfh asdf
s sdfds
&lt;div class="blah" .......
.....
blah
</code></pre>
<br /><b>#5</b><br /><p>Use Beautiful soup and do something like this to get all of those elements, and then just replace inside</p>

<pre><code>tomatosoup = BeautifulSoup(myhtml)

tomatochunks = tomatosoup.findall("div", {"class":"comment"} )

for chunk in tomatochunks:
   #remove the stuff
</code></pre>
<br />