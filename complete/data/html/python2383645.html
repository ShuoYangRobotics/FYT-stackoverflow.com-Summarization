<h3>Question (ID-2383645):</h3><h2>Using Numpy to find the average distance in a set of points</h2><p>I have an array of points in unknown dimensional space, such as:</p>

<pre><code>data=numpy.array(
[[ 115, 241, 314],
[ 153, 413, 144],
[ 535, 2986, 41445]])
</code></pre>

<p>and I would like to find the average euclidean distance between all points.</p>

<p>Please note that I have over 20,000 points, so I would like to do this as efficiently as possible.</p>

<p>Thanks.</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>There's no getting around the number of evaluations: </p>

<p><img src="http://www.equationsheet.com/latexrender/pictures/27744c0bd81116aa31c138ab38a2aa87.gif" alt="Sum[n-i, {i, 0, n}] ="> </p>

<p>But you can save yourself the expense of all those square roots if you can get by with an <a href="http://www.flipcode.com/archives/Fast_Approximate_Distance_Functions.shtml" rel="nofollow">approximate result</a>.  It depends on your needs.</p>

<p>If you're going to calculate an average, I would advise you to not try putting all the values into an array before calculating.  Just calculate the sum (and sum of squares if you need standard deviation as well) and throw away each value as you calculate it.</p>

<p>Since <img src="http://www.equationsheet.com/latexrender/pictures/12a8776b729c0f86352787b4f0125226.gif" alt="alt text"> and <img src="http://www.equationsheet.com/latexrender/pictures/2c405dc40c555302bfb6183ec34af822.gif" alt="alt text">, I don't know if this means you have to multiply by two somewhere.</p>
<br /><b>#1</b><br /><p>If you have access to scipy, you could try the following:</p>

<p><a href="http://docs.scipy.org/doc/scipy/reference/spatial.distance.html" rel="nofollow"><code>scipy.spatial.distance.cdist(data,data)</code></a></p>
<br /><b>#2</b><br /><p>Well, I don't think that there is a super fast way to do this, but this should do it:</p>

<pre><code>tot = 0.

for i in xrange(data.shape[0]-1):
    tot += ((((data[i+1:]-data[i])**2).sum(1))**.5).sum()

avg = tot/((data.shape[0]-1)*(data.shape[0])/2.)
</code></pre>
<br /><b>#3</b><br /><p>Now that you've stated your goal of finding the outliers, you are probably better off computing the sample mean and, with that, the sample variance, since both those operations will give you an O(nd) operation. With that, you should be able to find outliers (e.g. excluding points further from the mean than some fraction of the std. dev.), and that filtering process should be possible to perform in O(nd) time for a total of O(nd).</p>

<p>You might be interested in a refresher on <a href="http://en.wikipedia.org/wiki/Chebyshev%27s_inequality" rel="nofollow">Chebyshev's inequality</a>.</p>
<br /><b>#4</b><br /><p>Is it ever worthwhile to optimize without a working solution?  Also, computation of a distance matrix over the entire data set rarely needs to be fast because you only do it once--when you need to know a distance between two points, you just look it up, it's already calculated. </p>

<p>So if you don't have a place to start, here's one.  If you want to do this in Numpy without the need to write any inline fortran or C, that should be no problem, though perhaps you want to include this small vector-based virtual machine called "<a href="http://pypi.python.org/pypi/numexpr/1.3.1" rel="nofollow">numexpr</a>" (available on PyPI, trivial to intall) which in this case gave a 5x performance boost versus Numpy alone.</p>

<p>Below i've calculated a <strong>distance matrix</strong> for 10,000 points in 2D space (a 10K x 10k matrix giving the distance between all 10k points). This took 59 seconds on my MBP.</p>

<pre><code>import numpy as NP
import numexpr as NE

# data are points in 2D space (x, y)--obviously, this code can accept data of any dimension
x = NP.random.randint(0, 10, 10000)
y = NP.random.randint(0, 10, 10000)
fnx = lambda q : q - NP.reshape(q, (len(q), 1))
delX = fnx(x)
delY = fnx(y)
dist_mat = NE.evaluate("(delX**2 + delY**2)**0.5")
</code></pre>
<br /><b>#5</b><br /><p>If you want a fast and inexact solution, you could probably adapt the <a href="http://en.wikipedia.org/wiki/Fast_multipole_method" rel="nofollow">Fast Multipole Method</a> algorithm.</p>

<p>Points that are separated by a small distance have a smaller contribution to the final average distance, so it would make sense to group points into clusters and compare the clusters distances.</p>
<br />