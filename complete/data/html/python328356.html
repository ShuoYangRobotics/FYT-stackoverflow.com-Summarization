<h3>Question (ID-328356):</h3><h2>Extracting text from HTML file using Python</h2><p>I'd like to extract the text from an HTML file using Python.  I want essentially the same output I would get if I copied the text from a browser and pasted it into notepad.  </p>

<p>I'd like something more robust than using regular expressions that may fail on poorly formed HTML.  I've seen many people recommend Beautiful Soup, but I've had a few problems using it.  For one, it picked up unwanted text, such as JavaScript source.  Also, it did not interpret HTML entities.  For example, I would expect &amp;#39; in HTML source to be converted to an apostrophe in text, just as if I'd pasted the browser content into notepad.</p>

<p><strong>Update</strong> html2text looks promising. It handles HTML entities correctly and ignores JavaScript.  However, it does not exactly produce plain text; it produces markdown that would then have to be turned into plain text. It comes with no examples or documentation, but the code looks clean.</p>

<p><hr /></p>

<p>Related questions:</p>

<ul>
<li><a href="http://stackoverflow.com/questions/37486/filter-out-html-tags-and-resolve-entities-in-python">Filter out HTML tags and resolve entities in python</a></li>
<li><a href="http://stackoverflow.com/questions/57708/convert-xmlhtml-entities-into-unicode-string-in-python">Convert XML/HTML Entities into Unicode String in Python</a></li>
</ul>
<br /><h3>Answers (Total-8):</h3><b>#0</b><br /><p>Found myself facing just the same problem today. I wrote a very simple HTML parser to strip incoming content of all markups, returning the remaining text with only a minimum of formatting.</p>

<pre><code>from HTMLParser import HTMLParser
from re import sub
from sys import stderr
from traceback import print_exc

class _DeHTMLParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.__text = []

    def handle_data(self, data):
        text = data.strip()
        if len(text) &gt; 0:
            text = sub('[ \t\r\n]+', ' ', text)
            self.__text.append(text + ' ')

    def handle_starttag(self, tag, attrs):
        if tag == 'p':
            self.__text.append('\n\n')
        elif tag == 'br':
            self.__text.append('\n')

    def handle_startendtag(self, tag, attrs):
        if tag == 'br':
            self.__text.append('\n\n')

    def text(self):
        return ''.join(self.__text).strip()


def dehtml(text):
    try:
        parser = _DeHTMLParser()
        parser.feed(text)
        parser.close()
        return parser.text()
    except:
        print_exc(file=stderr)
        return text


def main():
    text = r'''
        &lt;html&gt;
            &lt;body&gt;
                &lt;b&gt;Project:&lt;/b&gt; DeHTML&lt;br&gt;
                &lt;b&gt;Description&lt;/b&gt;:&lt;br&gt;
                This small script is intended to allow conversion from HTML markup to 
                plain text.
            &lt;/body&gt;
        &lt;/html&gt;
    '''
    print(dehtml(text))


if __name__ == '__main__':
    main()
</code></pre>
<br /><b>#1</b><br /><p><a href="http://www.aaronsw.com/2002/html2text/" rel="nofollow">html2text</a> is a Python program that does a pretty good job at this.</p>
<br /><b>#2</b><br /><p>PyParsing does a great job.  Paul McGuire has several scrips that are easy to adopt for various uses on the pyparsing wiki. (<a href="http://pyparsing.wikispaces.com/Examples">http://pyparsing.wikispaces.com/Examples</a>) One reason for investing a little time with pyparsing is that he has also written a very brief very well organized O'Reilly Short Cut manual that is also inexpensive.</p>

<p>Having said that, I use BeautifulSOup a lot and it is not that hard to deal with the entitites issues, you can convert them before you run BeautifulSoup.  </p>

<p>Goodluck   </p>
<br /><b>#3</b><br /><p>Use NLTK  </p>

<p>I wasted my 4-5 hours fixing the issues with html2text.  Luckily i could encounter NLTK.<br>
It works magically.    </p>

<pre><code>import nltk   
from urllib import urlopen


url = "http://news.bbc.co.uk/2/hi/health/2284783.stm"    
html = urlopen(url).read()    
raw = nltk.clean_html(html)  
print(raw)
</code></pre>
<br /><b>#4</b><br /><p>You can use html2text method in the stripogram library also.</p>

<pre><code>from stripogram import html2text
text = html2text(your_html_string)
</code></pre>

<p>To install stripogram run sudo easy_install stripogram</p>
<br /><b>#5</b><br /><p><a href="http://pypi.python.org/pypi/webstemmer/0.5.0" rel="nofollow">http://pypi.python.org/pypi/webstemmer/0.5.0</a></p>

<p><a href="http://atropine.sourceforge.net/documentation.html" rel="nofollow">http://atropine.sourceforge.net/documentation.html</a></p>

<p><hr /></p>

<p>alternatively, i think you can drive lynx from python, search on that</p>
<br /><b>#6</b><br /><p>@PyNEwbie
the entities should be converted after BeautifulSoup else the Document gets a different meaning. (For example when &lt;div&gt; was encoded)</p>
<br /><b>#7</b><br /><p><strong>Bolierpipe:</strong></p>

<p>Try with this.</p>

<p><a href="http://ai-depot.com/articles/the-easy-way-to-extract-useful-text-from-arbitrary-html/" rel="nofollow">http://ai-depot.com/articles/the-easy-way-to-extract-useful-text-from-arbitrary-html/</a>
 <a href="http://code.google.com/p/boilerpipe/" rel="nofollow">http://code.google.com/p/boilerpipe/</a></p>
<br />