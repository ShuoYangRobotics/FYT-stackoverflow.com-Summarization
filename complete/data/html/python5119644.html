<h3>Question (ID-5119644):</h3><h2>Identifying points with the smallest Euclidean distance</h2><p>I have a collection of n dimensional points and I want to find which 2 are the closest. The best I could come up for 2 dimensions is:</p>

<pre><code>from numpy import *
myArr = array( [[1, 2],
                [3, 4],
                [5, 6],
                [7, 8]] )

n = myArr.shape[0]
cross = [[sum( ( myArr[i] - myArr[j] ) ** 2 ), i, j]
         for i in xrange( n )
         for j in xrange( n )
         if i != j
         ]

print min( cross )
</code></pre>

<p>which gives</p>

<pre><code>[8, 0, 1]
</code></pre>

<p>But this is too slow for large arrays. What kind of optimisation can I apply to it?</p>

<p>RELATED:</p>

<hr>

<p><a href="http://stackoverflow.com/q/1871536/188368">Euclidean distance between points in two different Numpy arrays, not within</a></p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>There's a whole Wikipedia page on just this problem, see:  <a href="http://en.wikipedia.org/wiki/Closest_pair_of_points" rel="nofollow">http://en.wikipedia.org/wiki/Closest_pair_of_points</a></p>

<p>Executive summary:  you can achieve O(n log n) with a recursive divide and conquer algorithm (outlined on the Wiki page, above).</p>
<br /><b>#1</b><br /><p>Try <code>scipy.spatial.distance.pdist(myArr)</code>.  This will give you a condensed distance matrix.  You can use <code>argmin</code> on it and find the index of the smallest value.  This can be converted into the pair information.</p>
<br /><b>#2</b><br /><p>There is a scipy function <code>pdist</code> that will get you the pairwise distances between points in an array in a fairly efficient manner:</p>

<p><a href="http://docs.scipy.org/doc/scipy/reference/spatial.distance.html" rel="nofollow">http://docs.scipy.org/doc/scipy/reference/spatial.distance.html</a></p>

<p>that outputs the N*(N-1)/2 unique pairs (since r_ij == r_ji). You can then search on the minimum value and avoid the whole loop mess in your code. </p>
<br /><b>#3</b><br /><p>You could take advantage of the latest version of SciPy's (v0.9) Delaunay triangulation tools.  You can be sure that the closest two points will be an edge of a simplex in the triangulation, which is a much smaller subset of pairs than doing every combination.  </p>

<p>Here's the code (updated for general N-D):</p>

<pre><code>import numpy
from scipy import spatial

def closest_pts(pts):
    # set up the triangluataion
    # let Delaunay do the heavy lifting
    mesh = spatial.Delaunay(pts)

    # TODO: eliminate reduncant edges (numpy.unique?)
    edges = numpy.vstack((mesh.vertices[:,:dim], mesh.vertices[:,-dim:]))

    # the rest is easy
    x = mesh.points[edges[:,0]]
    y = mesh.points[edges[:,1]]

    dists = numpy.sum((x-y)**2, 1)
    idx = numpy.argmin(dists)

    return edges[idx]
    #print 'distance: ', dists[idx]
    #print 'coords:\n', pts[closest_verts]

dim = 3
N = 1000*dim
pts = numpy.random.random(N).reshape(N/dim, dim)
</code></pre>

<p>Seems closely O(n):</p>

<p><img src="http://i.stack.imgur.com/OFDYR.png" alt="enter image description here"></p>
<br /><b>#4</b><br /><p>Perhaps you could proceed along these lines:</p>

<pre><code>In []: from scipy.spatial.distance import pdist as pd, squareform as sf
In []: m= 1234
In []: n= 123
In []: p= randn(m, n)
In []: d= sf(pd(p))
In []: a= arange(m)
In []: d[a, a]= d.max()
In []: where(d&lt; d.min()+ 1e-9)
Out[]: (array([701, 730]), array([730, 701]))
</code></pre>

<p>With substantially more points you need to be able to somehow utilize the hierarchical structure of your clustering.</p>
<br /><b>#5</b><br /><p>How fast is it compared to just doing a nested loop and keeping track of the shortest pair? I think creating a huge cross array is what might be hurting you. Even O(n^2) is still pretty quick if you're only doing 2 dimensional points.</p>
<br />