<h3>Question (ID-7364076):</h3><h2>Fastest way to cast values to their respective datatypes in Python</h2><p>I have a list of values - all strings. I want to convert these values to their respective datatypes. I have mapping of values to the types information available.</p>

<p>There are three different datatypes: int, str, datetime.
The code needs to be able to handle the error cases with the data.</p>

<p>I am doing something like:-</p>

<pre><code>tlist =  [ 'some datetime value', '12', 'string', .... ]

#convert it to: [ datetime object, 12, 'string', ....]

error_data = ['', ' ', '?', ...]

d = { 0: lambda x: datetime.strptime(x,...) if x not in error_data else x, 
      1: lambda x: int(x) if x not in error_data else 0,
      2: lambda x: x 
      ...
     }

result = [ d[i](j) for i, j in enumerate(tlist) ]
</code></pre>

<p>The list to convert is very long, like 180 values and I need to do it for thousands of such lists. The performance of above code is very poor. What is the fastest way to do it?</p>

<p>Thank you</p>
<br /><h3>Answers (Total-7):</h3><b>#0</b><br /><p>Something like:</p>

<pre><code>&gt;&gt;&gt; values = ["12", "a", "bcd", "2.2"]
&gt;&gt;&gt; types = [int, int, str, float]
&gt;&gt;&gt; defaults = {int: 0, float: 0.0}
&gt;&gt;&gt; res = []
&gt;&gt;&gt; for v, f in itertools.izip(values, types): #Just use zip for Python 3+.
    try:
        res.append(f(v))
    except ValueError:
        res.append(defaults[f])
&gt;&gt;&gt; print(res)
[12, 0, 'bcd', 2.2]
</code></pre>

<p><strong>Edit:</strong></p>

<p>This doesn't handle datetime values. My solution for that is use <code>str</code> for that, and convert to datetime after the loop, like:</p>

<pre><code>res[0] = datetime.strptime(res[0], "...")
</code></pre>

<p>Both getting and setting the list item has O(1) complexity, so it shouldn't be a problem.</p>
<br /><b>#1</b><br /><p>If your datetime value is always consistant why not let the type casting handle the invalid data that you're trying to manage in error_data. This is not as sexy as some solutions but makes managing type conversion based on position of data in list a little easier to maintain and expand upon. </p>

<pre><code>def convert(position, val):
    if position == 0:
        try:
            return datetime.strptime(val, '%Y-%m-%d %H:%M:%S') # assuming date is in a constant format
        except ValueError:
            return val
    elif position in (1, 15, 16): # assuming that you have other int values in other "columns"
        try:
            return int(val)
        except ValueError:
            return 0
    else: # string type
       return val

result = [convert(i,j) for i, j in enumerate(tlist)]
</code></pre>
<br /><b>#2</b><br /><p>Since you know the types you want to convert to, you probably won't get a performance boost from trying to optimize your conversions. The poor performance probably comes from repeatedly iterating over <code>error_data</code>. If it is possible, reconstruct your <code>error_data</code> list as a <code>set</code> to exploit nature of that type:</p>

<pre><code>error_set = set((err, None) for err in error_data)
</code></pre>

<p>Then proceed as you have been. Further improvements would require profiling your code to actually determine where time is being spent.</p>
<br /><b>#3</b><br /><p>There's an incongruity in your code:</p>

<p>if all elements in a list are strings, you can't write <code>datetime(x)</code> with <strong>x</strong> being a string</p>

<h3>edit</h3>

<p>It depicts nothing since it is incongruous. The complexity of what is not in you code doesn't justify the weirdness that is in your code. As long as you won't explain how you can pass a string as argument to the function <strong>datetime.datetime()</strong>, nobody will be able to help you, IMO.</p>

<h2>Edit</h2>

<p>I think that it's better to create directly your list at the moment the file is read.</p>

<p>I wrote an example:</p>

<p>.</p>

<p>First, I created a CSV file with the following code:</p>

<pre><code>import csv
from random import randint,choice
from time import gmtime


xx = ['Whose', 'all', 'birth', 'just', 'infant', 'William',
      'dearest', 'rooms', 'find', 'Deserts', 'saucy', 'His',
      'how', 'considerate', 'only', 'other', 'Houses', 'has',
      'Fanny', 'them', 'his', 'very', 'dispense', 'early',
      'words', 'not', 'thus', 'now', 'pettish', 'Worth']

def gen(n):
    for i in xrange(n):
        yield ['AAAA','%d/%02d/%02d %02d:%02d:%02d' % gmtime(randint(0,80000000))[0:6],'@@@']
        yield ['BBBB',randint(100,999),'^^^^^^']
        yield ['CCCC',choice(xx),'-----------------']

with open('zzz.txt','wb') as f:
    writ = csv.writer(f, delimiter='#')
    writ.writerows(x for x in gen(60))
</code></pre>

<p>The structure of the CSV file is so:</p>

<pre><code>AAAA#1972/02/11 08:53:53#@@@
BBBB#557#^^^^^^
CCCC#dearest#-----------------
AAAA#1971/10/15 06:55:20#@@@
BBBB#668#^^^^^^
CCCC#?#-----------------
AAAA#1972/07/13 11:10:05#@@@
BBBB#190#^^^^^^
CCCC#infant#-----------------
AAAA#1971/11/22 19:31:42#@@@
BBBB#202#^^^^^^
CCCC##-----------------
AAAA#1971/06/12 05:48:39#@@@
BBBB#81#^^^^^^
CCCC#find#-----------------
AAAA#1970/12/09 06:26:29#@@@
BBBB#72#^^^^^^
CCCC#find#-----------------
AAAA#1972/07/05 10:45:32#@@@
BBBB#270#^^^^^^
CCCC#rooms#-----------------
AAAA#1972/06/23 05:52:20#@@@
BBBB#202#^^^^^^
CCCC##-----------------
AAAA#1972/03/21 23:06:47#@@@
BBBB#883#^^^^^^
CCCC#William#-----------------
...... etc
</code></pre>

<p>.</p>

<p>The following code extracts the data in a similar way to what you want.   </p>

<p>There is no need of a dictionary, a tuple is sufficient. Given the structure of the CSV file created, I defined  <code>funcs = 60 * (to_dt, int, lambda x: x)</code> but you'll use the succession of functions that is your dictionary's values (sorted)</p>

<pre><code>import re
import csv
from datetime import datetime
from itertools import izip

reg = re.compile('(\d{4})/(\d\d)/(\d\d) (\d\d):(\d\d):(\d\d)')

def to_dt(x, error_data = ('', ' ', '?')):
    if x in error_data:
        return x
    else:
        return datetime(*map(int,reg.match(x).groups()))

def teger(x,  error_data = ('', ' ', '?')):
    if x in error_data:
        return 0
    else:
        return int(x)

funcs = 60 * (to_dt, int, lambda y: y)

with open('zzz.txt','rb') as f:
    rid = csv.reader(f, delimiter='#')
    li = [fct(x[1]) for fct,x in izip(funcs,rid)]



# display
it = (str(el) for el in li).next
print '\n'.join('%-21s %4s  %10s' % (it(),it(),it()) for i in xrange(60))
</code></pre>

<p>result</p>

<pre><code>1972-02-11 08:53:53    557     dearest
1971-10-15 06:55:20    668           ?
1972-07-13 11:10:05    190      infant
1971-11-22 19:31:42    202            
1971-06-12 05:48:39     81        find
1970-12-09 06:26:29     72        find
1972-07-05 10:45:32    270       rooms
1972-06-23 05:52:20    202            
1972-03-21 23:06:47    883     William
1970-02-08 23:47:26    617            
1970-10-08 09:09:33    387     William
1971-04-30 11:05:07    721           ?
1970-02-12 11:57:48    827     Deserts
1972-03-27 21:30:39    363        just
1971-06-02 00:23:52    977            
1970-04-20 04:38:38    113     William
1971-01-20 23:10:26     75       Whose
1971-07-01 12:46:13    352     dearest
1971-01-31 17:01:34    220     William
1970-06-09 20:38:52    148       rooms
1971-08-08 07:42:10    146            
1970-01-28 15:17:41    903        find
...............etc
</code></pre>
<br /><b>#4</b><br /><p>I don't know if this would be much faster, but to me it's clearer:</p>

<pre><code>tlist =  [ 'some datetime value', '12', 'string', .... ]

#convert it to: [ datetime object, 12, 'string', ....]

error_data = set(['', ' ', '?', ...])

def s(x):
    return x

def d(x):
    return datetime(x) if x not in error_data else x

def i(x):
    return int(x) if x not in error_data else 0

types = [ d, i, s, s, s, i, i, d, i, ... ]

result = [ t(x) for t, x in zip(types, tlist) ]
</code></pre>

<p>As others have mentioned, I'm using a set for the error values, which will be faster than the list you had.</p>
<br /><b>#5</b><br /><p>As a variant on utdemir's answer, if error values are fairly infrequent, then you could optimize the common case:</p>

<pre><code>&gt;&gt;&gt; values = ["12", "a", "bcd", "2.2"]
&gt;&gt;&gt; types = [int, int, str, float]
&gt;&gt;&gt; defaults = {int: 0, float: 0.0}
&gt;&gt;&gt; try: res = [f(v) for v,f in zip(values,types)]
... except: 
...     res = []
...     for v, f in zip(values, types):
...        try:
...             res.append(f(v))
...         except ValueError:
...             res.append(defaults[f])
</code></pre>

<p>I.e., first try converting the whole line assuming that nothing will go wrong.  If anything does go wrong, then go back and convert values one at a time, fixing any error values.</p>
<br /><b>#6</b><br /><p>Thank you guys for all those approaches. Yeah, I tried pretty much all the approaches mentioned, but none did perform well.</p>

<p>I tried the following approach and it worked pretty well for my performance needs. This is what I did.</p>

<ol>
<li>I handled the datetime values as suggested by utdemir </li>
<li><p>I've inserted value 0 for all the int error values with code like -</p>

<p><code>[i] = value if value != '' else 0</code></p></li>
<li><p>Instead of coercing value by value using dictionary, I coerced all the value at once using a list.</p>

<p><code>
def coerce(l):<br>
return [ l[0], int(l[1]), int(l[2]) ... ]
</code></p></li>
</ol>

<p>My Observations:</p>

<ol>
<li>handling the error cases separately and coercing at once helps a lot. </li>
<li>letting the code recover from an exception takes a lot of time.</li>
<li>Going over a list multiple times doesn't really hurt( I did it for handling error cases)</li>
<li>To give an idea, for couple of hours of data (0.60 million records), my approach brought down the runtime from 6-7 minutes to 2m30s</li>
</ol>
<br />