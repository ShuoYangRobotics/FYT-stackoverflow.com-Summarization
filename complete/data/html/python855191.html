<h3>Question (ID-855191):</h3><h2>How Big can a Python Array Get?</h2><p>In Python,</p>

<p>how big can an array/list get? I need an array about 12000 elements large... is that okay? - will I still be able to run array/list methods such as sorting, etc?</p>

<p>Thanks so much,
Ed</p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>According to the <a href="http://svn.python.org/view/python/trunk/Objects/listobject.c?revision=69227&amp;view=markup" rel="nofollow">source code</a>, the maximum size of a list is PY_SSIZE_T_MAX/sizeof(PyObject*).</p>

<p>PY_SSIZE_T_MAX is defined in <a href="http://svn.python.org/view/python/trunk/Include/pyport.h?revision=70489&amp;view=markup" rel="nofollow">pyport.h</a> to be ((size_t) -1)>>1</p>

<p>On a regular 32bit system, this is (4294967295 / 2) / 4  or 536870912.</p>

<p>Therefore the maximum size of a python list on a 32 bit system is <strong>536,870,912</strong> elements. </p>

<p>As long as the number of elements you have is equal or below this, all list functions should operate correctly.</p>
<br /><b>#1</b><br /><p>Sure it is OK. Actually you can see for yourself easily:</p>

<pre><code>l = range(12000)
l = sorted(l, reverse=True)
</code></pre>

<p>Running the those lines on my machine took:</p>

<pre><code>real    0m0.036s
user    0m0.024s
sys  0m0.004s
</code></pre>

<p>But sure as everyone else said. The larger the array the slower the operations will be.</p>
<br /><b>#2</b><br /><p>In casual code I've created lists with millions of elements. I believe that Python's implementation of lists are only bound by the amount of memory on your system. </p>

<p>In addition, the list methods / functions should continue to work despite the size of the list. </p>

<p>If you care about performance, it might be worthwhile to look into a library such as <a href="http://numpy.scipy.org/" rel="nofollow">NumPy</a>.</p>
<br /><b>#3</b><br /><p>12000 elements is nothing in Python... and actually the number of elements can go as far as the Python interpreter has memory on your system.</p>
<br /><b>#4</b><br /><p><a href="http://effbot.org/zone/python-list.htm#performance" rel="nofollow">Performance characteristics for lists</a> are described on Effbot.</p>

<p>Python lists are actually implemented as vector for fast random access, so the container will basically hold as many items as there is space for in memory. (You need space for pointers contained in the list as well as space in memory for the object(s) being pointed to.)</p>

<p>Appending is <code>O(1)</code> (amortized constant complexity), however, inserting into/deleting from the middle of the sequence will require an <code>O(n)</code> (linear complexity) reordering, which will get slower as the number of elements in your list.</p>

<p>Your sorting question is more nuanced, since the comparison operation can take an unbounded amount of time. If you're performing really slow comparisons, it will take a long time, though it's no fault of <a href="http://docs.python.org/library/stdtypes.html#sequence-types-str-unicode-list-tuple-buffer-xrange" rel="nofollow">Python's list data type</a>.</p>

<p>Reversal just takes the amount of time it required to swap all the pointers in the list (necessarily <code>O(n)</code> (linear complexity), since you touch each pointer once).</p>
<br /><b>#5</b><br /><p>I'd say you're only limited by the total amount of RAM available.  Obviously the larger the array the longer operations on it will take.</p>
<br />