<h3>Question (ID-4209781):</h3><h2>How to speed up this Python code?</h2><p>I've got the following tiny Python method that is <strong><em>by far</em></strong> the performance hotspot (according to my profiler, >95% of execution time is spent here) in a much larger program:</p>

<pre><code>def topScore(self, seq):
    ret = -1e9999
    logProbs = self.logProbs  # save indirection
    l = len(logProbs)
    for i in xrange(len(seq) - l + 1):
        score = 0.0
        for j in xrange(l):
            score += logProbs[j][seq[j + i]]
        ret = max(ret, score)

    return ret
</code></pre>

<p>The code is being run in the Jython implementation of Python, not CPython, if that matters.  <code>seq</code> is a DNA sequence string, on the order of 1,000 elements.  <code>logProbs</code> is a list of dictionaries, one for each position.  The goal is to find the maximum score of any length <code>l</code> (on the order of 10-20 elements) subsequence of <code>seq</code>.</p>

<p>I realize all this looping is inefficient due to interpretation overhead and would be a heck of a lot faster in a statically compiled/JIT'd language.  However, I'm not willing to switch languages.  First, I need a JVM language for the libraries I'm using, and this kind of constrains my choices.  Secondly, I don't want to translate this code wholesale into a lower-level JVM language.  However, I'm willing to rewrite this hotspot in something else if necessary, though I have no clue how to interface it or what the overhead would be.</p>

<p>In addition to the single-threaded slowness of this method, I also can't get the program to scale much past 4 CPUs in terms of parallelization.  Given that it spends almost all its time in the 10-line hotspot I've posted, I can't figure out what the bottleneck could be here.</p>
<br /><h3>Answers (Total-8):</h3><b>#0</b><br /><p>The reason it is slow is because it is O(N*N)</p>

<p>The <a href="http://wordaligned.org/articles/the-maximum-subsequence-problem" rel="nofollow">maximum subsequence</a> algorithm may help you improve this</p>
<br /><b>#1</b><br /><p>if <code>topScore</code> is called repeatedly for same <code>seq</code> you could <code>memoize</code> its value. </p>

<p>E.g. <a href="http://code.activestate.com/recipes/52201/" rel="nofollow">http://code.activestate.com/recipes/52201/</a></p>
<br /><b>#2</b><br /><p>i don't have any idea what i'm doing but maybe this can help speed up your algo:</p>

<pre><code>ret = -1e9999
logProbs = self.logProbs  # save indirection
l = len(logProbs)

scores = collections.defaultdict(int)

for j in xrange(l):
    prob = logProbs[j]
    for i in xrange(len(seq) - l + 1):
        scores[i] += prob[seq[j + i]]


ret = max(ret, max(scores.values()))
</code></pre>
<br /><b>#3</b><br /><p>What about precomputing <code>xrange(l)</code> outside the for i loop?</p>
<br /><b>#4</b><br /><p>Nothing jumps out as being slow. I might rewrite the inner loop like this:</p>

<pre><code>score = sum(logProbs[j][seq[j+i]] for j in xrange(l))
</code></pre>

<p>or even:</p>

<pre><code>seqmatch = zip(seq[i:i+l], logProbs)
score = sum(posscores[base] for base, posscores in seqmatch)
</code></pre>

<p>but I don't know that either would save much time.</p>

<p>It might be marginally quicker to store DNA bases as integers 0-3, and look up the scores from a tuple instead of a dictionary. There'll be a performance hit on translating letters to numbers, but that only has to be done once.</p>
<br /><b>#5</b><br /><p>Definitely use numpy and store logProbs as a 2D array instead of a list of dictionaries.  Also store seq as a 1D array of (short) integers as suggested above.  This will help if you don't have to do these conversions every time you call the function (doing these conversions inside the function won't save you much).  You can them eliminate the second loop:</p>

<pre><code>import numpy as np
...
print np.shape(self.logProbs) # (20, 4)
print np.shape(seq) # (1000,)
...
def topScore(self, seq):
ret = -1e9999
logProbs = self.logProbs  # save indirection
l = len(logProbs)
for i in xrange(len(seq) - l + 1):
    score = np.sum(logProbs[:,seq[i:i+l]])
    ret = max(ret, score)

return ret
</code></pre>

<p>What you do after that depends on which of these 2 data elements changes the most often:</p>

<p>If logProbs generally stays the same and you want to run many DNA sequences through it, then consider stacking your DNA sequences as a 2D array.  numpy can loop through the 2D array very quickly so if you have 200 DNA sequences to process, it will only take a little longer than a single.</p>

<p>Finally, if you really need speed up, use scipy.weave.  This is a very easy way to write a few lines of fast C to accelerate you loops.  However, I recommend scipy >0.8.</p>
<br /><b>#6</b><br /><p>You can try hoisting more than just self.logProbs outside the loops:</p>

<pre><code>def topScore(self, seq):
    ret = -1e9999
    logProbs = self.logProbs  # save indirection
    l = len(logProbs)
    lrange = range(l)
    for i in xrange(len(seq) - l + 1):
        score = 0.0
        for j in lrange:
            score += logProbs[j][seq[j + i]]
        if score &gt; ret: ret = score # avoid lookup and function call

    return ret
</code></pre>
<br /><b>#7</b><br /><p>I doubt it will make a significant difference, but you could try changing:</p>

<pre><code>  for j in xrange(l):
        score += logProbs[j][seq[j + i]]
</code></pre>

<p>to </p>

<pre><code>  for j,lP in enumerate(logProbs):
        score += lP[seq[j + i]]
</code></pre>

<p>or even hoisting that enumeration outside the seq loop. </p>
<br />