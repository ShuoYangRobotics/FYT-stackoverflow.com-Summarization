<h3>Question (ID-513882):</h3><h2>Python: List vs Dict for look up table</h2><p>I have about 10million values that I need to put in some type of look up table, so I was wondering which would be more efficient a <i>list</i> or <i>dict</i>?</p>

<p>I know you can do something like this for both:</p>

<pre><code>if something in dict_of_stuff:
    pass
</code></pre>

<p>and</p>

<pre><code>if something in list_of_stuff:
    pass
</code></pre>

<p>My thought is the dict will be faster and more efficient.</p>

<p>Thanks for your help.</p>

<p><b>EDIT 1</b> <br>
Little more info on what I'm trying to do.  <a href="http://projecteuler.net/index.php?section=problems&amp;id=92" rel="nofollow">Euler Problem 92</a>.  I'm making a look up table to see if a value calculated has all ready been calculated. </p>

<p><b>EDIT 2</b> <br>
Efficiency for look up.</p>

<p><b>EDIT 3</b> <br>
There are no values assosiated with the value...so would a <i>set</i> be better?</p>
<br /><h3>Answers (Total-7):</h3><b>#0</b><br /><h1>Speed</h1>

<p>Lookups in lists are O(n), lookups in dictionaries are amortized O(1), with regard to the number of items in the data structure. If you don't need to associate values, use sets.</p>

<h1>Memory</h1>

<p>Both dictionaries and sets use hashing and they use much more memory than only for object storage. According to A.M. Kuchling in <em>Beautiful Code</em>, the implementation tries to keep the hash 2/3 full, so you might waste quite some memory. </p>

<p>If you do not add new entries on the fly (which you do, based on your updated question), it might be worthwhile to sort the list and use binary search. This is O(log n), and is likely to be slower for strings, impossible for objects which do not have a natural ordering.</p>
<br /><b>#1</b><br /><p>A dict is a hash table, so it is really fast to find the keys. So between dict and list, dict would be faster. But if you don't have a value to associate, it is even better to use a set. It is a hash table, without the "table" part.</p>

<p><hr /></p>

<p>EDIT: for your new question, YES, a set would be better. Just create 2 sets, one for sequences ended in 1 and other for the sequences ended in 89. I have sucessfully solved this problem using sets.</p>
<br /><b>#2</b><br /><p>if data are unique set() will be the most efficient, but of two - dict (which also requires uniqueness, oops :)</p>
<br /><b>#3</b><br /><p>You want a dict.  </p>

<p>For (unsorted) lists in Python, the "in" operation requires O(n) time---not good when you have a large amount of data.  A dict, on the other hand, is a hash table, so you can expect O(1) lookup time.  </p>

<p>As others have noted, you might choose a set (a special type of dict) instead, if you only have keys rather than key/value pairs.</p>

<p>Related:</p>

<ul>
<li><a href="http://wiki.python.org/moin/TimeComplexity" rel="nofollow">Python wiki</a>: information on the time complexity of Python container operations.</li>
<li><a href="http://stackoverflow.com/questions/45228/where-can-i-find-the-time-and-memory-efficencies-of-the-built-in-sequence-types-i">SO</a>: Python container operation time and memory complexities</li>
</ul>
<br /><b>#4</b><br /><p><a href="http://docs.python.org/library/sets.html" rel="nofollow"><code>set()</code></a> is exactly what you want.  O(1) lookups, and smaller than a dict.</p>
<br /><b>#5</b><br /><p>I am not an expert in python, but:
If you need the key-value structure, the dict is a good option.</p>

<p>If you looks for efficiency with this ammounts of data, you should try to develop your own mechanism to managing this data in your context.</p>

<p>Sorry if this response have any grammatical mistake, I'm learning english.</p>
<br /><b>#6</b><br /><p>You don't actually need to store 10 million values in the table, so it's not a big deal either way.</p>

<p>Hint: think about how large your result can be after the first sum of squares operation. The largest possible result will be much smaller than 10 million...</p>
<br />