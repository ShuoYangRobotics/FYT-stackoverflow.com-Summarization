<h3>Question (ID-2337700):</h3><h2>Exceeding the size of lists in python</h2><p>I'm trying to implement the <a href="http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes" rel="nofollow" title="Sieve of Eratosthenes">sieve of eratosthenes</a> in python, however when trying to find all primes up to the sqare root of for instance <a href="http://www.wolframalpha.com/input/?i=779695003923747564589111193840021" rel="nofollow" title="779695003923747564589111193840021">779695003923747564589111193840021</a> I get an error saying result of range() has too many items. My question is, how do I avoid this problem, if I instantiate the list with a while loop I will get an error saying I'm using too much memory (before it even starts to use the pagefile), the two are listed below:</p>

<p>Using range()</p>

<pre><code>maxnum = 39312312323123123

primes = []
seq = []
i = 0
seq = range(2,maxnum)

for i in seq:
    mul = i * seq
    for j in mul:
        try:
            seq.remove(j)
        except:
            pass
        primes.append(i)

print primes
</code></pre>

<p>Using while:</p>

<pre><code>maxnum = 39312312323123123

primes = []
seq = []
i = 0
while i &lt; maxnum:
    seq.append(i)
    i+=1

for i in seq:
    mul = i * seq
    for j in mul:
        try:
            seq.remove(j)
        except:
            pass
        primes.append(i)

print primes
</code></pre>
<br /><h3>Answers (Total-7):</h3><b>#0</b><br /><p>I would say, "use <code>xrange()</code> instead", but you are actually using the list of ints as the sieve result.....  So an integer generator is not a correct solution.</p>

<p>I think it will be difficult to materialize a list with 39312312323123123 elements in it, no matter what function you use to do so.... That is, after all, 279 petabytes of 64-bit integers.</p>

<p>Try this.</p>

<pre><code>class FoundComposite(Exception): pass

primes = [2]

seq = itertools.takewhile(        # Take integers from a list
          lambda x: x&lt;MAXNUM,     #   until we reach MAXNUM
          itertools.count(2)      #   the list of integers starting from 2
          )

#seq = xrange(2, MAXNUM)          # alternatively

for i in seq:
    try:
        for divisor in primes:
            if not (i % divisor):
                # no remainder - thus an even divisor
                # continue to next i in seq
                raise FoundComposite 
        # if this is reached, we have tried all divisors.
        primes.append(i)
    except FoundComposite:
        pass
</code></pre>
<br /><b>#1</b><br /><p>Your algorithm is broken. Get it to work for maxnum=100 first.</p>

<p>Once you get it working you will find maxnum=100000000 will takes a long long time to run.</p>

<p>Plot the time it takes to run for maxnum in (10,100,1000,10000,100000,1000000...) you may be able to extrapolate how long 39312312323123123 will take :)</p>
<br /><b>#2</b><br /><p>It's a more complex algorithm, perhaps technically not counting as the sieve, but one approach is to not remove all multiples of a given prime at once, but queue the next multiple (along with the prime). This could be used in a generator implementation. The queue will still end up containing a lot of (multiples of) primes, but not as many as by building then filtering a list.</p>

<p>First few steps done manually, to show the principle...</p>

<ul>
<li>2 is prime - yield and queue (4, 2)</li>
<li>3 is prime - yield and queue (6, 3)</li>
<li>4 is composite - replace (4, 2) with (6, 2) in the queue</li>
<li>5 is prime - yield and queue (10, 5)</li>
<li>6 is composite - replace (6, 2) with (8, 2) and (6, 3) with (9, 3)</li>
</ul>

<p>Note - the queue isn't a FIFO. You will always be extracting the tuples with the lowest first item, but new/replacement tuples don't (usually) have the highest first item and (as with 6 above) there will be duplicates.</p>

<p>To handle the queue efficiently in Python, I suggest a dictionary (ie hashtable) keyed by the first item of the tuple. The data is a set of second item values (original primes).</p>

<p>As suggested elsewhere, test with small targets before trying for the big one. And don't be too surprised if you fail. It may still be that you need too many heap-allocated large integers at one time (in the queue) to complete the solution.</p>
<br /><b>#3</b><br /><p>There is a third party module for python called <code>gmpy</code></p>

<p>It has a couple of functions that may be useful to you as they are very fast. The probabilistic stuff kicks in around the 4 billion mark.</p>

<pre><code>next_prime(...)
    next_prime(x): returns the smallest prime number &gt; x.  Note that
    GMP may use a probabilistic definition of 'prime', and also that
    if x&lt;0 GMP considers x 'prime' iff -x is prime; gmpy reflects these
    GMP design choices. x must be an mpz, or else gets coerced to one.

is_prime(...)
    is_prime(x,n=25): returns 2 if x is _certainly_ prime, 1 if x is
    _probably_ prime (probability &gt; 1 - 1/2**n), 0 if x is composite.
    If x&lt;0, GMP considers x 'prime' iff -x is prime; gmpy reflects this
    GMP design choice. x must be an mpz, or else gets coerced to one.
</code></pre>
<br /><b>#4</b><br /><p><code>range()</code> returns a list containing all the numbers in the requested range, while <code>xrange</code> is a generator and yields the numbers one after another with a memory consumption close to zero. </p>
<br /><b>#5</b><br /><p>About the memory limit, how about creating a custom list (class) that internally is a linked list of lists or arrays. Magically traverse from one to the other internally, and add more as needed, as the caller uses your custom list with the external interface you've provided which will be similar to those members needed to facilitate the .append .remove, etc needs of the arrays used in your problem.</p>

<p><em>Note</em>: I'm not a Python programmer. Not a clue how to implement what I said in Python. Maybe I don't know the context here, so I will understand if I'm voted down.</p>

<p>Maybe use "<a href="http://www.ibm.com/developerworks/library/l-pycon.html" rel="nofollow">generators</a>" as they're called in python to yield results of your internal lists as if it were one huge single list. Possibly with <a href="http://stackoverflow.com/questions/280243/python-linked-list">linked list</a>.</p>
<br /><b>#6</b><br /><p>Try this:</p>

<pre><code>def getPrimes(maxnum):
    primes = []
    for i in xrange(2, maxnum):
        is_mul = False
        for j in primes:         # Try dividing by all previous primes
            if i % j == 0:
                is_mul = True    # Once we find a prime that i is divisible by
                break            # short circuit so we don't have to try all of them
        if not is_mul:           # if we try every prime we've seen so far and `i`
            primes.append(i)     # isn't a multiple, so it must be prime
    return primes
</code></pre>

<p>You shouldn't run out of memory until you get to a very large number of primes.  This way you don't have to worry about creating a list of multiples.  Not sure if this still counts as the sieve though.</p>

<p>Actually, this won't work for <code>maxnum = 39312312323123123</code>.  Using the <a href="http://en.wikipedia.org/wiki/Prime_number_theorem" rel="nofollow">Prime number theorem</a> we can estimate that there will be approximately <code>1,028,840,332,567,181</code> prime numbers in that range.</p>

<p>As pointed out in <a href="http://stackoverflow.com/questions/855191/how-big-can-a-python-array-get">this question</a> the maximum size of a python list on a 32-bit system is <code>536,870,912</code>.  So even if you don't run out of memory, you still won't be able to finish the calculation.</p>

<p>You shouldn't have that problem with a 64-bit system though.</p>

<p><code>2 ** 64 =&gt; 18446744073709551616</code></p>

<p>Using the math from the aforementioned question <code>(2 ** 64) / 8</code>, the maximum number of elements in a list would be <code>2,305,843,009,213,693,951</code> which is greater than the estimated number of primes you will encounter.</p>

<p><strong>Edit:</strong></p>

<p>To avoid memory issues, you could store your list of primes in a file on the hard disk. Store one prime per line and read the file every time you check a new number.</p>

<p>Maybe something like this:</p>

<pre><code>primes_path = r'C:\temp\primes.txt'

def genPrimes():
    for line in open(primes_path, 'r'):
        yield int(line.strip())    

def addPrime(prime):
    primes_file = open(primes_path, 'a')
    primes_file.write('%s\n' % prime)
    primes_file.close()

def findPrimes(maxnum):
    for i in xrange(2, maxnum):
        is_mul = False
        for prime in genPrimes():  # generate the primes from a file on disk
            if i % prime == 0:
                is_mul = True    
                break            
        if not is_mul:           
            addPrime(i)  # append the new prime to the end of your primes file
</code></pre>

<p>At the end, you would have a file on your hard drive that contained all your primes.</p>

<p>Ok, so this would be pretty slow, but you wouldn't run out of memory.  You could make it faster by increasing the speed at which you can read/write files (like <a href="http://en.wikipedia.org/wiki/RAID" rel="nofollow">RAID</a>).</p>
<br />