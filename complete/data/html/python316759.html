<h3>Question (ID-316759):</h3><h2>Are there any Python libraries, or features, that make screen scraping easier?</h2><p>I'm wanting to create a REST API for TV listings in my country. While online aggregations of TV listings do exist they're too tied to the presentation to be of any use to software developers.</p>

<p>In order to get hold of this information I'm thinking of going to each source and scraping the relevant information. While I've obtained similar information from HTML pages before it was an extremely cumbersome process. Do any Python features/libraries exist that would make this process easier? </p>
<br /><h3>Answers (Total-7):</h3><b>#0</b><br /><p><a href="http://www.crummy.com/software/BeautifulSoup/" rel="nofollow">Beautiful Soup</a> will save you a great deal of pain.</p>
<br /><b>#1</b><br /><p>Another option is to use <a href="http://codespeak.net/lxml/lxml2.html" rel="nofollow">lxml</a>.<a href="http://codespeak.net/lxml/lxmlhtml.html" rel="nofollow">html</a>.  I've occasionally found this to handle some pages better than BeautifulSoup (odd HTML comment corner cases), and the API may be more familiar if you've worked with XML.  If BeautifulSoup does handle certain pages better, you can still use it while retaining the same interface by using <a href="http://codespeak.net/lxml/elementsoup.html" rel="nofollow">soupparser</a> module.</p>
<br /><b>#2</b><br /><p>Use <a href="http://wwwsearch.sourceforge.net/mechanize/">mechanize</a> to automate browsing, and BeautifulSoup to parse the HTML. (I do lots of stuff like what you described.)</p>
<br /><b>#3</b><br /><p>Another option, if you don't mind learning "yet another framework", is <a href="http://scrapy.org" rel="nofollow">Scrapy</a>, which is a full-featured screen scraping environment for writing scrapers, in Python.</p>

<p>The difference between Scrapy and lxml/BS or Mechanize is that Scrapy is a complete integrated solution, while lxml/BS only do the parsing side, and Mecanize the crawling side. There is no silver bullet, so you'll have to try for yourself and decide which technology fits better for your needs.</p>
<br /><b>#4</b><br /><p>While BeautifulSoup is a good piece of code, depending on what you are trying to extract from the web page, you may not need that much intelligence.  The data you're looking for may be easily picked out by a regular expression, for example.  </p>
<br /><b>#5</b><br /><p>This isn't answering you question directly, but you may want to think about getting your data from another service, such as <a href="http://www.schedulesdirect.org/" rel="nofollow">Schedules Direct</a>. They provide XML, and it's the recommended data provider for <a href="http://wiki.xmltv.org/index.php/Main_Page" rel="nofollow">xmltv</a>.</p>
<br /><b>#6</b><br /><pre><code>import urllib
</code></pre>

<p>Docs:
<a href="http://docs.python.org/library/urllib.html" rel="nofollow">urllib docs</a></p>
<br />