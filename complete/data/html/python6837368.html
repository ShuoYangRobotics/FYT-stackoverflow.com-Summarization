<h3>Question (ID-6837368):</h3><h2>How to read a file in python which has newline and tabs into a string?</h2><p>I am trying to read a file which has tabs and newline etc and the data is JSON format.</p>

<p>When I read it using <code>file.read()</code>/<code>readlines()</code> etc, all the newlines and tabs are also read.</p>

<p>I have tried <code>rstrip()</code>, split etc but in vain, maybe I am missing some thing:</p>

<p>Here is essentially what I am doing:</p>

<pre><code> f = open('/path/to/file.txt')
 line = f.readlines()
 line.split('\n')
</code></pre>

<p>This is the data (including the raw tabs, hence the poor formatting):</p>

<pre><code>        {
      "foo": [ {
       "id1" : "1",
   "blah": "blah blah",
       "id2" : "5885221122",
      "bar" : [
              {  
         "name" : "Joe JJ", 
          "info": [                 {
         "custid": "SSN",    
         "type" : "String",             }        ]
        }     ]     }     ]  }
</code></pre>

<p>I was wondering if we can ignore it elegantly.</p>

<p>Also hoping to use <code>json.dumps()</code> </p>
<br /><h3>Answers (Total-6):</h3><b>#0</b><br /><p>Why not just use json.load() if the data is json?</p>

<pre><code>import json
d = json.load(open('myfile.txt', 'r'))
</code></pre>
<br /><b>#1</b><br /><p>Where did that structure come from?  My condolences.  Anyway, as a start you might try this:</p>

<pre><code>cleanedData = re.sub('[\n\t]', '', f.read())
</code></pre>

<p>That's a brute-force removal of newline and tab characters.  What it returns <em>might</em> be suitable for feeding into <code>json.loads</code>.  It'll depend greatly on whether or not the contents of the file are actually valid JSON once you clear out the extra white space and line breaks.</p>
<br /><b>#2</b><br /><p>If you want to loop over each line, you can just:</p>

<pre><code>for line in open('path/to/file.txt'):
  # Remove whitespace from both ends of line
  line = line.strip()

  # Do whatever you want with line
</code></pre>
<br /><b>#3</b><br /><p>A little hack, inefficient I guess:</p>

<pre><code>f = open("/path/to/file.txt")
lines = f.read().replace("\n", "").replace("\t", "").replace(" ", "")

print lines
</code></pre>
<br /><b>#4</b><br /><p>What about the usage of the json module?</p>

<pre><code>import json

tmp = json.loads(open("/path/to/file.txt", "r"))

output = open("/path/to/file2.txt", "w")
output.write(json.dumps(tmp, sort_keys=True, indent=4))
</code></pre>
<br /><b>#5</b><br /><pre><code>$ cat foo.json | python -mjson.tool
Expecting property name: line 11 column 41
</code></pre>

<p>The comma in <code>"type" : "String",</code> is causing the JSON decoder to choke.  If it wasn't for that problem, you could use <code>json.load()</code> to load the file directly.</p>

<p>In other words, you have malformed JSON, meaning you'll need to perform a replacement operation before feeding it to <code>json.loads()</code>. Since you'll need to read the file into a string completely to do the replacement operation anyway, use <code>json.loads(jsonstr)</code> instead of <code>json.load(jsonfilep)</code>:</p>

<pre><code>    &gt;&gt;&gt; import json, re
    &gt;&gt;&gt; jsonfilep = open('foo.json')
    &gt;&gt;&gt; jsonstr = re.sub(r'''(["'0-9.]\s*),\s*}''', r'\1}', jsonfilep.read())
    &gt;&gt;&gt; jsonobj = json.loads(jsonstr)
    &gt;&gt;&gt; jsonstr = json.dumps(jsonobj)
    &gt;&gt;&gt; print(jsonstr)
    {"foo": [{"blah": "blah blah", "id2": "5885221122", "bar": [{"info":
    [{"type": "String", "custid": "SSN"}], "name": "Joe JJ"}], "id1": "1"}]}
</code></pre>

<p>I only used the <code>re</code> module because it could happen for any value, number or string.</p>
<br />