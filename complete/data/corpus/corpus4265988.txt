Question (ID-4265988): Generate random numbers with a given (numerical) distribution I have a file with some probabilities for different values e.g.: 

 1 0.1
2 0.05
3 0.05
4 0.2
5 0.4
6 0.2
 

 I would like to generate random numbers using this distribution. Does an existing module that handles this exist? It's fairly simple to code on your own (build the cumulative density function, generate a random value [0,1] and pick the corresponding value) but it seems like this should be a common problem and probably someone has created a function/module for it. 

 I need this because I want to generate a list of birthdays (which do not follow any distribution in the standard random module). 
 Answers (Total-6): #0  scipy.stats.rv_discrete might be what you want. You can supply your probabilities via the values parameter. You can then use the rvs() method of the distribution object to generate random numbers. 
 #1 (OK, I know you are asking for shrink-wrap, but maybe those home-grown solutions just weren't succinct enough for your liking. :-) 

 pdf = [(1, 0.1), (2, 0.05), (3, 0.05), (4, 0.2), (5, 0.4), (6, 0.2)]
cdf = [(i, sum(p for j,p in pdf if j &lt; i)) for i,_ in pdf]
R = max(i for r in [random.random()] for i,c in cdf if c &lt;= r)
 

 I pseudo-confirmed that this works by eyeballing the output of this expression: 

 sorted(max(i for r in [random.random()] for i,c in cdf if c &lt;= r)
  for _ in range(1000))
 
 #2 you might want to have a look at NumPy Random sampling distributions 
 #3 Make a list of items, based on their weights : 

 items = [1, 2, 3, 4, 5, 6]
probabilities= [0.1, 0.05, 0.05, 0.2, 0.4, 0.2]
# if the list of probs is normalized (sum(probs) == 1), omit this part
prob = sum(probabilities) # find sum of probs, to normalize them
c = (1.0)/prob # a multiplier to make a list of normalized probs
probabilities = map(lambda x: c*x, probabilities)
print probabilities

ml = max(probabilities, key=lambda x: len(str(x)) - str(x).find('.'))
ml = len(str(ml)) - str(ml).find('.') -1
amounts = [ int(x*(10**ml)) for x in probabilities]
itemsList = list()
for i in range(0, len(items)): # iterate through original items
 itemsList += items[i:i+1]*amounts[i]

# choose from itemsList randomly
print itemsList
 

 An optimization may be to normalize amounts by the greatest common divisor, to make the target list smaller. 

 Also, this might be interesting. 
 #4 Another answer, probably faster :) 

 distribution = [(1, 0.2), (2, 0.3), (3, 0.5)] 
# init distribution 
dlist = [] 
sumchance = 0 
for value, chance in distribution: 
 sumchance += chance 
 dlist.append((value, sumchance)) 
assert sumchance == 1.0 # not good assert because of float equality 

# get random value 
r = random.random() 
# for small distributions use lineair search 
if len(distribution) &lt; 64: # don't know exact speed limit 
 for value, sumchance in dlist: 
  if r &lt; sumchance: 
   return value 
else: 
 # else (not implemented) binary search algorithm 
 
 #5 An advantage to generating the list using CDF is that you can use binary search. While you need O(n) time and space for preprocessing, you can get k numbers in O(k log n). Since normal Python lists are inefficient, you can use array module. 

 If you insist on constant space, you can do the following; O(n) time, O(1) space. 

 def random_distr(l):
 r = random.uniform(0, 1)
 s = 0
 for item, prob in l:
  s += prob
  if s &gt;= r:
   return item
 return l[-1] # Might occur because of floating point inaccuracies