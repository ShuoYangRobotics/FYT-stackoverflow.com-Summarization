Question (ID-5190507): How do I grep for words coming from a file in files listed in a file? Searching a single file for a word is easy: 

 grep stuff file.txt
 

 But I have many files, each is a line in files.txt , and many words I want to find, each is a line in words.txt . The output should be a file with each line a =&gt; b with a being the line number in words.txt , b being the line number in files.txt . 

 I need to run it on OSX, so preferably something simple in shell, but any other language would be fine. I haven't had much experience with shell scripts myself, and I'm more used to languages that aren't useful for string searching (namely C - I'm guessing Perl or Python may be helpful, but I've not used them). 
 Answers (Total-8): #0 First, learn to specify the files of interest. In one directory or more than one directory? The Unix find utility will do that. 

 At the Bash prompt: 

 $ cd [the root directory where your files are]
$ find . -name "*.txt"
 

 You did not say, but assumably the files are describable with "star dot something" then find will find the files. 

 Next, pipe the files names to what you want to do to them: 

 $ find . -name "*.txt" -print0 | xargs -0 egrep 'stuff'
 

 That will run egrep on each file with the search pattern of stuff  

 Google find plus xargs for literally thousands of examples. Once you are comfortable finding the files -- rephrase your question so that it is a bit more obvious what you want to do to them. Then I can help you with Perl to do it. 
 #1 You might this to be faster, more Pythonic, and easier to understand: 

 with open("words.txt") as words:
 wlist=[(ln,word.strip()) for ln,word in enumerate(words,1)]

with open("files.txt") as files:
 flist=[(ln,file.strip()) for ln,file in enumerate(files,1)]

for filenum, filename in flist:
 with open(filename) as fdata:
  for fln,line in enumerate(fdata,1):
   for wln, word in wlist:
    if word in line:
     print "%d =&gt; %d" % (wln, fln)
 
 #2 This is a two-parter with awk:
1. scan each file in files.txt, and map the word number to the name of the file
2. map the filename to the line number in files.txt 

 awk '
 NR == FNR {word[$1] = NR; next}
 {for (i=1; i&lt;=NF; i++) {if ($i in word) {print word[$i] " =&gt; " FILENAME; break}}}
' words.txt $(&lt;files.txt) | 
sort -u |
awk '
 NR == FNR {filenum[$1] = NR; next}
 {$3 = filenum[$3]; print}
' files.txt -
 
 #3 Here's something that will do what you want, but the only thing is that it will not print out the matched word, instead just prints out the line matched, the file name, and the line number. However, if you use --color=auto on grep, it will highlight the matched words using whatever you have set in ${GREP_COLOR} , the default is red. 

 cat files.txt | xargs grep -nf words.txt --color=auto
 

 This command will dump all contents of files.txt , line by line, and it will pipe the file names to grep, which will search the file for every word that matches in words.txt . Similar to files.txt , words.txt should be all the search terms you want delimited by new-lines. 

 If your grep was built with the perl regular expression engine, then, you can use Perl regular expressions if you pass the -P option to grep like so: 

 grep -Pnf words.txt --color=auto
 

 Hope this helps. 

 Update: At first, I wasn't really sure what @Zeophlite was asking but after he posted his example, I see what he wanted. Here's a python implementation of what he wants to do: 

 from contextlib import nested


def search_file(line_num, filename):
 with nested(open(filename), open('words.txt')) as managers:
  open_filename, word_file = managers
  for line in open_filename:
   for wordfile_line_number, word in enumerate(word_file, 1):
    if word.strip() in line:
     print "%s =&gt; %s" % (line_num, wordfile_line_number)


with open('files.txt') as filenames_file:
 for filenames_line_number, fname in enumerate(filenames_file, 1):
  search_file(filenames_line_number, fname.strip())
 
 #4 The following script in python does it. This is my first attempt at python, so I'd appreciate any comments 

 flist = open('files.txt')

filenum = 0
for filename in flist:
 filenum = filenum + 1
 filenamey = filename.strip()
 filedata = open(filenamey)
 for fline in filedata:
  wordnum = 0
  wlist = open('words.txt')
  for word in wlist:
   wordnum = wordnum + 1
   sword = word.strip()
   if sword in fline:
    s = repr(filenum) + ' =&gt; ' + repr(wordnum)
    print s
 
 #5 To answer your demand 

 . 

 Your code: 

 flist = open('files.txt') 

filenum = 0 
for filename in flist: 
 filenum = filenum + 1 
 filenamey = filename.strip() 
 filedata = open(filenamey) 
 for fline in filedata: 
  wordnum = 0 
  wlist = open('words.txt') 
  for word in wlist: 
   wordnum = wordnum + 1 
   sword = word.strip() 
   if sword in fline: 
    s = repr(filenum) + ' =&gt; ' + repr(wordnum) 
    print s 
 

 You open 'files.txt' but don't close it.
 with open('files.txt') as flist: is preferable because it is textually cleaner and it manages to close alone. 

 Instead of filenum = filenum + 1 , use enumerate() 
From now, you must never forget enumerate() because it is an extremely useful function. It works very very fast, too. 

 fline isn't a good name for an iterator of lines, IMO; Isn't line a good one ? 

 The instruction wlist = open('words.txt') isn't in a good place: it is executed not only each for each file opened, but even each time a line is analysed.
Moreover, the treatment of the names listed in wlist is performed each time the wlist is iterated, that is to say at each line. You must put this treatment out of all the iterations. 

 wordnum is nothing else than the index of word in wlist . You can use again enumerate() or simply loop with index i and use wlist[i] instead of word 

 Each time a sword of wlist is in the line, you do 

 print repr(filenum) + ' =&gt; ' + repr(wordnum) 
 

 It would be better to do print repr(filenum) + ' =&gt; ' + repr(all_wordnum) in which all_wordnum would be the list of all the sword found in one line 

 You keep your list of words in a file. You'd better serialise the list of this words. See the modules pickle and pickle 

 There is also something to improve in the recording of result. Because executing the instruction 

 print repr(filenum) + ' =&gt; ' + repr(wordnum)
 

 each time is not a good practice. It's the same if you want to record in a file: you can't repeatedly order write() Better is to list all the result in a list, and print or record when process is over, making "\n".join(list) or something like that 
 #6 Doing it in pure shell, I'm close: 

 $ grep -n $(tr '\n' '|' &lt; words.txt | sed 's/|$//') $(cat files.txt)
 

 (Tried to figure out how to remove the $(cat files.txt) , but couldn't) 

 This prints out the words in each file, and prints out the lines where they occur, but it doesn't print out the line in words.txt where that word was located. 

 There's probably some really ugly (if you didn't think this was ugly enough) stuff I could do, but your real answer is to use a higher level language. The awk solution is shellish since most people now consider awk as just part of the Unix environment. However, if you're using awk , you might as well use perl , python , or ruby . 

 The only advantage awk has is that it is automatically included in a Linux/Unix distro even if the user who created the distro didn't include any of the development packages. It's rare, but it happens. 
 #7 A pure sh answer, assuming that words or filenames do not contain any shell metacharacters such as blanks: 

 nw=0; while read w; do nw=`expr $nw + 1`; nf=0; { while read f; do nf=`expr $nf + 1`; fgrep -n $w $f | sed 's/:.*//' | while read n; do echo $nw =\&gt; $nf; done; done &lt; /tmp/files.txt;}; done &lt; /tmp/words.txt
 

 But I prefer Perl for this kind of thing.
And the Perl script won't be quite as short or readable as carrrot-top's Python code, unless you use IO::All .