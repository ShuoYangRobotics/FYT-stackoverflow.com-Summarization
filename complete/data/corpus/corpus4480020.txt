Question (ID-4480020): Division by zero: int vs. float Deviding an int by zero, will throw an exception, but a float won't - at least in Java. Why a float have an additional NaN info, while int haven't? 
 Answers (Total-6): #0 The representation of a float has been designed such that there are some special combination of bits reserved to store special values such as NaN, infinity, etc. 

 There are no unused representations for an int type - every bit pattern corresponds to an integer. This has many advantages: 

 
 The range of an integer type is as large as possible - no bit patterns are wasted. 
 The representation of an integer is easy to understand because there are no special cases. 
 Integer arithmetic can be done at extremely high speed even on very simple processors. 
 
 #1 A clear Explanation about float arithmetic is given here 

 http://www.artima.com/underthehood/floatingP.html 
 #2 Basically, it's a purely arbitrary decision. 

 The traditional int tries to use all the bits for representing possible numbers, whereas IEEE 754 standard reserves a special value for NaN . 

 The standard could be changed for int s to include special values, at a cost of less efficient operations. The developers usually expect int operations to be very efficient, whereas the operations with floating point numbers are (purely psychologically) more allowed to be slower. 
 #3 Java reflects the way most CPUs are implemented. Integer divide by zero causes an interrupt on x86/x64 and Floating point divide by zero results in Infinity, Negative infinity or NaN. Note: with floating point you can also divide by negative zero. :P 
 #4 I think the real reason, the root of this, is the well known fact: computers store everything in zeroes and ones. 

 What does it have to do with integers, floats and zero division? It's pretty simple. If you have only zeroes and ones, it is pretty easy to combine them into integer numbers, like you do with decimal digits. So "10" becomes two, "11" becomes three and so on. This kind of integer representation is so natural that no one would think of inventing anything else for integers, it would just make CPUs more complicated and things more confusing. The only "invention" that was required is to figure out how to store negative numbers, but that's also very natural and simple if you start from the point that x+(-x) should always be equal to zero, without using any special kind of addition here. That's why 11111111 is -1 for 8-bit integers, because if you add 1 to it, it becomes 100000000, then 8th bit is truncated due to overflow and you get your zero. But this natural format has no place for infinities and NaNs, and nobody wanted to invent a non-natural representation just for that. Well, I won't be surprised if someone actually did that, but there is no way such format would become well-known and widely used. 

 Now, for floating-point numbers, there is no natural representation. Even if we translate 0.5 to binary, it would still be something like 0.1 only now we have "binary point" instead of decimal point. But CPUs can't naturally represent a "point", only 1 and 0. So some kind of special format was needed. There was simply no other way to go. And then someone probably suggested, "Hey guys, while we are at it, why not to include special representation for infinity and other numeric nonsense?" and so it was done. 

 This is the reason why these formats are so different. How to handle divisions by zero, it's up to language designers, but for floating-points they have the choice between inf/NaN and exceptions, while for integers they don't naturally have such kind of thing. 
 #5 Ints and floats are represented differently inside the machine. Integers usually use a signed, two's complement representation that is (essentially) the number written out in base two. Floats, on the other hand, use a more complex representation that can hold much larger and much smaller values. However, the machine reserves several special bit patterns for floats to mean things other than numbers. There's values for NaN, and for positive or negative infinity, for example. This means that if you divide a float by zero, there is a series of bits that the computer can use to encode that you divided by zero. For ints, all bit patterns are used to encode numbers, so there's no meaningful series of bits the computer could use to represent the error. 

 This isn't an essential property of ints, though. One could, in theory, make an integer representation that handles division by zero by returning some NaN variant. It's just not what's done in practice.