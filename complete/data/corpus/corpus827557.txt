Question (ID-827557): How do you validate a URL with a regular expression in Python? I'm building a Google App Engine app, and I have a class to represent an RSS Feed. 

 I have a method called setUrl which is part of the feed class. It accepts a url as an input. 

 I'm trying to use the re python module to validate off of the RFC 3986 Reg-ex ( http://www.ietf.org/rfc/rfc3986.txt ) 

 Below is a snipped which should work, right? I'm incredibly new to Python and have been beating my head against this for the past 3 days. 

 p = re.compile('^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?')
m = p.match(url)
if m:
 self.url = url
 return url
 
 Answers (Total-10): #0 Here's the complete regexp to parse a URL. 

 (?:http://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.
)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)
){3}))(?::(?:\d+))?)(?:/(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F
\d]{2}))|[;:@&amp;=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{
2}))|[;:@&amp;=])*))*)(?:\?(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{
2}))|[;:@&amp;=])*))?)?)|(?:ftp://(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?
:%[a-fA-F\d]{2}))|[;?&amp;=])*)(?::(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-
fA-F\d]{2}))|[;?&amp;=])*))?@)?(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-
)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?
:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?))(?:/(?:(?:(?:(?:[a-zA-Z\d$\-_.+!
*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&amp;=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'()
,]|(?:%[a-fA-F\d]{2}))|[?:@&amp;=])*))*)(?:;type=[AIDaid])?)?)|(?:news:(?:
(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;/?:&amp;=])+@(?:(?:(
?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[
a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3})))|(?:[a-zA-Z](
?:[a-zA-Z\d]|[_.+-])*)|\*))|(?:nntp://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[
a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d
])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?)/(?:[a-zA-Z](?:[a-zA-Z
\d]|[_.+-])*)(?:/(?:\d+))?)|(?:telnet://(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+
!*'(),]|(?:%[a-fA-F\d]{2}))|[;?&amp;=])*)(?::(?:(?:(?:[a-zA-Z\d$\-_.+!*'()
,]|(?:%[a-fA-F\d]{2}))|[;?&amp;=])*))?@)?(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a
-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d]
)?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?))/?)|(?:gopher://(?:(?:
(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:
(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+
))?)(?:/(?:[a-zA-Z\d$\-_.+!*'(),;/?:@&amp;=]|(?:%[a-fA-F\d]{2}))(?:(?:(?:[
a-zA-Z\d$\-_.+!*'(),;/?:@&amp;=]|(?:%[a-fA-F\d]{2}))*)(?:%09(?:(?:(?:[a-zA
-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;:@&amp;=])*)(?:%09(?:(?:[a-zA-Z\d$
\-_.+!*'(),;/?:@&amp;=]|(?:%[a-fA-F\d]{2}))*))?)?)?)?)|(?:wais://(?:(?:(?:
(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:
[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?
)/(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)(?:(?:/(?:(?:[a-zA
-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)/(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(
?:%[a-fA-F\d]{2}))*))|\?(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]
{2}))|[;:@&amp;=])*))?)|(?:mailto:(?:(?:[a-zA-Z\d$\-_.+!*'(),;/?:@&amp;=]|(?:%
[a-fA-F\d]{2}))+))|(?:file://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]
|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:
(?:\d+)(?:\.(?:\d+)){3}))|localhost)?/(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'()
,]|(?:%[a-fA-F\d]{2}))|[?:@&amp;=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(
?:%[a-fA-F\d]{2}))|[?:@&amp;=])*))*))|(?:prospero://(?:(?:(?:(?:(?:[a-zA-Z
\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)
*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?)/(?:(?:(?:(?
:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&amp;=])*)(?:/(?:(?:(?:[a-
zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&amp;=])*))*)(?:(?:;(?:(?:(?:[
a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&amp;])*)=(?:(?:(?:[a-zA-Z\d
$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[?:@&amp;])*)))*)|(?:ldap://(?:(?:(?:(?:
(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?:
[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))?
))?/(?:(?:(?:(?:(?:(?:(?:[a-zA-Z\d]|%(?:3\d|[46][a-fA-F\d]|[57][Aa\d])
)|(?:%20))+|(?:OID|oid)\.(?:(?:\d+)(?:\.(?:\d+))*))(?:(?:%0[Aa])?(?:%2
0)*)=(?:(?:%0[Aa])?(?:%20)*))?(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F
\d]{2}))*))(?:(?:(?:%0[Aa])?(?:%20)*)\+(?:(?:%0[Aa])?(?:%20)*)(?:(?:(?
:(?:(?:[a-zA-Z\d]|%(?:3\d|[46][a-fA-F\d]|[57][Aa\d]))|(?:%20))+|(?:OID
|oid)\.(?:(?:\d+)(?:\.(?:\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])
?(?:%20)*))?(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)))*)(?:(
?:(?:(?:%0[Aa])?(?:%20)*)(?:[;,])(?:(?:%0[Aa])?(?:%20)*))(?:(?:(?:(?:(
?:(?:[a-zA-Z\d]|%(?:3\d|[46][a-fA-F\d]|[57][Aa\d]))|(?:%20))+|(?:OID|o
id)\.(?:(?:\d+)(?:\.(?:\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])?(
?:%20)*))?(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*))(?:(?:(?:
%0[Aa])?(?:%20)*)\+(?:(?:%0[Aa])?(?:%20)*)(?:(?:(?:(?:(?:[a-zA-Z\d]|%(
?:3\d|[46][a-fA-F\d]|[57][Aa\d]))|(?:%20))+|(?:OID|oid)\.(?:(?:\d+)(?:
\.(?:\d+))*))(?:(?:%0[Aa])?(?:%20)*)=(?:(?:%0[Aa])?(?:%20)*))?(?:(?:[a
-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))*)))*))*(?:(?:(?:%0[Aa])?(?:%2
0)*)(?:[;,])(?:(?:%0[Aa])?(?:%20)*))?)(?:\?(?:(?:(?:(?:[a-zA-Z\d$\-_.+
!*'(),]|(?:%[a-fA-F\d]{2}))+)(?:,(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-f
A-F\d]{2}))+))*)?)(?:\?(?:base|one|sub)(?:\?(?:((?:[a-zA-Z\d$\-_.+!*'(
),;/?:@&amp;=]|(?:%[a-fA-F\d]{2}))+)))?)?)?)|(?:(?:z39\.50[rs])://(?:(?:(?
:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?)\.)*(?:[a-zA-Z](?:(?
:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:\d+)){3}))(?::(?:\d+))
?)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))+)(?:\+(?:(?:
[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))+))*(?:\?(?:(?:[a-zA-Z\d$\-_
.+!*'(),]|(?:%[a-fA-F\d]{2}))+))?)?(?:;esn=(?:(?:[a-zA-Z\d$\-_.+!*'(),
]|(?:%[a-fA-F\d]{2}))+))?(?:;rs=(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA
-F\d]{2}))+)(?:\+(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))+))*)
?))|(?:cid:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;?:@&amp;=
])*))|(?:mid:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;?:@
&amp;=])*)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[;?:@&amp;=]
)*))?)|(?:vemmi://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z
\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\
.(?:\d+)){3}))(?::(?:\d+))?)(?:/(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a
-fA-F\d]{2}))|[/?:@&amp;=])*)(?:(?:;(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a
-fA-F\d]{2}))|[/?:@&amp;])*)=(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d
]{2}))|[/?:@&amp;])*))*))?)|(?:imap://(?:(?:(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+
!*'(),]|(?:%[a-fA-F\d]{2}))|[&amp;=~])+)(?:(?:;[Aa][Uu][Tt][Hh]=(?:\*|(?:(
?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[&amp;=~])+))))?)|(?:(?:;[
Aa][Uu][Tt][Hh]=(?:\*|(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2
}))|[&amp;=~])+)))(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[
&amp;=~])+))?))@)?(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])
?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:\.(?:
\d+)){3}))(?::(?:\d+))?))/(?:(?:(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:
%[a-fA-F\d]{2}))|[&amp;=~:@/])+)?;[Tt][Yy][Pp][Ee]=(?:[Ll](?:[Ii][Ss][Tt]|
[Ss][Uu][Bb])))|(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))
|[&amp;=~:@/])+)(?:\?(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[
&amp;=~:@/])+))?(?:(?:;[Uu][Ii][Dd][Vv][Aa][Ll][Ii][Dd][Ii][Tt][Yy]=(?:[1-
9]\d*)))?)|(?:(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[&amp;=~
:@/])+)(?:(?:;[Uu][Ii][Dd][Vv][Aa][Ll][Ii][Dd][Ii][Tt][Yy]=(?:[1-9]\d*
)))?(?:/;[Uu][Ii][Dd]=(?:[1-9]\d*))(?:(?:/;[Ss][Ee][Cc][Tt][Ii][Oo][Nn
]=(?:(?:(?:[a-zA-Z\d$\-_.+!*'(),]|(?:%[a-fA-F\d]{2}))|[&amp;=~:@/])+)))?))
)?)|(?:nfs:(?:(?://(?:(?:(?:(?:(?:[a-zA-Z\d](?:(?:[a-zA-Z\d]|-)*[a-zA-
Z\d])?)\.)*(?:[a-zA-Z](?:(?:[a-zA-Z\d]|-)*[a-zA-Z\d])?))|(?:(?:\d+)(?:
\.(?:\d+)){3}))(?::(?:\d+))?)(?:(?:/(?:(?:(?:(?:(?:[a-zA-Z\d\$\-_.!~*'
(),])|(?:%[a-fA-F\d]{2})|[:@&amp;=+])*)(?:/(?:(?:(?:[a-zA-Z\d\$\-_.!~*'(),
])|(?:%[a-fA-F\d]{2})|[:@&amp;=+])*))*)?)))?)|(?:/(?:(?:(?:(?:(?:[a-zA-Z\d
\$\-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&amp;=+])*)(?:/(?:(?:(?:[a-zA-Z\d\$\
-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&amp;=+])*))*)?))|(?:(?:(?:(?:(?:[a-zA-
Z\d\$\-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&amp;=+])*)(?:/(?:(?:(?:[a-zA-Z\d
\$\-_.!~*'(),])|(?:%[a-fA-F\d]{2})|[:@&amp;=+])*))*)?)))
 

 Given its complexibility, I think you should go the urlparse way. 

 For completeness, here's the pseudo-BNF of the above regex (as a documentation): 

 ; The generic form of a URL is:

genericurl  = scheme ":" schemepart

; Specific predefined schemes are defined here; new schemes
; may be registered with IANA

url   = httpurl | ftpurl | newsurl |
     nntpurl | telneturl | gopherurl |
     waisurl | mailtourl | fileurl |
     prosperourl | otherurl

; new schemes follow the general syntax
otherurl  = genericurl

; the scheme is in lower case; interpreters should use case-ignore
scheme   = 1*[ lowalpha | digit | "+" | "-" | "." ]
schemepart  = *xchar | ip-schemepart


; URL schemeparts for ip based protocols:

ip-schemepart = "//" login [ "/" urlpath ]

login   = [ user [ ":" password ] "@" ] hostport
hostport  = host [ ":" port ]
host   = hostname | hostnumber
hostname  = *[ domainlabel "." ] toplabel
domainlabel = alphadigit | alphadigit *[ alphadigit | "-" ] alphadigit
toplabel  = alpha | alpha *[ alphadigit | "-" ] alphadigit
alphadigit  = alpha | digit
hostnumber  = digits "." digits "." digits "." digits
port   = digits
user   = *[ uchar | ";" | "?" | "&" | "=" ]
password  = *[ uchar | ";" | "?" | "&" | "=" ]
urlpath  = *xchar ; depends on protocol see section 3.1

; The predefined schemes:

; FTP (see also RFC959)

ftpurl   = "ftp://" login [ "/" fpath [ ";type=" ftptype ]]
fpath   = fsegment *[ "/" fsegment ]
fsegment  = *[ uchar | "?" | ":" | "@" | "&" | "=" ]
ftptype  = "A" | "I" | "D" | "a" | "i" | "d"

; FILE

fileurl  = "file://" [ host | "localhost" ] "/" fpath

; HTTP

httpurl  = "http://" hostport [ "/" hpath [ "?" search ]]
hpath   = hsegment *[ "/" hsegment ]
hsegment  = *[ uchar | ";" | ":" | "@" | "&" | "=" ]
search   = *[ uchar | ";" | ":" | "@" | "&" | "=" ]

; GOPHER (see also RFC1436)

gopherurl  = "gopher://" hostport [ / [ gtype [ selector
     [ "%09" search [ "%09" gopher+_string ] ] ] ] ]
gtype   = xchar
selector  = *xchar
gopher+_string = *xchar

; MAILTO (see also RFC822)

mailtourl  = "mailto:" encoded822addr
encoded822addr = 1*xchar    ; further defined in RFC822

; NEWS (see also RFC1036)

newsurl  = "news:" grouppart
grouppart  = "*" | group | article
group   = alpha *[ alpha | digit | "-" | "." | "+" | "_" ]
article  = 1*[ uchar | ";" | "/" | "?" | ":" | "&" | "=" ] "@" host

; NNTP (see also RFC977)

nntpurl  = "nntp://" hostport "/" group [ "/" digits ]

; TELNET

telneturl  = "telnet://" login [ "/" ]

; WAIS (see also RFC1625)

waisurl  = waisdatabase | waisindex | waisdoc
waisdatabase = "wais://" hostport "/" database
waisindex  = "wais://" hostport "/" database "?" search
waisdoc  = "wais://" hostport "/" database "/" wtype "/" wpath
database  = *uchar
wtype   = *uchar
wpath   = *uchar

; PROSPERO

prosperourl = "prospero://" hostport "/" ppath *[ fieldspec ]
ppath   = psegment *[ "/" psegment ]
psegment  = *[ uchar | "?" | ":" | "@" | "&" | "=" ]
fieldspec  = ";" fieldname "=" fieldvalue
fieldname  = *[ uchar | "?" | ":" | "@" | "&" ]
fieldvalue  = *[ uchar | "?" | ":" | "@" | "&" ]

; Miscellaneous definitions

lowalpha  = "a" | "b" | "c" | "d" | "e" | "f" | "g" | "h" |
     "i" | "j" | "k" | "l" | "m" | "n" | "o" | "p" |
     "q" | "r" | "s" | "t" | "u" | "v" | "w" | "x" |
     "y" | "z"
hialpha  = "A" | "B" | "C" | "D" | "E" | "F" | "G" | "H" | "I" |
     "J" | "K" | "L" | "M" | "N" | "O" | "P" | "Q" | "R" |
     "S" | "T" | "U" | "V" | "W" | "X" | "Y" | "Z"
alpha   = lowalpha | hialpha
digit   = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" |
     "8" | "9"
safe   = "$" | "-" | "_" | "." | "+"
extra   = "!" | "*" | "'" | "(" | ")" | ","
national  = "{" | "}" | "|" | "\" | "^" | "~" | "[" | "]" | "`"
punctuation = "" | "#" | "%" | 


reserved  = ";" | "/" | "?" | ":" | "@" | "&" | "="
hex   = digit | "A" | "B" | "C" | "D" | "E" | "F" |
     "a" | "b" | "c" | "d" | "e" | "f"
escape   = "%" hex hex

unreserved  = alpha | digit | safe | extra
uchar   = unreserved | escape
xchar   = unreserved | reserved | escape
digits   = 1*digit
 
 #1 An easy way to parse (and validate) URL's is the urlparse module. 

 A regex is too much work. 

 

 There's no "validate" method because almost anything is a valid URL. There are some punctuation rules for splitting it up. Absent any punctuation, you still have a valid URL. 

 Check the RFC carefully and see if you can construct an "invalid" URL. The rules are very flexible. 

 For example ::::: is a valid URL. The path is ":::::" . A pretty stupid filename, but a valid filename. 

 Also, ///// is a valid URL. The netloc ("hostname") is "" . The path is "///" . Again, stupid. Also valid. This URL normalizes to "///" which is the equivalent. 

 Something like "bad://///worse/////" is perfectly valid. Dumb but valid. 

 Bottom Line . Parse it, and look at the pieces to see if they're displeasing in some way. 

 Do you want the scheme to always be "http"? Do you want the netloc to always be "www.somename.somedomain"? Do you want the path to look unix-like? Or windows-like? Do you want to remove the query string? Or preserve it? 

 These are not RFC-specified validations. These are validations unique to your application. 
 #2 I admit, I find your regular expression totally incomprehensible. I wonder if you could use urlparse instead? Something like: 

 pieces = urlparse.urlparse(url)
assert all([pieces.scheme, pieces.netloc])
assert set(pieces.netloc) &lt;= set(string.letters + string.digits + '-.') # and others?
assert pieces.scheme in ['http', 'https', 'ftp'] # etc.
 

 It might be slower, and maybe you'll miss conditions, but it seems (to me) a lot easier to read and debug than a regular expression for URLs . 
 #3 RFC 3696 defines "best practices" for URL validation - http://www.faqs.org/rfcs/rfc3696.html 

 The latest release of Lepl (a Python parser library) includes an implementation of RFC 3696. You would use it something like: 

 from lepl.apps.rfc3696 import Email, HttpUrl

# compile the validators (do once at start of program)
valid_email = Email()
valid_http_url = HttpUrl()

# use the validators (as often as you like)
if valid_email(some_email):
 # email is ok
else:
 # email is bad
if valid_http_url(some_url):
 # url is ok
else:
 # url is bad
 

 Although the validators are defined in Lepl, which is a recursive descent parser, they are largely compiled internally to regular expressions. That combines the best of both worlds - a (relatively) easy to read definition that can be checked against RFC 3696 and an efficient implementation. There's a post on my blog showing how this simplifies the parser - http://www.acooke.org/cute/LEPLOptimi0.html 

 Lepl is available at http://www.acooke.org/lepl and the RFC 3696 module is documented at http://www.acooke.org/lepl/rfc3696.html 

 This is completely new in this release, so may contain bugs. Please contact me if you have any problems and I will fix them ASAP. Thanks. 
 #4 The regex provided should match any url of the form http://www.ietf.org/rfc/rfc3986.txt ; and does when tested in the python interpreter. 

 What format have the URLs you've been having trouble parsing had? 
 #5 I've needed to do this many times over the years and always end up copying someone else's regular expression who has thought about it way more than I want to think about it. 

 Having said that, there is a regex in the Django forms code which should do the trick: 

 http://code.djangoproject.com/browser/django/trunk/django/forms/fields.py#L534 
 #6 urlparse quite happily takes invalid URLs, it is more a string string-splitting library than any kind of validator. For example: 

 from urlparse import urlparse
urlparse('http://----')
# returns: ParseResult(scheme='http', netloc='----', path='', params='', query='', fragment='')
 

 Depending on the situation, this might be fine.. 

 If you mostly trust the data, and just want to verify the protocol is HTTP, then urlparse is perfect. 

 If you want to make the URL is actually a legal URL, use the ridiculous regex 

 If you want to make sure it's a real web address, 

 import urllib
try:
 urllib.urlopen(url)
except IOError:
 print "Not a real URL"
 
 #7 urlfinders = [
 re.compile("([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}|(((news|telnet|nttp|file|http|ftp|https)://)|(www|ftp)[-A-Za-z0-9]*\\.)[-A-Za-z0-9\\.]+)(:[0-9]*)?/[-A-Za-z0-9_\\$\\.\\+\\!\\*\\(\\),;:@&amp;=\\?/~\\#\\%]*[^]'\\.}&gt;\\),\\\"]"),
 re.compile("([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}|(((news|telnet|nttp|file|http|ftp|https)://)|(www|ftp)[-A-Za-z0-9]*\\.)[-A-Za-z0-9\\.]+)(:[0-9]*)?"),
 re.compile("(~/|/|\\./)([-A-Za-z0-9_\\$\\.\\+\\!\\*\\(\\),;:@&amp;=\\?/~\\#\\%]|\\\\
)+"),
 re.compile("'\\&lt;((mailto:)|)[-A-Za-z0-9\\.]+@[-A-Za-z0-9\\.]+"),
]
 

 NOTE: As ugly as it looks in your browser just copy paste and the formatting should be good 

 Found at the python mailing lists and used for the gnome-terminal 

 source: http://mail.python.org/pipermail/python-list/2007-January/595436.html 
 #8 I'm using the one used by Django and it seems pretty well: 

 def is_valid_url(url):
 import re
 regex = re.compile(
  r'^https?://' # http:// or https://
  r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|' # domain...
  r'localhost|' # localhost...
  r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})' # ...or ip
  r'(?::\d+)?' # optional port
  r'(?:/?|[/?]\S+)$', re.IGNORECASE)
 return url is not None and regex.search(url)
 

 You always can check the last version here: https://code.djangoproject.com/browser/django/trunk/django/core/validators.py#L47 
 #9 function isUrl(s) {
 var regexp = /(ftp|http|https):\/\/(\w+:{0,1}\w*@)?(\S+)(:[0-9]+)?(\/|\/([\w#!:.?+=&amp;%@!-\/]))?/
 return regexp.test(s);
}