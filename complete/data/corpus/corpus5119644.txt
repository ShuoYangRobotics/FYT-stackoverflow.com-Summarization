Question (ID-5119644): Identifying points with the smallest Euclidean distance I have a collection of n dimensional points and I want to find which 2 are the closest. The best I could come up for 2 dimensions is: 

 from numpy import *
myArr = array( [[1, 2],
    [3, 4],
    [5, 6],
    [7, 8]] )

n = myArr.shape[0]
cross = [[sum( ( myArr[i] - myArr[j] ) ** 2 ), i, j]
   for i in xrange( n )
   for j in xrange( n )
   if i != j
   ]

print min( cross )
 

 which gives 

 [8, 0, 1]
 

 But this is too slow for large arrays. What kind of optimisation can I apply to it? 

 RELATED: 

 

 Euclidean distance between points in two different Numpy arrays, not within 
 Answers (Total-6): #0 There's a whole Wikipedia page on just this problem, see: http://en.wikipedia.org/wiki/Closest_pair_of_points 

 Executive summary: you can achieve O(n log n) with a recursive divide and conquer algorithm (outlined on the Wiki page, above). 
 #1 Try scipy.spatial.distance.pdist(myArr) . This will give you a condensed distance matrix. You can use argmin on it and find the index of the smallest value. This can be converted into the pair information. 
 #2 There is a scipy function pdist that will get you the pairwise distances between points in an array in a fairly efficient manner: 

 http://docs.scipy.org/doc/scipy/reference/spatial.distance.html 

 that outputs the N*(N-1)/2 unique pairs (since r_ij == r_ji). You can then search on the minimum value and avoid the whole loop mess in your code. 
 #3 You could take advantage of the latest version of SciPy's (v0.9) Delaunay triangulation tools. You can be sure that the closest two points will be an edge of a simplex in the triangulation, which is a much smaller subset of pairs than doing every combination. 

 Here's the code (updated for general N-D): 

 import numpy
from scipy import spatial

def closest_pts(pts):
 # set up the triangluataion
 # let Delaunay do the heavy lifting
 mesh = spatial.Delaunay(pts)

 # TODO: eliminate reduncant edges (numpy.unique?)
 edges = numpy.vstack((mesh.vertices[:,:dim], mesh.vertices[:,-dim:]))

 # the rest is easy
 x = mesh.points[edges[:,0]]
 y = mesh.points[edges[:,1]]

 dists = numpy.sum((x-y)**2, 1)
 idx = numpy.argmin(dists)

 return edges[idx]
 #print 'distance: ', dists[idx]
 #print 'coords:\n', pts[closest_verts]

dim = 3
N = 1000*dim
pts = numpy.random.random(N).reshape(N/dim, dim)
 

 Seems closely O(n): 

 
 #4 Perhaps you could proceed along these lines: 

 In []: from scipy.spatial.distance import pdist as pd, squareform as sf
In []: m= 1234
In []: n= 123
In []: p= randn(m, n)
In []: d= sf(pd(p))
In []: a= arange(m)
In []: d[a, a]= d.max()
In []: where(d&lt; d.min()+ 1e-9)
Out[]: (array([701, 730]), array([730, 701]))
 

 With substantially more points you need to be able to somehow utilize the hierarchical structure of your clustering. 
 #5 How fast is it compared to just doing a nested loop and keeping track of the shortest pair? I think creating a huge cross array is what might be hurting you. Even O(n^2) is still pretty quick if you're only doing 2 dimensional points.