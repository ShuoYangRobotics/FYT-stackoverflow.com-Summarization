Question (ID-1336489): job queue implementation for python Do you know/use any distributed job queue for python? Can you share links or tools 
 Answers (Total-9): #0 Pyres is a resque clone built in python. Resque is used by Github as their message queue. Both use Redis as the queue backend and provide a web-based monitoring application. 

 http://binarydud.github.com/pyres/intro.html 
 #1 In addition to multiprocessing there's also the Celery project, if you're using Django. 
 #2 There's also "bucker" by Sylvain Hellegouarch which you can find here: 

 
 http://trac.defuze.org/wiki/bucker 
 

 It describes itself like this: 

 
 bucker is a queue system that supports multiple storage for the queue (memcached, Amazon SQS for now) and is driven by XML messages sent over a TCP connections between a client and the queue server. 
 
 #3 there are a couple of python rabbitmq clients - see this thread for instance. 
 #4 redqueue?
It's implemented in python+tornado framework, speaks memcached protocol and is optionally persistent into log files.
Currently it is also able to behave like beanstalkd, the reserve/delete way in memcache protocol as well. 

 REDQUEUE 
 #5 It's a year late or whatever, but this is something I've hacked together to make a queue of Processes executing them only X number at a time. http://github.com/goosemo/job_queue 
 #6 You probably want to look at multiprocessing's Queue. Included in Python 2.6, get it on PyPI for earlier versions of Python. 

 Standard library documentation: http://docs.python.org/library/multiprocessing.html 
On PyPI: http://pypi.python.org/pypi/multiprocessing 
 #7 Look at beanstalkd 
 #8 Also there is Unix 'at' 

 For more info:
man at