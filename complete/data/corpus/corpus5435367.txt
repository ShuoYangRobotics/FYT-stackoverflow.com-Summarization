Question (ID-5435367): Best matches for a partially specified word in Python I have a file dict.txt that has all words in the English language. 

 The user will input their word: 

 x = raw_input("Enter partial word: ") 

 Example inputs would be: r-n, --n, -u-, he--o, h-llo and so on, unknown characters would be specified by a underscore preferably instead of (-). 

 I want the program to come up with a list, of all the best matches that are found in the dictionary. 

 Example: If partial word was r--, the list would contain run, ran, rat, rob and so on. 

 Is there any way to do this using for loops? 
 Answers (Total-6): #0 One easy way to do this would be by using regular expressions . Since it is unclear whether this question is homework, the details are left as an exercise for the reader. 
 #1 Instead of using _ to denote wildcards, use \w instead. Add \b to the beginning and end of the pattern, then just run the dictionary through a regexp matcher. So -un--- becomes: 

 &gt;&gt;&gt; import re
&gt;&gt;&gt; re.findall(r'\b\wun\w\w\w\b', "run runner bunt bunter bunted bummer")
['runner', 'bunter', 'bunted']
 

 \w matches any 'word character'. \b matches any word boundary. 
 #2 If you want to do this repeatedly you should create a index: 

 wordlist = [word.strip() for word in "run, ran, rat, rob, fish, tree".split(',')]

from collections import defaultdict

class Index(object):

 def __init__(self, wordlist=()):
  self.trie = defaultdict(set)
  for word in wordlist:
   self.add_word(word)

 def add_word(self, word):
  """ adds word to the index """
  # save the length of the word
  self.trie[len(word)].add(word) 
  for marker in enumerate(word):
   # add word to the set of words with (pos,char)
   self.trie[marker].add(word)


 def find(self, pattern, wildcard='-' ):
  # get all word with matching length as candidates
  candidates = self.trie[len(pattern)]

  # get all words with all the markers
  for marker in enumerate(pattern):   
   if marker[1] != wildcard:
    candidates &amp;= self.trie[marker]

   # exit early if there are no candicates
   if not candidates:    
    return None

  return candidates


with open('dict.txt', 'rt') as lines:
 wordlist = [word.strip() for word in lines]

s = Index(wordlist)
print s.find("r--")
 

 Tries are made for searching strings. This is a simple prefix trie, using a single dict. 
 #3 A few approaches occur to me; 

 The first is to preprocess your dictionary into words[wordlength][offset][charAtOffset] = set(matching words); then your query becomes an intersection of all relevant word-sets. Very fast, but memory-intensive and a lot of set-up work. 

 Ex: 

 # search for 'r-n'
matches = list(words[3][0]['r'] &amp; words[3][2]['n'])
 

 The second is a linear scan of the dictionary using regular expressions; much slower, but minimal memory footprint. 

 Ex: 

 import re

foundMatch = re.compile('r.n').match
matches = [word for word in allWords if foundMatch(word)]
 

 Third would be a recursive search into a word-Trie; 

 Fourth - and it sounds like what you want - is a naive word-matcher: 

 with open('dictionary.txt') as inf:
 all_words = [word.strip().lower() for word in inf] # one word per line

find_word = 'r-tt-r'
matching_words = []
for word in all_words:
 if len(word)==len(find_word):
  if all(find==ch or find=='-' for find,ch in zip(find_word, word)):
   matching_words.append(word)
 

 Edit : full code for the first option follows: 

 from collections import defaultdict
import operator

try:
 inp = raw_input # Python 2.x
except NameError:
 inp = input  # Python 3.x

class Words(object):
 @classmethod
 def fromFile(cls, fname):
  with open(fname) as inf:
   return cls(inf)

 def __init__(self, words=None):
  super(Words,self).__init__()
  self.words = set()
  self.index = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))
  _addword = self.addWord
  for word in words:
   _addword(word.strip().lower())

 def addWord(self, word):
  self.words.add(word)
  _ind = self.index[len(word)]
  for ind,ch in enumerate(word):
   _ind[ind][ch].add(word)

 def findAll(self, pattern):
  pattern = pattern.strip().lower()
  _ind = self.index[len(pattern)]
  return reduce(operator.__and__, (_ind[ind][ch] for ind,ch in enumerate(pattern) if ch!='-'), self.words)

def main():
 print('Loading dict... ')
 words = Words.fromFile('dict.txt')
 print('done.')

 while True:
  seek = inp('Enter partial word ("-" is wildcard, nothing to exit): ').strip()
  if seek:
   print("Matching words: "+' '.join(words.findAll(seek))+'\n')
  else:
   break

if __name__=="__main__":
 main()
 
 #4 Sounds like homework involving searching algorithms or something, but I'll give you a start. 

 One solution might be to index the file (if this can be done in a reasonable time) into a tree structure with each character representing a node value and each child being all subsequent characters. You could then traverse the tree using the input as a map. A character represents the next node to go to and a dash represents that it should include all child nodes. Every time you hit a leaf n levels deeps with n being the length of the input you know you've found a match. 

 The nice thing is that once you index, your search will speed up considerably. It's the indexing that can take forever... 
 #5 Takes a bit of memory but this does the trick: 

 import re
import sys

word = '\\b' + sys.argv[1].replace('-', '\\w') + '\\b'
print word

with open('data.txt', 'r') as fh:
 print re.findall(word, fh.read())