Question (ID-7961363): Python removing duplicates in lists So pretty much I need to write a program to check if a list has any duplicates and if it does it removes them and returns a new list with the items that werent duplicated/removed. This is what I have but to be honest I do not know what to do. 

 def remove_duplicates():
 t = ['a', 'b', 'c', 'd']
 t2 = ['a', 'c', 'd']
 for t in t2:
  t.append(t.remove())
 return t
 
 Answers (Total-6): #0 This should cover whatever you are trying to do: 

 &gt;&gt;&gt; t = [ 1, 2, 3, 1, 2, 5, 6, 7, 8 ]
&gt;&gt;&gt; t
[1, 2, 3, 1, 2, 5, 6, 7, 8]
&gt;&gt;&gt; list( set( t ) )
[1, 2, 3, 5, 6, 7, 8]
&gt;&gt;&gt; s = [ 1, 2, 3 ]
&gt;&gt;&gt; list( set( t ) - set( s ) )
[8, 5, 6, 7]
 
 #1 It's a one-liner: list(set(source_list)) will do the trick. 

 A set is something that can't possibly have duplicates. 
 #2 If you don't care about the order, just do this: 

 def remove_duplicates(l):
 return list(set(l))
 

 A set is guaranteed to not have duplicates. 
 #3 Check out this blog post for a few ways to do it, all benchmarked: http://www.peterbe.com/plog/uniqifiers-benchmark 
 #4 FWIW, the new Python way for removing duplicates from an iterable while keeping it in the original order is: 

 &gt;&gt;&gt; from collections import OrderedDict
&gt;&gt;&gt; list(OrderedDict.fromkeys('abracadabra'))
['a', 'b', 'r', 'c', 'd']
 
 #5 Try using sets: 

 import sets
t = sets.Set(['a', 'b', 'c', 'd'])
t1 = sets.Set(['a', 'b', 'c'])

print t | t1
print t - t1