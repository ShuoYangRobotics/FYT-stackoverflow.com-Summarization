Question (ID-1942298): Wrapping a C library in Python: C, Cython or ctypes? I want to call a C library from a Python application. I don't want to wrap the whole API, only the functions and datatypes that are relevant to my case. As I see it, I have three choices: 

 
 Create an actual extension module in C. Probably overkill, and I'd also like to avoid the overhead of learning extension writing. 
 Use Cython to expose the relevant parts from the C library to Python. 
 Do the whole thing in Python, using ctypes to communicate with the external library. 
 

 I'm not sure whether 2) or 3) is the better choice. The advantage of 3) is that ctypes is part of the standard library, and the resulting code would be pure Python &ndash; although I'm not sure how big that advantage actually is. 

 Are there more advantages / disadvantages with either choice? Which approach do you recommend? 

 

 Edit: Thanks for all your answers, they provide a good resource for anyone looking to do something similar. The decision, of course, is still to be made for the single case&mdash;there's no one "This is the right thing" sort of answer. For my own case, I'll probably go with ctypes, but I'm also looking forward to trying out Cython in some other project. 

 With there being no single true answer, accepting one is somewhat arbitrary; I chose FogleBird's answer as it provides some good insight into ctypes and it currently also is the highest-voted answer. However, I suggest to read all the answers to get a good overview. 

 Thanks again. 
 Answers (Total-8): #0 Cython is a pretty cool tool in itself, well worth learning, and is surprisingly close to the Python syntax. If you do any scientific computing with Numpy, then Cython is the way to go because it integrates with Numpy for fast matrix operations. 

 Cython is a superset of Python language. You can throw any valid Python file at it, and it will spit out a valid C program. In this case, Cython will just map the Python calls to the underlying CPython API. This results in perhaps a 50% speedup because your code is no longer interpreted. 

 To get some optimizations, you have to start telling Cython additional facts about your code, such as type declarations. If you tell it enough, it can boil the code down to pure C. That is, a for loop in Python becomes a for loop in C. Here you will see massive speed gains. You can also link to external C programs here. 

 Using Cython code is also incredibly easy. I thought the manual makes it sound difficult. You literally just do: 

 $ cython mymodule.pyx
$ gcc [some arguments here] mymodule.c -o mymodule.so
 

 and then you can import mymodule in your Python code and forget entirely that it compiles down to C. 

 In any case, because Cython is so easy to setup and start using, I suggest trying it to see if it suits your needs. It won't be a waste if it turns out not to be the tool you're looking for. 
 #1 ctypes is your best bet for getting it done quickly, and it's a pleasure to work with as you're still writing Python! 

 I recently wrapped an FTDI driver for communicating with a USB chip using ctypes and it was great. I had it all done and working in less than one work day. (I only implemented the functions we needed, about 15 functions). 

 We were previously using a third-party module, PyUSB , for the same purpose. PyUSB is an actual C/Python extension module. But PyUSB wasn't releasing the GIL when doing blocking reads/writes, which was causing problems for us. So I wrote our own module using ctypes, which does release the GIL when calling the native functions. 

 One thing to note is that ctypes won't know about #define constants and stuff in the library you're using, only the functions, so you'll have to redefine those constants in your own code. 

 Here's an example of how the code ended up looking (lots snipped out, just trying to show you the gist of it): 

 from ctypes import *

d2xx = WinDLL('ftd2xx')

OK = 0
INVALID_HANDLE = 1
DEVICE_NOT_FOUND = 2
DEVICE_NOT_OPENED = 3

...

def openEx(serial):
 serial = create_string_buffer(serial)
 handle = c_int()
 if d2xx.FT_OpenEx(serial, OPEN_BY_SERIAL_NUMBER, byref(handle)) == OK:
  return Handle(handle.value)
 raise D2XXException

class Handle(object):
 def __init__(self, handle):
  self.handle = handle
 ...
 def read(self, bytes):
  buffer = create_string_buffer(bytes)
  count = c_int()
  if d2xx.FT_Read(self.handle, buffer, bytes, byref(count)) == OK:
   return buffer.raw[:count.value]
  raise D2XXException
 def write(self, data):
  buffer = create_string_buffer(data)
  count = c_int()
  bytes = len(data)
  if d2xx.FT_Write(self.handle, buffer, bytes, byref(count)) == OK:
   return count.value
  raise D2XXException
 

 Someone did some benchmarks on the various options. 

 I might be more hesitant if I had to wrap a C++ library with lots of classes/templates/etc. But ctypes works well with structs and can even callback into Python. 
 #2 I'll throw another one out there: SWIG 

 It's easy to learn, does a lot of things right, and supports many more languages so the time spent learning it can be pretty useful. 

 If you use SWIG, you are creating a new python extension module, but with SWIG doing most of the heavy lifting for you. 
 #3 Personally, I'd write an extension module in C. Don't be intimidated by Python C extensions -- they're not hard at all to write. The documentation is very clear and helpful. When I first wrote a C extension in Python, I think it took me about an hour to figure out how to write one -- not much time at all. 
 #4 If you have already a library with a defined API, I'll think ctypes it's the best option, as you only have to do a little initialization and then more or less call the library the way you're used to. 

 I think Cython or creating an extension module in C (which it's not very difficult) are more useful when you've need need new code, e.g. calling that library and do some complex, time-consuming tasks, and then passing the result to Python. 

 Another approach, for simple programs, is directly do a different process (compiled externally), outputting the result to standard output and call it with subprocess module. Sometimes it's the easiest approach. 

 For example, if you make a console C program that works more or less that way 

 $miCcode 10
Result: 12345678
 

 You could call it from Python 

 &gt;&gt;&gt; import subprocess
&gt;&gt;&gt; p = subprocess.Popen(['miCcode', '10'], shell=True, stdout=subprocess.PIPE)
&gt;&gt;&gt; std_out, std_err = p.communicate()
&gt;&gt;&gt; print std_out
Result: 12345678
 

 With a little string formating, you can take the result in any way you want.You can also capture the standard error output, so it's quite flexible. 
 #5 Warning: a Cython core developer's opinion ahead. 

 I almost always recommend Cython over ctypes. The reason is that it has a much smoother upgrade path. If you use ctypes, many things will be simple at first, and it's certainly cool to write your FFI code in plain Python, without compilation, build dependencies and all that. However, at some point, you will almost certainly find that you have to call into your C library a lot, either in a loop or in a longer series of interdependent calls, and you would like to speed that up. That's the point where you'll notice that you can't do that with ctypes. Or, when you need callback functions and you find that your Python callback code becomes a bottleneck, you'd like to speed it up and/or move it down into C as well. Again, you cannot do that with ctypes. So you have to switch languages at that point and start rewriting parts of your code, potentially reverse engineering your Python/ctypes code into plain C, thus spoiling the whole benefit of writing your code in plain Python in the first place. 

 With Cython, OTOH, you're completely free to make the wrapping and calling code as thin or thick as you want. You can start with simple calls into your C code from regular Python code, and Cython will translate them into native C calls, without any additional calling overhead, and with an extremely low conversion overhead for Python parameters. When you notice that you need even more performance at some point where you are making too many expensive calls into your C library, you can start annotating your surrounding Python code with static types and let Cython optimise it straight down into C for you. Or, you can start rewriting parts of your C code in Cython in order to avoid calls and to specialise and tighten your loops algorithmically. And if you need a fast callback, just write a function with the appropriate signature and pass it into the C callback registry directly. Again, no overhead, and it gives you plain C calling performance. And in the much less likely case that you really cannot get your code fast enough in Cython, you can still consider rewriting the truly critical parts of it in C (or C++ or Fortran) and call it from your Cython code naturally and natively. But then, this really becomes the last resort instead of the only option. 

 So, ctypes is nice to do simple things and to quickly get something running. However, as soon as things start to grow, you'll most likely come to the point where you notice that you'd better used Cython right from the start. 
 #6 ctypes is great when you've already got a compiled library blob to deal with (such as OS libraries). The calling overhead is severe, however, so if you'll be making a lot of calls into the library, and you're going to be writing the C code anyway (or at least compiling it), I'd say to go for cython . It's not much more work, and it'll be much faster and more pythonic to use the resulting pyd file. 

 I personally tend to use cython for quick speedups of python code (loops and integer comparisons are two areas where cython particularly shines), and when there is some more involved code/wrapping of other libraries involved, I'll turn to Boost.Python . Boost.Python can be finicky to set up, but once you've got it working, it makes wrapping C/C++ code straightforward. 

 cython is also great at wrapping numpy (which I learned from the SciPy 2009 proceedings ), but I haven't used numpy, so I can't comment on that. 
 #7 There's also one possibility to use GObject Introspection for libraries that are using GLib .