Question (ID-291740): How do I split a huge text file in python I have a huge text file (~1GB) and sadly the text editor I use won't read such a large file. However, if I can just split it into two or three parts I'll be fine, so, as an exercise I wanted to write a program in python to do it. 

 What I think I want the program to do is to find the size of a file, divide that number into parts, and for each part, read up to that point in chunks, writing to a filename .nnn output file, then read up-to the next line-break and write that, then close the output file, etc. Obviously the last output file just copies to the end of the input file. 

 Can you help me with the key filesystem related parts: filesize, reading and writing in chunks and reading to a line-break? 

 I'll be writing this code test-first, so there's no need to give me a complete answer, unless its a one-liner ;-) 
 Answers (Total-7): #0 Check out os.stat() for file size and file.readlines([sizehint]) . Those two functions should be all you need for the reading part, and hopefully you know how to do the writing :) 
 #1 linux has a split command 

 split -l 100000 file.txt 

 would split into files of equal 100,000 line size 
 #2 You can use wc and split (see the respective manpages) to get the desired effect. In bash : 

 split -dl$((`wc -l 'filename'|sed 's/ .*$//'` / 3 + 1)) filename filename-chunk.
 

 produces 3 parts of the same linecount (with a rounding error in the last, of course), named filename-chunk.00 to filename-chunk.02 . 
 #3 I've written the program and it seems to work fine. So thanks to Kamil Kisiel for getting me started. 
(Note that FileSizeParts() is a function not shown here) 
Later I may get round to doing a version that does a binary read to see if its any quicker. 

 def Split(inputFile,numParts,outputName):
 fileSize=os.stat(inputFile).st_size
 parts=FileSizeParts(fileSize,numParts)
 openInputFile = open(inputFile, 'r')
 outPart=1
 for part in parts:
  if openInputFile.tell()&lt;fileSize:
   fullOutputName=outputName+os.extsep+str(outPart)
   outPart+=1
   openOutputFile=open(fullOutputName,'w')
   openOutputFile.writelines(openInputFile.readlines(part))
   openOutputFile.close()
 openInputFile.close()
 return outPart-1
 
 #4 This generator method is a (slow) way to get a slice of lines without blowing up your memory. 

 def slicefile(filename, start, end):
 for i, line in enumerate(open(filename)):
  if i &gt;= end:
   return
  if start &lt;= i:
   yield line

out = open("/blah.txt", "w")
for line in slicefile("/python26/readme.txt", 10, 15):
 out.write(line)
 
 #5 don't forget seek() and mmap() for random access to files. 

 def getSomeChunk(filename, start, len):
 fobj = open(filename, 'r+b')
 m = mmap.mmap(fobj.fileno(), 0)
 return m[start:start+len]
 
 #6 Or, a python version of wc and split: 

 lines = 0
for l in open(filename): lines += 1
 

 Then some code to read the first lines/3 into one file, the next lines/3 into another , etc.