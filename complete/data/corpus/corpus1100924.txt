Question (ID-1100924): Best way to denormalize data in Django? I'm developing a simple web app, and it makes a lot of sense to store some denormalized data. 

 Imagine a blogging platform that keeps track of Comments, and the BlogEntry model has a "CommentCount" field that I'd like to keep up to date. 

 One way of doing this would be to use Django signals. 

 Another way of doing this would be to put hooks directly in my code that creates and destrys Comment objects to synchronously call some methods on BlogEntry to increment/decrement the comment count. 

 I suppose there are other pythonic ways of accomplishing this with decorators or some other voodoo. 

 What is the standard Design Pattern for denormalizing in Django? In practice, do you also have to write consistency checkers and data fixers in case of errors? 
 Answers (Total-6): #0 You have managers in Django. 

 Use a customized manager to do creates and maintain the FK relationships. 

 The manager can update the counts as the sets of children are updated. 

 If you don't want to make customized managers, just extend the save method. Everything you want to do for denormalizing counts and sums can be done in save . 

 You don't need signals. Just extend save . 
 #1 I found django-denorm to be useful. It uses database-level triggers instead of signals, but as far as I know, there is also branch based on different approach. 
 #2 definitely use signals 
 #3 The first approach (signals) has the advantage to loose the coupling between models. 
However, signals are somehow more difficult to maintain, because dependencies are less explicit (at least, in my opinion). 
If the correctness of the comment count is not so important, you could also think of a cron job that will update it every n minutes. 

 However, no matter the solution, denormalizing will make maintenance more difficult ; for this reason I would try to avoid it as much as possible, resolving instead to using caches or other techniques -- for example, using with comments.count as cnt in templates may improve performance quite a lot. 
Then, if everything else fails, and only in that case, think about what could be the best approach for the specific problem. 
 #4 Django offers a great and efficient (though not very known) alternative to counter denormalization . 

 It will save your many lines of code and it's really slow since you retrieve the count in the same SQL query. 

 I will suppose you have these classes: 

 class BlogEntry(models.Model):
  title = models.CharField()
  ...


class Comment(models.Model):
  body = models.TextField()
  blog_entry = models.ForeignKey(BlogEntry)
 

 In your views.py, use annotations : 

 from django.db.models import Count

def blog_entry_list(Request):
 blog_entries = BlogEntry.objects.annotate(count=Count('comment_set')).all()
 ...
 

 And you will have an extra field per each BlogEntry, that contains the count of comments, plus the rest of fields of BlobEntry. 

 You can use this extra field in the templates too: 

 {% for blog_entry in blog_entries %}
 {{ blog_entry.title }} has {{ blob_entry.count }} comments!
{% endfor %}
 

 This will not only save you coding and maintenance time but it is really efficient (the query takes only a bit longer to be executed). 
 #5 Why not just get the set of comments, and find the number of elements, using the count() method: 

 count = blog_entry.comment_set.count()
 

 Then you can pass that into your template. 

 Or, alternative, in the template itself, you can do: 

 {{ blog_entry.comment_set.count }}
 

 to get the number of comments.