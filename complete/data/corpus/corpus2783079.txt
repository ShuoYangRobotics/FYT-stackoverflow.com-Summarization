Question (ID-2783079): How do I convert a unicode to a string at the Python level? The following unicode and string can exist on their own if defined explicitly: 

 &gt;&gt;&gt; value_str='Andr\xc3\xa9'
&gt;&gt;&gt; value_uni=u'Andr\xc3\xa9'
 

 If I only have u'Andr\xc3\xa9' assigned to a variable like above, how do I convert it to 'Andr\xc3\xa9' in Python 2.5 or 2.6? 

 EDIT: 

 I did the following: 

 &gt;&gt;&gt; value_uni.encode('latin-1')
'Andr\xc3\xa9'
 

 which fixes my issue. Can someone explain to me what exactly is happening? 
 Answers (Total-7): #0 You seem to have gotten your encodings muddled up. It seems likely that what you really want is u'Andr\xe9' which is equivalent to 'André' . 

 But what you have seems to be a UTF-8 encoding that has been incorrectly decoded. You can fix it by converting the unicode string to an ordinary string. I'm not sure what the best way is, but this seems to work: 

 &gt;&gt;&gt; ''.join(chr(ord(c)) for c in u'Andr\xc3\xa9')
'Andr\xc3\xa9'
 

 Then decode it correctly: 

 &gt;&gt;&gt; ''.join(chr(ord(c)) for c in u'Andr\xc3\xa9').decode('utf8')
u'Andr\xe9' 
 

 Now it is in the correct format. 

 However instead of doing this, if possible you should try to work out why the data has been incorrectly encoded in the first place, and fix that problem there. 
 #1 value_uni.encode('utf8') or whatever encoding you need. 

 See http://docs.python.org/library/stdtypes.html#str.encode 
 #2 The OP is not converting to ascii nor utf-8. That's why the suggested encode methods won't work. Try this: 

 v = u'Andr\xc3\xa9'
s = ''.join(map(lambda x: chr(ord(x)),v))
 

 The chr(ord(x)) business gets the numeric value of the unicode character (which better fit in one byte for your application), and the ''.join call is an idiom that converts a list of ints back to an ordinary string. No doubt there is a more elegant way. 
 #3 You asked (in a comment) """That is what's puzzling me. How did it go from it original accented to what it is now? When you say double encoding with utf8 and latin1, is that a total of 3 encodings(2 utf8 + 1 latin1)? What's the order of the encode from the original state to the current one?""" 

 In the answer by Mark Byers, he says """what you have seems to be a UTF-8 encoding that has been incorrectly decoded""". You have accepted his answer. But you are still puzzled? OK, here's the blow-by-blow description: 

 Note: All strings will be displayed using (implicitly) repr() . unicodedata.name() will be used to verify the contents. That way, variations in console encoding cannot confuse interpretation of the strings. 

 Initial state: you have a unicode object that you have named u1. It contains e-acute: 

 &gt;&gt;&gt; u1 = u'\xe9'
&gt;&gt;&gt; import unicodedata as ucd
&gt;&gt;&gt; ucd.name(u1)
'LATIN SMALL LETTER E WITH ACUTE'
 

 You encode u1 as UTF-8 and name the result s: 

 &gt;&gt;&gt; s = u1.encode('utf8')
&gt;&gt;&gt; s
'\xc3\xa9'
 

 You decode s using latin1 -- INCORRECTLY; s was encoded using utf8, NOT latin1. The result is meaningless rubbish. 

 &gt;&gt;&gt; u2 = s.decode('latin1')
&gt;&gt;&gt; u2
u'\xc3\xa9'
&gt;&gt;&gt; ucd.name(u2[0]); ucd.name(u2[1])
'LATIN CAPITAL LETTER A WITH TILDE'
'COPYRIGHT SIGN'
&gt;&gt;&gt;
 

 Please understand: unicode_object.encode('x').decode('y) when x != y is normally [see note below] a nonsense; it will raise an exception if you are lucky; if you are unlucky it will silently create gibberish. Also please understand that silently creating gibberish is not a bug -- there is no general way that Python (or any other language) can detect that a nonsense has been committed. This applies particularly when latin1 is involved, because all 256 codepoints map 1 to 1 with the first 256 Unicode codepoints, so it is impossible to get a UnicodeDecodeError from str_object.decode('latin1'). 

 Of course, abnormally (one hopes that it's abnormal) you may need to reverse out such a nonsense by doing gibberish_unicode_object.encode('y').decode('x') as suggested in various answers to your question. 
 #4 Simplified explanation. The str type is able to hold only characters from 0-255 range. If you want to store unicode (which can contain characters from much wider range) in str you first have to encode unicode to format suitable for str, for example UTF-8. 

 To do this call method encode on your str object and as an argument give desired encoding, for example this_is_str = value_uni.encode('utf-8') . 

 You can read longer and more in-depth (and language agnostic) article on Unicode handling here: The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) . 

 Another excellent article (this time Python-specific): Unicode HOWTO 
 #5 If you have u'Andr\xc3\xa9' , it was likely originally UTF-8 from whatever source this was obtained from. If possible, read the source again decoding with 'utf-8' instead. Otherwise just reverse the mistake: 

 &gt;&gt;&gt; print u'Andr\xc3\xa9'.encode('latin-1').decode('utf-8')
André
 
 #6 It seems like 

 str(value_uni)
 

 should work... at least, it did when I tried it. 

 EDIT : Turns out that this only works because my system's default encoding is, as far as I can tell, ISO-8859-1 (Latin-1). So for a platform-independent version of this, try 

 value_uni.encode('latin1')