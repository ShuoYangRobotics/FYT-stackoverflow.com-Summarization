Question (ID-8431917): extracting data from a dictionary I have two tab delimited files, file 1 contains identifiers and file 2 has values related to these identifiers (or say it is a very big dictionary). 

 file 1 

 
Ronny
Rubby
Suzie
Paul
 

 file 1 has only one column. 

 file 2 

 
Alistar Barm Cathy Paul Ronny Rubby Suzie Tom Uma Vai Zai
12  13 14 12  11 11 12 23 30 0.34 0.65
1  4  56 23  12 8.9 5.1 1 4 25 3
 

 n number of rows are present in file 2. 

 what I want, if the identifiers of file 1 are present in file 2, I should have all the values related to it in an another tab delimited file. 

 Something like this: 

 
Paul Ronny Rubby Suzie
12  11 11 12
23  12 8.9 5.1
 

 Thank you in advance. 
 Answers (Total-7): #0 NOTE 

 your example output is NOT correct, since there you have "Ruby" but in your file1 example you had "Rubby" Ruby =/= Rubby 

 kent$ awk 'NR==FNR{t[$0]++;next}
{if(FNR==1){
  for(i=1;i&lt;=NF;i++)
    if($i in t){
      v[i]++;
      printf $i"\t";
    }
  print "";
  }else{
  for(x in v)
    printf $x"\t"
  print "";
}

}' file1 file2
 

 output 

 Paul Ronny Suzie
12  11  12
23  12  5.1
 
 #1 $ awk 'FILENAME~1{a[$0];next};FNR==1{for(i=1;i&lt;=NF;i++)if($i in a)b[i]};{for(j in b)printf("%s\t",$j);print ""}' file{1,2}.txt
Paul Ronny Suzie
12  11  12
23  12  5.1
 

 break into multi lines &amp;&amp; add whitespace 

 $ awk '
&gt; FILENAME~1 { a[$0]; next }
&gt; FNR==1 { for(i=1; i&lt;=NF; i++) if($i in a) b[i] }
&gt; { for(j in b) printf("%s\t",$j); print ""}
&gt; ' file{1,2}.txt

Paul Ronny Suzie
12  11  12
23  12  5.1
 
 #2 You can use only bash to do it: 

 FIELDS=`head -1 f2.txt | tr "\t" "\n" | nl -ba | grep -f f1.txt | cut -f1 | tr -d " " | tr "\n" ","`; FIELDS=${FIELDS/%,/}
cut -f$FIELDS f2.txt 
Paul Ronny Ruby Suzie
12 11 11 12
23 12 8.9 5.1
 
 #3 An example in Python that does the work in stream (ie: don't need to load the full file before starting the output): 

 # read keys
with open('file1', 'r') as fd:
 keys = fd.read().splitlines()

# output keys
print '\t'.join(keys)

# read data file, with header line and content
with open('file2', 'r') as fd:
 headers = fd.readline().split()
 while True:
  line = fd.readline().split()
  if len(line) == 0:
   break
  print '\t'.join([line[headers.index(x)] for x in keys if x in headers])
 

 Output: 

 $ python test.py 
Ronny Ruby Suzie Paul
11  11  12  12
12  8.9  5.1  23
 
 #4 Perl solution: 

 #!/usr/bin/perl
use warnings;
use strict;

open my $KEYS, '&lt;', 'file1' or die $!;
my @keys = &lt;$KEYS&gt;;
close $KEYS;
chomp @keys;
my %is_key;
undef @is_key{@keys};

open my $TAB, '&lt;', 'file2' or die $!;
$_ = &lt;$TAB&gt;;
my ($i, @columns);
for (split) {
 push @columns, $i if exists $is_key{$_};
 $i++;
}
do {{
 my @values = split;
 print join("\t", @values[@columns]), "\n";
}} while &lt;$TAB&gt;;
 
 #5 Something like this could probably work, depending on what you want. 

 use strict;
use warnings;

my %names;
open ( my $nh, '&lt;', $name_file_path ) or die "Could not open '$name_file_path'!";
while ( &lt;$nh&gt; ) { 
 m/^\s*(.*?\S)\s*$/ and $names{ $1 } = 1; 
}
close $nh;

my $coln = -1;
open ( my $dh, '&lt;', $data_file_path ) or die "Could not open '$data_file_path'!";

my ( @name_list, @col_list )
my @names = split /\t/, &lt;$dh&gt;;
foreach my $name ( 0..$#names ) {
 next unless exists $names{ $names[ $name ] };
 push @name_list, $name;
 push @col_list, $coln;
}
local $" = "\t";
print "@name_list\n";
print "@{[ split /\t/ ]}[ @col_list ]\n" while &lt;$dh&gt;;
close $dh;
 
 #6 This might work for you: 

 sed '1{s/\t/\n/gp};d' file2 |
 nl |
 grep -f file1 |
 cut -f1 |
 paste -sd, |
 sed 's/ //g;s,.*,cut -f&amp; /tmp/b,' |
 sh
 

 Explanation: 

 
 Pivot the column names 
 Number the column names 
 Match the column names against the input file. 
 Ditch the column names retaining the column numbers. 
 Pivot the column numbers separating by , 's. 
 Build a cut command from the comma separated column number list. 
 Run the cut command against the data file.