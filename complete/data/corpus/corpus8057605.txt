Question (ID-8057605): How do numbers work in Python? So, I open terminal. 

 &gt; python
&gt; 1 / 3
0
&gt; 1.0 / 3
0.33333333333333331
 

 Could someone tell me what the rules are when it comes to decimals. Does it matter which number when being divided carries the decimal? Is there a best practice? 

 If I want more decimal points, or less for that matter, do I need to use a function? 
 Answers (Total-6): #0 The division in Python &lt; 3.0 works like in many different programming languages and the output is an integer: 

 &gt;&gt;&gt; 3 / 2
1
 

 If you use float for any of the parts, the output will be a float also: 

 &gt;&gt;&gt; 3.0 / 2
1.5
&gt;&gt;&gt; 3 / 2.0
1.5
 

 But there is a solution, if you want to do division more precisely without the need to convert some of the parts into float: 

 &gt;&gt;&gt; from __future__ import division
&gt;&gt;&gt; 3 / 2
1.5
 

 After the above you can still make "classical divisions" by using double slashes : 

 &gt;&gt;&gt; 3 // 2
1
 

 Is it clear enough? Did it help? 
 #1 By default in python2 we have following division behavior: 

 
 int / int == int 
 int / float == float 
 float / int == float 
 float / float == float 
 

 In python3 division behavior has been changed and int/int returns float. This can also be enabled in python2 by adding following import: 

 from __future__ import division 
 

 As you might have noticed float division is not precise. Small errors in the last digit can happen haphazardly. This is caused the way how float numbers are represents on the hardware level. You can read more about it on wikipedia . 

 If you want to have precise arithmetic in pythonÂ it can be done with built-in module decimal : 

 &gt;&gt;&gt; from decimal import Decimal
&gt;&gt;&gt; Decimal('1') / 3
Decimal('0.3333333333333333333333333333')
 

 It's also possible to change precision: 

 &gt;&gt;&gt; from decimal import Decimal, getcontext
&gt;&gt;&gt; getcontext().prec = 50
&gt;&gt;&gt; Decimal('1') / 3
Decimal('0.33333333333333333333333333333333333333333333333333')
 
 #2 The rules are that if both input numbers are integers (no decimal point), the output will be an integer, otherwise it will be a float. The float precision is defined by your system and if you want more precision than that, you need to use a library. Google arbitrary precision math python . 

 If you want to divide two literal whole numbers and get a float, then it doesn't matter which one you give the decimal point to and there's no convention. That's rare enough that it isn't something that too many people make rules about. 
 #3 In Python 2, dividing an int by an int always truncates the result to an int. However, if one or both operands are floats, then your answer is a float. 

 In terms of choosing how many decimal points to display, you can use the .format method of string ( http://docs.python.org/library/string.html#formatspec ). 
 #4 The standard library decimal module provides "an arithmetic that works in the same way as the arithmetic that people learn at school." See http://docs.python.org/library/decimal.html 

 Here's docs on string formatting:
 http://docs.python.org/library/stdtypes.html#string-formatting 
 #5 To control the number of digits you can use 

 &gt;&gt;&gt; print("%.10f\n" % 0.4)
0.4000000000
 

 here we tell print to display 10 digits. See format spec for more details on the available formats. 

 Division is a bit confusion topic in python. The behavior of / depends on command line options: 

 $ python -Qnew
&gt;&gt;&gt; 4 / 3
1.3333333333333333
&gt;&gt;&gt; ^D
$ python -Qold
&gt;&gt;&gt; 4 / 3
1
&gt;&gt;&gt; 
 

 In the new semantics / always produces a float. In the old it produces an int if both operands are ints and a float if at least one of them is a float. Check with your python version to determine which one is the default for you. To enable the new semantics you can also use 

 from __future__ import division
 

 Note that there is also the truncating division operator: // which divides two numbers and truncates the result irrespective of their types. It returns an int if arguments are both ints and float if at least one of them is a float. 

 &gt; 5.0 // 3
1.0
&gt; 5 // 3.0
1.0
&gt; 5 // 3
1
 

 The behavior of this operator doesn't depend on command line options.