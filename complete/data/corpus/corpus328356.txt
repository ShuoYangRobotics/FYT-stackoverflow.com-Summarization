Question (ID-328356): Extracting text from HTML file using Python I'd like to extract the text from an HTML file using Python. I want essentially the same output I would get if I copied the text from a browser and pasted it into notepad. 

 I'd like something more robust than using regular expressions that may fail on poorly formed HTML. I've seen many people recommend Beautiful Soup, but I've had a few problems using it. For one, it picked up unwanted text, such as JavaScript source. Also, it did not interpret HTML entities. For example, I would expect &amp;#39; in HTML source to be converted to an apostrophe in text, just as if I'd pasted the browser content into notepad. 

 Update html2text looks promising. It handles HTML entities correctly and ignores JavaScript. However, it does not exactly produce plain text; it produces markdown that would then have to be turned into plain text. It comes with no examples or documentation, but the code looks clean. 

 

 Related questions: 

 
 Filter out HTML tags and resolve entities in python 
 Convert XML/HTML Entities into Unicode String in Python 
 
 Answers (Total-8): #0 Found myself facing just the same problem today. I wrote a very simple HTML parser to strip incoming content of all markups, returning the remaining text with only a minimum of formatting. 

 from HTMLParser import HTMLParser
from re import sub
from sys import stderr
from traceback import print_exc

class _DeHTMLParser(HTMLParser):
 def __init__(self):
  HTMLParser.__init__(self)
  self.__text = []

 def handle_data(self, data):
  text = data.strip()
  if len(text) &gt; 0:
   text = sub('[ \t\r\n]+', ' ', text)
   self.__text.append(text + ' ')

 def handle_starttag(self, tag, attrs):
  if tag == 'p':
   self.__text.append('\n\n')
  elif tag == 'br':
   self.__text.append('\n')

 def handle_startendtag(self, tag, attrs):
  if tag == 'br':
   self.__text.append('\n\n')

 def text(self):
  return ''.join(self.__text).strip()


def dehtml(text):
 try:
  parser = _DeHTMLParser()
  parser.feed(text)
  parser.close()
  return parser.text()
 except:
  print_exc(file=stderr)
  return text


def main():
 text = r'''
  &lt;html&gt;
   &lt;body&gt;
    &lt;b&gt;Project:&lt;/b&gt; DeHTML&lt;br&gt;
    &lt;b&gt;Description&lt;/b&gt;:&lt;br&gt;
    This small script is intended to allow conversion from HTML markup to 
    plain text.
   &lt;/body&gt;
  &lt;/html&gt;
 '''
 print(dehtml(text))


if __name__ == '__main__':
 main()
 
 #1 html2text is a Python program that does a pretty good job at this. 
 #2 PyParsing does a great job. Paul McGuire has several scrips that are easy to adopt for various uses on the pyparsing wiki. ( http://pyparsing.wikispaces.com/Examples ) One reason for investing a little time with pyparsing is that he has also written a very brief very well organized O'Reilly Short Cut manual that is also inexpensive. 

 Having said that, I use BeautifulSOup a lot and it is not that hard to deal with the entitites issues, you can convert them before you run BeautifulSoup. 

 Goodluck 
 #3 Use NLTK 

 I wasted my 4-5 hours fixing the issues with html2text. Luckily i could encounter NLTK. 
It works magically.  

 import nltk 
from urllib import urlopen


url = "http://news.bbc.co.uk/2/hi/health/2284783.stm" 
html = urlopen(url).read() 
raw = nltk.clean_html(html) 
print(raw)
 
 #4 You can use html2text method in the stripogram library also. 

 from stripogram import html2text
text = html2text(your_html_string)
 

 To install stripogram run sudo easy_install stripogram 
 #5 http://pypi.python.org/pypi/webstemmer/0.5.0 

 http://atropine.sourceforge.net/documentation.html 

 

 alternatively, i think you can drive lynx from python, search on that 
 #6 @PyNEwbie
the entities should be converted after BeautifulSoup else the Document gets a different meaning. (For example when &lt;div&gt; was encoded) 
 #7 Bolierpipe: 

 Try with this. 

 http://ai-depot.com/articles/the-easy-way-to-extract-useful-text-from-arbitrary-html/ 
 http://code.google.com/p/boilerpipe/