Question (ID-4500232): Why are JITted Python implementations still slow? I understand why interpretation overhead is expensive, but why are JITted Python implementations (Psyco and PyPy) still so much slower than other JITted languages like C# and Java? 

 Edit: I also understand that everything is an object, dynamic typing is costly, etc. However, for functions where types can be inferred, I'm not sure why this matters. 
 Answers (Total-6): #0 Python is a dynamic language . 

 This means that much of the work that other static languages (like C# and Java) do at compile time, is done at runtime and this reduces performances. 

 EDIT: 
Furthermore, JIT compiler for a dynamic language like python, can perform much less optimisations on the code because it can't do many assumptions due to the dynamicity of the code. 

 e.g. 
Dynamic typing prevents assumptions about type of fields/variables/parameters... , thus any optimisation involving that is almost impossible. 

 EDIT2: 
just a clarification: 
when I say compile time, I mean also JIT compile time, because actually JIT is a compiler. 
Applying this to my first sentence, yields that Python can perform much less work at JIT time than C# or Java... 
 #1 People have already pointed out the technical details, so I'll add another factor: money. 

 In the last few years, Javascript VMs (Google's V8, Mozilla's Tracemonkey &amp; Jaegermonkey, Apple's Nitro) have delivered a huge speed increase for another dynamic language. That's been driven in large part by Google's desire to make web apps more powerful. Python just doesn't have a big company standing to gain by making it 50x faster. 

 Oh, and the integration with C extensions like numpy means that speed is rarely critical for Python code, anyway. 
 #2 The simplest possible answer is that PyPy is simply not yet as fast as hotspot and Psyco never will. 

 Writing a reasonable JIT is a long and tedious process and it took for example many years for hotspot to get where it is (with a lot of funding as well). The more complex and dynamic the language is, the longer it takes. On the bright side, we have good examples how JITs for dynamic languages can be very fast, take LuaJIT for one, which can beat C or JVM on many examples. 

 There are good news however: According to speed center PyPy got 27% faster on average in the past 100 revisions, so it'll happen eventually. 
 #3 A really good question. I can't give you a complete answer, but I think one of the reasons is the "everything is objects and an object could be anything" concept. In Java, if you try "1.getClass()", it won't work unless you box it first, either explicitly or implicitly. In Python, it works out of the box. But objects are definitely more heavyweight than primitive types, which Python just doesn't seem to have. 

 The "an object can be anything" part is even more important. If you write "someobject.somefield" in Java, it knows at compile time what exactly is "somefield" and generates code that accesses it directly. Well, there are probably some tricks to give better binary compatibility, but that's nothing like Python, where it actually performs some sort of dictionary look-up at run time to figure out what exactly is "somefield" at that particular moment, as fields can be added and deleted dynamically. 

 To put it short, Python is more powerful, but that power has its cost. 
 #4 You can't really compare dynamic languages to enterprise-level static languages. Sun spent a lot of money optimizing the language, VM and JIT. Microsoft also did a fair job with their VM. 

 It is more interesting to compare jit'ed dynamic languages. Is it something about JavaScript that let google make their V8 faster than both PyPy and ruby 1.9 or it is just amount of money one invests? 
 #5 
 I understand why interpretation
 overhead is expensive... 
 

 Compare those Python implementations to non-JIT interpreted-mode Java and think about your question again.