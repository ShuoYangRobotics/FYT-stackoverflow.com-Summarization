Question (ID-8780797): Split String In List While Preserving Original List Order I would like to do something a bit tricky and I'm not sure the best way to go about it. 

 I have a two dimensional array that is in the form a nested list. Each "Row" in the list has the following structure: 

 ['171000', 'Thing..Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', 'Cheese', '0.012174']
 

 What I would like to do is loop through the entire array, row by row, and create a new row that splits the string in the second position into three new strings in the list so the result is as follows: 

 ['171000', 'Mega~Corporate', 'Mid~Dairy', 'Micro~Cheese', 'Cheese', '0.012174']
 

 A couple things I have to mention. In the above case, I split the string into three sub strings, Mega, Mid, Micro. Not every string will have a "Mid" and a "Micro" portion of it. Some of these strings could simply be shorter versions of the same format: 

 'Thing..Mega~Corporate'
 

 For this case, I'd like to insert a placeholder to preserve the position of each element in the array (so that the numbers in the final position always have the same index). 

 The array I'm working with is rather large, upwards of 100k rows. Any help would be greatly appreciated as I'm really struggling with this one. 
 Answers (Total-6): #0 If Thing.. represents an arbitrary text (not a literal data in the string): 

 import re

def explode(s, keywords):
 for k in keywords:
  m = re.search(r'(%s~[^~]*)(?:~|$)' % (re.escape(k),), s)
  yield m and m.group(1)

for row in lst:
 row[1:2] = explode(row[1], "Mega Mid Micro".split())
 

 Example 

 import re
from pprint import pprint

def explode(s, keywords):
 for k in keywords:
  m = re.search(r'(%s~[^~]*)(?:~|$)' % (re.escape(k),), s)
  yield m and m.group(1)


lst = [
 ['171000', 'Thing..Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', 'Cheese', '0.012174'],
 ['171000', 'Thing..Mega~Corporate', 'Cheese', '0.012174'],
]

print("Before:")
pprint(lst)

for row in lst:
 row[1:2] = explode(row[1], "Mega Mid Micro".split())

print("\nAfter:")
pprint(lst)
 

 Output 

 Before:
[['171000',
 'Thing..Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese',
 'Cheese',
 '0.012174'],
 ['171000', 'Thing..Mega~Corporate', 'Cheese', '0.012174']]

After:
[['171000',
 'Mega~Corporate',
 'Mid~Dairy',
 'Micro~Cheese',
 'Cheese',
 '0.012174'],
 ['171000', 'Mega~Corporate', None, None, 'Cheese', '0.012174']]
 
 #1 If you loop through it, spliting on '..' each time; you can concat everything together in a new list. I don't think there's a much simpler solution. Speed however, isn't my specialty. 

 row = ['171000', 'Thing..Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', 'Cheese', '0.012174']
new_row = []
for i in row: 
 new_row += i.split('..')
 

 The end result is... 

 ['171000', 'Thing', 'Mega~Corporate~Thing', 'Mid~Dairy~Thing', 'Micro~Cheese', 'Cheese', '0.012174']
 

 

 If you don't want to use an extra variable, another way to do it is using reduce . 

 row = reduce(lambda x, y: x + y.split('..'), row, [])
 

 

 I'm not quite sure what the significance of 'Thing' is in your code, or why it doesn't appear in the output. If you explain the rule for it, I'll update my answer. 
 #2 I don't think I really understand the question... but hopefully this will give you a hint: 

 l = ['171000', 'Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', 'Cheese', '0.012174']

strs = l[1].split('..')
l = [l[0]] + strs + l[2:]
print l
 
 #3 FakeRainBrigand nailed it already, except if '..' appears in other elements. Regardless, I'd be curious to compare timings to see how bad this idea is, which is also technically more correct: 

 for row in myfile:
 toSplit = row.pop(1) # 1 being the position of the string to manipulate
 for fragment in toSplit.split('..'):
 row.insert(-2,fragment) 
 

 UPDATE: this is what timeit says: 

 s1 = """myfile = [ ['171000', 'Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', 'Cheese', '0.012174'] for i in xrange(1,10000) ]
for row in myfile:
 toSplit = row.pop(1)
 for fragment in toSplit.split('..'):
 row.insert(-2,fragment)
"""
s2 = """myfile = [ ['171000', 'Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', 'Cheese', '0.012174'] for i in xrange(1,10000) ]
for row in myfile:
 new_row = []
 for i in row: 
 new_row += i.split('..')
"""
&gt;&gt;&gt; t1 = timeit.Timer(stmt=s1)
&gt;&gt;&gt; t2 = timeit.Timer(stmt=s2)
&gt;&gt;&gt; print "%.2f usec/pass" % (1000000 * t1.timeit(number=1000)/100000)
166.36 usec/pass
&gt;&gt;&gt; print "%.2f usec/pass" % (1000000 * t2.timeit(number=1000)/100000)
214.22 usec/pass
 

 Both are not very fast, I'm sure we can do better. I'd expect any regex-based solution to be slower.
Note that splitting on '..' or splitting on '~Thing..' are exactly equivalent, as long as the string remains the same throughout the entire operation. 
 #4 Try running this code: 

 import re

row = ['171000', 'Thing..Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', 'Cheese', '0.012174']
 

 Now, for each row: 

 col2 = re.split(r'~?Thing\.\.', row[1])[1:]
row[1:2] = col2 + ['placeholder'] * (3 - len(col2))
 

 After the last line, row will be as you asked, even filling-in with placeholders if the second position has less than 3 elements after splitting it. 
 #5 This version does lots of checking: 

 def explode_strg(strg):
 temp = strg.split('~')
 npieces = len(temp)
 assert npieces in (6, 4, 2)
 result = ['', '', '']
 prefix = 'Thing..'
 for i in xrange(0, npieces, 2):
  k = temp[i]
  v = temp[i+1]
  assert k.startswith(prefix)
  k = k[len(prefix):]
  j = i // 2
  assert k == ('Mega', 'Mid', 'Micro')[j]
  result[j] = k + '~' + v
 return result

tests = [
 ('Thing..Mega~Corporate~Thing..Mid~Dairy~Thing..Micro~Cheese', ['Mega~Corporate', 'Mid~Dairy', 'Micro~Cheese']),
 ('Thing..Mega~Corporate~Thing..Mid~Dairy',      ['Mega~Corporate', 'Mid~Dairy', '']),
 ('Thing..Mega~Corporate',          ['Mega~Corporate', '', '']),
 ]

for s, elist in tests:
 alist = explode_strg(s)
 print alist == elist, s, alist