[{"text": ["How to deserialize 1GB of objects into Python faster than cPickle?"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["We've got a Python-based web server that unpickles a number of large data files on startup using cPickle.", "The data files (pickled using HIGHEST_PROTOCOL) are around 0.4 GB on disk and load into memory as about 1.2 GB of Python objects -- this takes about 20 seconds.", "We're using Python 2.6 on 64-bit Windows machines."], "childNum": 3, "tag": "p", "senID": 1, "childList": [{"text": "cPickle", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "HIGHEST_PROTOCOL", "childNum": 0, "tag": "code", "pos": 1, "childList": []}, {"text": "20 seconds", "childNum": 0, "tag": "strong", "pos": -1, "childList": []}]}, {"text": ["The bottleneck is certainly not disk (it takes less than 0.5s to actually read that much data), but memory allocation and object creation (there are millions of objects being created).", "We want to reduce the 20s to decrease startup time."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["Is there any way to deserialize more than 1GB of objects into Python much faster than cPickle (like 5-10x)?", "Because the execution time is bound by memory allocation and object creation, I presume using another unpickling technique such as JSON wouldn't help here."], "childNum": 1, "tag": "p", "senID": 3, "childList": [{"text": "cPickle", "childNum": 0, "tag": "code", "pos": 0, "childList": []}]}, {"text": ["I know some interpreted languages have a way to save their entire memory image as a disk file, so they can load it back into memory all in one go, without allocation/creation for each object.", "Is there a way to do this, or achieve something similar, in Python?"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}]