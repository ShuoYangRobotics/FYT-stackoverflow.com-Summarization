[{"text": ["sandbox to execute possibly unfriendly python code"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["Let's say there is a server on the internet that one can send a piece of code to for evaluation.", "At some point server takes all code that has been submitted, and starts running and evaluating it.", "However, at some point it will definitely bump into \"os.system('rm -rf *')\" sent by some evil programmer.", "Apart from \"rm -rf\" you could expect people try using the server to send spam or dos someone, or fool around with \"while True: pass\" kind of things."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Is there a way to coop with such unfriendly/untrusted code?", "In particular I'm interested in a solution for python.", "However if you have info for any other language, please share."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}]