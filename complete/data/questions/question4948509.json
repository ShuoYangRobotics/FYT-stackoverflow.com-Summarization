[{"text": ["Removing duplicated lines from a txt file"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["I am processing large text files (~20MB) containing data delimited by line.", "Most data entries are duplicated and I want to remove these duplications to only keep one copy."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["Also, to make the problem slightly more complicated, some entries are repeated with an extra bit of info appended.", "In this case I need to keep the entry containing the extra info and delete the older versions."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["e.g.", "I need to go from this:\nBOB 123 1DB\nJIM 456 3DB AX\nDAVE 789 1DB\nBOB 123 1DB\nJIM 456 3DB AX\nDAVE 789 1DB\nBOB 123 1DB EXTRA BITS\nto this:\nJIM 456 3DB AX\nDAVE 789 1DB\nBOB 123 1DB EXTRA BITS\nNB.", "the final order doesn't matter."], "childNum": 2, "tag": "p", "senID": 3, "childList": [{"text": "BOB 123 1DB\nJIM 456 3DB AX\nDAVE 789 1DB\nBOB 123 1DB\nJIM 456 3DB AX\nDAVE 789 1DB\nBOB 123 1DB EXTRA BITS", "childNum": 0, "tag": "pre", "pos": 1, "childList": []}, {"text": "JIM 456 3DB AX\nDAVE 789 1DB\nBOB 123 1DB EXTRA BITS", "childNum": 0, "tag": "pre", "pos": -1, "childList": []}]}, {"text": ["What is an efficient way to do this?"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["I can use awk, python or any standard linux command line tool."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["Thanks."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}]