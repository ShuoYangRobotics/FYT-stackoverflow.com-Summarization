[{"text": ["the fastest way to create checksum for large files in python"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["i need to transfer large files across network and need to create checksum for them on hourly basis.", "so the speed for generating checksum is critical for me."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["somehow i can't make zlib.crc32 and zlib.adler32 working with files larger than 4GB on Windows XP Pro 64bit machine.", "i suspect i've hit the 32bit limitation here?", "using hashlib.md5 i could get a result but the problem is the speed.", "it takes roughly about 5 minutes to generate an md5 for 4.8GB file.", "task manager shows that the process is using one core only."], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["my questions are:"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["many thanks guys,"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["Pietra Arumaga"], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["PS: i'm working on somethimg similar like an \"Asset Management\" system, kind of like svn but the asset consist of large compressed image files.", "the files have tiny bit incremental changes.", "the hashing/checksum is needed for detecting changes and error detection."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}]