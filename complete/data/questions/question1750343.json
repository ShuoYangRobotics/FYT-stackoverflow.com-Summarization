[{"text": ["Fastest way to search 1GB+ a string of data for the first occurence of a pattern in Python"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["There's a 1 Gigabyte string of arbitrary data which you can assume to be equivalent to something like:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n 1_gb_string=os.urandom(1*gigabyte)\n</code>\n</pre>\n", "senID": 2}, {"text": ["We will be searching this string, 1_gb_string, for an infinite number of fixed width, 1 kilobyte patterns, 1_kb_pattern.", "Every time we search the pattern will be different.", "So caching opportunities are not apparent.", "The same 1 gigabyte string will be searched over and over.", "Here is a simple generator to describe what's happening:"], "childNum": 2, "tag": "p", "senID": 3, "childList": [{"text": "1_gb_string", "childNum": 0, "tag": "code", "pos": 0, "childList": []}, {"text": "1_kb_pattern", "childNum": 0, "tag": "code", "pos": -1, "childList": []}]}, {"code": "<pre>\n<code>\n def findit(1_gb_string):\n    1_kb_pattern=get_next_pattern()\n    yield 1_gb_string.find(1_kb_pattern)\n</code>\n</pre>\n", "senID": 4}, {"text": ["Note that only the first occurrence of the pattern needs to be found.", "After that, no other major processing should be done."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["What can I use that's faster than python's bultin find for matching 1KB patterns against 1GB or greater data strings?"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["(I am already aware of how to split up the string and searching it in parallel, so you can disregard that basic optimization."], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Update: Please bound memory requirements to 16GB."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}]