[{"text": ["how to process long-running requests in python workers?"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["I have a python (well, it's php now but we're rewriting) function that takes some parameters (A and B) and compute some results (finds best path from A to B in a graph, graph is read-only), in typical scenario one call takes 0.1s to 0.9s to complete.", "This function is accessed by users as a simple REST web-service (GET bestpath.php?from=A&amp;to=B).", "Current implementation is quite stupid - it's a simple php script+apache+mod_php+APC, every requests needs to load all the data (over 12MB in php arrays), create all structures, compute a path and exit.", "I want to change it. "], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["I want a setup with N independent workers (X per server with Y servers), each worker is a python app running in a loop (getting request -> processing -> sending reply -> getting req...), each worker can process one request at a time.", "I need something that will act as a frontend: get requests from users, manage queue of requests (with configurable timeout) and feed my workers with one request at a time. "], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["how to approach this?", "can you propose some setup?", "nginx + fcgi or wsgi or something else?", "haproxy?", "as you can see i'am a newbie in python, reverse-proxy, etc.", "i just need a starting point about architecture (and data flow)"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["btw.", "workers are using read-only data so there is no need to maintain locking and communication between them"], "childNum": 0, "tag": "p", "senID": 4, "childList": []}]