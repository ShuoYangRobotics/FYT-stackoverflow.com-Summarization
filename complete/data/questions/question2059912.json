[{"text": ["Using an index to recursively get all files in a directory really fast"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["Attempt #2:"], "childNum": 1, "tag": "p", "senID": 1, "childList": [{"text": "Attempt #2:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["People don't seem to be understanding what I'm trying to do.", "Let me see if I can state it more clearly:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"text": ["1)  Reading a list of files is much faster than walking a directory."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["2)  So let's have a function that walks a directory and writes the resulting list to a file.", "Now, in the future, if we want to get all the files in that directory we can just read this file instead of walking the dir.", "I call this file the index."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["3)  Obviously, as the filesystem changes the index file gets out of sync.", "To overcome this, we have a separate program that hooks into the OS in order to monitor changes to the filesystem.", "It writes those changes to a file called the monitor log.", "Immediately after we read the index file for a particular directory, we use the monitor log to apply the various changes to the index so that it reflects the current state of the directory."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["Because reading files is so much cheaper than walking a directory, this should be much faster than walking for all calls after the first."], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["Original post:"], "childNum": 1, "tag": "p", "senID": 7, "childList": [{"text": "Original post:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["I want a function that will recursively get all the files in any given directory and filter them according to various parameters.", "And I want it to be fast -- like, an order of magnitude faster than simply walking the dir.", "And I'd prefer to do it in Python.", "Cross-platform is preferable, but Windows is most important."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["Here's my idea for how to go about this:"], "childNum": 0, "tag": "p", "senID": 9, "childList": []}, {"text": ["I have a function called all_files:"], "childNum": 0, "tag": "p", "senID": 10, "childList": []}, {"code": "<pre>\n<code>\n def all_files(dir_path, ...parms...):\n    ...\n</code>\n</pre>\n", "senID": 11}, {"text": ["The first time I call this function it will use os.walk to build a list of all the files, along with info about the files such as whether they are hidden, a symbolic link, etc.", "I'll write this data to a file called \".index\" in the directory.", "On subsequent calls to all_files, the .index file will be detected, and I will read that file rather than walking the dir."], "childNum": 0, "tag": "p", "senID": 12, "childList": []}, {"text": ["This leaves the problem of the index getting out of sync as files are added and removed.", "For that I'll have a second program that runs on startup, detects all changes to the entire filesystem, and writes them to a file called \"mod_log.txt\".", "It detects changes via Windows signals, like the method described here.", "This file will contain one event per line, with each event consisting of the path affected, the type of event (create, delete, etc.", "), and a timestamp.", "The .index file will have a timestamp as well for the time it was last updated.", "After I read the .index file in all_files I will tail mod_log.txt and find any events that happened after the timestamp in the .index file.", "It will take these recent events, find any that apply to the current directory, and update the .index accordingly."], "childNum": 1, "tag": "p", "senID": 13, "childList": [{"text": "here", "tag": "a", "pos": 2, "childList": [], "childNum": 0, "href": "http://tgolden.sc.sabren.com/python/win32_how_do_i/watch_directory_for_changes.html"}]}, {"text": ["Finally, I'll take the list of all files, filter it according to various parameters, and return the result."], "childNum": 0, "tag": "p", "senID": 14, "childList": []}, {"text": ["What do you think of my approach?", "Is there a better way to do this?"], "childNum": 0, "tag": "p", "senID": 15, "childList": []}, {"text": ["Edit:"], "childNum": 1, "tag": "p", "senID": 16, "childList": [{"text": "Edit:", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}]}, {"text": ["Check this code out.", "I'm seeing a drastic speedup from reading a cached list over a recursive walk."], "childNum": 0, "tag": "p", "senID": 17, "childList": []}, {"code": "<pre>\n<code>\n import os\nfrom os.path import join, exists\nimport cProfile, pstats\n\ndir_name = \"temp_dir\"\nindex_path = \".index\"\n\ndef create_test_files():\n    os.mkdir(dir_name)\n    index_file = open(index_path, 'w')\n    for i in range(10):\n        print \"creating dir: \", i\n        sub_dir = join(dir_name, str(i))\n        os.mkdir(sub_dir)\n        for i in range(100):\n            file_path = join(sub_dir, str(i))\n            open(file_path, 'w').close() \n            index_file.write(file_path + \"\\n\")\n    index_file.close()\n#\n\n#  0.238 seconds\ndef test_walk():            \n    for info in os.walk(\"temp_dir\"):\n        pass\n\n#  0.001 seconds\ndef test_read():\n    open(index_path).readlines()\n\nif not exists(\"temp_dir\"):\n    create_test_files()\n\ndef profile(s):\n    cProfile.run(s, 'profile_results.txt')\n    p = pstats.Stats('profile_results.txt')\n    p.strip_dirs().sort_stats('cumulative').print_stats(10)\n\nprofile(\"test_walk()\")\nprofile(\"test_read()\")\n</code>\n</pre>\n", "senID": 18}]