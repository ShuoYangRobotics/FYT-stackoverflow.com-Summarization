[{"text": ["memory use in large data-structures manipulation/processing"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["I have a number of large (~100 Mb) files which I'm regularly processing.", "While I'm trying to delete unneeded data structures during processing, memory consumption is a bit too high.", "so, I was wondering is there a way to 'efficiently' manipulate large data, e.g."], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n def read(self, filename):\n    fc = read_100_mb_file(filename)\n    self.process(fc)\ndef process(self, content):\n    # do some processing of file content\n</code>\n</pre>\n", "senID": 2}, {"text": ["is there a duplication of data structures?", "isn't it more memory efficient to use class-wide variable like self.fc?"], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["how to garbage-collect?", "I know about gc module, but do I call it after i del fc for example?", "does garbage collector called after a del statement at all?", "when should I use garbage collection?"], "childNum": 1, "tag": "p", "senID": 4, "childList": [{"text": "del fc", "childNum": 0, "tag": "code", "pos": 1, "childList": []}]}, {"text": ["update\np.s.", "100 Mb is not a problem in itself.", "but float conversion, further processing add significantly more to both working set and virtual size (i'm on windows)."], "childNum": 2, "tag": "p", "senID": 5, "childList": [{"text": "update", "childNum": 0, "tag": "strong", "pos": 0, "childList": []}, {"text": "", "childNum": 0, "tag": "br", "pos": 1, "childList": []}]}]