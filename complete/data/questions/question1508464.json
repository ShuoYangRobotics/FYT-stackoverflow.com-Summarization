[{"text": ["fast string modification in python"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["This is partially a theoretical question:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"text": ["I have a string (say UTF-8), and I need to modify it so that each character (not byte) becomes 2 characters, for instance:"], "childNum": 0, "tag": "p", "senID": 2, "childList": []}, {"code": "<pre>\n<code>\n \"Nissim\" becomes \"N-i-s-s-i-m-\"\n\n\n\"01234\" becomes \"0a1b2c3d4e\"\n</code>\n</pre>\n", "senID": 3}, {"text": ["and so on.", "I would suspect that naive concatenation in a loop would be too expensive (it IS the bottleneck, this is supposed to happen all the time)."], "childNum": 0, "tag": "p", "senID": 4, "childList": []}, {"text": ["I would either use an array (pre-allocated) or try to make my own C module to handle this."], "childNum": 0, "tag": "p", "senID": 5, "childList": []}, {"text": ["Anyone has better ideas for this kind of thing?"], "childNum": 0, "tag": "p", "senID": 6, "childList": []}, {"text": ["(Note that the problem is always about multibyte encodings, and must be solved for UTF-8 as well),"], "childNum": 0, "tag": "p", "senID": 7, "childList": []}, {"text": ["Oh and its Python 2.5, so no shiny Python 3 thingies are available here."], "childNum": 0, "tag": "p", "senID": 8, "childList": []}, {"text": ["Thanks"], "childNum": 0, "tag": "p", "senID": 9, "childList": []}]