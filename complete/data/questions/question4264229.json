[{"text": ["No speed gains from Cython"], "childNum": 0, "tag": "h2", "senID": 0, "childList": []}, {"text": ["I am trying to define a function that contains an inner loop for simulating an integral.", "The problem is speed.", "Evaluating the function once can take up to 30 seconds on my machine.", "Since my ultimate goal is to minimize this function, some extra speed would be nice.", "As such, I have tried to get Cython to work for me, but I must be making a severe mistake (likely many of them!).", "Following the Cython documentation, I have tried to type my variables.", "After doing so, the code is just as slow as pure Python.", "This seems strange.", "Here is my code:"], "childNum": 0, "tag": "p", "senID": 1, "childList": []}, {"code": "<pre>\n<code>\n import numpy as np \ncimport cython\ncimport numpy as np\nimport minuit\n\ndata = np.genfromtxt('q6data.csv', usecols = np.arange(1, 24, 1), delimiter = ',')  \n\ncdef int ns    = 1000                 # Number of simulation draws\ncdef int K     = 5                    # Number of observed characteristics, including            constant\ncdef int J     = len(data[:,1])       # Number of products, including outside\ncdef double tol   = 0.0001            # Inner GMM loop tolerance\nnu = np.random.normal(0, 1, (6, ns))  # ns random deviates\n\n@cython.boundscheck(False)\n@cython.wraparound(False)\n\n\ndef S(np.ndarray[double, ndim=1] delta, double s1, double s2, double s3, double s4,  double s5, double a):\n    \"\"\"Computes the simulated integrals, one for each good.\n    Parameters: delta is an array of length J containing mean product specific utility levels\n    Returns: Numpy array with length J.\"\"\"\n    cdef np.ndarray[double, ndim=2] mu_ij = np.dot((data[:,2:7]*np.array([s1, s2, s3, s4, s5])), nu[1:K+1,:])\n    cdef np.ndarray[double, ndim=2] mu_y  = a * np.log(np.exp(data[:,21].reshape(J,1) +  data[:,22].reshape(J,1)*nu[0,:].reshape(1, ns)) - data[:,7].reshape(J,1))\n    cdef np.ndarray[double, ndim=2] V = delta.reshape(J,1) + mu_ij + mu_y\n    cdef np.ndarray[double, ndim=2] exp_vi = np.exp(V)\n    cdef np.ndarray[double, ndim=2] P_i = (1.0 / np.sum(exp_vi[np.where(data[:,1] == 71)], 0)) * exp_vi[np.where(data[:,1] == 71)] \n    cdef int yrs = 19\n    cdef int yr\n    for yr in xrange(yrs):\n        P_yr = (1.0 / np.sum(exp_vi[np.where(data[:,1]== (yr + 72))], 0)) *   exp_vi[np.where(data[:,1] == (yr + 72))]\n        P_i  = np.concatenate((P_i, P_yr)) \n    cdef np.ndarray[double, ndim=1] S = np.zeros(dtype = \"d\", shape = J)\n    cdef int j\n    for j in xrange(ns):\n        S += P_i[:,j]\n    return (1.0 / ns) * S\n\ndef d_infty(np.ndarray[double, ndim=1] x, np.ndarray[double, ndim=1] y):\n    \"\"\"Sup norm.\"\"\"\n    return np.max(np.abs(x - y)) \n\ndef T(np.ndarray[double, ndim=1] delta_exp, double s1, double s2, double s3, double s4,  double s5, double a):\n    \"\"\"The contraction operator.  This function takes the parameters and the exponential\n    of the starting value of delta and returns the fixed point.\"\"\" \n    cdef int iter = 0\n    cdef int maxiter = 200\n    cdef int i\n    for i in xrange(maxiter): \n        delta1_exp = delta_exp * (data[:, 8] / S(np.log(delta_exp), s1, s2, s3, s4, s5, a))                    \n        print i\n        if d_infty(delta_exp, delta1_exp) &lt; tol:                                       \n            break\n        delta_exp = delta1_exp\n    return np.log(delta1_exp)\n\n\ndef Q(double s1, double s2, double s3, double s4, double s5, double a):\n    \"\"\"GMM objective function.\"\"\"  \n    cdef np.ndarray[double, ndim=1] delta0_exp = np.exp(data[:,10])                                                     \n    cdef np.ndarray[double, ndim=1] delta1 = T(delta0_exp, s1, s2, s3, s4, s5, a)\n    delta1[np.where(data[:,10]==0)] = np.zeros(len(np.where(data[:,10]==0)))            \n    cdef np.ndarray[double, ndim=1] xi =  delta1 - (np.dot(data[:,2:7],   np.linalg.lstsq(data[:,2:7], delta1)[0]))   \n    cdef np.ndarray[double, ndim=2] g_J = xi.reshape(J,1) * data[:,11:21]\n    cdef np.ndarray[double, ndim=1] G_J = (1.0 / J) * np.sum(g_J, 0) \n    return np.sqrt(np.dot(G_J, G_J))\n</code>\n</pre>\n", "senID": 2}, {"text": ["I have profiled the code, and it seems to be the function S, the integral simulator, that is killing performance.", "Anyways, I would have expected at least some speed gains from typing my variables.", "Since it produced no gains, I am led to believe that I am making some fundamental mistakes.", "Does anybody see a glaring error in the Cython code that could lead to this result?", "Any tips would be great... this has kept me up late for too many nights."], "childNum": 0, "tag": "p", "senID": 3, "childList": []}, {"text": ["Oh, and since I am very new to programming there is surely a lot of bad style and a lot of things slowing the code down.", "If you have the time, feel free to set me straight on these points as well.  "], "childNum": 0, "tag": "p", "senID": 4, "childList": []}]